{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69d1a5f",
   "metadata": {},
   "source": [
    "# Connect 4\n",
    "\n",
    "---\n",
    "\n",
    "Author: S. Menary [sbmenary@gmail.com]\n",
    "\n",
    "Date  : 2023-01-03, last edit 2023-01-15\n",
    "\n",
    "Brief : Develop a simple Connect 4 game environment and implement a bot using Monte Carlo Tree Search (MCTS)\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "- Connect 4 is a two-player, fully-observable, zero-sum game. \n",
    "- The game states may be represented as a tree sturcture, We can therefore implement a bot using tree-search algorithms. We choose Connect 4 because it is simple, and therefore provides a launch-pad for more complex games such as checkers or chess.\n",
    "- Initially we implement vanilla MCTS with no machine learning. We expect this to be limited by (i) the stochastic rollout of the tree and (ii) the simplicity of the simulation policy.\n",
    "- To introduce ML, we would perform alternate steps of MCTS evaluation and simulation policy improvement. In this way, the simulated games will _hopefully_ begin to approach \"good play\", and the final MCTS values will reflect the behaviour of good players.\n",
    "- MCTS configuration:\n",
    "    + Tree-traversal policy is:\n",
    "        1. From the current node, uniformly-randomly select a non-expanded child if one is available\n",
    "        2. Otherwise select child with highest UCB-1 score, traverse to this node and repeat\n",
    "    + Resulting node is expanded by adding all possible children and selecting one by performing a uniformly-random action\n",
    "    + Simulation policy is to select a uniformly-random action\n",
    "- The UCB-1 score is designed to optimally balance exploration/exploitation for static multi-arm bandits. Strictly speaking, we are applying this in a non-stationary environment because the reward-distribution for each action changes according to the evolution of the down-stream tree. This makes UCB-1 theoretically sub-optimal. However, it is often used nonetheless.\n",
    "- When playing an actual move (i.e. inference time), greedily select the action with the max average score from its MCTS visits (do not use UCB-1 since we are no longer exploring).\n",
    "\n",
    "Observations:\n",
    "- Strength of decision-making depends on how many iterations of MCTS we perform:\n",
    "    1. When tree is shallow, we effectively assume that future play is random, which means we will choose options with the greatest number of permutations of winning. We therefore may neglect to defend against an imminent loss, favouring a different move with many win permutations (bad behaviour).\n",
    "    2. When tree is deep and UCB1 score converges towards true means, at least for the best moves, then we effectively assume that future play is optimal. As play-count goes to infinity, our scores become unbiased.\n",
    "    3. For finite but sufficient run-time, we assume optimal play, but using mean scores that are biased by the fact that our early simulations used random play instead of optimal play.\n",
    "- This explains why even random simulation MCTS is pretty good - we end up doing most of our simulations with pretty effective play, at least for the next few moves where our tree is sufficiently grown.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef54ef68",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff93cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Required imports\n",
    "###  - all imports should be placed here\n",
    "###\n",
    "\n",
    "\n",
    "##  Python core libs\n",
    "import sys, time\n",
    "from enum import IntEnum\n",
    "from abc  import ABC, abstractmethod, abstractstaticmethod\n",
    "from __future__ import annotations\n",
    "\n",
    "##  PyPI libs\n",
    "import numpy as np\n",
    "\n",
    "##  Local packages\n",
    "from connect4.utils import DebugLevel\n",
    "from connect4.game  import GameBoard\n",
    "from connect4.MCTS  import Node_VanillaMCTS\n",
    "from connect4.bot   import Bot_VanillaMCTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e7c892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version is 3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]\n",
      "Numpy  version is 1.23.2\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "###  Print version for reproducibility\n",
    "###\n",
    "\n",
    "print(f\"Python version is {sys.version}\")\n",
    "print(f\"Numpy  version is {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df8c24e",
   "metadata": {},
   "source": [
    "##  GameBoard\n",
    "\n",
    "The `GameBoard` object is used to interact with a game of Connect 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d455c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial game board:\n",
      "+---+---+---+---+\n",
      "| . | . | . | . |\n",
      "| . | . | . | . |\n",
      "| . | . | . | . |\n",
      "| . | . | . | . |\n",
      "+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 |\n",
      "+---+---+---+---+\n",
      "Game result is: NONE\n",
      "\n",
      "After a few moves:\n",
      "+---+---+---+---+\n",
      "| . | . | . | . |\n",
      "| . | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . |\n",
      "+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 |\n",
      "+---+---+---+---+\n",
      "Game result is: NONE\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "###  Setup a small game\n",
    "###  - 4x4 grid\n",
    "###  - line of 3 needed to win\n",
    "###\n",
    "\n",
    "##  Create game board\n",
    "game_board = GameBoard(4, 4, 3)\n",
    "\n",
    "##  Show initial game board\n",
    "print(f\"Initial game board:\\n{game_board}\")\n",
    "\n",
    "##  Play a few moves\n",
    "game_board.apply_action(1)\n",
    "game_board.apply_action(2)\n",
    "game_board.apply_action(1)\n",
    "\n",
    "##  Show updated game state\n",
    "print(f\"\\nAfter a few moves:\\n{game_board}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e64267f",
   "metadata": {},
   "source": [
    "##  MCTS\n",
    "\n",
    "The `Node_VanillaMCTS` object is used to perform vanilla MCTS searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d80faa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial tree:\n",
      "> [0: ROOT] N=0, T=0.000, E=inf, Q=-inf\n",
      "     > None\n",
      "     > None\n",
      "     > None\n",
      "     > None\n",
      "\n",
      "Running MCTS step 0\n",
      "Select unvisited action O:2\n",
      "Simulation ended with result DRAW with compound_discount=1.000\n",
      "Simulated trajectory was: X:2 O:0 X:3 O:3 X:3 O:1 X:0 O:3 X:1 O:0 X:0 O:2\n",
      "Node O:2 with parent=O, N=0, T=0.00 receiving score -0.00\n",
      "Node ROOT with parent=NONE, N=0, T=0.00 receiving score 0.00\n",
      "\n",
      "Running MCTS step 1\n",
      "Select unvisited action O:1\n",
      "Simulation ended with result X with compound_discount=1.000\n",
      "Simulated trajectory was: X:3 O:3 X:1 O:0 X:3 O:2 X:3 O:0 X:2\n",
      "Node O:1 with parent=O, N=0, T=0.00 receiving score -1.00\n",
      "Node ROOT with parent=NONE, N=1, T=0.00 receiving score 0.00\n",
      "\n",
      "Running MCTS step 2\n",
      "Select unvisited action O:3\n",
      "Simulation ended with result O with compound_discount=1.000\n",
      "Simulated trajectory was: X:0 O:1 X:0 O:3 X:1 O:3\n",
      "Node O:3 with parent=O, N=0, T=0.00 receiving score 1.00\n",
      "Node ROOT with parent=NONE, N=2, T=0.00 receiving score 0.00\n",
      "\n",
      "Running MCTS step 3\n",
      "Select unvisited action O:0\n",
      "Simulation ended with result X with compound_discount=1.000\n",
      "Simulated trajectory was: X:2 O:2 X:0\n",
      "Node O:0 with parent=O, N=0, T=0.00 receiving score -1.00\n",
      "Node ROOT with parent=NONE, N=3, T=0.00 receiving score 0.00\n",
      "\n",
      "Running MCTS step 4\n",
      "Select known action O:3\n",
      "... iterating to next level ...\n",
      "Select unvisited action X:3\n",
      "Simulation ended with result O with compound_discount=1.000\n",
      "Simulated trajectory was: O:0 X:0 O:0 X:0 O:2 X:2 O:3 X:2 O:1\n",
      "Node X:3 with parent=X, N=0, T=0.00 receiving score -1.00\n",
      "Node O:3 with parent=O, N=1, T=1.00 receiving score 1.00\n",
      "Node ROOT with parent=NONE, N=4, T=0.00 receiving score 0.00\n",
      "\n",
      "Running MCTS step 5\n",
      "Select known action O:3\n",
      "... iterating to next level ...\n",
      "Select unvisited action X:0\n",
      "Simulation ended with result X with compound_discount=1.000\n",
      "Simulated trajectory was: O:3 X:3 O:1 X:2\n",
      "Node X:0 with parent=X, N=0, T=0.00 receiving score 1.00\n",
      "Node O:3 with parent=O, N=2, T=2.00 receiving score -1.00\n",
      "Node ROOT with parent=NONE, N=5, T=0.00 receiving score 0.00\n",
      "\n",
      "Running MCTS step 6\n",
      "Select known action O:2\n",
      "... iterating to next level ...\n",
      "Select unvisited action X:2\n",
      "Simulation ended with result X with compound_discount=1.000\n",
      "Simulated trajectory was: O:2 X:0\n",
      "Node X:2 with parent=X, N=0, T=0.00 receiving score 1.00\n",
      "Node O:2 with parent=O, N=1, T=0.00 receiving score -1.00\n",
      "Node ROOT with parent=NONE, N=6, T=0.00 receiving score 0.00\n",
      "\n",
      "Running MCTS step 7\n",
      "Select known action O:3\n",
      "... iterating to next level ...\n",
      "Select unvisited action X:1\n",
      "Leaf node found with result X\n",
      "Node X:1 with parent=X, N=0, T=0.00 receiving score 1.00\n",
      "Node O:3 with parent=O, N=3, T=1.00 receiving score -1.00\n",
      "Node ROOT with parent=NONE, N=7, T=0.00 receiving score 0.00\n",
      "\n",
      "Running MCTS step 8\n",
      "Select known action O:0\n",
      "... iterating to next level ...\n",
      "Select unvisited action X:1\n",
      "Leaf node found with result X\n",
      "Node X:1 with parent=X, N=0, T=0.00 receiving score 1.00\n",
      "Node O:0 with parent=O, N=1, T=-1.00 receiving score -1.00\n",
      "Node ROOT with parent=NONE, N=8, T=0.00 receiving score 0.00\n",
      "\n",
      "Running MCTS step 9\n",
      "Select known action O:1\n",
      "... iterating to next level ...\n",
      "Select unvisited action X:2\n",
      "Simulation ended with result X with compound_discount=1.000\n",
      "Simulated trajectory was: O:3 X:1 O:3 X:0 O:2 X:0\n",
      "Node X:2 with parent=X, N=0, T=0.00 receiving score 1.00\n",
      "Node O:1 with parent=O, N=1, T=-1.00 receiving score -1.00\n",
      "Node ROOT with parent=NONE, N=9, T=0.00 receiving score 0.00\n",
      "\n",
      "Updated tree:\n",
      "> [0: ROOT] N=10, T=0.000, E=nan, Q=0.000\n",
      "     > [1: O:0] N=2, T=-2.000, E=1.146, Q=-1.000\n",
      "          > None\n",
      "          > [2: X:1] N=1, T=1.000, E=2.665, Q=1.000\n",
      "          > None\n",
      "          > None\n",
      "     > [1: O:1] N=2, T=-2.000, E=1.146, Q=-1.000\n",
      "          > None\n",
      "          > None\n",
      "          > [2: X:2] N=1, T=1.000, E=2.665, Q=1.000\n",
      "               > None\n",
      "               > None\n",
      "               > None\n",
      "               > None\n",
      "          > None\n",
      "     > [1: O:2] N=2, T=-1.000, E=1.646, Q=-0.500\n",
      "          > None\n",
      "          > None\n",
      "          > [2: X:2] N=1, T=1.000, E=2.665, Q=1.000\n",
      "               > None\n",
      "               > None\n",
      "               > None\n",
      "               > None\n",
      "          > None\n",
      "     > [1: O:3] N=4, T=0.000, E=1.517, Q=0.000\n",
      "          > [2: X:0] N=1, T=1.000, E=3.355, Q=1.000\n",
      "               > None\n",
      "               > None\n",
      "               > None\n",
      "               > None\n",
      "          > [2: X:1] N=1, T=1.000, E=3.355, Q=1.000\n",
      "          > None\n",
      "          > [2: X:3] N=1, T=-1.000, E=1.355, Q=-1.000\n",
      "               > None\n",
      "               > None\n",
      "               > None\n",
      "               > None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "###  Perform a few MCTS steps\n",
    "###  - transitions into a ciritical state where O player needs to be careful not to \n",
    "###    blunder a win for X\n",
    "###\n",
    "\n",
    "##  Create a root node at the current game state\n",
    "root_node = Node_VanillaMCTS(game_board, label=\"ROOT\")\n",
    "\n",
    "##  Print the initial value tree (should be a ROOT node with no children)\n",
    "print(\"Initial tree:\")\n",
    "print(root_node.tree_summary())\n",
    "print()\n",
    "\n",
    "##  Perform several MCTS steps with a HIGH debug level\n",
    "root_node.multi_step_MCTS(num_steps=10, max_sim_steps=-1, debug_lvl=DebugLevel.MEDIUM)\n",
    "\n",
    "##  Print the updated value tree \n",
    "print(\"Updated tree:\")\n",
    "print(root_node.tree_summary())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752564a9",
   "metadata": {},
   "source": [
    "##  MCTS\n",
    "\n",
    "The `Bot_VanillaMCTS` object is used to apply bot actions using vanilla MCTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016132ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling action from posterior policy 0.12 0.60 0.15 0.12\n",
      "Action values are:  -0.810  -0.504  -0.762  -0.810\n",
      "Visit counts are:   84      409     101     84    \n",
      "Selecting action 1\n",
      "+---+---+---+---+\n",
      "| . | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . |\n",
      "+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 |\n",
      "+---+---+---+---+\n",
      "Game result is: NONE\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "###  Use MCTS to play a move\n",
    "###\n",
    "\n",
    "##  Use MCTS to search for an optimal action\n",
    "bot    = Bot_VanillaMCTS()\n",
    "action = bot.choose_action(game_board, duration=1, debug_lvl=DebugLevel.LOW)\n",
    "\n",
    "##  Play bot move\n",
    "game_board.apply_action(action)\n",
    "\n",
    "##  Show updated game state\n",
    "print(game_board)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27992527",
   "metadata": {},
   "source": [
    "## Play a game\n",
    "\n",
    "Play a game of connect 4 against our bot!\n",
    "\n",
    "Just add new calls to `game_board.apply_action(column_index)` to play a move in column `column_index`, and `bot.take_move(game_board, duration)` to play a bot move in response. Turning up the `duration` parameter will improve the bot by allowing it to search for longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4802ca4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n"
     ]
    }
   ],
   "source": [
    "##  Create a new game\n",
    "\n",
    "game_board = GameBoard()\n",
    "bot        = Bot_VanillaMCTS(greedy=True)\n",
    "print(game_board)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a0f122",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | \u001b[31mX\u001b[0m | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action\n",
      "Action values are:  -0.365  -0.392  -0.279  -0.344  -0.252  -0.302  -0.382\n",
      "Visit counts are:   167     148     269     186     294     232     157   \n",
      "Selecting action 4\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n"
     ]
    }
   ],
   "source": [
    "##  Play a move in column index 3\n",
    "\n",
    "game_board.apply_action(3)\n",
    "print(game_board)\n",
    "\n",
    "if not game_board.get_result() :\n",
    "    bot.take_move(game_board, duration=10, debug_lvl=DebugLevel.LOW)\n",
    "    print(game_board)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f7a7a7",
   "metadata": {},
   "source": [
    "\n",
    "... and so on until the game is complete!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1385f901",
   "metadata": {},
   "source": [
    "## Bot-only game\n",
    "\n",
    "Let's watch the bot play itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1109740",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.11 0.08 0.16 0.33 0.22 0.07 0.04\n",
      "Action values are:  0.072   0.015   0.148   0.256   0.204   -0.018  -0.236\n",
      "Visit counts are:   166     130     244     508     348     112     55    \n",
      "Selecting action 0\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | . | . | . | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.08 0.09 0.13 0.30 0.19 0.08 0.14\n",
      "Action values are:  -0.200  -0.185  -0.092  0.038   -0.024  -0.217  -0.083\n",
      "Visit counts are:   120     130     195     449     286     115     206   \n",
      "Selecting action 1\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.07 0.08 0.18 0.23 0.20 0.11 0.13\n",
      "Action values are:  -0.129  -0.073  0.100   0.124   0.105   -0.006  0.030 \n",
      "Visit counts are:   101     123     280     346     305     168     202   \n",
      "Selecting action 2\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.09 0.11 0.33 0.11 0.15 0.15 0.05\n",
      "Action values are:  -0.110  -0.083  0.103   -0.074  -0.005  -0.014  -0.269\n",
      "Visit counts are:   136     157     468     162     218     217     78    \n",
      "Selecting action 2\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.22 0.16 0.12 0.17 0.09 0.17 0.06\n",
      "Action values are:  -0.026  -0.089  -0.143  -0.075  -0.192  -0.074  -0.302\n",
      "Visit counts are:   350     248     189     268     146     270     96    \n",
      "Selecting action 2\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.04 0.28 0.17 0.15 0.13 0.22 0.03\n",
      "Action values are:  -0.323  0.111   0.037   0.013   -0.015  0.080   -0.435\n",
      "Visit counts are:   62      450     272     240     206     352     46    \n",
      "Selecting action 5\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | \u001b[34mO\u001b[0m | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.15 0.23 0.23 0.09 0.14 0.03 0.14\n",
      "Action values are:  -0.034  0.036   0.038   -0.147  -0.031  -0.550  -0.040\n",
      "Visit counts are:   238     360     370     136     223     40      224   \n",
      "Selecting action 0\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | \u001b[34mO\u001b[0m | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.17 0.09 0.11 0.24 0.09 0.17 0.13\n",
      "Action values are:  0.123   0.000   0.023   0.162   0.000   0.115   0.065 \n",
      "Visit counts are:   285     154     175     394     154     287     216   \n",
      "Selecting action 1\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | \u001b[34mO\u001b[0m | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.27 0.18 0.18 0.11 0.13 0.06 0.07\n",
      "Action values are:  0.058   0.000   -0.003  -0.084  -0.047  -0.218  -0.204\n",
      "Visit counts are:   465     310     305     191     233     110     113   \n",
      "Selecting action 6\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.19 0.38 0.14 0.08 0.07 0.12 0.03\n",
      "Action values are:  0.097   0.190   0.037   -0.061  -0.111  0.011   -0.429\n",
      "Visit counts are:   299     599     215     132     108     184     42    \n",
      "Selecting action 1\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.03 0.81 0.03 0.03 0.03 0.03 0.03\n",
      "Action values are:  -0.509  0.075   -0.574  -0.587  -0.600  -0.509  -0.509\n",
      "Visit counts are:   57      1335    47      46      45      57      57    \n",
      "Selecting action 1\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | . | . | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.24 0.15 0.14 0.12 0.14 0.14 0.06\n",
      "Action values are:  -0.033  -0.092  -0.112  -0.144  -0.119  -0.119  -0.290\n",
      "Visit counts are:   367     239     224     188     218     218     100   \n",
      "Selecting action 0\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | . | . | . | . | . |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.60 0.04 0.08 0.10 0.06 0.05 0.07\n",
      "Action values are:  0.233   -0.254  -0.105  -0.041  -0.165  -0.224  -0.110\n",
      "Visit counts are:   911     67      114     147     91      76      109   \n",
      "Selecting action 3\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | . | . | . | . | . |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling action from posterior policy 0.05 0.04 0.01 0.77 0.05 0.05 0.03\n",
      "Action values are:  -0.210  -0.277  -0.739  0.247   -0.250  -0.257  -0.422\n",
      "Visit counts are:   81      65      23      1188    72      70      45    \n",
      "Selecting action 3\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | . | . | . | . | . |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.15 0.06 0.31 0.20 0.04 0.11 0.14\n",
      "Action values are:  -0.252  -0.477  -0.134  -0.204  -0.569  -0.306  -0.259\n",
      "Visit counts are:   226     86      486     304     65      173     216   \n",
      "Selecting action 2\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.12 0.14 0.31 0.11 0.15 0.06 0.10\n",
      "Action values are:  0.020   0.046   0.160   -0.005  0.053   -0.135  -0.018\n",
      "Visit counts are:   204     239     505     183     246     104     169   \n",
      "Selecting action 2\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.35 0.18 0.05 0.30 0.03 0.04 0.05\n",
      "Action values are:  -0.034  -0.122  -0.436  -0.051  -0.592  -0.452  -0.405\n",
      "Visit counts are:   587     303     78      505     49      73      84    \n",
      "Selecting action 0\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.10 0.24 0.09 0.03 0.18 0.22 0.13\n",
      "Action values are:  -0.028  0.124   -0.058  -0.345  0.073   0.105   0.018 \n",
      "Visit counts are:   177     428     155     58      315     391     224   \n",
      "Selecting action 6\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.10 0.12 0.05 0.52 0.03 0.07 0.11\n",
      "Action values are:  0.006   0.053   -0.156  0.279   -0.375  -0.083  0.034 \n",
      "Visit counts are:   178     225     90      950     48      121     205   \n",
      "Selecting action 0\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.17 0.23 0.09 0.03 0.18 0.14 0.15\n",
      "Action values are:  0.114   0.160   0.006   -0.309  0.128   0.089   0.094 \n",
      "Visit counts are:   298     413     162     55      329     257     267   \n",
      "Selecting action 0\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | . | . | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.41 0.13 0.12 0.02 0.17 0.15\n",
      "Action values are:  0.086   -0.076  -0.082  -0.688  -0.012  -0.046\n",
      "Visit counts are:   783     238     232     32      322     282   \n",
      "Selecting action 1\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | . | . | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.13 0.35 0.03 0.10 0.20 0.19\n",
      "Action values are:  -0.109  0.027   -0.475  -0.161  -0.047  -0.057\n",
      "Visit counts are:   265     700     61      199     403     371   \n",
      "Selecting action 2\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.29 0.00 0.16 0.02 0.39 0.14\n",
      "Action values are:  0.063   -0.031  -0.532  0.083   -0.053\n",
      "Visit counts are:   599     320     47      808     284   \n",
      "Selecting action 6\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | . |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.18 0.00 0.03 0.06 0.13 0.60\n",
      "Action values are:  -0.117  -0.559  -0.331  -0.172  0.027 \n",
      "Visit counts are:   393     59      127     273     1273  \n",
      "Selecting action 6\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.42 0.00 0.17 0.02 0.22 0.17\n",
      "Action values are:  0.118   0.006   -0.510  0.044   0.006 \n",
      "Visit counts are:   920     360     49      476     362   \n",
      "Selecting action 3\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling action from posterior policy 0.00 0.02 0.00 0.94 0.01 0.01 0.01\n",
      "Action values are:  -0.512  0.253   -0.704  -0.625  -0.704\n",
      "Visit counts are:   41      2115    27      32      27    \n",
      "Selecting action 3\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.37 0.00 0.21 0.04 0.20 0.18\n",
      "Action values are:  -0.192  -0.268  -0.619  -0.273  -0.283\n",
      "Visit counts are:   832     456     84      440     407   \n",
      "Selecting action 5\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.86 0.00 0.06 0.01 0.03 0.05\n",
      "Action values are:  0.666   0.255   -0.385  0.077   0.218 \n",
      "Visit counts are:   2369    153     26      78      133   \n",
      "Selecting action 1\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.00 0.00 0.11 0.10 0.50 0.29\n",
      "Action values are:  -0.873  -0.882  -0.717  -0.760\n",
      "Visit counts are:   394     372     1859    1066  \n",
      "Selecting action 5\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.00 0.00 0.02 0.00 0.93 0.04\n",
      "Action values are:  0.214   -0.529  0.841   0.403 \n",
      "Visit counts are:   84      17      3787    181   \n",
      "Selecting action 6\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.00 0.00 0.21 0.15 0.36 0.28\n",
      "Action values are:  -0.932  -0.957  -0.894  -0.910\n",
      "Visit counts are:   1530    1125    2703    2102  \n",
      "Selecting action 5\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.00 0.00 0.00 0.00 1.00 0.00\n",
      "Action values are:  -0.400  -0.714  0.978   -0.444\n",
      "Visit counts are:   20      14      15624   18    \n",
      "Selecting action 5\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.00 0.00 0.26 0.23 0.26 0.26\n",
      "Action values are:  -0.979  -0.984  -0.979  -0.979\n",
      "Visit counts are:   4697    4239    4697    4667  \n",
      "Selecting action 6\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.00 0.00 0.49 0.00 0.51 0.00\n",
      "Action values are:  0.997   -0.556  0.998 \n",
      "Visit counts are:   25233   18      25996 \n",
      "Selecting action 5\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.00 0.00 0.50 0.50 0.00 0.00\n",
      "Action values are:  -0.999  -0.999\n",
      "Visit counts are:   51025   51025 \n",
      "Selecting action 4\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Sampling action from posterior policy 0.00 0.00 0.00 0.00 1.00 0.00 0.00\n",
      "Action values are:  -0.667  1.000 \n",
      "Visit counts are:   18      176666\n",
      "Selecting action 4\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: O\n"
     ]
    }
   ],
   "source": [
    "#  Play a bot game!\n",
    "\n",
    "game_board = GameBoard()\n",
    "bot        = Bot_VanillaMCTS()\n",
    "print(game_board)\n",
    "\n",
    "result = game_board.get_result()\n",
    "while not result :\n",
    "    bot.take_move(game_board, duration=10, debug_lvl=DebugLevel.LOW)\n",
    "    result = game_board.get_result()\n",
    "    print(game_board)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19438a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
