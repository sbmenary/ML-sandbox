{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69d1a5f",
   "metadata": {},
   "source": [
    "# Connect 4\n",
    "\n",
    "---\n",
    "\n",
    "Author: S. Menary [sbmenary@gmail.com]\n",
    "\n",
    "Date  : 2023-01-15, last edit 2023-01-18\n",
    "\n",
    "Brief : Develop a bot using a neural network bot with Monte Carlo Tree Search (MCTS)\n",
    "\n",
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "- apply random reflections to exploit parity symmetry\n",
    "- represent all inputs from perspective of current player, so +1 for self and -1 for other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef54ef68",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff93cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Required imports\n",
    "###  - all imports should be placed here\n",
    "###\n",
    "\n",
    "\n",
    "##  Python core libs\n",
    "import pickle, sys, time\n",
    "\n",
    "##  PyPI libs\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "##  Local packages\n",
    "from connect4.utils    import DebugLevel\n",
    "from connect4.game     import BinaryPlayer, GameBoard, GameResult\n",
    "from connect4.MCTS     import Node_NeuralMCTS\n",
    "from connect4.bot      import Bot_NeuralMCTS, Bot_VanillaMCTS\n",
    "from connect4.parallel import MonitorThread, WorkerThread, kill_threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e7c892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Python version is 3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]\n",
      "       Numpy version is 1.23.2\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "###  Print version for reproducibility\n",
    "###\n",
    "\n",
    "print(f\"{'Python'    .rjust(12)} version is {sys.version}\")\n",
    "print(f\"{'Numpy'     .rjust(12)} version is {np.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a136cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using old model: ../models/.neural_model_v3.h5\n",
      "Using new model: ../models/.neural_model_v4.h5\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "###  Global config\n",
    "###\n",
    "\n",
    "model_idx = 4\n",
    "old_model_name = f\"../models/.neural_model_v{model_idx-1}.h5\"\n",
    "new_model_name = f\"../models/.neural_model_v{model_idx}.h5\"\n",
    "\n",
    "print(f\"Using old model: {old_model_name}\")\n",
    "print(f\"Using new model: {new_model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a900a46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_training_data_from_bot_game(model, duration:int=1, discount=1., debug_lvl:DebugLevel=DebugLevel.MUTE) :\n",
    "    ##  Create game and bot\n",
    "    game_board = GameBoard()\n",
    "    bot        = Bot_NeuralMCTS(model) if model else Bot_VanillaMCTS()\n",
    "    debug_lvl.message(DebugLevel.LOW, f\"Using bot {bot}\")\n",
    "    debug_lvl.message(DebugLevel.LOW, game_board)\n",
    "\n",
    "    ##  Create containers for model input and output\n",
    "    model_inputs, posteriors, values = [], [], []\n",
    "\n",
    "    ##  Take moves until end of game, storing model in and target out at each turn\n",
    "    ##  - values currently equal to +1 if the move is player X and -1 for player O\n",
    "    ##  -  N.B. we do not invert sign of model_input because this already done by root_node\n",
    "    result = game_board.get_result()\n",
    "    while not result :\n",
    "        bot.take_move(game_board, duration=duration, discount=discount, debug_lvl=debug_lvl)\n",
    "        debug_lvl.message(DebugLevel.LOW, game_board)\n",
    "        if model : \n",
    "            model_input = bot.root_node.model_input\n",
    "        else : \n",
    "            model_input = bot.root_node.game_board.board.reshape((game_board.horizontal_size, game_board.vertical_size, 1))\n",
    "            if bot.root_node.player == BinaryPlayer.O : model_input = -model_input\n",
    "        model_inputs.append(model_input)\n",
    "        posteriors  .append(bot.root_node.get_posterior_policy())\n",
    "        values      .append(bot.root_node.player.value)\n",
    "        result = game_board.get_result()\n",
    "        \n",
    "    ##  Resolve values\n",
    "    backprop_value = result.get_game_score_for_player(BinaryPlayer.X)\n",
    "    for idx in range(len(values)) :\n",
    "        values[-1-idx] *= backprop_value\n",
    "        backprop_value *= discount\n",
    "\n",
    "    ##  Return containers as np arrays\n",
    "    return np.array(model_inputs), np.array(posteriors), np.array(values).reshape((len(values),1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a929b157",
   "metadata": {},
   "source": [
    "##  Test neural model MCTS\n",
    "\n",
    "- Test that we can propagate values and make decisions correctly with neural MCTS\n",
    "- Find a good value for the duration parameter, (smallest value that allows us to make stable posteriors)\n",
    "- Cannot run these cells when doing regular run, since tf cannot be used in main process before spawning children\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e83b333f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from connect4.neural import load_model\\n\\n##  Create game board\\ngame_board = GameBoard()\\nprint(f\"\\nInitial game board:\\n{game_board}\")\\n\\n##  Create a root node at the current game state\\nmodel      = load_model(old_model_name)\\nroot_node  = Node_NeuralMCTS(game_board, params=[model, 1.], label=\"ROOT\")\\n\\n##  Print the initial value tree (should be a ROOT node with no children)\\nprint(\"Initial tree:\")\\nprint(root_node.tree_summary())\\nprint()\\n\\n##  Perform several MCTS steps with a HIGH debug level\\nroot_node.multi_step_MCTS(num_steps=10, max_sim_steps=-1, discount=0.99, debug_lvl=DebugLevel.MEDIUM)\\n\\n##  Print the updated value tree \\nprint(\"Updated tree:\")\\nprint(root_node.tree_summary())\\nprint()'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "###  Perform a few MCTS steps\n",
    "###\n",
    "\n",
    "'''from connect4.neural import load_model\n",
    "\n",
    "##  Create game board\n",
    "game_board = GameBoard()\n",
    "print(f\"\\nInitial game board:\\n{game_board}\")\n",
    "\n",
    "##  Create a root node at the current game state\n",
    "model      = load_model(old_model_name)\n",
    "root_node  = Node_NeuralMCTS(game_board, params=[model, 1.], label=\"ROOT\")\n",
    "\n",
    "##  Print the initial value tree (should be a ROOT node with no children)\n",
    "print(\"Initial tree:\")\n",
    "print(root_node.tree_summary())\n",
    "print()\n",
    "\n",
    "##  Perform several MCTS steps with a HIGH debug level\n",
    "root_node.multi_step_MCTS(num_steps=10, max_sim_steps=-1, discount=0.99, debug_lvl=DebugLevel.MEDIUM)\n",
    "\n",
    "##  Print the updated value tree \n",
    "print(\"Updated tree:\")\n",
    "print(root_node.tree_summary())\n",
    "print()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b41384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_inputs, posteriors, values = get_training_data_from_bot_game(model, duration=0.1, discount=0.99)\\n\\nfor inp, pos, val in zip(model_inputs, posteriors, values) :\\n    print(inp[:,:,0], \",  posterior=\"+\"  \".join([f\"{x:.2f}\" for x in pos]), f\",  value = {val[0]:.3f}\")\\n    '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "###  Check that a game looks sensible\n",
    "###\n",
    "\n",
    "'''\n",
    "model_inputs, posteriors, values = get_training_data_from_bot_game(model, duration=0.1, discount=0.99)\n",
    "\n",
    "for inp, pos, val in zip(model_inputs, posteriors, values) :\n",
    "    print(inp[:,:,0], \",  posterior=\"+\"  \".join([f\"{x:.2f}\" for x in pos]), f\",  value = {val[0]:.3f}\")\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a3dcbdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngame_board = GameBoard()\\nbot = Bot_NeuralMCTS(model)\\n\\nwhile not game_board.get_result() :\\n    action = bot.choose_action(game_board, duration=3, discount=0.99, debug_lvl=DebugLevel.LOW)\\n    print(\"Prior policy:  \" + \"  \".join([f\"{c:.2f}\" for c in bot.root_node.child_priors]))\\n    print(\"Prior values:  \" + \"  \".join([f\"{c.prior_value:.2f}\" for c in bot.root_node.children]))\\n    game_board.apply_action(action)\\n    print(game_board)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "###  Use MCTS to search for an optimal action\n",
    "###\n",
    "\n",
    "'''\n",
    "game_board = GameBoard()\n",
    "bot = Bot_NeuralMCTS(model)\n",
    "\n",
    "while not game_board.get_result() :\n",
    "    action = bot.choose_action(game_board, duration=3, discount=0.99, debug_lvl=DebugLevel.LOW)\n",
    "    print(\"Prior policy:  \" + \"  \".join([f\"{c:.2f}\" for c in bot.root_node.child_priors]))\n",
    "    print(\"Prior values:  \" + \"  \".join([f\"{c.prior_value:.2f}\" for c in bot.root_node.children]))\n",
    "    game_board.apply_action(action)\n",
    "    print(game_board)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad4ef1",
   "metadata": {},
   "source": [
    "## Multiprocess datapoint generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e50c3b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_datapoints_process(proc_idx, num_games, out_queue, base_seed, model_name, duration, discount) :\n",
    "    from connect4.neural import load_model\n",
    "    np.random.seed(base_seed+proc_idx)\n",
    "    model = load_model(model_name) if len(model_name) > 0 else None\n",
    "    for game_idx in range(num_games) :\n",
    "        _ = get_training_data_from_bot_game(model, duration, discount)\n",
    "        out_queue.put(_)\n",
    "                \n",
    "def generate_datapoints(num_processes, num_games_per_proc, base_seed, model_name, duration, discount, mon_freq=3) :\n",
    "    worker  = WorkerThread(generate_datapoints_process, num_processes, num_games_per_proc, \n",
    "                       func_args=[base_seed, model_name, duration, discount])\n",
    "    monitor = MonitorThread(worker, frequency=mon_freq)\n",
    "\n",
    "    monitor.start()\n",
    "    worker .start()\n",
    "\n",
    "    worker .join()\n",
    "    monitor.join()\n",
    "    \n",
    "    return worker.results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc26dd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6 / 14 results [t=24.04s]"
     ]
    }
   ],
   "source": [
    "###\n",
    "###  Generate training data\n",
    "###\n",
    "\n",
    "num_processes      = 7\n",
    "num_games_per_proc = 2\n",
    "base_seed          = 10\n",
    "duration           = 1\n",
    "discount           = 0.99\n",
    "monitor_frequency  = 3\n",
    "\n",
    "results = generate_datapoints(num_processes, num_games_per_proc, base_seed, old_model_name, \n",
    "                              duration, discount, monitor_frequency)\n",
    "                              \n",
    "##  Retrieve training data from worker thread\n",
    "\n",
    "model_in = np.concatenate([r[0] for r in results])\n",
    "model_p  = np.concatenate([r[1] for r in results])\n",
    "model_v  = np.concatenate([r[2] for r in results])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83baa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Load expensive generated data\n",
    "###\n",
    "'''\n",
    "data_fname = f\"../data/.training_data_v{model_idx}.pickle\"\n",
    "loaded     = pickle.load(open(data_fname, \"wb\"))\n",
    "print(f\"Generated data loaded from file: {data_fname}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa90cff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "###  Sanity-check a game\n",
    "###\n",
    "\n",
    "test_model_inputs, test_posteriors, test_values = results[0]\n",
    "\n",
    "for inp, pos, val in zip(test_model_inputs, test_posteriors, test_values) :\n",
    "    print(inp[:,:,0], \",  posterior=\"+\"  \".join([f\"{x:.2f}\" for x in pos]), f\",  value = {val[0]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Save expensive generated data\n",
    "###\n",
    "\n",
    "data_fname = f\"../data/.training_data_v{model_idx}.pickle\"\n",
    "to_save    = {\"model_in\":model_in, \"model_p\":model_p, \"model_v\":model_v}\n",
    "pickle.dump(to_save, open(data_fname, \"wb\"))\n",
    "print(f\"Generated data saved to file: {data_fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f658bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Report on the data generated\n",
    "###\n",
    "\n",
    "print(f\"model_in with shape: {model_in.shape}\")\n",
    "print(f\"model_p  with shape: {model_p .shape}\")\n",
    "print(f\"model_v  with shape: {model_v .shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37adc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Sanity-check a few datapoints\n",
    "###\n",
    "\n",
    "test_indices = np.arange(3) \n",
    "\n",
    "print(\"Print first few inputs:\")\n",
    "for i in test_indices : print(model_in[i,:,:,0])\n",
    "\n",
    "print(\"\\nPrint first few policies\")\n",
    "for i in test_indices : print(\",  \".join([f\"{p:.2f}\" for p in model_p[i]]))\n",
    "\n",
    "print(\"\\nPrint first few values\")\n",
    "for i in test_indices : print(\",  \".join([f\"{v:.2f}\" for v in model_v[i]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Data Augmentation and splitting\n",
    "###\n",
    "\n",
    "#  Randomly flip board and posterior in x-direction to created augmented dataset reflecting game symmetry\n",
    "for idx in range(len(model_in)) :\n",
    "    if np.random.choice([True, False]) : continue\n",
    "    model_in[idx] = np.flip(model_in[idx], axis=0)\n",
    "    model_p [idx] = np.flip(model_p [idx], axis=0)\n",
    "\n",
    "##  Shuffle data\n",
    "indices = np.arange(len(model_in))\n",
    "np.random.shuffle(indices)\n",
    "model_in, model_p, model_v = model_in[indices], model_p [indices], model_v [indices]\n",
    "\n",
    "##  Split data into train and val sets\n",
    "num_datapoints = len(model_in)\n",
    "split_idx = int(0.7*num_datapoints)\n",
    "\n",
    "train_model_in = model_in[:split_idx]\n",
    "train_model_p  = model_p [:split_idx]\n",
    "train_model_v  = model_v [:split_idx]\n",
    "\n",
    "val_model_in = model_in[split_idx:]\n",
    "val_model_p  = model_p [split_idx:]\n",
    "val_model_v  = model_v [split_idx:]\n",
    "\n",
    "print(f\"Created training set of size {len(train_model_v)}\")\n",
    "print(f\"Created validation set of size {len(val_model_v)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b66e4c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "###  Create or load a model\n",
    "###\n",
    "\n",
    "from connect4.neural import create_model, load_model\n",
    "\n",
    "'''new_model = create_model(name=new_model_name, num_conv_blocks=4, num_filters=40, num_dense=5, \n",
    "                         dense_width=200, batch_norm=True)'''\n",
    "\n",
    "new_model = load_model(old_model_name)\n",
    "\n",
    "new_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ecd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  View a few predictions of this model\n",
    "###\n",
    "\n",
    "test_model_p, test_model_v = new_model(val_model_in)\n",
    "test_model_p, test_model_v = test_model_p.numpy(), test_model_v.numpy()\n",
    "\n",
    "test_indices = np.arange(10) \n",
    "\n",
    "print(\"Policy cross-check\")\n",
    "for i in test_indices :\n",
    "    print(\",  \".join([f\"{p:.2f}\" for p in val_model_p[i]]) + \"  -->  \" + \",  \".join([f\"{p:.2f}\" for p in test_model_p[i]]))\n",
    "\n",
    "print(\"\\nValue cross-check\")\n",
    "for i in test_indices :\n",
    "    print(\",  \".join([f\"{v:.2f}\" for v in val_model_v[i]]) + \"  -->  \" + \",  \".join([f\"{v:.2f}\" for v in test_model_v[i]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e95745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "###  Fit and save our model!\n",
    "###\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "history = new_model.fit(\n",
    "            model_in, [model_p, model_v], epochs=1000, batch_size=100,\n",
    "            validation_data=(val_model_in, [val_model_p, val_model_v]),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)])\n",
    "\n",
    "new_model.save(new_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8418161",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  View a few predictions of this model\n",
    "###\n",
    "\n",
    "test_model_p, test_model_v = new_model(val_model_in)\n",
    "test_model_p, test_model_v = test_model_p.numpy(), test_model_v.numpy()\n",
    "\n",
    "test_indices = np.arange(10) \n",
    "\n",
    "print(\"Policy cross-check\")\n",
    "for i in test_indices :\n",
    "    print(\",  \".join([f\"{p:.2f}\" for p in val_model_p[i]]) + \"  -->  \" + \",  \".join([f\"{p:.2f}\" for p in test_model_p[i]]))\n",
    "\n",
    "print(\"\\nValue cross-check\")\n",
    "for i in test_indices :\n",
    "    print(\",  \".join([f\"{v:.2f}\" for v in val_model_v[i]]) + \"  -->  \" + \",  \".join([f\"{v:.2f}\" for v in test_model_v[i]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687fceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Visualise our training curves\n",
    "###\n",
    "\n",
    "monitor_pairs = [[\"loss\"       , \"val_loss\"],\n",
    "                 [\"policy_loss\", \"val_policy_loss\"],\n",
    "                 [\"value_loss\" , \"val_value_loss\"]]\n",
    "\n",
    "for do_log in [False, True] :\n",
    "    \n",
    "    num_axes = len(monitor_pairs)\n",
    "    fig      = plt.figure(figsize=(4*num_axes, 3))\n",
    "    for ax_idx, monitor_pair in enumerate(monitor_pairs) :\n",
    "        ax  = fig.add_subplot(1, num_axes, 1+ax_idx)\n",
    "        ax.plot(history.history[monitor_pair[0]], \"-\", lw=3, c=\"r\", alpha=0.5, label=monitor_pair[0])\n",
    "        ax.plot(history.history[monitor_pair[1]], \"-\", lw=3, c=\"b\", alpha=0.5, label=monitor_pair[1])\n",
    "        ax.legend(loc=\"upper right\", frameon=False, fontsize=10)\n",
    "        ax.set_xlabel(\"Epoch\", labelpad=15, fontsize=11, ha=\"center\", va=\"top\")\n",
    "        if do_log : ax.set_yscale(\"log\")\n",
    "    plt.show(fig)\n",
    "    plt.close(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb140ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "###  Play against our old bot!\n",
    "###\n",
    "\n",
    "old_model = load_model(old_model_name)\n",
    "\n",
    "bot_old = Bot_NeuralMCTS(old_model, greedy=True)\n",
    "bot_new = Bot_NeuralMCTS(new_model, greedy=True)\n",
    "\n",
    "game_board = GameBoard()\n",
    "print(game_board)\n",
    "\n",
    "while not game_board.get_result() :\n",
    "    if game_board.to_play == BinaryPlayer.X :\n",
    "        print(\"OLD BOT TO PLAY:\")\n",
    "        bot = bot_new\n",
    "    else :\n",
    "        print(\"NEW BOT TO PLAY:\")\n",
    "        bot = bot_new\n",
    "    action = bot.choose_action(game_board, duration=3, discount=0.99, debug_lvl=DebugLevel.LOW)\n",
    "    print(\"Prior values:  \" + \"  \".join([f\"{x.prior_value:.3f}\" for x in bot.root_node.children]))\n",
    "    game_board.apply_action(action)\n",
    "    print(game_board)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27bf50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed46d9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
