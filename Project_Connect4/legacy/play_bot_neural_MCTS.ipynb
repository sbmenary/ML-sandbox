{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69d1a5f",
   "metadata": {},
   "source": [
    "# Connect 4\n",
    "\n",
    "---\n",
    "\n",
    "Author: S. Menary [sbmenary@gmail.com]\n",
    "\n",
    "Date  : 2023-01-18, last edit 2023-01-18\n",
    "\n",
    "Brief : Play a bot using Monte Carlo Tree Search (MCTS) with a neural policy/value function.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef54ef68",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff93cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  All imports should be placed here\n",
    "###\n",
    "\n",
    "##  Python core libs\n",
    "import sys, time\n",
    "\n",
    "##  PyPI libs\n",
    "import numpy as np\n",
    "\n",
    "##  Local packages\n",
    "from connect4.utils    import DebugLevel\n",
    "from connect4.game     import BinaryPlayer, GameBoard\n",
    "from connect4.MCTS     import PolicyStrategy\n",
    "from connect4.bot      import Bot_NeuralMCTS\n",
    "from connect4.neural   import load_model\n",
    "from connect4.parallel import MonitorThread, WorkerThread, kill_threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e7c892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version is 3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]\n",
      "Numpy  version is 1.23.2\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "###  Print version for reproducibility\n",
    "###\n",
    "\n",
    "print(f\"Python version is {sys.version}\")\n",
    "print(f\"Numpy  version is {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752564a9",
   "metadata": {},
   "source": [
    "##  MCTS\n",
    "\n",
    "The `Bot_NeuralMCTS` object is used to apply bot actions using MCTS with a loaded model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718812a0",
   "metadata": {},
   "source": [
    "##  Create a bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f6f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Load a model\n",
    "###\n",
    "\n",
    "model_name = \"../models/.neural_model_v2.h5\"\n",
    "model = load_model(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "016132ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior values\n",
      "Action values are:  N/A     N/A     N/A     N/A     N/A     N/A     N/A   \n",
      "Visit counts are:   N/A     N/A     N/A     N/A     N/A     N/A     N/A   \n",
      "Selecting action 4\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | \u001b[31mX\u001b[0m | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "###  Ask bot to play a move\n",
    "###\n",
    "\n",
    "##  Create game board\n",
    "game_board = GameBoard()\n",
    "print(game_board)\n",
    "\n",
    "##  Use bot to search for an optimal action\n",
    "bot = Bot_NeuralMCTS(model, policy_strategy=PolicyStrategy.GREEDY_PRIOR_VALUE)\n",
    "bot.take_move(game_board, duration=0, debug_lvl=DebugLevel.LOW)\n",
    "\n",
    "##  Show updated game state\n",
    "print(game_board)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27992527",
   "metadata": {},
   "source": [
    "## Play a game\n",
    "\n",
    "Play a game of connect 4 against our bot!\n",
    "\n",
    "Just add new calls to `game_board.apply_action(column_index)` to play a move in column `column_index`, and `bot.take_move(game_board, duration)` to play a bot move in response. Turning up the `duration` parameter will improve the bot by allowing it to search for longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4802ca4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n"
     ]
    }
   ],
   "source": [
    "##  Create a new game\n",
    "\n",
    "game_board = GameBoard()\n",
    "bot        = Bot_NeuralMCTS(model, policy_strategy=PolicyStrategy.GREEDY_PRIOR_POLICY)\n",
    "print(game_board)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8a0f122",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | \u001b[31mX\u001b[0m | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  N/A     N/A     N/A     N/A     N/A     N/A     N/A   \n",
      "Visit counts are:   N/A     N/A     N/A     N/A     N/A     N/A     N/A   \n",
      "Selecting action 3\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | . | \u001b[31mX\u001b[0m | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n"
     ]
    }
   ],
   "source": [
    "##  Play a move in column index 3\n",
    "\n",
    "game_board.apply_action(3)\n",
    "print(game_board)\n",
    "\n",
    "if not game_board.get_result() :\n",
    "    bot.take_move(game_board, duration=0, debug_lvl=DebugLevel.LOW)\n",
    "    print(game_board)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f7a7a7",
   "metadata": {},
   "source": [
    "\n",
    "... and so on until the game is complete!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1385f901",
   "metadata": {},
   "source": [
    "## Bot-only game\n",
    "\n",
    "Let's watch the bot play itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1109740",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  0.090   0.004   -0.035  0.315   -0.228  -0.090  -0.089\n",
      "Visit counts are:   1       1       1       165     2       1       1     \n",
      "Selecting action 3\n",
      "Prior values:  0.090  0.004  -0.035  0.159  0.166  -0.090  -0.089\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | \u001b[31mX\u001b[0m | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.596  -0.535  -0.466  -0.209  -0.326  -0.267  -0.705\n",
      "Visit counts are:   1       1       12      111     29      20      1     \n",
      "Selecting action 3\n",
      "Prior values:  -0.596  -0.535  0.002  -0.183  -0.234  -0.040  -0.705\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | . | \u001b[31mX\u001b[0m | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  0.248   0.176   -0.145  -0.097  0.337   0.254   -0.955\n",
      "Visit counts are:   21      15      4       14      78      42      1     \n",
      "Selecting action 3\n",
      "Prior values:  0.753  0.446  -0.287  0.270  -0.065  0.219  -0.955\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | . | . | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | . | \u001b[31mX\u001b[0m | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.821  -0.964  -0.404  0.370   -0.091  -0.687  -0.879\n",
      "Visit counts are:   1       1       6       168     10      1       1     \n",
      "Selecting action 2\n",
      "Prior values:  -0.821  -0.964  -0.012  0.820  -0.000  -0.687  -0.879\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | . | . | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  0.214   -0.537  0.001   0.415   0.179   0.181   0.097 \n",
      "Visit counts are:   3       1       29      126     4       12      3     \n",
      "Selecting action 2\n",
      "Prior values:  0.877  -0.537  0.138  0.939  0.908  0.990  0.968\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.857  -0.313  -0.997  -0.007  -0.145  -0.053  -0.429\n",
      "Visit counts are:   1       6       1       141     1       13      2     \n",
      "Selecting action 3\n",
      "Prior values:  -0.857  -0.016  -0.997  0.226  -0.145  0.061  0.049\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | . | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  0.003   -0.044  0.120   -0.535  -0.007  -0.196  -0.023\n",
      "Visit counts are:   1       4       130     1       3       39      2     \n",
      "Selecting action 5\n",
      "Prior values:  0.003  0.651  0.905  -0.535  0.060  0.002  0.224\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | . | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  0.114   0.031   0.118   0.068   0.021   0.094   0.140 \n",
      "Visit counts are:   7       69      13      1       2       14      76    \n",
      "Selecting action 1\n",
      "Prior values:  0.994  -0.215  0.986  0.068  0.107  0.737  0.002\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | . | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.059  -0.329  -0.183  -0.641  -0.037  -0.250  0.160 \n",
      "Visit counts are:   1       3       43      1       20      14      96    \n",
      "Selecting action 2\n",
      "Prior values:  -0.059  -0.057  -0.012  -0.641  0.002  -0.167  -0.055\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.105  -0.021  -0.001  -0.030  -0.105  0.071   0.164 \n",
      "Visit counts are:   2       2       40      1       4       20      106   \n",
      "Selecting action 2\n",
      "Prior values:  0.536  0.004  0.198  -0.030  0.246  0.191  0.036\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.403  -0.667  -0.039  -0.276  -0.600  -0.665  0.299 \n",
      "Visit counts are:   1       1       1       1       1       1       194   \n",
      "Selecting action 6\n",
      "Prior values:  -0.403  -0.667  -0.039  -0.276  -0.600  -0.665  -0.143\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.620  -0.489  -0.290  -0.271  -0.281  -0.315  -0.270\n",
      "Visit counts are:   1       2       14      3       135     11      13    \n",
      "Selecting action 4\n",
      "Prior values:  -0.620  0.022  -0.009  -0.139  0.676  0.151  0.348\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.998  -0.958  -0.651  0.056   -0.337  -0.973  0.375 \n",
      "Visit counts are:   1       2       3       5       1       1       153   \n",
      "Selecting action 1\n",
      "Prior values:  -0.998  -0.973  -0.427  0.629  -0.337  -0.973  0.997\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.995  0.385   0.422   0.448   -0.687  -0.460  0.396 \n",
      "Visit counts are:   1       123     11      16      1       1       32    \n",
      "Selecting action 1\n",
      "Prior values:  -0.995  0.747  0.942  0.685  -0.687  -0.460  0.404\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.999  -0.128  -0.555  -0.591  -0.686  -0.854  -0.471\n",
      "Visit counts are:   1       79      17      11      7       9       69    \n",
      "Selecting action 5\n",
      "Prior values:  -0.999  -0.954  -0.897  -0.323  -0.721  -0.998  0.920\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  0.493   0.877   0.769   0.758   0.409   0.793   0.827 \n",
      "Visit counts are:   6       64      53      4       1       35      14    \n",
      "Selecting action 2\n",
      "Prior values:  0.651  0.961  1.000  0.777  0.409  0.999  0.939\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -1.000  -0.509  -0.758  -0.979  -0.994  -0.999  -0.951\n",
      "Visit counts are:   1       164     3       2       1       2       1     \n",
      "Selecting action 1\n",
      "Prior values:  -1.000  -0.964  -0.393  -0.958  -0.994  -0.998  -0.951\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  0.341   0.435   0.508   0.479   -0.196  0.462   0.419 \n",
      "Visit counts are:   14      13      41      43      2       54      13    \n",
      "Selecting action 5\n",
      "Prior values:  0.980  0.973  0.886  0.993  -0.044  0.574  0.890\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | . | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.999  -0.990  -0.393  -0.169  -0.598  -0.769  -0.782\n",
      "Visit counts are:   1       1       18      152     8       2       1     \n",
      "Selecting action 3\n",
      "Prior values:  -0.999  -0.990  -0.295  -0.962  -0.992  -0.999  -0.782\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | . | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  0.226   0.012   0.185   -0.128  0.145   0.164   0.241 \n",
      "Visit counts are:   62      12      18      10      13      13      50    \n",
      "Selecting action 3\n",
      "Prior values:  0.632  -0.383  0.576  -0.733  0.800  0.118  -0.120\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.286  -0.545  -0.001  -0.292  0.029   -0.148\n",
      "Visit counts are:   1       1       1       1       173     1     \n",
      "Selecting action 5\n",
      "Prior values:  -0.286  -0.545  -0.001  -0.292  0.002  -0.148\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | . | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.220  -0.230  -0.253  -0.110  0.056   -0.251\n",
      "Visit counts are:   9       6       11      44      114     7     \n",
      "Selecting action 2\n",
      "Prior values:  -0.874  -0.319  -0.901  -0.251  -0.663  -0.974\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.037  -0.065  -0.640  0.073   -0.299\n",
      "Visit counts are:   19      44      1       120     1     \n",
      "Selecting action 1\n",
      "Prior values:  -0.764  -0.286  -0.640  0.340  -0.299\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.078  -0.232  0.123   0.027   -0.084\n",
      "Visit counts are:   15      6       122     31      12    \n",
      "Selecting action 0\n",
      "Prior values:  -0.319  -0.275  -0.054  0.402  -0.656\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  0.015   -0.367  0.028   0.213   -0.115\n",
      "Visit counts are:   16      3       19      135     13    \n",
      "Selecting action 6\n",
      "Prior values:  -0.038  -0.133  -0.783  0.294  -0.101\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  0.067   -0.252  0.062   0.263   0.031 \n",
      "Visit counts are:   36      3       6       136     19    \n",
      "Selecting action 5\n",
      "Prior values:  0.620  0.471  0.689  -0.675  -0.659\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.096  -0.704  -0.959  -0.174  -0.050\n",
      "Visit counts are:   148     6       1       14      10    \n",
      "Selecting action 1\n",
      "Prior values:  -0.185  0.187  -0.959  -0.155  0.141\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.150  -0.060  -0.082  0.091 \n",
      "Visit counts are:   12      20      6       141   \n",
      "Selecting action 6\n",
      "Prior values:  0.842  0.804  0.997  0.795\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | . |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.984  -0.927  -0.087  -0.032\n",
      "Visit counts are:   3       2       65      115   \n",
      "Selecting action 6\n",
      "Prior values:  -0.965  -0.976  -0.037  -0.607\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.619  -0.040  -0.505  0.013 \n",
      "Visit counts are:   2       29      2       207   \n",
      "Selecting action 6\n",
      "Prior values:  -0.279  0.135  -0.160  -0.843\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.057  -0.008  -0.057  -0.978\n",
      "Visit counts are:   49      122     63      1     \n",
      "Selecting action 0\n",
      "Prior values:  -0.983  -0.997  -0.272  -0.978\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  0.186   0.123   0.025   -0.992\n",
      "Visit counts are:   181     30      13      1     \n",
      "Selecting action 4\n",
      "Prior values:  -0.116  -0.844  -0.490  -0.992\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| . | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.137  -0.449  -0.279  -0.179\n",
      "Visit counts are:   290     9       15      17    \n",
      "Selecting action 0\n",
      "Prior values:  -0.842  -0.472  -0.291  -0.147\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.193  -0.037  0.340   -0.999\n",
      "Visit counts are:   9       45      381     1     \n",
      "Selecting action 4\n",
      "Prior values:  -0.998  -0.723  -0.375  -0.999\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.509  -0.117  -0.651  -0.556\n",
      "Visit counts are:   10      528     12      6     \n",
      "Selecting action 4\n",
      "Prior values:  -0.941  -0.925  -0.743  -0.744\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.199  -0.072  0.153   0.139 \n",
      "Visit counts are:   42      57      405     119   \n",
      "Selecting action 0\n",
      "Prior values:  -1.000  -0.634  -0.994  -1.000\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  0.019   -0.042  0.010   0.013 \n",
      "Visit counts are:   504     117     82      28    \n",
      "Selecting action 0\n",
      "Prior values:  -0.740  -0.821  -0.880  0.002\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | . |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.390  -0.120  0.588   0.001 \n",
      "Visit counts are:   11      49      835     616   \n",
      "Selecting action 6\n",
      "Prior values:  -1.000  -0.983  -1.000  -1.000\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | . | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.023  -0.019  0.001 \n",
      "Visit counts are:   388     782     1131  \n",
      "Selecting action 4\n",
      "Prior values:  -0.712  -0.984  -0.508\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.002  0.008   0.012 \n",
      "Visit counts are:   259     1736    1326  \n",
      "Selecting action 4\n",
      "Prior values:  -1.000  -1.000  -1.000\n",
      "+---+---+---+---+---+---+---+\n",
      "| . | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  -0.994  -0.000\n",
      "Visit counts are:   24      4547  \n",
      "Selecting action 0\n",
      "Prior values:  -0.855  -0.672\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | . | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: NONE\n",
      "Selecting greedy action from prior policy\n",
      "Action values are:  1.000 \n",
      "Visit counts are:   13696 \n",
      "Selecting action 5\n",
      "Prior values:  -1.000\n",
      "+---+---+---+---+---+---+---+\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m |\n",
      "| \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "| \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[34mO\u001b[0m | \u001b[31mX\u001b[0m | \u001b[31mX\u001b[0m |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
      "+---+---+---+---+---+---+---+\n",
      "Game result is: O\n"
     ]
    }
   ],
   "source": [
    "#  Play a bot game!\n",
    "\n",
    "game_board = GameBoard()\n",
    "print(game_board)\n",
    "\n",
    "result = game_board.get_result()\n",
    "while not result :\n",
    "    bot.take_move(game_board, duration=1, debug_lvl=DebugLevel.LOW)\n",
    "    prior_values = np.array([x.prior_value for x in bot.root_node.children])\n",
    "    if bot.root_node.player == BinaryPlayer.O : prior_values = -prior_values\n",
    "    print(\"Prior values:  \" + \"  \".join([f\"{x:.3f}\" for x in prior_values]))\n",
    "    result = game_board.get_result()\n",
    "    print(game_board)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19438a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
