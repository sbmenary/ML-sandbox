{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c9e74fe",
   "metadata": {},
   "source": [
    "- Monitors observed to follow damped oscillate when learning rate is too large, and we repeatedly overshoot the target even when the target is not especially mis-modelled\n",
    "\n",
    "- Function appears to be dragged around, since its inductive bias is to be very smooth. This smoothness is reinforced by the target which is the rewards + y * bootstrap, which is itself smooth. This has two effects: 1. if the function is not very versatile then it will struggle to mould the near-to-terminal states into their correct positions, and all of the other datapoints override them in importance, and 2. it will struggle to capture harsh turning points in the value function. In this example, we can clearly see that in trying to model the \"long-arm\", which has more states and so receives a higher effective weight in the gradient update, we enact a lever-effect which pulls the \"short arm\" in the wrong direction. Ideally we would be updating the NN parameters to fold the value function in the middle and so describe both arms well.\n",
    "    - it is possible that this effects occurs because of having too simply a NN, so will add capacity and see if it resolves\n",
    "    - even if a lever-arm does not occur, we still focus on the arm with more states in, since these gradient updates take precedence when they act in opposite direction\n",
    "\n",
    "- On the issue of using q1-and-q2 as different models, compared with just using q1 and a frozen version of itself to bootstrap from. In the first case, it seems that one function simply leads the other, i.e. we update q1 to a new iteration, then update q2 to catch up with q1, then iterate q1 again. Therefore we are not learning very efficiently, since 50% of the time we are duplicating progress. It is more efficient to freeze the original model and avoid this duplication. \n",
    "\n",
    "- Currently use SGD to avoid confounding learning momentum with the bias/divergence of FA + Q-learning, which is what I am trying to understand\n",
    "\n",
    "- Maybe some of the massive jumps which occur seemingly out-of-nowhere occur because the greedy policy suddenly changes and starts selecting a different action, therefore dramatically changing the bootstrap target. Should highlight on the plot which action the bootstrap target selects each time. Might also just be due to learning rate being too high.\n",
    "\n",
    "- \"Good\" solution works with both a simple NN and complicated one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee6941d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ste/miniforge3/envs/tf-sandbox-py3p9/lib/python3.9/site-packages/jax/_src/lib/__init__.py:33: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow has found devices:\n",
      "-  PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "-  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "#  Required imports\n",
    "\n",
    "import math, os, pickle, sys, time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import animation, pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from multiprocess import Process, Value\n",
    "from threading import Lock, Thread\n",
    "\n",
    "import threading\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers    import Conv2D, Concatenate, Dense, Dropout, Flatten, Input, MaxPooling2D, Rescaling\n",
    "from tensorflow.keras.models    import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print(\"TensorFlow has found devices:\")\n",
    "for device in tf.config.list_physical_devices() :\n",
    "    print(f\"-  {device}\")\n",
    "    \n",
    "  # create global list of all threads we will create\n",
    "all_threads = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05cb1deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using game board config: x_min = 0, x_max = 19, x_start = 3, x_end = 16 (20 states)\n",
      "Using 3 available actions: dx = [-1  0  1] with min -1 and max 1\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "###  Global constants\n",
    "###\n",
    "\n",
    "#  Initially we will just run on a game board of fixed size, to avoid building an architecture to handle \n",
    "#  variable board sizes, so let's configure this here\n",
    "\n",
    "distance_to_end     = 13\n",
    "game_board_pad_size = 3\n",
    "horizontal_size     = distance_to_end + 2*game_board_pad_size + 1\n",
    "\n",
    "reward_per_turn = -1.\n",
    "lambda_dx       = 0.\n",
    "lambda_b        = -1.\n",
    "gamma           = 1.\n",
    "\n",
    "x_min      = 0\n",
    "x_max      = horizontal_size - 1\n",
    "x_range    = x_max - x_min\n",
    "x_start    = game_board_pad_size\n",
    "x_end      = x_start + distance_to_end\n",
    "num_states = x_range + 1\n",
    "\n",
    "action_list  = [-1, 0, 1]\n",
    "num_actions  = len(action_list)\n",
    "action_list  = np.array(action_list).reshape((num_actions,1))\n",
    "a_min, a_max = action_list.min(), action_list.max()\n",
    "a_range      = a_max - a_min\n",
    "\n",
    "print(f\"Using game board config: x_min = {x_min}, x_max = {x_max}, x_start = {x_start}, x_end = {x_end} ({num_states} states)\")\n",
    "print(f\"Using {num_actions} available actions: dx = {action_list.flatten()} with min {a_min} and max {a_max}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9cffd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Define environment methods\n",
    "###\n",
    "\n",
    "\n",
    "def is_terminal(x_agent) :\n",
    "    '''\n",
    "    Return True if the agent is in the terminal state and False otherwise.\n",
    "    Inputs:\n",
    "      > x_agent, int [x_min, x_max]\n",
    "        x position of agent\n",
    "    Returns:\n",
    "      > bool\n",
    "        whether the agent is in the terminal state\n",
    "    '''\n",
    "    if x_agent == x_end :\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_out_of_bounds(x_agent) :\n",
    "    '''\n",
    "    Return True if the agent is out of bounds and False otherwise.\n",
    "    Inputs:\n",
    "      > x_agent, int [x_min, x_max]\n",
    "        x position of agent\n",
    "    Returns:\n",
    "      > bool\n",
    "        whether the agent is out of bounds\n",
    "    '''\n",
    "    if x_agent < x_min : return True\n",
    "    if x_agent > x_max : return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def perform_action(x_agent, action, base_reward=reward_per_turn, boundary_reward=lambda_b, dx_reward=lambda_dx) :\n",
    "    '''\n",
    "    Given the current environment and agent states, perform the specified action and return the reward \n",
    "    obtaine along with the new agent state.\n",
    "    Inputs:\n",
    "      > x_agent, int [x_min, x_max]\n",
    "        x position of agent at initial timestep\n",
    "      > action, int in action_list\n",
    "        dx of action to be performed\n",
    "      > base_reward, float, default=reward_per_turn\n",
    "        basic reward returned every turn (expected -ve)\n",
    "      > boundary_reward, float, default=lambda_b\n",
    "        reward received when encountering the edge of the game board (expected -ve)\n",
    "      > dx_reward, float, default=lambda_dx\n",
    "        factor multiplied by change-in-distance to calculate movement reward (expected +ve def)\n",
    "    Returns:\n",
    "      > float\n",
    "        reward obtained by performing action\n",
    "      > int [0, horizontal_max)\n",
    "        x position of agent at iterated timestep\n",
    "    '''\n",
    "    ##  Make sure initial state is valid to protect against unexpected behaviour\n",
    "    if is_terminal(x_agent) :\n",
    "        raise RuntimeError(f\"Agent position is terminal, so no actions may be performed\")\n",
    "    if is_out_of_bounds(x_agent) :\n",
    "        raise RuntimeError(f\"Agent position ({x_agent}) is out of bounds, so no actions may be performed\")\n",
    "    ##  Make sure action is valid to protect against unexpected behaviour\n",
    "    if action not in action_list :\n",
    "        raise RuntimeError(f\"Action ({action}) not found in available list ({action_list})\")\n",
    "    ##  Get initial distance of agent from the end\n",
    "    dx_agent = np.fabs(x_agent - x_end)\n",
    "    ##  Iterate agent position, if hit boundary then add penalty and return to original position \n",
    "    x_agent_p = x_agent + action\n",
    "    reward_b  = 0\n",
    "    if is_out_of_bounds(x_agent_p) :\n",
    "        reward_b  = boundary_reward\n",
    "        x_agent_p = x_agent.copy()\n",
    "    ##  Get distance-based reward\n",
    "    dx_agent_p = np.fabs(x_agent_p - x_end)\n",
    "    reward_dx  = dx_reward * (dx_agent - dx_agent_p)\n",
    "    ##  Calculate total reward by summing the base, boundary, distance and weather rewards\n",
    "    reward = base_reward + reward_b + reward_dx\n",
    "    ##  Return reward and new agent state\n",
    "    return reward, x_agent_p\n",
    "    \n",
    "\n",
    "def get_greedy_action(x_agent, *q_models) :\n",
    "    '''\n",
    "    Sample a greedy action from the q-value models provided. If multiple models provided then use their mean.\n",
    "    Inputs:\n",
    "      > x_agent, int [x_min, x_max]\n",
    "        x position of agent at initial timestep\n",
    "      > q_models, list of tf.keras Model class, each with inputs [x_agent, action] = [Input(1), Input(1)]\n",
    "        list of Keras q(s,a) models\n",
    "    Returns:\n",
    "      > int in action_list\n",
    "        action defined by greedy policy over the model(s) at this agent position\n",
    "      > list of np.ndarray objects of shape (num_actions,)\n",
    "        action values in the same order as action_list, once for each model provided\n",
    "    '''\n",
    "    x_agents            = np.array([x_agent for i in range(num_actions)]).reshape((num_actions, 1))\n",
    "    model_args          = [x_agents, action_list]\n",
    "    model_action_values = [model.predict(model_args).flatten() for model in q_models]\n",
    "    action_values       = np.mean(model_action_values, axis=0)\n",
    "    best_action         = action_list[np.argmax(action_values)][0]\n",
    "    return best_action\n",
    "\n",
    "\n",
    "def get_state_action_pairs() :\n",
    "    state_action_pairs = []\n",
    "    for x_agent in range(x_min, x_max+1) : \n",
    "        if is_terminal(x_agent) : continue\n",
    "        if is_out_of_bounds(x_agent) :\n",
    "            raise RuntimeError(f\"Trying to add out-of-bounds state x={x_agent} to state_action_pairs\")\n",
    "        for action in action_list.flatten() :\n",
    "            state_action_pairs.append((x_agent, action))\n",
    "    return np.array(state_action_pairs)\n",
    "\n",
    "\n",
    "def get_true_q(states, actions) :\n",
    "    num_states = len(states)\n",
    "    q_values = np.zeros(shape=(num_states,))\n",
    "    for x_idx, (s, a) in enumerate(zip(states, actions)) :\n",
    "        if is_terminal(s) :\n",
    "            q_values[x_idx] = np.nan\n",
    "            continue\n",
    "        g, s = perform_action(s, a)\n",
    "        while not is_terminal(s) :\n",
    "            if s > x_end : a = -1\n",
    "            else         : a = 1\n",
    "            r, s = perform_action(s, a)\n",
    "            g += r\n",
    "        q_values[x_idx] = g\n",
    "    return q_values\n",
    "\n",
    "\n",
    "def get_mse(q_values_1, q_values_2) :\n",
    "    q_res = q_values_2 - q_values_1\n",
    "    q_res = np.where(np.isfinite(q_res), q_res, 0)\n",
    "    q_res = q_res**2\n",
    "    return np.mean(q_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af51aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_directory_for_file_path(fname, print_msg_on_dir_creation=True) :\n",
    "    \"\"\"\n",
    "    Create the directory structure needed to place file fname. Call this before fig.savefig(fname, ...) to \n",
    "    make sure fname can be created without a FileNotFoundError\n",
    "    Input:\n",
    "       - fname: str\n",
    "                name of file you want to create a tree of directories to enclose\n",
    "                also create directory at this path if fname ends in '/'\n",
    "       - print_msg_on_dir_creation: bool, default = True\n",
    "                                    if True then print a message whenever a new directory is created\n",
    "    \"\"\"\n",
    "    while \"//\" in fname :\n",
    "        fname = fname.replace(\"//\", \"/\")\n",
    "    dir_tree = fname.split(\"/\")\n",
    "    dir_tree = [\"/\".join(dir_tree[:i]) for i in range(1,len(dir_tree))]\n",
    "    dir_path = \"\"\n",
    "    for dir_path in dir_tree :\n",
    "        if len(dir_path) == 0 : continue\n",
    "        if not os.path.exists(dir_path) :\n",
    "            os.mkdir(dir_path)\n",
    "            if print_msg_on_dir_creation :\n",
    "                print(f\"Directory {dir_path} created\")\n",
    "            continue\n",
    "        if os.path.isdir(dir_path) : \n",
    "            continue\n",
    "        raise RuntimeError(f\"Cannot create directory {dir_path} because it already exists and is not a directory\")\n",
    "    \n",
    "\n",
    "def create_config(config_fname, run_config, q1_model, q2_model, optimizer_q1, optimizer_q2, to_stdout=True) :\n",
    "    '''\n",
    "    Print environment, training and model configurations to file config_fname. Also print environment and\n",
    "    training configurations to sys.stdout if requested, but do not print model summaries as they are verbose.\n",
    "    Inputs:\n",
    "      > config_fname, str\n",
    "        name of config file to create\n",
    "      > q1_model, keras Model\n",
    "        first q-value model\n",
    "      > q2_model, keras Model\n",
    "        second q-value model\n",
    "      > to_stdout, bool, default=True\n",
    "        if True then repeat environment and training configurations to sys.stdout\n",
    "    Returns:\n",
    "      > None\n",
    "    '''\n",
    "    # Create message as list of strings\n",
    "    config_message = []\n",
    "    config_message.append(f\"=\"*114 + \"\\n\")\n",
    "    config_message.append(f\"Environment config:\\n\")\n",
    "    config_message.append(f\"> distance_to_end: {distance_to_end}\\n\")\n",
    "    config_message.append(f\"> game_board_pad_size: {game_board_pad_size}\\n\")\n",
    "    config_message.append(f\"> horizontal_size: {horizontal_size}\\n\")\n",
    "    config_message.append(f\"> reward_per_turn: {reward_per_turn}\\n\")\n",
    "    config_message.append(f\"> lambda_dx: {lambda_dx}\\n\")\n",
    "    config_message.append(f\"> lambda_b: {lambda_b}\\n\")\n",
    "    config_message.append(f\"> gamma: {gamma}\\n\")\n",
    "    config_message.append(f\"> x_min: {x_min}\\n\")\n",
    "    config_message.append(f\"> x_max: {x_max}\\n\")\n",
    "    config_message.append(f\"> x_range: {x_range}\\n\")\n",
    "    config_message.append(f\"> x_start: {x_start}\\n\")\n",
    "    config_message.append(f\"> x_end: {x_end}\\n\")\n",
    "    config_message.append(f\"> action_list: {action_list.flatten()}\\n\")\n",
    "    config_message.append(f\"=\"*114 + \"\\n\")\n",
    "    config_message.append(f\"Training config:\\n\")\n",
    "    config_message.append(f\"> Stop training when mse_true exceeds {run_config.get('max_mse_true')}\\n\")\n",
    "    config_message.append(f\"> Using {run_config.get('num_step_returns')} step empirical returns\\n\")\n",
    "    config_message.append(f\"> Using bootstrap method: {run_config.get('bootstrap_method')}\\n\")\n",
    "    config_message.append(f\"> Using epochs of length {run_config.get('num_state_action_pairs')}\\n\")\n",
    "    config_message.append(f\"> Updating gradient every batch of size {run_config.get('batch_size')}\\n\")\n",
    "    config_message.append(f\"> Using optimizer_q1 {optimizer_q1} with learning rate {run_config.get('learning_rate'):.6}\\n\")\n",
    "    config_message.append(f\"> Using optimizer_q2 {optimizer_q2} with learning rate {run_config.get('learning_rate'):.6}\\n\")\n",
    "    config_message.append(f\"> Swapping q1 and q2 every {run_config.get('switch_after_epochs')} epochs\\n\")\n",
    "    config_message.append(f\"> Cloning q2 from q1 every {run_config.get('clone_after_epochs')} epochs\\n\")\n",
    "    config_message.append(f\"> Assigning a weight of {run_config.get('priority_weight')} to anchoring state/action pairs\\n\")\n",
    "    config_message.append(f\"=\"*114 + \"\\n\")\n",
    "    # Make sure directory exists for file\n",
    "    generate_directory_for_file_path(config_fname, print_msg_on_dir_creation=True)\n",
    "    # Open file and print messages, also to stdout if configured\n",
    "    # - also print q-model summaries, only to file\n",
    "    with open(config_fname, \"w\") as config_file :\n",
    "        for line in config_message :\n",
    "            config_file.write(line)\n",
    "            if not to_stdout : continue\n",
    "            sys.stdout.write(line)\n",
    "        config_file.write(\"\\nModel configs:\\n\\n\")\n",
    "        q1_model.summary(print_fn=lambda x: config_file.write(x + '\\n'))\n",
    "        config_file.write(\"\\n\")\n",
    "        q2_model.summary(print_fn=lambda x: config_file.write(x + '\\n'))\n",
    "        \n",
    "        \n",
    "def create_value_estimate_plot(test_states, true_q, target_q, q_model, bs_model, epoch_idx=-1, \n",
    "                               show=False, close=False, verbose=False, save=\"\", dpi=100) :\n",
    "    '''\n",
    "    Create a plt.Figure instance visualising the greedy policy defined by the average of the q-value models \n",
    "    provided. Allows for plot to be shown, saved and/or closed using plt interface. Returns the plot figure\n",
    "    and axis objects so they can continue to be manipulated, but note that objects will no longer be in scope\n",
    "    if we have called plt.close(fig).\n",
    "    Inputs:\n",
    "      > test_states, np.ndarray of size (num_states,)\n",
    "        states used to evaluate models\n",
    "      > true_q, np.array of shape (3*num_states,)\n",
    "        true q-values in concatenated list of actions = [-1, 0, 1]\n",
    "      > target_q, np.array of shape (3*num_states,)\n",
    "        target q-values in concatenated list of actions = [-1, 0, 1]\n",
    "      > q_model, np.array of shape (3*num_states,)\n",
    "        estimated q-values in concatenated list of actions = [-1, 0, 1]\n",
    "      > bs_model, np.array of shape (3*num_states,)\n",
    "        bootstrap q-values in concatenated list of actions = [-1, 0, 1]\n",
    "      > epoch_idx, int, default=-1\n",
    "        if positive then draw a text box displaying how many epochs have been performed\n",
    "      > show, bool, default=False\n",
    "        if True then call plt.show(fig)\n",
    "      > close, bool, default=False\n",
    "        if True then call plt.close(fig)\n",
    "      > save, str, default=\"\"\n",
    "        if string provided then call fig.savefig(save, ...), creating any required subdirectories if needed\n",
    "    Returns:\n",
    "      > plt.Figure instance\n",
    "        Figure object\n",
    "      > plt.Axes instance\n",
    "        Left-hand axis object\n",
    "      > plt.Axes instance\n",
    "        Middle axis object\n",
    "      > plt.Axes instance\n",
    "        Right-hand axis object\n",
    "    '''\n",
    "    \n",
    "    num_test_states = len(test_states)\n",
    "     \n",
    "    #  Keep track of how long plotting takes, to help inform how often to call this function    \n",
    "    start_time = time.time()\n",
    "\n",
    "    #  Make plot\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    fig.set_facecolor(\"white\")\n",
    "    fig.set_alpha(1)\n",
    "    \n",
    "    ax1 = fig.add_subplot(1, 3, 1)\n",
    "    ax1.tick_params(axis=\"both\", which=\"both\", right=True, top=True, direction=\"in\", labelsize=12)\n",
    "    ax1.plot(test_states, q_model [:num_test_states], \"o-\" , c=\"r\"         , ms=5, lw=3, alpha=0.5, label=\"Estimated $q(s,a)$\")\n",
    "    ax1.plot(test_states, bs_model[:num_test_states], \"x-\" , c=\"b\"         , ms=5, lw=3, alpha=0.5, label=\"Bootstrap\")\n",
    "    ax1.plot(test_states, target_q[:num_test_states], \"x-\" , c=\"darkorange\", ms=5, lw=3, alpha=0.5, label=\"Target\")\n",
    "    ax1.plot(test_states, true_q  [:num_test_states], \".--\", c=\"gray\"      , ms=5, lw=3, alpha=0.5, label=\"True\")\n",
    "    ax1.grid(True, which='both')\n",
    "    ax1.set_xlabel(\"$x$\", labelpad=15, fontsize=14)\n",
    "    \n",
    "    ax2 = fig.add_subplot(1, 3, 2)\n",
    "    ax2.tick_params(axis=\"both\", which=\"both\", right=True, top=True, direction=\"in\", labelsize=12)\n",
    "    ax2.plot(test_states, q_model [num_test_states:2*num_test_states], \"o-\" , c=\"r\"         , ms=5, lw=3, alpha=0.5, label=\"Estimated $q(s,a)$\")\n",
    "    ax2.plot(test_states, bs_model[num_test_states:2*num_test_states], \"x-\" , c=\"b\"         , ms=5, lw=3, alpha=0.5, label=\"Bootstrap\")\n",
    "    ax2.plot(test_states, target_q[num_test_states:2*num_test_states], \"x-\" , c=\"darkorange\", ms=5, lw=3, alpha=0.5, label=\"Target\")\n",
    "    ax2.plot(test_states, true_q  [num_test_states:2*num_test_states], \".--\", c=\"gray\"      , ms=5, lw=3, alpha=0.5, label=\"True\")\n",
    "    ax2.grid(True, which='both')\n",
    "    ax2.set_xlabel(\"$x$\", labelpad=15, fontsize=14)\n",
    "    \n",
    "    ax3 = fig.add_subplot(1, 3, 3)\n",
    "    ax3.tick_params(axis=\"both\", which=\"both\", right=True, top=True, direction=\"in\", labelsize=12)\n",
    "    ax3.plot(test_states, q_model [2*num_test_states:3*num_test_states], \"o-\" , c=\"r\"         , ms=5, lw=3, alpha=0.5, label=\"Estimated $q(s,a)$\")\n",
    "    ax3.plot(test_states, bs_model[2*num_test_states:3*num_test_states], \"x-\" , c=\"b\"         , ms=5, lw=3, alpha=0.5, label=\"Bootstrap\")\n",
    "    ax3.plot(test_states, target_q[2*num_test_states:3*num_test_states], \"x-\" , c=\"darkorange\", ms=5, lw=3, alpha=0.5, label=\"Target\")\n",
    "    ax3.plot(test_states, true_q  [2*num_test_states:3*num_test_states], \".--\", c=\"gray\"      , ms=5, lw=3, alpha=0.5, label=\"True\")\n",
    "    ax3.grid(True, which='both')\n",
    "    ax3.set_xlabel(\"$x$\", labelpad=15, fontsize=14)\n",
    "    \n",
    "    #  Find string representing bootstrap greedy policy\n",
    "    str_bs_greedy_policy = \"Bootstrap policy: \"\n",
    "    for s in test_states :\n",
    "        if is_terminal(s) : \n",
    "            str_bs_greedy_policy += \"  |\"\n",
    "            continue\n",
    "        qL, q0, qR = bs_model[s], bs_model[num_test_states+s], bs_model[2*num_test_states+s]\n",
    "        if   qL > q0 and qL > qR : str_bs_greedy_policy += \"  L\"\n",
    "        elif q0 > qL and q0 > qR : str_bs_greedy_policy += \"  0\"\n",
    "        elif qR > qL and qR > q0 : str_bs_greedy_policy += \"  R\"\n",
    "        else : str_bs_greedy_policy += \"  ?\"\n",
    "             \n",
    "    #  Draw accompanying plot objects\n",
    "    ax1.legend(loc=(0.7,1.06), ncol=4, fontsize=14, frameon=False)\n",
    "    ax1.axhline(0, lw=1, c=\"k\", ls=\"-\")\n",
    "    ax2.axhline(0, lw=1, c=\"k\", ls=\"-\")\n",
    "    ax3.axhline(0, lw=1, c=\"k\", ls=\"-\")\n",
    "    ax1.text(0.01, 1.01, f\"Action: left\" , ha=\"left\", va=\"bottom\", weight=\"bold\", transform=ax1.transAxes, \n",
    "             alpha=0.8, fontsize=12, c=\"k\")\n",
    "    ax2.text(0.01, 1.01, f\"Action: stay\" , ha=\"left\", va=\"bottom\", weight=\"bold\", transform=ax2.transAxes, \n",
    "             alpha=0.8, fontsize=12, c=\"k\")\n",
    "    ax3.text(0.01, 1.01, f\"Action: right\", ha=\"left\", va=\"bottom\", weight=\"bold\", transform=ax3.transAxes, \n",
    "             alpha=0.8, fontsize=12, c=\"k\")\n",
    "    ax1.text(0, -0.2, f\"{str_bs_greedy_policy}\", ha=\"left\", va=\"top\", weight=\"bold\", transform=ax1.transAxes, fontsize=12, c=\"k\")\n",
    "        \n",
    "    #  Figure out and set y-axis ranges\n",
    "    true_q, q_model, bs_model\n",
    "    y_min   = np.nanmin([0, np.nanmin(true_q), np.nanmin(target_q), np.nanmin(q_model), np.nanmin(bs_model)])\n",
    "    y_max   = np.nanmax([0, np.nanmax(true_q), np.nanmax(target_q), np.nanmax(q_model), np.nanmax(bs_model)])\n",
    "    y_range = y_max - y_min\n",
    "    y_pad   = 0.1\n",
    "    y_lim   = [y_min - y_pad*y_range, y_max + y_pad*y_range]\n",
    "    ax1.set_ylim(y_lim)\n",
    "    ax2.set_ylim(y_lim)\n",
    "    ax3.set_ylim(y_lim)\n",
    "    \n",
    "    #  Draw text boxes displaying title and num. epochs\n",
    "    if epoch_idx >= 0 :\n",
    "        ax1.text(0., 1.08, f\"After {epoch_idx} epochs\", ha=\"left\", va=\"bottom\", weight=\"bold\", \n",
    "                 transform=ax1.transAxes, fontsize=14)\n",
    "       \n",
    "    #  Save / show / close\n",
    "    if len(save) > 0 :\n",
    "        generate_directory_for_file_path(save, print_msg_on_dir_creation=verbose)\n",
    "        plt.savefig(save, bbox_inches=\"tight\", dpi=dpi)\n",
    "    if show :\n",
    "        plt.show(fig)\n",
    "    if close :\n",
    "        plt.close(fig)\n",
    "        \n",
    "    #  Return figure and axis\n",
    "    return fig, ax1, ax2, ax3\n",
    "\n",
    "        \n",
    "def create_training_curves_plot(loss_record, ref_loss_record, maxQ_record, true_max_Q=np.nan, \n",
    "                                show=False, close=False, verbose=False, save=\"\", dpi=100) :\n",
    "    '''\n",
    "    Create a plt.Figure instance visualising the training curves. Allows for plot to be shown, saved and/or \n",
    "    closed using plt interface. Returns the plot figure and axis objects so they can continue to be \n",
    "    manipulated, but note that objects will no longer be in scope if we have called plt.close(fig).\n",
    "    Inputs:\n",
    "      > q_models, list of keras Model class\n",
    "        list of q-value models to define the greedy policy\n",
    "      > verbose, bool, default=False\n",
    "        if True then print some text to display progress as we evaluate the models for every state/action pair\n",
    "      > show, bool, default=False\n",
    "        if True then call plt.show(fig)\n",
    "      > close, bool, default=False\n",
    "        if True then call plt.close(fig)\n",
    "      > save, str, default=\"\"\n",
    "        if string provided then call fig.savefig(save, ...), creating any required subdirectories if needed\n",
    "    Returns:\n",
    "      > plt.Figure instance\n",
    "      > plt.Axes instance (axis corresponding to loss curves)\n",
    "      > plt.Axes instance (axis corresponding to ref_loss curves)\n",
    "      > plt.Axes instance (axis corresponding to maxQ curves)\n",
    "    '''\n",
    "    \n",
    "    def draw_curve(ax, container, m, c, label) :\n",
    "        ax.plot([x for x,y in container], [y for x,y in container], m, ms=7, c=c, alpha=1.0, label=label)\n",
    "        for ((x1,y1), (x2,y2)) in zip(container[:-1], container[1:]) :\n",
    "            if np.fabs(x2-x1) > 1.5 : continue\n",
    "            ax.plot([x1, x2], [y1, y2], \"-\", c=c, lw=2, alpha=0.7)\n",
    "            \n",
    "    fig = plt.figure(figsize=(30,15))\n",
    "    fig.set_facecolor(\"white\")\n",
    "    fig.set_alpha(1)\n",
    "    \n",
    "    ax1 = fig.add_subplot(3, 1, 1)\n",
    "    ax1.grid(True, which='both')\n",
    "    ax1.tick_params(axis=\"both\", which=\"both\", right=True, top=True, direction=\"in\", labelsize=30)\n",
    "    ax1.set_title(r\"Mean loss per batch [$(1-\\lambda)\\cdot$batch + $\\lambda\\cdot$ref]\", fontsize=30)\n",
    "    ax1.xaxis.set_ticklabels([])\n",
    "    draw_curve(ax1, loss_record[\"Q1\"], \"o\", \"r\", \"$q_1$\")\n",
    "    draw_curve(ax1, loss_record[\"Q2\"], \"x\", \"b\", \"$q_2$\")\n",
    "    ax1.set_yscale(\"log\")\n",
    "    ax1.legend(loc=(0,1.02), fontsize=30, ncol=3, title_fontsize=30)\n",
    "    \n",
    "    ax2 = fig.add_subplot(3, 1, 2)\n",
    "    ax2.grid(True, which='both')\n",
    "    ax2.tick_params(axis=\"both\", which=\"both\", right=True, top=True, direction=\"in\", labelsize=30)\n",
    "    ax2.set_title(r\"Mean loss per batch [ref only]\", fontsize=30)\n",
    "    ax2.xaxis.set_ticklabels([])\n",
    "    draw_curve(ax2, ref_loss_record[\"Q1\"], \"o\", \"r\", \"$q_1$\")\n",
    "    draw_curve(ax2, ref_loss_record[\"Q2\"], \"x\", \"b\", \"$q_2$\")\n",
    "    ax2.set_yscale(\"log\")\n",
    "    \n",
    "    ax3 = fig.add_subplot(3, 1, 3)\n",
    "    ax3.grid(True, which='both')\n",
    "    ax3.tick_params(axis=\"both\", which=\"both\", right=True, top=True, direction=\"in\", labelsize=30)\n",
    "    ax3.set_title(r\"Max $|q(s,a)|$ over all batches\", fontsize=30)\n",
    "    ax3.set_xlabel(r\"Epoch\", labelpad=15, fontsize=30)\n",
    "    draw_curve(ax3, maxQ_record[\"Q1\"], \"o\", \"r\", \"$q_1$\")\n",
    "    draw_curve(ax3, maxQ_record[\"Q2\"], \"x\", \"b\", \"$q_2$\")\n",
    "    ax3.axhline(0, ls=\"--\", lw=2, c=\"gray\")\n",
    "    if np.isfinite(true_max_Q) :\n",
    "        ax3.axhline(true_max_Q, ls=\"--\", lw=2, c=\"gray\")\n",
    "        ax3.text(0, true_max_Q, \"True maximum\", fontsize=20, ha=\"left\", va=\"top\", c=\"k\")\n",
    "    \n",
    "    fig.subplots_adjust(hspace=0.2)\n",
    "    \n",
    "    if len(save) > 0 :\n",
    "        generate_directory_for_file_path(save, print_msg_on_dir_creation=verbose)\n",
    "        plt.savefig(save, bbox_inches=\"tight\", dpi=dpi)\n",
    "    if show :\n",
    "        plt.show(fig)\n",
    "    if close :\n",
    "        plt.close(fig)\n",
    "        \n",
    "    return fig, ax1, ax2, ax3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26f12f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Method for creating action-value model\n",
    "###\n",
    "\n",
    "def create_action_value_model(name=None) :\n",
    "    '''\n",
    "    Create a network for the action-value model.\n",
    "    Inputs:\n",
    "      > name, str, default=None\n",
    "        model name, if None then keras default is used\n",
    "    Returns:\n",
    "      > keras Model: uncompiled keras model (must be trained using custom loop)\n",
    "    '''\n",
    "    input_layer_x = Input ((1,))\n",
    "    input_layer_a = Input ((1,))\n",
    "    next_layer_x  = Rescaling(2./x_range, offset=-(x_max+x_min)/x_range)(input_layer_x)\n",
    "    next_layer_a  = Rescaling(2./a_range, offset=-(a_max+a_min)/a_range)(input_layer_a)\n",
    "    next_layer_x  = Dense(25, activation=\"relu\")(next_layer_x)\n",
    "    next_layer_a  = Dense(25, activation=\"relu\")(next_layer_a)\n",
    "    next_layer    = Concatenate()([next_layer_x, next_layer_a])\n",
    "    next_layer    = Dense(100, activation=\"relu\")(next_layer)\n",
    "    next_layer    = Dense(100, activation=\"relu\")(next_layer)\n",
    "    output_layer  = Dense(1, activation=\"linear\")(next_layer)\n",
    "    model         = Model([input_layer_x, input_layer_a], output_layer, name=name)\n",
    "    model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c466fc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 priority state-action pairs with returns:  -1.00  -1.00\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "###  Identify priority state/action pairs\n",
    "###\n",
    "\n",
    "priority_states, priority_actions, priority_returns = [], [], []\n",
    "num_priority_datapoints = 0\n",
    "for action in action_list :\n",
    "    x_initial = x_end - action\n",
    "    if is_terminal(x_initial) : continue\n",
    "    if is_out_of_bounds(x_initial) : continue\n",
    "    reward, _ = perform_action(x_initial, action)\n",
    "    num_priority_datapoints += 1\n",
    "    priority_states .append(x_initial)\n",
    "    priority_actions.append(action)\n",
    "    priority_returns.append(reward)\n",
    "    \n",
    "priority_states  = np.array(priority_states ).reshape((num_priority_datapoints, 1))\n",
    "priority_actions = np.array(priority_actions).reshape((num_priority_datapoints, 1))\n",
    "priority_returns = np.array(priority_returns).reshape((num_priority_datapoints, 1))\n",
    "\n",
    "print(f\"Found {num_priority_datapoints} priority state-action pairs with returns:  {'  '.join([f'{r:.2f}' for r in priority_returns.flatten()])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72c1c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Experiment initialisation functions\n",
    "###\n",
    "\n",
    "def initialise_keras_objects(bootstrap_method, learning_rate, tag=\"no_tag\") :\n",
    "    loss_fcn     = tf.keras.losses.MeanSquaredError()\n",
    "    q1_model     = create_action_value_model(name=f\"action_value_model_1_{tag}\")\n",
    "    optimizer_q1 = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    if bootstrap_method == \"self\" :\n",
    "        q2_model     = q1_model\n",
    "        optimizer_q2 = None\n",
    "    elif bootstrap_method == \"clone\" :\n",
    "        q2_model     = create_action_value_model(name=f\"action_value_model_1_{tag}_clone\")\n",
    "        optimizer_q2 = None\n",
    "    elif bootstrap_method == \"self\" :\n",
    "        q2_model     = create_action_value_model(name=f\"action_value_model_{tag}_2\")\n",
    "        optimizer_q2 = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else :\n",
    "        raise NotImplementedError\n",
    "    return loss_fcn, q1_model, q2_model, optimizer_q1, optimizer_q2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5f4e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Get global constants for experiments\n",
    "###\n",
    "\n",
    "# State-action pairs from which to form batches\n",
    "\n",
    "all_state_action_pairs = get_state_action_pairs()\n",
    "num_state_action_pairs = len(all_state_action_pairs)\n",
    "\n",
    "# True value function, also 'test' objects for evaluating keras models for comparison later\n",
    "\n",
    "test_states_flat = np.arange(x_min, x_max+1)\n",
    "num_test_states  = len(test_states_flat)\n",
    "test_states      = test_states_flat.reshape((num_test_states,1))\n",
    "test_states      = np.concatenate([test_states, test_states, test_states])\n",
    "test_actions_L   = np.full(fill_value=-1, shape=(num_test_states,1))\n",
    "test_actions_0   = np.full(fill_value=0 , shape=(num_test_states,1))\n",
    "test_actions_R   = np.full(fill_value=1 , shape=(num_test_states,1))\n",
    "test_actions     = np.concatenate([test_actions_L, test_actions_0, test_actions_R])\n",
    "true_q           = get_true_q(test_states.flatten(), test_actions.flatten())\n",
    "true_max_abs_q   = np.nanmax(np.fabs(true_q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84bb5579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment(run_config, run_idx=1, verbose=True, epoch_tracker=None) :\n",
    "            #  Extract configuration variables from dict\n",
    "    max_mse_true               = run_config.get(\"max_mse_true\", -np.inf)\n",
    "    max_epochs                 = run_config.get(\"max_epochs\")\n",
    "    batch_size                 = run_config.get(\"batch_size\")\n",
    "    learning_rate              = run_config.get(\"learning_rate\")\n",
    "    test_after_epochs          = run_config.get(\"test_after_epochs\")\n",
    "    plot_estimate_after_epochs = run_config.get(\"plot_estimate_after_epochs\")\n",
    "    plot_monitors_after_epochs = run_config.get(\"plot_monitors_after_epochs\")\n",
    "    save_objects_after_epochs  = run_config.get(\"save_objects_after_epochs\")\n",
    "    switch_after_epochs        = run_config.get(\"switch_after_epochs\")\n",
    "    clone_after_epochs         = run_config.get(\"clone_after_epochs\")\n",
    "    priority_weight            = run_config.get(\"priority_weight\")\n",
    "    bootstrap_method           = run_config.get(\"bootstrap_method\")\n",
    "    num_step_returns           = run_config.get(\"num_step_returns\")\n",
    "    run_tag                    = run_config.get(\"run_tag\")\n",
    "            #  Make sure bootstrap method is valid\n",
    "    if bootstrap_method not in [\"clone\", \"self\", \"other\"] :\n",
    "        raise NotImplementedError(f\"Bootstrap method {bootstrap_method} not implemented\")\n",
    "            #  Resolve top directory based on configured run tag and run index\n",
    "    top_directory = f\"figures/Helicopter_NB0/{run_tag}/experiment_{run_idx}\"\n",
    "            #  Initialise keras objects\n",
    "    loss_fcn, q1_model, q2_model, optimizer_q1, optimizer_q2 = initialise_keras_objects(bootstrap_method, learning_rate, tag=f\"{run_tag}_{run_idx}\")\n",
    "            #  Print config to file\n",
    "    create_config(f\"{top_directory}/config.txt\", run_config, q1_model, q2_model, optimizer_q1, optimizer_q2, to_stdout=verbose)\n",
    "            #  Initialise monitors\n",
    "    model_key_q1, model_key_q2 = \"Q1\", \"Q2\"  # used to keep track of which model is being traing each epoch\n",
    "    loss_record     = {model_key_q1:[], model_key_q2:[]}\n",
    "    ref_loss_record = {model_key_q1:[], model_key_q2:[]}\n",
    "    maxQ_record     = {model_key_q1:[], model_key_q2:[]}\n",
    "    epochs_record   = [0]\n",
    "    q1_record       = [q1_model.predict([test_states, test_actions]).flatten()]\n",
    "    q2_record       = [q2_model.predict([test_states, test_actions]).flatten()]\n",
    "    mse_true        = get_mse(q1_record[-1], true_q)\n",
    "    mse_true_record = []\n",
    "            #  Create methods to help monitoring\n",
    "    def test_and_record(epoch_idx) :\n",
    "        epochs_record.append(epoch_idx)\n",
    "        q1_record      .append(q1_model.predict([test_states, test_actions]).flatten())\n",
    "        q2_record      .append(q2_model.predict([test_states, test_actions]).flatten())\n",
    "        mse_true_record.append(get_mse(q1_record[-1], true_q))\n",
    "        return mse_true_record[-1]\n",
    "    def plot_value_functions(epoch_idx) :\n",
    "        create_value_estimate_plot(test_states_flat, true_q, target_q, q1_record[-1], q2_record[-1], \n",
    "                                   epoch_idx=epoch_idx, verbose=verbose, show=False, close=True, \n",
    "                                   save=f\"{top_directory}/value_estimates_epoch{epoch_idx}.png\")\n",
    "    def plot_training_curves() :\n",
    "        create_training_curves_plot(loss_record, ref_loss_record, maxQ_record, true_max_Q=true_max_abs_q,\n",
    "                                    verbose=verbose, show=False, close=True, \n",
    "                                    save=f\"{top_directory}/training_curves.pdf\")\n",
    "    def save_objects() :\n",
    "        to_save = {\"run_config\":run_config, \"run_idx\":run_idx, \"epoch_idx\":epoch_idx, \"loss_record\":loss_record,\n",
    "                   \"ref_loss_record\":ref_loss_record, \"maxQ_record\":maxQ_record, \"epochs_record\":epochs_record,\n",
    "                   \"q1_record\":q1_record, \"q2_record\":q2_record}\n",
    "        fname   = f\"{top_directory}/saved_objects.pickle\"\n",
    "        generate_directory_for_file_path(fname, print_msg_on_dir_creation=verbose)\n",
    "        pickle.dump(to_save, open(fname,\"wb\"))\n",
    "        tf_log_level = tf.get_logger().level\n",
    "        tf.get_logger().setLevel('WARNING')\n",
    "        q1_model.save(f\"{top_directory}/q1_model\")\n",
    "        q2_model.save(f\"{top_directory}/q2_model\")\n",
    "        tf.get_logger().setLevel(tf_log_level)\n",
    "    \n",
    "            #  Start training\n",
    "    epoch_idx, start_time  = 0, time.time()\n",
    "    state_action_pairs     = all_state_action_pairs.copy()\n",
    "    state_action_pair_idcs = np.arange(num_state_action_pairs)\n",
    "    target_q               = np.ones_like(true_q)*np.nan\n",
    "    while (epoch_idx < max_epochs or max_epochs < 0) and mse_true > max_mse_true :\n",
    "\n",
    "        # Determine whether to test and save value function estimates\n",
    "        if test_after_epochs > 0 and epoch_idx % test_after_epochs == 0 :\n",
    "            mse_true = test_and_record(epoch_idx)\n",
    "\n",
    "        # Determine whether to plot value function estimates\n",
    "        if plot_estimate_after_epochs > 0 and epoch_idx % plot_estimate_after_epochs == 0 :\n",
    "            if epochs_record[-1] != epoch_idx :\n",
    "                print(f\"WARNING: plot value function is out of date at epoch index ({epochs_record[-1]} < {epoch_idx})\")\n",
    "            plot_value_functions(epoch_idx)\n",
    "            \n",
    "        # Determine whether to plot training curves\n",
    "        if plot_monitors_after_epochs > 0 and epoch_idx > 0 and epoch_idx % plot_monitors_after_epochs == 0 :\n",
    "            plot_training_curves()\n",
    "\n",
    "        # Determine whether to save objects\n",
    "        if save_objects_after_epochs > 0 and epoch_idx % save_objects_after_epochs == 0 :\n",
    "            save_objects()\n",
    "            \n",
    "        # Determine whether to switch q1 and q2\n",
    "        if bootstrap_method == \"other\" and switch_after_epochs > 0 and epoch_idx > 0 and epoch_idx % switch_after_epochs == 0 :\n",
    "            model_key_q1, model_key_q2 = model_key_q2, model_key_q1\n",
    "            q1_model, q2_model         = q2_model, q1_model\n",
    "            optimizer_q1, optimizer_q2 = optimizer_q2, optimizer_q1\n",
    "\n",
    "        # Determine whether to copy q1 to q2\n",
    "        if bootstrap_method == \"clone\" and clone_after_epochs > 0 and epoch_idx % clone_after_epochs == 0 :\n",
    "            q2_model.set_weights(q1_model.get_weights()) \n",
    "\n",
    "        if verbose :\n",
    "            sys.stdout.write(f\"Epoch {epoch_idx+1} / {max_epochs}  [t={time.time()-start_time:.2f}s]\")\n",
    "\n",
    "        # Shuffle states and loop over batches, performing one gradient update per batch\n",
    "        # - this has lower variance than applying one gradient update per sample, and also allows parallelisation\n",
    "        np.random.shuffle(state_action_pair_idcs)\n",
    "        state_action_pairs = state_action_pairs[state_action_pair_idcs]\n",
    "        epoch_losses, ref_losses, max_abs_q_values = [], [], []\n",
    "        for batch_idx in range(math.ceil(num_state_action_pairs/batch_size)) :\n",
    "            # Resolve sample indices to be used for this batch update\n",
    "            batch_idx_low, batch_idx_high = batch_idx*batch_size, min((batch_idx+1)*batch_size, num_state_action_pairs)\n",
    "            actual_batch_size = batch_idx_high - batch_idx_low\n",
    "            if actual_batch_size == 0 : continue\n",
    "\n",
    "            # Update the current epoch message to keep track of batch progress \n",
    "            if verbose :\n",
    "                sys.stdout.write(f\"\\rEpoch {epoch_idx+1} / {max_epochs} batch indices ({batch_idx_low}, {batch_idx_high}) / {num_state_action_pairs}  [t={time.time()-start_time:.2f}s]\")\n",
    "\n",
    "            # Get batch of states and generate a random exploration action for each\n",
    "            batch_state_action_pairs = state_action_pairs[batch_idx_low:batch_idx_high]\n",
    "\n",
    "            # For each state/action pair, apply the action to get the immediate reward, and also find the\n",
    "            # greedy action in the next state from which to calculate bootstraps\n",
    "            batch_emp_returns, batch_states_p, batch_actions_p, batch_state_p_is_terminal = [], [], [], []\n",
    "            for state, action in batch_state_action_pairs :\n",
    "                state_p, action_p, emp_return, step_discount = state, action, 0., 1.\n",
    "                for step_idx in range(num_step_returns) :\n",
    "                    if not is_terminal(state_p) :\n",
    "                        step_reward, state_p = perform_action(state_p, action_p)\n",
    "                        action_p             = get_greedy_action(state_p, q1_model)\n",
    "                        emp_return          += step_discount*step_reward\n",
    "                    step_discount *= gamma\n",
    "                batch_emp_returns        .append(emp_return)\n",
    "                batch_states_p           .append([state_p])\n",
    "                batch_actions_p          .append([action_p])\n",
    "                batch_state_p_is_terminal.append(True if is_terminal(state_p) else False)\n",
    "            batch_emp_returns, batch_states_p            = np.array(batch_emp_returns), np.array(batch_states_p)\n",
    "            batch_actions_p  , batch_state_p_is_terminal = np.array(batch_actions_p  ), np.array(batch_state_p_is_terminal)\n",
    "\n",
    "            # Get inputs and ensure correct shapes\n",
    "            batch_states  = batch_state_action_pairs[:,0].reshape((actual_batch_size,1))\n",
    "            batch_actions = batch_state_action_pairs[:,1].reshape((actual_batch_size,1))\n",
    "\n",
    "            # Calculate obs_returns using the observed immediate rewards plut gamma * bootstrap values\n",
    "            batch_bootstrap_values = q2_model.predict([batch_states_p, batch_actions_p]).flatten()\n",
    "            batch_bootstrap_values = np.array([0. if is_term else q for is_term,q in zip(batch_state_p_is_terminal,batch_bootstrap_values)])        \n",
    "            batch_obs_returns      = batch_emp_returns + step_discount * batch_bootstrap_values\n",
    "            \n",
    "            # Make sure output shapes are correctly formatted                    \n",
    "            batch_obs_returns = batch_obs_returns.reshape((actual_batch_size,1))\n",
    "\n",
    "            # Store target q for later plot (tricky to resolve correct index since we shuffled state-action pairs)\n",
    "            for sample_idx, (state, action) in enumerate(batch_state_action_pairs) :\n",
    "                test_idx = num_states * (action+1) + state\n",
    "                target_q[test_idx] = batch_obs_returns[sample_idx]\n",
    "\n",
    "            # Calculate weights to apply to regular batch and priority samples\n",
    "            batch_weights    = np.full(shape=(actual_batch_size      ,), fill_value=1./actual_batch_size      )\n",
    "            priority_weights = np.full(shape=(num_priority_datapoints,), fill_value=1./num_priority_datapoints)\n",
    "\n",
    "            # Concatenate regular batch and priority samples\n",
    "            train_weights, train_states, train_actions, train_obs_returns = batch_weights, batch_states, batch_actions, batch_obs_returns\n",
    "            if priority_weight > 0 and priority_weight <= 1 :\n",
    "                batch_weights    *= (1.-priority_weight)\n",
    "                priority_weights *= priority_weight\n",
    "                train_weights     = np.concatenate([batch_weights    , priority_weights])\n",
    "                train_states      = np.concatenate([batch_states     , priority_states ])\n",
    "                train_actions     = np.concatenate([batch_actions    , priority_actions])\n",
    "                train_obs_returns = np.concatenate([batch_obs_returns, priority_returns])\n",
    "\n",
    "            # Train weights must be normalised to num samples instead of 1 to recover the expected loss value\n",
    "            train_weights = train_weights * len(train_weights) / train_weights.sum()\n",
    "\n",
    "            # ref_loss is the loss over only the priority state/action pairs, before gradient updates\n",
    "            ref_returns = q1_model([priority_states, priority_actions], training=False)\n",
    "            ref_loss    = loss_fcn(priority_returns.reshape((num_priority_datapoints,1)), ref_returns.numpy())\n",
    "            ref_losses.append(ref_loss)\n",
    "\n",
    "            # Apply gradient updates and store monitor values\n",
    "            with tf.GradientTape() as tape:\n",
    "                train_pred_returns = q1_model([train_states, train_actions], training=True)\n",
    "                loss_value         = loss_fcn(train_obs_returns, train_pred_returns, sample_weight=train_weights)\n",
    "                grads              = tape.gradient(loss_value, q1_model.trainable_weights)\n",
    "                optimizer_q1.apply_gradients(zip(grads, q1_model.trainable_weights))\n",
    "                epoch_losses.append(loss_value.numpy())\n",
    "                max_abs_q_values.append(np.fabs(train_pred_returns.numpy()).max())\n",
    "\n",
    "        # Print epoch summary and end stdout line to keep this on screen\n",
    "        epoch_mean_loss, epoch_mean_ref_loss, epoch_maxQ = np.mean(epoch_losses), np.mean(ref_losses), np.max(max_abs_q_values)\n",
    "        if verbose :\n",
    "            sys.stdout.write(f\"\\rEpoch {epoch_idx+1} / {max_epochs}  [t={time.time()-start_time:.2f}s]  <loss = {epoch_mean_loss:.5f}, ref_loss = {epoch_mean_ref_loss:.5f}, max_Q = {epoch_maxQ:.1f},  mse_true = {mse_true:.3f}>\".ljust(100)+\"\\n\")\n",
    "        loss_record    [model_key_q1].append((epoch_idx, epoch_mean_loss    ))\n",
    "        ref_loss_record[model_key_q1].append((epoch_idx, epoch_mean_ref_loss))\n",
    "        maxQ_record    [model_key_q1].append((epoch_idx, epoch_maxQ         ))\n",
    "\n",
    "        # Manually iterate epoch index and make sure stdout not lagging\n",
    "        if type(epoch_tracker) != type(None) :\n",
    "            with epoch_tracker.get_lock():\n",
    "                epoch_tracker.value += 1\n",
    "        epoch_idx += 1\n",
    "        \n",
    "    # Save final results\n",
    "    test_and_record(epoch_idx)\n",
    "    plot_value_functions(epoch_idx)\n",
    "    plot_training_curves()\n",
    "    save_objects()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "411801a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Methods for running experiments in threads\n",
    "###\n",
    "\n",
    "\n",
    "def kill_threads(threads=None, verbose=False) :\n",
    "    '''\n",
    "    Kills all running threads\n",
    "    '''\n",
    "    if type(threads) is type(None) :\n",
    "        global all_threads\n",
    "        threads = all_threads\n",
    "    for thread in threads :\n",
    "        if not hasattr(thread, \"kill\") :\n",
    "            continue\n",
    "        thread.kill(verbose=verbose)\n",
    "        \n",
    "        \n",
    "class BaseThread(Thread) :\n",
    "    \n",
    "    def __init__(self):\n",
    "        Thread.__init__(self)\n",
    "        self.killed = False\n",
    "        self.lock   = Lock()\n",
    "        global all_threads\n",
    "        all_threads.append(self)\n",
    "        \n",
    "    def kill(self, killed=True, verbose=False) :\n",
    "        if not self.killed and killed and verbose :\n",
    "            self.info(f\"Killing thread: {self.name}\\n\")\n",
    "        self.killed = killed\n",
    "            \n",
    "    def info(self, message) :\n",
    "        self.lock.acquire()\n",
    "        sys.stdout.write(f\"{message}\")\n",
    "        sys.stdout.flush()\n",
    "        self.lock.release()\n",
    "    \n",
    "    \n",
    "class WorkerThread(BaseThread):\n",
    "    \n",
    "    def __init__(self, num_processes, run_config={}):\n",
    "        BaseThread.__init__(self)\n",
    "        self.num_processes = num_processes\n",
    "        self.run_config    = run_config\n",
    "        \n",
    "    def run(self):\n",
    "        self.kill(False)\n",
    "        self.is_running = True\n",
    "        self.processes  = []\n",
    "        for proc_idx in range(self.num_processes) :\n",
    "            run_idx         = proc_idx + 1\n",
    "            epoch_tracker   = Value('i', -1)\n",
    "            p               = Process(target=run_experiment, args=(self.run_config, run_idx, False, epoch_tracker))\n",
    "            p.epoch_tracker = epoch_tracker\n",
    "            p.start()\n",
    "            self.processes.append(p)\n",
    "        for p in self.processes :\n",
    "            p.join()\n",
    "        self.is_running = False\n",
    "       \n",
    "    \n",
    "class MonitorThread(BaseThread):\n",
    "    \n",
    "    def __init__(self, worker, interval=1):\n",
    "        BaseThread.__init__(self)\n",
    "        self.worker   = worker\n",
    "        self.interval = interval\n",
    "        \n",
    "    def run(self):\n",
    "        self.kill(False)\n",
    "        while worker.is_running and not self.killed :\n",
    "            self.info(f\"\\r{len(worker.processes)} processes running at epochs [{', '.join([str(i) for p.epoch_tracker.value in worker.processes])}] / {worker.run_config.get('max_epochs',np.nan)}\")\n",
    "            time.sleep(self.interval)\n",
    "        self.info(\"\\n\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "356242ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure\n",
    "\n",
    "run_config_baseline = dict(\n",
    "    max_mse_true               = 0.05        ,\n",
    "    max_epochs                 = 400         ,\n",
    "    batch_size                 = 10          ,\n",
    "    learning_rate              = 1e-2        ,\n",
    "    test_after_epochs          = 1           ,\n",
    "    plot_estimate_after_epochs = 5           ,\n",
    "    plot_monitors_after_epochs = 10          ,\n",
    "    save_objects_after_epochs  = 10          ,\n",
    "    switch_after_epochs        = -1          ,\n",
    "    clone_after_epochs         = 5           ,\n",
    "    priority_weight            = 0.3         ,\n",
    "    bootstrap_method           = \"clone\"     ,       # [\"clone\", \"self\", \"other\"]\n",
    "    num_step_returns           = 1           ,\n",
    "    run_tag                    = \"baseline\"\n",
    ")\n",
    "\n",
    "run_config_multistep = dict(\n",
    "    max_mse_true               = 0.05        ,\n",
    "    max_epochs                 = 400         ,\n",
    "    batch_size                 = 10          ,\n",
    "    learning_rate              = 1e-2        ,\n",
    "    test_after_epochs          = 1           ,\n",
    "    plot_estimate_after_epochs = 5           ,\n",
    "    plot_monitors_after_epochs = 10          ,\n",
    "    save_objects_after_epochs  = 10          ,\n",
    "    switch_after_epochs        = -1          ,\n",
    "    clone_after_epochs         = 5           ,\n",
    "    priority_weight            = 0.3         ,\n",
    "    bootstrap_method           = \"clone\"     ,       # [\"clone\", \"self\", \"other\"]\n",
    "    num_step_returns           = 3           ,\n",
    "    run_tag                    = \"multistep\"\n",
    ")\n",
    "\n",
    "run_config_no_priority = dict(\n",
    "    max_mse_true               = 0.05        ,\n",
    "    max_epochs                 = 400         ,\n",
    "    batch_size                 = 10          ,\n",
    "    learning_rate              = 1e-2        ,\n",
    "    test_after_epochs          = 1           ,\n",
    "    plot_estimate_after_epochs = 5           ,\n",
    "    plot_monitors_after_epochs = 10          ,\n",
    "    save_objects_after_epochs  = 10          ,\n",
    "    switch_after_epochs        = -1          ,\n",
    "    clone_after_epochs         = 5           ,\n",
    "    priority_weight            = -1          ,\n",
    "    bootstrap_method           = \"clone\"     ,       # [\"clone\", \"self\", \"other\"]\n",
    "    num_step_returns           = 1           ,\n",
    "    run_tag                    = \"no_priority\"\n",
    ")\n",
    "\n",
    "run_config_self_bootstrap = dict(\n",
    "    max_mse_true               = 0.05        ,\n",
    "    max_epochs                 = 400         ,\n",
    "    batch_size                 = 10          ,\n",
    "    learning_rate              = 1e-2        ,\n",
    "    test_after_epochs          = 1           ,\n",
    "    plot_estimate_after_epochs = 5           ,\n",
    "    plot_monitors_after_epochs = 10          ,\n",
    "    save_objects_after_epochs  = 10          ,\n",
    "    switch_after_epochs        = -1          ,\n",
    "    clone_after_epochs         = -1          ,\n",
    "    priority_weight            = 0.3         ,\n",
    "    bootstrap_method           = \"self\"      ,       # [\"clone\", \"self\", \"other\"]\n",
    "    num_step_returns           = 1           ,\n",
    "    run_tag                    = \"self_bootstrap\"\n",
    ")\n",
    "\n",
    "run_config_big_batch = dict(\n",
    "    max_mse_true               = 0.05        ,\n",
    "    max_epochs                 = 400         ,\n",
    "    batch_size                 = 999         ,\n",
    "    learning_rate              = 1e-2        ,\n",
    "    test_after_epochs          = 1           ,\n",
    "    plot_estimate_after_epochs = 5           ,\n",
    "    plot_monitors_after_epochs = 10          ,\n",
    "    save_objects_after_epochs  = 10          ,\n",
    "    switch_after_epochs        = -1          ,\n",
    "    clone_after_epochs         = 5           ,\n",
    "    priority_weight            = 0.3         ,\n",
    "    bootstrap_method           = \"clone\"     ,       # [\"clone\", \"self\", \"other\"]\n",
    "    num_step_returns           = 1           ,\n",
    "    run_tag                    = \"big_batch\"\n",
    ")\n",
    "\n",
    "run_config_standard_Q = dict(\n",
    "    max_mse_true               = 0.05        ,\n",
    "    max_epochs                 = 150         ,\n",
    "    batch_size                 = 1           ,\n",
    "    learning_rate              = 1e-2        ,\n",
    "    test_after_epochs          = 1           ,\n",
    "    plot_estimate_after_epochs = 1           ,\n",
    "    plot_monitors_after_epochs = 10          ,\n",
    "    save_objects_after_epochs  = 10          ,\n",
    "    switch_after_epochs        = -1          ,\n",
    "    clone_after_epochs         = 1           ,\n",
    "    priority_weight            = 0.          ,\n",
    "    bootstrap_method           = \"clone\"     ,       # [\"clone\", \"self\", \"other\"]\n",
    "    num_step_returns           = 1           ,\n",
    "    run_tag                    = \"standard_Q\"\n",
    ")\n",
    "\n",
    "run_config_clone_20 = dict(\n",
    "    max_mse_true               = 0.05        ,\n",
    "    max_epochs                 = 400         ,\n",
    "    batch_size                 = 10          ,\n",
    "    learning_rate              = 1e-2        ,\n",
    "    test_after_epochs          = 1           ,\n",
    "    plot_estimate_after_epochs = 5           ,\n",
    "    plot_monitors_after_epochs = 10          ,\n",
    "    save_objects_after_epochs  = 10          ,\n",
    "    switch_after_epochs        = -1          ,\n",
    "    clone_after_epochs         = 20          ,\n",
    "    priority_weight            = 0.3         ,\n",
    "    bootstrap_method           = \"clone\"     ,       # [\"clone\", \"self\", \"other\"]\n",
    "    num_step_returns           = 1           ,\n",
    "    run_tag                    = \"clone_20\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc525304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_runs = 3\n",
    "\n",
    "for run_idx in range(num_runs) :\n",
    "    run_experiment(run_config_baseline, run_idx+1, verbose=True)\n",
    "\n",
    "for run_idx in range(num_runs) :\n",
    "    run_experiment(run_config_multistep, run_idx+1, verbose=True)\n",
    "\n",
    "for run_idx in range(num_runs) :\n",
    "    run_experiment(run_config_no_priority, run_idx+1, verbose=True)\n",
    "\n",
    "for run_idx in range(num_runs) :\n",
    "    run_experiment(run_config_self_bootstrap, run_idx+1, verbose=True)\n",
    "\n",
    "for run_idx in range(num_runs) :\n",
    "    run_experiment(run_config_big_batch, run_idx+1, verbose=True)\n",
    "\n",
    "for run_idx in range(num_runs) :\n",
    "    run_experiment(run_config_standard_Q, run_idx+1, verbose=True)\n",
    "\n",
    "for run_idx in range(num_runs) :\n",
    "    run_experiment(run_config_clone_20, run_idx+1, verbose=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cc6905c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory figures/Helicopter_NB0/standard_Q/experiment_1 created\n",
      "==================================================================================================================\n",
      "Environment config:\n",
      "> distance_to_end: 13\n",
      "> game_board_pad_size: 3\n",
      "> horizontal_size: 20\n",
      "> reward_per_turn: -1.0\n",
      "> lambda_dx: 0.0\n",
      "> lambda_b: -1.0\n",
      "> gamma: 1.0\n",
      "> x_min: 0\n",
      "> x_max: 19\n",
      "> x_range: 19\n",
      "> x_start: 3\n",
      "> x_end: 16\n",
      "> action_list: [-1  0  1]\n",
      "==================================================================================================================\n",
      "Training config:\n",
      "> Stop training when mse_true exceeds 0.05\n",
      "> Using 1 step empirical returns\n",
      "> Using bootstrap method: clone\n",
      "> Using epochs of length None\n",
      "> Updating gradient every batch of size 1\n",
      "> Using optimizer_q1 <keras.optimizer_v2.gradient_descent.SGD object at 0x2bface8e0> with learning rate 0.01\n",
      "> Using optimizer_q2 None with learning rate 0.01\n",
      "> Swapping q1 and q2 every -1 epochs\n",
      "> Cloning q2 from q1 every 1 epochs\n",
      "> Assigning a weight of 0.0 to anchoring state/action pairs\n",
      "==================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/ipykernel_58834/1750174422.py:191: RuntimeWarning: All-NaN slice encountered\n",
      "  y_min   = np.nanmin([0, np.nanmin(true_q), np.nanmin(target_q), np.nanmin(q_model), np.nanmin(bs_model)])\n",
      "/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/ipykernel_58834/1750174422.py:192: RuntimeWarning: All-NaN slice encountered\n",
      "  y_max   = np.nanmax([0, np.nanmax(true_q), np.nanmax(target_q), np.nanmax(q_model), np.nanmax(bs_model)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 150  [t=5.40s]  <loss = 0.22965, ref_loss = 0.21672, max_Q = 1.1,  mse_true = 92.668>    \n",
      "Epoch 2 / 150  [t=10.43s]  <loss = 0.19632, ref_loss = 0.83732, max_Q = 2.2,  mse_true = 76.534>   \n",
      "Epoch 3 / 150  [t=14.66s]  <loss = 0.25019, ref_loss = 3.04245, max_Q = 3.1,  mse_true = 64.762>   \n",
      "Epoch 4 / 150  [t=18.75s]  <loss = 0.39396, ref_loss = 7.95363, max_Q = 4.1,  mse_true = 53.640>   \n",
      "Epoch 5 / 150  [t=22.99s]  <loss = 0.48947, ref_loss = 7.80177, max_Q = 4.4,  mse_true = 50.882>   \n",
      "Epoch 6 / 150  [t=26.94s]  <loss = 0.77316, ref_loss = 11.40518, max_Q = 5.5,  mse_true = 41.840>  \n",
      "Epoch 7 / 150  [t=31.15s]  <loss = 1.02149, ref_loss = 18.89093, max_Q = 6.7,  mse_true = 34.620>  \n",
      "Epoch 8 / 150  [t=35.34s]  <loss = 1.05905, ref_loss = 16.29185, max_Q = 7.4,  mse_true = 28.567>  \n",
      "Epoch 9 / 150  [t=39.38s]  <loss = 1.95633, ref_loss = 22.81470, max_Q = 9.6,  mse_true = 23.948>  \n",
      "Epoch 10 / 150  [t=43.60s]  <loss = 2.17651, ref_loss = 31.20228, max_Q = 10.1,  mse_true = 20.863>\n",
      "Epoch 11 / 150  [t=49.16s]  <loss = 2.14339, ref_loss = 30.66537, max_Q = 10.5,  mse_true = 18.051>\n",
      "Epoch 12 / 150  [t=53.22s]  <loss = 3.82613, ref_loss = 53.34054, max_Q = 14.4,  mse_true = 17.393>\n",
      "Epoch 13 / 150  [t=57.37s]  <loss = 4.03668, ref_loss = 63.14743, max_Q = 12.7,  mse_true = 17.722>\n",
      "Epoch 14 / 150  [t=61.40s]  <loss = 4.14831, ref_loss = 71.79382, max_Q = 15.3,  mse_true = 19.852>\n",
      "Epoch 15 / 150  [t=65.66s]  <loss = 4.69812, ref_loss = 79.61000, max_Q = 15.0,  mse_true = 20.572>\n",
      "Epoch 16 / 150  [t=69.71s]  <loss = 4.21834, ref_loss = 67.18871, max_Q = 15.5,  mse_true = 19.524>\n",
      "Epoch 17 / 150  [t=73.97s]  <loss = 5.35262, ref_loss = 87.25067, max_Q = 15.9,  mse_true = 24.367>\n",
      "Epoch 18 / 150  [t=78.04s]  <loss = 4.22179, ref_loss = 91.49799, max_Q = 16.2,  mse_true = 24.920>\n",
      "Epoch 19 / 150  [t=82.68s]  <loss = 7.30664, ref_loss = 116.09882, max_Q = 21.2,  mse_true = 30.352>\n",
      "Epoch 20 / 150  [t=86.88s]  <loss = 7.51265, ref_loss = 133.02878, max_Q = 17.8,  mse_true = 38.687>\n",
      "Epoch 21 / 150  [t=92.75s]  <loss = 8.17019, ref_loss = 144.08388, max_Q = 18.5,  mse_true = 47.289>\n",
      "Epoch 22 / 150  [t=96.85s]  <loss = 8.29444, ref_loss = 149.30458, max_Q = 20.7,  mse_true = 54.464>\n",
      "Epoch 23 / 150  [t=101.26s]  <loss = 10.42619, ref_loss = 179.24419, max_Q = 18.2,  mse_true = 63.404>\n",
      "Epoch 24 / 150  [t=105.81s]  <loss = 8.77309, ref_loss = 200.15280, max_Q = 20.0,  mse_true = 73.353>\n",
      "Epoch 25 / 150  [t=110.58s]  <loss = 2.57063, ref_loss = 54.25761, max_Q = 11.1,  mse_true = 18.966>\n",
      "Epoch 26 / 150  [t=114.64s]  <loss = 3.27474, ref_loss = 64.94927, max_Q = 12.2,  mse_true = 18.910>\n",
      "Epoch 27 / 150  [t=119.07s]  <loss = 3.75632, ref_loss = 75.08094, max_Q = 13.3,  mse_true = 20.416>\n",
      "Epoch 28 / 150  [t=123.14s]  <loss = 3.66023, ref_loss = 91.51379, max_Q = 14.7,  mse_true = 22.988>\n",
      "Epoch 29 / 150  [t=127.36s]  <loss = 12.53965, ref_loss = 103.13199, max_Q = 25.1,  mse_true = 37.523>\n",
      "Epoch 30 / 150  [t=131.36s]  <loss = 30.73484, ref_loss = 137.21542, max_Q = 31.1,  mse_true = 38.346>\n",
      "Epoch 31 / 150  [t=136.95s]  <loss = 3.84231, ref_loss = 63.49448, max_Q = 15.1,  mse_true = 18.612>\n",
      "Epoch 32 / 150  [t=141.26s]  <loss = 4.23658, ref_loss = 75.99378, max_Q = 15.1,  mse_true = 24.548>\n",
      "Epoch 33 / 150  [t=145.27s]  <loss = 4.03488, ref_loss = 55.58844, max_Q = 17.4,  mse_true = 16.298>\n",
      "Epoch 34 / 150  [t=149.56s]  <loss = 3.47831, ref_loss = 54.10466, max_Q = 17.8,  mse_true = 22.279>\n",
      "Epoch 35 / 150  [t=153.55s]  <loss = 4.58766, ref_loss = 74.09620, max_Q = 19.9,  mse_true = 31.414>\n",
      "Epoch 36 / 150  [t=157.46s]  <loss = 12.56091, ref_loss = 105.46809, max_Q = 26.9,  mse_true = 49.966>\n",
      "Epoch 37 / 150  [t=161.72s]  <loss = 23.29218, ref_loss = 179.08035, max_Q = 27.1,  mse_true = 68.638>\n",
      "Epoch 38 / 150  [t=165.72s]  <loss = 11.41233, ref_loss = 141.46133, max_Q = 23.8,  mse_true = 51.544>\n",
      "Epoch 39 / 150  [t=170.03s]  <loss = 13.14257, ref_loss = 172.53789, max_Q = 29.1,  mse_true = 78.841>\n",
      "Epoch 40 / 150  [t=174.04s]  <loss = 6.63343, ref_loss = 131.88068, max_Q = 13.9,  mse_true = 36.150>\n",
      "Epoch 41 / 150  [t=179.60s]  <loss = 6.82093, ref_loss = 136.79677, max_Q = 15.3,  mse_true = 42.367>\n",
      "Epoch 42 / 150  [t=183.95s]  <loss = 8.42581, ref_loss = 161.32005, max_Q = 16.7,  mse_true = 50.693>\n",
      "Epoch 43 / 150  [t=188.08s]  <loss = 8.56652, ref_loss = 186.65251, max_Q = 17.4,  mse_true = 61.922>\n",
      "Epoch 44 / 150  [t=192.06s]  <loss = 8.85229, ref_loss = 160.44656, max_Q = 20.9,  mse_true = 67.386>\n",
      "Epoch 45 / 150  [t=196.44s]  <loss = 11.14033, ref_loss = 183.81523, max_Q = 21.3,  mse_true = 78.946>\n",
      "Epoch 46 / 150  [t=200.51s]  <loss = 11.14048, ref_loss = 170.44951, max_Q = 22.9,  mse_true = 87.925>\n",
      "Epoch 47 / 150  [t=204.65s]  <loss = 12.25735, ref_loss = 240.96446, max_Q = 24.4,  mse_true = 111.337>\n",
      "Epoch 48 / 150  [t=209.01s]  <loss = 5.92566, ref_loss = 121.08821, max_Q = 16.6,  mse_true = 40.467>\n",
      "Epoch 49 / 150  [t=213.01s]  <loss = 6.26971, ref_loss = 123.48434, max_Q = 17.9,  mse_true = 47.192>\n",
      "Epoch 50 / 150  [t=217.17s]  <loss = 6.99911, ref_loss = 139.94453, max_Q = 19.1,  mse_true = 54.647>\n",
      "Epoch 51 / 150  [t=223.65s]  <loss = 8.28071, ref_loss = 105.70150, max_Q = 22.0,  mse_true = 58.490>\n",
      "Epoch 52 / 150  [t=227.91s]  <loss = 8.31494, ref_loss = 131.88603, max_Q = 23.8,  mse_true = 72.113>\n",
      "Epoch 53 / 150  [t=232.37s]  <loss = 6.20063, ref_loss = 140.12132, max_Q = 19.4,  mse_true = 61.272>\n",
      "Epoch 54 / 150  [t=237.24s]  <loss = 6.91331, ref_loss = 112.34746, max_Q = 19.2,  mse_true = 46.274>\n",
      "Epoch 55 / 150  [t=241.63s]  <loss = 4.28953, ref_loss = 85.13750, max_Q = 18.0,  mse_true = 26.360>\n",
      "Epoch 56 / 150  [t=245.82s]  <loss = 4.24020, ref_loss = 58.53820, max_Q = 20.7,  mse_true = 25.897>\n",
      "Epoch 57 / 150  [t=250.48s]  <loss = 4.18794, ref_loss = 68.63947, max_Q = 20.9,  mse_true = 33.871>\n",
      "Epoch 58 / 150  [t=254.65s]  <loss = 3.81042, ref_loss = 63.70629, max_Q = 20.5,  mse_true = 35.349>\n",
      "Epoch 59 / 150  [t=258.94s]  <loss = 13.28944, ref_loss = 101.22281, max_Q = 26.1,  mse_true = 64.694>\n",
      "Epoch 60 / 150  [t=263.42s]  <loss = 7.73117, ref_loss = 96.11526, max_Q = 24.9,  mse_true = 70.789>\n",
      "Epoch 61 / 150  [t=269.22s]  <loss = 17.45018, ref_loss = 92.30222, max_Q = 29.8,  mse_true = 87.444>\n",
      "Epoch 62 / 150  [t=273.87s]  <loss = 28.71251, ref_loss = 86.54092, max_Q = 26.5,  mse_true = 90.051>\n",
      "Epoch 63 / 150  [t=278.13s]  <loss = 7.80615, ref_loss = 93.13022, max_Q = 19.4,  mse_true = 42.491>\n",
      "Epoch 64 / 150  [t=283.07s]  <loss = 5.16241, ref_loss = 82.83347, max_Q = 21.4,  mse_true = 58.240>\n",
      "Epoch 65 / 150  [t=287.20s]  <loss = 6.27483, ref_loss = 114.26978, max_Q = 21.7,  mse_true = 71.207>\n",
      "Epoch 66 / 150  [t=291.37s]  <loss = 7.29507, ref_loss = 151.51898, max_Q = 21.9,  mse_true = 71.360>\n",
      "Epoch 67 / 150  [t=296.13s]  <loss = 7.29471, ref_loss = 136.91911, max_Q = 24.1,  mse_true = 81.575>\n",
      "Epoch 68 / 150  [t=300.47s]  <loss = 14.24130, ref_loss = 127.91738, max_Q = 27.6,  mse_true = 100.674>\n",
      "Epoch 69 / 150  [t=304.81s]  <loss = 18.29210, ref_loss = 113.31084, max_Q = 30.6,  mse_true = 103.113>\n",
      "Epoch 70 / 150  [t=309.22s]  <loss = 9.54693, ref_loss = 120.64549, max_Q = 28.6,  mse_true = 122.262>\n",
      "Epoch 71 / 150  [t=315.65s]  <loss = 10.72884, ref_loss = 108.90692, max_Q = 28.4,  mse_true = 129.703>\n",
      "Epoch 72 / 150  [t=320.15s]  <loss = 40.26370, ref_loss = 179.93124, max_Q = 30.0,  mse_true = 90.203>\n",
      "Epoch 73 / 150  [t=324.71s]  <loss = 8.45562, ref_loss = 220.62849, max_Q = 19.8,  mse_true = 88.354>\n",
      "Epoch 74 / 150  [t=328.84s]  <loss = 7.04830, ref_loss = 161.42188, max_Q = 16.7,  mse_true = 53.936>\n",
      "Epoch 75 / 150  [t=333.52s]  <loss = 6.77349, ref_loss = 153.97322, max_Q = 17.3,  mse_true = 58.286>\n",
      "Epoch 76 / 150  [t=338.05s]  <loss = 7.92520, ref_loss = 174.93735, max_Q = 18.3,  mse_true = 71.550>\n",
      "Epoch 77 / 150  [t=342.21s]  <loss = 6.35957, ref_loss = 139.49231, max_Q = 18.9,  mse_true = 54.559>\n",
      "Epoch 78 / 150  [t=346.43s]  <loss = 6.85455, ref_loss = 136.02202, max_Q = 20.0,  mse_true = 65.723>\n",
      "Epoch 79 / 150  [t=351.08s]  <loss = 104.33539, ref_loss = 421.02521, max_Q = 82.1,  mse_true = 102.605>\n",
      "Epoch 80 / 150  [t=355.31s]  <loss = 17.86937, ref_loss = 369.45926, max_Q = 23.6,  mse_true = 150.788>\n",
      "Epoch 81 / 150  [t=361.50s]  <loss = 12.97100, ref_loss = 279.33966, max_Q = 20.0,  mse_true = 101.745>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / 150  [t=365.89s]  <loss = 13.99043, ref_loss = 295.71210, max_Q = 21.6,  mse_true = 111.959>\n",
      "Epoch 83 / 150  [t=369.79s]  <loss = 13.28503, ref_loss = 275.31784, max_Q = 23.8,  mse_true = 108.034>\n",
      "Epoch 84 / 150  [t=374.31s]  <loss = 15.09311, ref_loss = 315.02991, max_Q = 23.1,  mse_true = 122.039>\n",
      "Epoch 85 / 150  [t=378.37s]  <loss = 14.14397, ref_loss = 245.77353, max_Q = 29.7,  mse_true = 93.786>\n",
      "Epoch 86 / 150  [t=382.27s]  <loss = 15.57577, ref_loss = 242.14896, max_Q = 28.3,  mse_true = 82.935>\n",
      "Epoch 87 / 150  [t=386.36s]  <loss = 13.37941, ref_loss = 288.66061, max_Q = 26.1,  mse_true = 110.531>\n",
      "Epoch 88 / 150  [t=391.14s]  <loss = 16.77017, ref_loss = 296.79550, max_Q = 29.0,  mse_true = 121.984>\n",
      "Epoch 89 / 150  [t=395.36s]  <loss = 23.88407, ref_loss = 280.62817, max_Q = 33.7,  mse_true = 126.434>\n",
      "Epoch 90 / 150  [t=399.45s]  <loss = 19.51276, ref_loss = 408.51788, max_Q = 22.5,  mse_true = 175.838>\n",
      "Epoch 91 / 150  [t=405.39s]  <loss = 17.40539, ref_loss = 452.30450, max_Q = 23.5,  mse_true = 200.863>\n",
      "Epoch 92 / 150  [t=409.48s]  <loss = 20.69303, ref_loss = 492.27646, max_Q = 24.5,  mse_true = 227.806>\n",
      "Epoch 93 / 150  [t=413.57s]  <loss = 26.84323, ref_loss = 531.97095, max_Q = 25.5,  mse_true = 257.264>\n",
      "Epoch 94 / 150  [t=418.22s]  <loss = 29.48629, ref_loss = 578.21375, max_Q = 26.6,  mse_true = 289.285>\n",
      "Epoch 95 / 150  [t=422.32s]  <loss = 29.90532, ref_loss = 648.50024, max_Q = 27.7,  mse_true = 322.041>\n",
      "Epoch 96 / 150  [t=426.51s]  <loss = 13.98777, ref_loss = 355.95596, max_Q = 20.7,  mse_true = 137.445>\n",
      "Epoch 97 / 150  [t=430.52s]  <loss = 12.34245, ref_loss = 295.90784, max_Q = 18.9,  mse_true = 110.099>\n",
      "Epoch 98 / 150  [t=435.05s]  <loss = 13.62898, ref_loss = 322.30130, max_Q = 19.7,  mse_true = 124.832>\n",
      "Epoch 99 / 150  [t=439.10s]  <loss = 14.96157, ref_loss = 350.12238, max_Q = 20.6,  mse_true = 141.156>\n",
      "Epoch 100 / 150  [t=443.12s]  <loss = 15.06451, ref_loss = 384.51053, max_Q = 21.7,  mse_true = 161.113>\n",
      "Epoch 101 / 150  [t=449.01s]  <loss = 16.93207, ref_loss = 427.62265, max_Q = 22.9,  mse_true = 187.453>\n",
      "Epoch 102 / 150  [t=453.17s]  <loss = 20.74558, ref_loss = 476.26993, max_Q = 23.9,  mse_true = 213.281>\n",
      "Epoch 103 / 150  [t=457.14s]  <loss = 16.81816, ref_loss = 395.73907, max_Q = 22.0,  mse_true = 168.064>\n",
      "Epoch 104 / 150  [t=461.77s]  <loss = 16.58722, ref_loss = 417.18124, max_Q = 22.4,  mse_true = 181.692>\n",
      "Epoch 105 / 150  [t=465.91s]  <loss = 18.92155, ref_loss = 457.75504, max_Q = 23.6,  mse_true = 207.581>\n",
      "Epoch 106 / 150  [t=469.86s]  <loss = 21.35164, ref_loss = 502.46570, max_Q = 24.6,  mse_true = 232.172>\n",
      "Epoch 107 / 150  [t=473.85s]  <loss = 19.20278, ref_loss = 448.90247, max_Q = 23.2,  mse_true = 202.737>\n",
      "Epoch 108 / 150  [t=477.85s]  <loss = 20.92920, ref_loss = 493.28751, max_Q = 24.0,  mse_true = 224.919>\n",
      "Epoch 109 / 150  [t=482.45s]  <loss = 18.03564, ref_loss = 429.16913, max_Q = 22.8,  mse_true = 190.571>\n",
      "Epoch 110 / 150  [t=486.49s]  <loss = 18.75087, ref_loss = 462.29047, max_Q = 23.5,  mse_true = 211.722>\n",
      "Epoch 111 / 150  [t=492.37s]  <loss = 21.32422, ref_loss = 520.67456, max_Q = 24.5,  mse_true = 238.961>\n",
      "Epoch 112 / 150  [t=496.45s]  <loss = 17.16115, ref_loss = 422.02383, max_Q = 22.4,  mse_true = 186.734>\n",
      "Epoch 113 / 150  [t=500.40s]  <loss = 18.54114, ref_loss = 475.07736, max_Q = 23.5,  mse_true = 207.876>\n",
      "Epoch 114 / 150  [t=504.39s]  <loss = 15.42551, ref_loss = 401.36255, max_Q = 21.9,  mse_true = 174.698>\n",
      "Epoch 115 / 150  [t=509.16s]  <loss = 17.31846, ref_loss = 449.28113, max_Q = 22.9,  mse_true = 195.544>\n",
      "Epoch 116 / 150  [t=513.22s]  <loss = 15.67008, ref_loss = 446.75848, max_Q = 22.5,  mse_true = 184.109>\n",
      "Epoch 117 / 150  [t=517.28s]  <loss = 14.81147, ref_loss = 391.06546, max_Q = 21.1,  mse_true = 160.957>\n",
      "Epoch 118 / 150  [t=521.29s]  <loss = 14.74808, ref_loss = 390.85159, max_Q = 21.2,  mse_true = 161.284>\n",
      "Epoch 119 / 150  [t=525.33s]  <loss = 14.82457, ref_loss = 386.23798, max_Q = 20.9,  mse_true = 162.621>\n",
      "Epoch 120 / 150  [t=530.04s]  <loss = 15.30627, ref_loss = 403.41556, max_Q = 21.4,  mse_true = 169.712>\n",
      "Epoch 121 / 150  [t=535.88s]  <loss = 15.36635, ref_loss = 400.72238, max_Q = 21.3,  mse_true = 172.236>\n",
      "Epoch 122 / 150  [t=539.96s]  <loss = 15.91706, ref_loss = 421.17917, max_Q = 22.0,  mse_true = 180.560>\n",
      "Epoch 123 / 150  [t=544.72s]  <loss = 15.95331, ref_loss = 434.09210, max_Q = 22.2,  mse_true = 183.113>\n",
      "Epoch 124 / 150  [t=548.83s]  <loss = 15.72203, ref_loss = 411.18466, max_Q = 21.6,  mse_true = 179.140>\n",
      "Epoch 125 / 150  [t=552.93s]  <loss = 16.31549, ref_loss = 431.15396, max_Q = 22.1,  mse_true = 187.901>\n",
      "Epoch 126 / 150  [t=556.93s]  <loss = 16.56660, ref_loss = 435.13913, max_Q = 22.1,  mse_true = 192.245>\n",
      "Epoch 127 / 150  [t=560.92s]  <loss = 16.97202, ref_loss = 448.36411, max_Q = 22.5,  mse_true = 198.907>\n",
      "Epoch 128 / 150  [t=565.74s]  <loss = 17.21083, ref_loss = 463.83594, max_Q = 22.8,  mse_true = 203.612>\n",
      "Epoch 129 / 150  [t=569.76s]  <loss = 17.04205, ref_loss = 465.28448, max_Q = 22.9,  mse_true = 202.444>\n",
      "Epoch 130 / 150  [t=574.25s]  <loss = 16.95678, ref_loss = 454.27338, max_Q = 22.5,  mse_true = 199.197>\n",
      "Epoch 131 / 150  [t=580.80s]  <loss = 16.95869, ref_loss = 445.79861, max_Q = 22.4,  mse_true = 200.175>\n",
      "Epoch 132 / 150  [t=585.32s]  <loss = 17.45755, ref_loss = 459.59216, max_Q = 22.7,  mse_true = 208.356>\n",
      "Epoch 133 / 150  [t=589.65s]  <loss = 17.94044, ref_loss = 476.50082, max_Q = 23.1,  mse_true = 215.983>\n",
      "Epoch 134 / 150  [t=593.97s]  <loss = 18.13462, ref_loss = 485.19638, max_Q = 23.4,  mse_true = 220.070>\n",
      "Epoch 135 / 150  [t=598.16s]  <loss = 18.17904, ref_loss = 478.74017, max_Q = 23.3,  mse_true = 222.545>\n",
      "Epoch 136 / 150  [t=603.08s]  <loss = 18.84051, ref_loss = 497.55521, max_Q = 23.6,  mse_true = 232.563>\n",
      "Epoch 137 / 150  [t=607.17s]  <loss = 19.30959, ref_loss = 519.19269, max_Q = 24.0,  mse_true = 240.182>\n",
      "Epoch 138 / 150  [t=611.22s]  <loss = 19.31458, ref_loss = 510.76620, max_Q = 23.8,  mse_true = 240.564>\n",
      "Epoch 139 / 150  [t=615.26s]  <loss = 19.70961, ref_loss = 530.11407, max_Q = 24.3,  mse_true = 247.547>\n",
      "Epoch 140 / 150  [t=619.38s]  <loss = 19.73413, ref_loss = 526.07404, max_Q = 24.3,  mse_true = 248.207>\n",
      "Epoch 141 / 150  [t=625.70s]  <loss = 19.97104, ref_loss = 540.34198, max_Q = 24.5,  mse_true = 252.573>\n",
      "Epoch 142 / 150  [t=629.84s]  <loss = 19.86581, ref_loss = 525.98309, max_Q = 24.3,  mse_true = 251.368>\n",
      "Epoch 143 / 150  [t=633.99s]  <loss = 20.32844, ref_loss = 538.68579, max_Q = 24.5,  mse_true = 259.378>\n",
      "Epoch 144 / 150  [t=638.93s]  <loss = 20.79611, ref_loss = 553.04706, max_Q = 24.8,  mse_true = 266.993>\n",
      "Epoch 145 / 150  [t=643.09s]  <loss = 21.09852, ref_loss = 562.07458, max_Q = 25.0,  mse_true = 272.462>\n",
      "Epoch 146 / 150  [t=647.18s]  <loss = 21.34505, ref_loss = 566.37653, max_Q = 25.1,  mse_true = 277.330>\n",
      "Epoch 147 / 150  [t=651.22s]  <loss = 21.64613, ref_loss = 573.32288, max_Q = 25.4,  mse_true = 284.441>\n",
      "Epoch 148 / 150  [t=655.24s]  <loss = 22.27039, ref_loss = 599.18256, max_Q = 25.9,  mse_true = 294.367>\n",
      "Epoch 149 / 150  [t=659.52s]  <loss = 22.40093, ref_loss = 602.32788, max_Q = 25.8,  mse_true = 295.862>\n",
      "Epoch 150 / 150  [t=664.77s]  <loss = 22.44364, ref_loss = 603.00946, max_Q = 25.8,  mse_true = 296.614>\n",
      "Directory figures/Helicopter_NB0/standard_Q/experiment_2 created\n",
      "==================================================================================================================\n",
      "Environment config:\n",
      "> distance_to_end: 13\n",
      "> game_board_pad_size: 3\n",
      "> horizontal_size: 20\n",
      "> reward_per_turn: -1.0\n",
      "> lambda_dx: 0.0\n",
      "> lambda_b: -1.0\n",
      "> gamma: 1.0\n",
      "> x_min: 0\n",
      "> x_max: 19\n",
      "> x_range: 19\n",
      "> x_start: 3\n",
      "> x_end: 16\n",
      "> action_list: [-1  0  1]\n",
      "==================================================================================================================\n",
      "Training config:\n",
      "> Stop training when mse_true exceeds 0.05\n",
      "> Using 1 step empirical returns\n",
      "> Using bootstrap method: clone\n",
      "> Using epochs of length None\n",
      "> Updating gradient every batch of size 1\n",
      "> Using optimizer_q1 <keras.optimizer_v2.gradient_descent.SGD object at 0x2effc3940> with learning rate 0.01\n",
      "> Using optimizer_q2 None with learning rate 0.01\n",
      "> Swapping q1 and q2 every -1 epochs\n",
      "> Cloning q2 from q1 every 1 epochs\n",
      "> Assigning a weight of 0.0 to anchoring state/action pairs\n",
      "==================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/ipykernel_58834/1750174422.py:191: RuntimeWarning: All-NaN slice encountered\n",
      "  y_min   = np.nanmin([0, np.nanmin(true_q), np.nanmin(target_q), np.nanmin(q_model), np.nanmin(bs_model)])\n",
      "/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/ipykernel_58834/1750174422.py:192: RuntimeWarning: All-NaN slice encountered\n",
      "  y_max   = np.nanmax([0, np.nanmax(true_q), np.nanmax(target_q), np.nanmax(q_model), np.nanmax(bs_model)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 150  [t=5.92s]  <loss = 0.22863, ref_loss = 0.21203, max_Q = 1.1,  mse_true = 92.668>    \n",
      "Epoch 2 / 150  [t=9.80s]  <loss = 0.19426, ref_loss = 0.74614, max_Q = 2.2,  mse_true = 76.762>    \n",
      "Epoch 3 / 150  [t=13.73s]  <loss = 0.27376, ref_loss = 3.05781, max_Q = 3.0,  mse_true = 64.406>   \n",
      "Epoch 4 / 150  [t=17.66s]  <loss = 0.44308, ref_loss = 7.01379, max_Q = 4.2,  mse_true = 54.054>   \n",
      "Epoch 5 / 150  [t=21.59s]  <loss = 0.72513, ref_loss = 11.57596, max_Q = 5.3,  mse_true = 45.259>  \n",
      "Epoch 6 / 150  [t=25.45s]  <loss = 0.62002, ref_loss = 9.43670, max_Q = 5.6,  mse_true = 42.263>   \n",
      "Epoch 7 / 150  [t=30.20s]  <loss = 1.08642, ref_loss = 16.96079, max_Q = 6.8,  mse_true = 33.663>  \n",
      "Epoch 8 / 150  [t=34.15s]  <loss = 1.78150, ref_loss = 23.89141, max_Q = 8.5,  mse_true = 25.185>  \n",
      "Epoch 9 / 150  [t=38.08s]  <loss = 2.42103, ref_loss = 35.08368, max_Q = 9.8,  mse_true = 19.764>  \n",
      "Epoch 10 / 150  [t=42.01s]  <loss = 2.70148, ref_loss = 43.45083, max_Q = 11.7,  mse_true = 14.858>\n",
      "Epoch 11 / 150  [t=47.89s]  <loss = 0.77638, ref_loss = 14.36013, max_Q = 7.4,  mse_true = 27.643> \n",
      "Epoch 12 / 150  [t=51.85s]  <loss = 1.09390, ref_loss = 20.05084, max_Q = 8.3,  mse_true = 23.649> \n",
      "Epoch 13 / 150  [t=55.74s]  <loss = 1.33879, ref_loss = 26.65325, max_Q = 9.4,  mse_true = 18.833> \n",
      "Epoch 14 / 150  [t=59.61s]  <loss = 1.79428, ref_loss = 26.50953, max_Q = 13.0,  mse_true = 12.549>\n",
      "Epoch 15 / 150  [t=63.54s]  <loss = 2.20931, ref_loss = 33.20093, max_Q = 13.6,  mse_true = 11.436>\n",
      "Epoch 16 / 150  [t=67.46s]  <loss = 2.82626, ref_loss = 43.00983, max_Q = 13.9,  mse_true = 12.534>\n",
      "Epoch 17 / 150  [t=72.30s]  <loss = 3.93183, ref_loss = 55.81870, max_Q = 17.6,  mse_true = 13.601>\n",
      "Epoch 18 / 150  [t=76.24s]  <loss = 2.07757, ref_loss = 33.68066, max_Q = 14.4,  mse_true = 11.139>\n",
      "Epoch 19 / 150  [t=80.14s]  <loss = 2.64096, ref_loss = 46.09388, max_Q = 14.3,  mse_true = 12.826>\n",
      "Epoch 20 / 150  [t=84.09s]  <loss = 3.64234, ref_loss = 57.48989, max_Q = 16.6,  mse_true = 14.036>\n",
      "Epoch 21 / 150  [t=90.02s]  <loss = 3.10931, ref_loss = 55.71309, max_Q = 16.6,  mse_true = 15.081>\n",
      "Epoch 22 / 150  [t=94.04s]  <loss = 3.93283, ref_loss = 53.67798, max_Q = 18.2,  mse_true = 14.705>\n",
      "Epoch 23 / 150  [t=97.98s]  <loss = 1.56328, ref_loss = 31.58551, max_Q = 12.3,  mse_true = 9.624> \n",
      "Epoch 24 / 150  [t=101.91s]  <loss = 1.76846, ref_loss = 32.17520, max_Q = 13.4,  mse_true = 9.419>\n",
      "Epoch 25 / 150  [t=105.80s]  <loss = 1.74450, ref_loss = 34.59033, max_Q = 13.7,  mse_true = 9.014>\n",
      "Epoch 26 / 150  [t=109.64s]  <loss = 2.19554, ref_loss = 33.10637, max_Q = 15.6,  mse_true = 9.436>\n",
      "Epoch 27 / 150  [t=113.62s]  <loss = 3.00015, ref_loss = 41.13424, max_Q = 16.9,  mse_true = 12.071>\n",
      "Epoch 28 / 150  [t=118.96s]  <loss = 4.97129, ref_loss = 41.33165, max_Q = 20.2,  mse_true = 12.922>\n",
      "Epoch 29 / 150  [t=123.35s]  <loss = 1.63736, ref_loss = 35.50154, max_Q = 13.4,  mse_true = 9.942>\n",
      "Epoch 30 / 150  [t=127.49s]  <loss = 1.32606, ref_loss = 26.35401, max_Q = 13.7,  mse_true = 7.868>\n",
      "Epoch 31 / 150  [t=132.76s]  <loss = 1.43328, ref_loss = 25.03553, max_Q = 14.9,  mse_true = 7.770>\n",
      "Epoch 32 / 150  [t=137.84s]  <loss = 1.66327, ref_loss = 24.79017, max_Q = 15.4,  mse_true = 8.023>\n",
      "Epoch 33 / 150  [t=142.19s]  <loss = 2.60215, ref_loss = 28.33583, max_Q = 16.7,  mse_true = 10.103>\n",
      "Epoch 34 / 150  [t=146.37s]  <loss = 1.75552, ref_loss = 30.48490, max_Q = 15.9,  mse_true = 10.802>\n",
      "Epoch 35 / 150  [t=150.58s]  <loss = 1.88384, ref_loss = 28.91717, max_Q = 15.5,  mse_true = 8.569>\n",
      "Epoch 36 / 150  [t=154.84s]  <loss = 7.77501, ref_loss = 44.35955, max_Q = 22.5,  mse_true = 11.489>\n",
      "Epoch 37 / 150  [t=159.03s]  <loss = 3.54773, ref_loss = 64.58215, max_Q = 17.2,  mse_true = 19.379>\n",
      "Epoch 38 / 150  [t=163.30s]  <loss = 3.64017, ref_loss = 50.25871, max_Q = 17.8,  mse_true = 19.765>\n",
      "Epoch 39 / 150  [t=168.67s]  <loss = 2.12944, ref_loss = 44.50714, max_Q = 13.5,  mse_true = 11.851>\n",
      "Epoch 40 / 150  [t=173.10s]  <loss = 2.47756, ref_loss = 40.52588, max_Q = 15.6,  mse_true = 11.985>\n",
      "Epoch 41 / 150  [t=178.72s]  <loss = 3.16789, ref_loss = 47.00871, max_Q = 18.5,  mse_true = 16.485>\n",
      "Epoch 42 / 150  [t=183.01s]  <loss = 3.48166, ref_loss = 50.11465, max_Q = 18.1,  mse_true = 20.366>\n",
      "Epoch 43 / 150  [t=187.94s]  <loss = 4.16748, ref_loss = 48.21455, max_Q = 20.0,  mse_true = 21.707>\n",
      "Epoch 44 / 150  [t=191.85s]  <loss = 7.99989, ref_loss = 73.23098, max_Q = 24.2,  mse_true = 32.345>\n",
      "Epoch 45 / 150  [t=195.74s]  <loss = 10.22386, ref_loss = 104.14423, max_Q = 24.1,  mse_true = 49.645>\n",
      "Epoch 46 / 150  [t=199.60s]  <loss = 24.95878, ref_loss = 178.96245, max_Q = 29.2,  mse_true = 80.714>\n",
      "Epoch 47 / 150  [t=203.51s]  <loss = 13.91437, ref_loss = 231.87708, max_Q = 20.6,  mse_true = 91.341>\n",
      "Epoch 48 / 150  [t=207.42s]  <loss = 36.79168, ref_loss = 479.63309, max_Q = 37.9,  mse_true = 250.419>\n",
      "Epoch 49 / 150  [t=211.31s]  <loss = 50.33506, ref_loss = 543.64288, max_Q = 31.1,  mse_true = 269.643>\n",
      "Epoch 50 / 150  [t=215.52s]  <loss = 27.43327, ref_loss = 603.16455, max_Q = 27.3,  mse_true = 297.851>\n",
      "Epoch 51 / 150  [t=222.43s]  <loss = 41.97512, ref_loss = 641.65552, max_Q = 28.3,  mse_true = 331.106>\n",
      "Epoch 52 / 150  [t=226.34s]  <loss = 46.36666, ref_loss = 696.01587, max_Q = 28.6,  mse_true = 371.463>\n",
      "Epoch 53 / 150  [t=230.21s]  <loss = 54.81990, ref_loss = 789.00238, max_Q = 31.3,  mse_true = 440.937>\n",
      "Epoch 54 / 150  [t=234.16s]  <loss = 55.87786, ref_loss = 850.40778, max_Q = 32.3,  mse_true = 481.736>\n",
      "Epoch 55 / 150  [t=238.37s]  <loss = 39.06615, ref_loss = 642.20990, max_Q = 28.2,  mse_true = 332.746>\n",
      "Epoch 56 / 150  [t=243.60s]  <loss = 42.59088, ref_loss = 690.26575, max_Q = 29.2,  mse_true = 368.000>\n",
      "Epoch 57 / 150  [t=247.85s]  <loss = 46.44641, ref_loss = 739.58551, max_Q = 30.3,  mse_true = 405.154>\n",
      "Epoch 58 / 150  [t=252.36s]  <loss = 50.09215, ref_loss = 790.78278, max_Q = 31.3,  mse_true = 444.208>\n",
      "Epoch 59 / 150  [t=256.37s]  <loss = 54.16291, ref_loss = 842.97577, max_Q = 32.3,  mse_true = 485.131>\n",
      "Epoch 60 / 150  [t=260.25s]  <loss = 58.39551, ref_loss = 896.45026, max_Q = 33.3,  mse_true = 527.984>\n",
      "Epoch 61 / 150  [t=266.80s]  <loss = 62.79718, ref_loss = 951.03162, max_Q = 34.3,  mse_true = 572.737>\n",
      "Epoch 62 / 150  [t=270.74s]  <loss = 45.57178, ref_loss = 1031.60498, max_Q = 35.3,  mse_true = 619.389>\n",
      "Epoch 63 / 150  [t=274.68s]  <loss = 57.63895, ref_loss = 1081.78125, max_Q = 36.3,  mse_true = 667.942>\n",
      "Epoch 64 / 150  [t=278.66s]  <loss = 76.44522, ref_loss = 1123.66833, max_Q = 37.3,  mse_true = 718.395>\n",
      "Epoch 65 / 150  [t=282.61s]  <loss = 69.10533, ref_loss = 1235.41162, max_Q = 38.2,  mse_true = 765.694>\n",
      "Epoch 66 / 150  [t=286.51s]  <loss = 18.06791, ref_loss = 430.97690, max_Q = 22.7,  mse_true = 190.379>\n",
      "Epoch 67 / 150  [t=290.40s]  <loss = 18.15852, ref_loss = 445.13034, max_Q = 23.1,  mse_true = 201.026>\n",
      "Epoch 68 / 150  [t=294.31s]  <loss = 20.54143, ref_loss = 484.26706, max_Q = 24.1,  mse_true = 226.812>\n",
      "Epoch 69 / 150  [t=299.44s]  <loss = 21.41572, ref_loss = 534.26666, max_Q = 25.2,  mse_true = 253.345>\n",
      "Epoch 70 / 150  [t=303.44s]  <loss = 19.10395, ref_loss = 492.01724, max_Q = 24.4,  mse_true = 231.409>\n",
      "Epoch 71 / 150  [t=308.68s]  <loss = 22.98682, ref_loss = 543.44220, max_Q = 25.3,  mse_true = 261.436>\n",
      "Epoch 72 / 150  [t=312.78s]  <loss = 19.29296, ref_loss = 543.59045, max_Q = 24.9,  mse_true = 245.337>\n",
      "Epoch 73 / 150  [t=316.67s]  <loss = 16.24209, ref_loss = 419.67139, max_Q = 22.3,  mse_true = 186.446>\n",
      "Epoch 74 / 150  [t=321.78s]  <loss = 18.03196, ref_loss = 460.17102, max_Q = 23.1,  mse_true = 204.795>\n",
      "Epoch 75 / 150  [t=325.70s]  <loss = 17.06511, ref_loss = 442.67993, max_Q = 22.9,  mse_true = 201.449>\n",
      "Epoch 76 / 150  [t=329.62s]  <loss = 18.74770, ref_loss = 475.14038, max_Q = 23.6,  mse_true = 221.521>\n",
      "Epoch 77 / 150  [t=333.58s]  <loss = 20.33949, ref_loss = 512.20166, max_Q = 24.4,  mse_true = 239.982>\n",
      "Epoch 78 / 150  [t=337.70s]  <loss = 19.54855, ref_loss = 497.84149, max_Q = 24.1,  mse_true = 236.860>\n",
      "Epoch 79 / 150  [t=342.18s]  <loss = 21.04565, ref_loss = 536.01410, max_Q = 25.0,  mse_true = 256.102>\n",
      "Epoch 80 / 150  [t=346.59s]  <loss = 20.42146, ref_loss = 522.68091, max_Q = 24.7,  mse_true = 253.989>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 / 150  [t=353.20s]  <loss = 22.22629, ref_loss = 558.59943, max_Q = 25.4,  mse_true = 274.542>\n",
      "Epoch 82 / 150  [t=357.19s]  <loss = 22.07330, ref_loss = 568.92572, max_Q = 25.8,  mse_true = 281.066>\n",
      "Epoch 83 / 150  [t=361.28s]  <loss = 22.76839, ref_loss = 588.19220, max_Q = 25.9,  mse_true = 287.427>\n",
      "Epoch 84 / 150  [t=365.13s]  <loss = 21.30755, ref_loss = 586.79346, max_Q = 25.7,  mse_true = 277.084>\n",
      "Epoch 85 / 150  [t=369.12s]  <loss = 20.40063, ref_loss = 535.49188, max_Q = 24.6,  mse_true = 259.647>\n",
      "Epoch 86 / 150  [t=373.11s]  <loss = 21.01887, ref_loss = 563.38818, max_Q = 25.2,  mse_true = 269.997>\n",
      "Epoch 87 / 150  [t=377.03s]  <loss = 21.02679, ref_loss = 561.64001, max_Q = 25.0,  mse_true = 269.426>\n",
      "Epoch 88 / 150  [t=382.23s]  <loss = 21.03269, ref_loss = 558.53705, max_Q = 24.9,  mse_true = 270.315>\n",
      "Epoch 89 / 150  [t=386.27s]  <loss = 21.12017, ref_loss = 581.29272, max_Q = 25.4,  mse_true = 275.055>\n",
      "Epoch 90 / 150  [t=390.18s]  <loss = 20.88843, ref_loss = 558.60120, max_Q = 24.9,  mse_true = 268.137>\n",
      "Epoch 91 / 150  [t=395.48s]  <loss = 21.01320, ref_loss = 559.26129, max_Q = 25.0,  mse_true = 270.652>\n",
      "Epoch 92 / 150  [t=399.73s]  <loss = 21.27226, ref_loss = 574.50507, max_Q = 25.3,  mse_true = 275.540>\n",
      "Epoch 93 / 150  [t=403.87s]  <loss = 21.23143, ref_loss = 570.88470, max_Q = 25.2,  mse_true = 274.540>\n",
      "Epoch 94 / 150  [t=409.52s]  <loss = 21.15433, ref_loss = 559.92310, max_Q = 25.1,  mse_true = 275.140>\n",
      "Epoch 95 / 150  [t=414.04s]  <loss = 21.63767, ref_loss = 595.40790, max_Q = 25.7,  mse_true = 284.670>\n",
      "Epoch 96 / 150  [t=418.36s]  <loss = 21.37368, ref_loss = 565.72864, max_Q = 25.1,  mse_true = 278.345>\n",
      "Epoch 97 / 150  [t=422.42s]  <loss = 21.77188, ref_loss = 576.19165, max_Q = 25.5,  mse_true = 287.094>\n",
      "Epoch 98 / 150  [t=426.78s]  <loss = 22.49603, ref_loss = 598.22192, max_Q = 25.7,  mse_true = 297.850>\n",
      "Epoch 99 / 150  [t=431.27s]  <loss = 22.77527, ref_loss = 620.81293, max_Q = 26.2,  mse_true = 303.910>\n",
      "Epoch 100 / 150  [t=435.70s]  <loss = 22.60485, ref_loss = 602.26544, max_Q = 25.8,  mse_true = 299.685>\n",
      "Epoch 101 / 150  [t=442.72s]  <loss = 22.85436, ref_loss = 611.48755, max_Q = 26.1,  mse_true = 304.729>\n",
      "Epoch 102 / 150  [t=446.81s]  <loss = 23.05517, ref_loss = 618.32416, max_Q = 26.2,  mse_true = 308.425>\n",
      "Epoch 103 / 150  [t=451.13s]  <loss = 22.98492, ref_loss = 610.18469, max_Q = 26.2,  mse_true = 311.045>\n",
      "Epoch 104 / 150  [t=455.21s]  <loss = 23.84713, ref_loss = 639.36292, max_Q = 26.7,  mse_true = 322.927>\n",
      "Epoch 105 / 150  [t=459.37s]  <loss = 23.95314, ref_loss = 650.05896, max_Q = 26.9,  mse_true = 325.609>\n",
      "Epoch 106 / 150  [t=463.37s]  <loss = 23.82541, ref_loss = 642.03900, max_Q = 26.7,  mse_true = 323.125>\n",
      "Epoch 107 / 150  [t=467.34s]  <loss = 23.91386, ref_loss = 645.87988, max_Q = 26.7,  mse_true = 324.009>\n",
      "Epoch 108 / 150  [t=471.48s]  <loss = 23.84328, ref_loss = 636.70795, max_Q = 26.6,  mse_true = 322.910>\n",
      "Epoch 109 / 150  [t=477.08s]  <loss = 24.09737, ref_loss = 641.82892, max_Q = 26.6,  mse_true = 327.605>\n",
      "Epoch 110 / 150  [t=481.19s]  <loss = 24.34471, ref_loss = 665.49597, max_Q = 27.1,  mse_true = 333.591>\n",
      "Epoch 111 / 150  [t=487.17s]  <loss = 24.09342, ref_loss = 645.33356, max_Q = 26.8,  mse_true = 328.135>\n",
      "Epoch 112 / 150  [t=491.36s]  <loss = 24.25198, ref_loss = 664.30035, max_Q = 27.1,  mse_true = 332.051>\n",
      "Epoch 113 / 150  [t=495.57s]  <loss = 24.01869, ref_loss = 646.79462, max_Q = 26.7,  mse_true = 325.824>\n",
      "Epoch 114 / 150  [t=499.80s]  <loss = 23.94114, ref_loss = 638.05365, max_Q = 26.7,  mse_true = 326.028>\n",
      "Epoch 115 / 150  [t=504.04s]  <loss = 24.31346, ref_loss = 666.27802, max_Q = 27.1,  mse_true = 333.209>\n",
      "Epoch 116 / 150  [t=509.90s]  <loss = 23.94342, ref_loss = 635.87030, max_Q = 26.6,  mse_true = 326.743>\n",
      "Epoch 117 / 150  [t=514.27s]  <loss = 24.56326, ref_loss = 654.74780, max_Q = 26.9,  mse_true = 336.422>\n",
      "Epoch 118 / 150  [t=518.68s]  <loss = 24.89679, ref_loss = 665.81073, max_Q = 27.1,  mse_true = 342.284>\n",
      "Epoch 119 / 150  [t=522.96s]  <loss = 25.08651, ref_loss = 672.02185, max_Q = 27.3,  mse_true = 346.113>\n",
      "Epoch 120 / 150  [t=527.37s]  <loss = 25.25220, ref_loss = 673.71771, max_Q = 27.3,  mse_true = 349.401>\n",
      "Epoch 121 / 150  [t=532.97s]  <loss = 25.54440, ref_loss = 682.53632, max_Q = 27.5,  mse_true = 355.029>\n",
      "Epoch 122 / 150  [t=538.74s]  <loss = 25.79723, ref_loss = 699.42517, max_Q = 27.8,  mse_true = 360.069>\n",
      "Epoch 123 / 150  [t=542.88s]  <loss = 25.49350, ref_loss = 706.38190, max_Q = 27.9,  mse_true = 357.598>\n",
      "Epoch 124 / 150  [t=547.09s]  <loss = 25.10410, ref_loss = 677.38580, max_Q = 27.4,  mse_true = 347.170>\n",
      "Epoch 125 / 150  [t=551.31s]  <loss = 24.97406, ref_loss = 690.75854, max_Q = 27.6,  mse_true = 347.518>\n",
      "Epoch 126 / 150  [t=555.52s]  <loss = 24.49953, ref_loss = 675.59912, max_Q = 27.3,  mse_true = 338.071>\n",
      "Epoch 127 / 150  [t=559.81s]  <loss = 24.22307, ref_loss = 647.01569, max_Q = 26.8,  mse_true = 329.870>\n",
      "Epoch 128 / 150  [t=564.02s]  <loss = 24.41873, ref_loss = 650.09198, max_Q = 26.8,  mse_true = 334.394>\n",
      "Epoch 129 / 150  [t=568.08s]  <loss = 24.78745, ref_loss = 661.52026, max_Q = 27.1,  mse_true = 341.612>\n",
      "Epoch 130 / 150  [t=572.42s]  <loss = 25.08370, ref_loss = 687.11951, max_Q = 27.6,  mse_true = 348.058>\n",
      "Epoch 131 / 150  [t=579.60s]  <loss = 24.87832, ref_loss = 665.48389, max_Q = 27.1,  mse_true = 341.939>\n",
      "Epoch 132 / 150  [t=583.75s]  <loss = 25.02402, ref_loss = 674.33777, max_Q = 27.4,  mse_true = 345.636>\n",
      "Epoch 133 / 150  [t=587.74s]  <loss = 25.13339, ref_loss = 673.35095, max_Q = 27.2,  mse_true = 346.639>\n",
      "Epoch 134 / 150  [t=591.78s]  <loss = 25.27616, ref_loss = 677.75183, max_Q = 27.4,  mse_true = 349.469>\n",
      "Epoch 135 / 150  [t=596.02s]  <loss = 25.38392, ref_loss = 677.47644, max_Q = 27.4,  mse_true = 352.038>\n",
      "Epoch 136 / 150  [t=600.79s]  <loss = 25.56381, ref_loss = 680.24036, max_Q = 27.5,  mse_true = 357.686>\n",
      "Epoch 137 / 150  [t=604.76s]  <loss = 26.22990, ref_loss = 702.47003, max_Q = 27.8,  mse_true = 367.550>\n",
      "Epoch 138 / 150  [t=609.26s]  <loss = 26.41440, ref_loss = 710.19690, max_Q = 27.9,  mse_true = 370.940>\n",
      "Epoch 139 / 150  [t=614.98s]  <loss = 26.38976, ref_loss = 704.32416, max_Q = 27.9,  mse_true = 372.052>\n",
      "Epoch 140 / 150  [t=618.97s]  <loss = 26.74556, ref_loss = 732.12787, max_Q = 28.4,  mse_true = 379.040>\n",
      "Epoch 141 / 150  [t=624.41s]  <loss = 26.43276, ref_loss = 719.03021, max_Q = 28.0,  mse_true = 372.045>\n",
      "Epoch 142 / 150  [t=628.40s]  <loss = 26.18530, ref_loss = 699.68750, max_Q = 27.8,  mse_true = 367.526>\n",
      "Epoch 143 / 150  [t=632.33s]  <loss = 26.40527, ref_loss = 722.27466, max_Q = 28.3,  mse_true = 373.091>\n",
      "Epoch 144 / 150  [t=636.31s]  <loss = 26.08385, ref_loss = 714.91315, max_Q = 28.1,  mse_true = 367.261>\n",
      "Epoch 145 / 150  [t=640.27s]  <loss = 25.85736, ref_loss = 690.06348, max_Q = 27.5,  mse_true = 360.762>\n",
      "Epoch 146 / 150  [t=644.24s]  <loss = 26.13840, ref_loss = 709.55188, max_Q = 27.9,  mse_true = 366.304>\n",
      "Epoch 147 / 150  [t=649.72s]  <loss = 25.97417, ref_loss = 702.32349, max_Q = 27.8,  mse_true = 362.832>\n",
      "Epoch 148 / 150  [t=653.76s]  <loss = 25.81782, ref_loss = 689.81494, max_Q = 27.7,  mse_true = 361.134>\n",
      "Epoch 149 / 150  [t=657.78s]  <loss = 26.12900, ref_loss = 695.07861, max_Q = 27.7,  mse_true = 367.326>\n",
      "Epoch 150 / 150  [t=661.84s]  <loss = 26.66119, ref_loss = 711.21490, max_Q = 27.9,  mse_true = 376.298>\n",
      "Directory figures/Helicopter_NB0/standard_Q/experiment_3 created\n",
      "==================================================================================================================\n",
      "Environment config:\n",
      "> distance_to_end: 13\n",
      "> game_board_pad_size: 3\n",
      "> horizontal_size: 20\n",
      "> reward_per_turn: -1.0\n",
      "> lambda_dx: 0.0\n",
      "> lambda_b: -1.0\n",
      "> gamma: 1.0\n",
      "> x_min: 0\n",
      "> x_max: 19\n",
      "> x_range: 19\n",
      "> x_start: 3\n",
      "> x_end: 16\n",
      "> action_list: [-1  0  1]\n",
      "==================================================================================================================\n",
      "Training config:\n",
      "> Stop training when mse_true exceeds 0.05\n",
      "> Using 1 step empirical returns\n",
      "> Using bootstrap method: clone\n",
      "> Using epochs of length None\n",
      "> Updating gradient every batch of size 1\n",
      "> Using optimizer_q1 <keras.optimizer_v2.gradient_descent.SGD object at 0x30790b940> with learning rate 0.01\n",
      "> Using optimizer_q2 None with learning rate 0.01\n",
      "> Swapping q1 and q2 every -1 epochs\n",
      "> Cloning q2 from q1 every 1 epochs\n",
      "> Assigning a weight of 0.0 to anchoring state/action pairs\n",
      "==================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/ipykernel_58834/1750174422.py:191: RuntimeWarning: All-NaN slice encountered\n",
      "  y_min   = np.nanmin([0, np.nanmin(true_q), np.nanmin(target_q), np.nanmin(q_model), np.nanmin(bs_model)])\n",
      "/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/ipykernel_58834/1750174422.py:192: RuntimeWarning: All-NaN slice encountered\n",
      "  y_max   = np.nanmax([0, np.nanmax(true_q), np.nanmax(target_q), np.nanmax(q_model), np.nanmax(bs_model)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 150  [t=4.84s]  <loss = 0.23666, ref_loss = 0.22415, max_Q = 1.0,  mse_true = 92.668>    \n",
      "Epoch 2 / 150  [t=10.26s]  <loss = 0.19686, ref_loss = 0.69052, max_Q = 2.1,  mse_true = 77.398>   \n",
      "Epoch 3 / 150  [t=14.25s]  <loss = 0.25955, ref_loss = 2.99233, max_Q = 2.9,  mse_true = 64.614>   \n",
      "Epoch 4 / 150  [t=18.19s]  <loss = 0.42582, ref_loss = 6.17252, max_Q = 3.9,  mse_true = 54.676>   \n",
      "Epoch 5 / 150  [t=22.04s]  <loss = 0.76105, ref_loss = 12.95489, max_Q = 5.3,  mse_true = 43.063>  \n",
      "Epoch 6 / 150  [t=26.02s]  <loss = 1.16497, ref_loss = 16.73214, max_Q = 7.0,  mse_true = 35.010>  \n",
      "Epoch 7 / 150  [t=29.98s]  <loss = 1.55624, ref_loss = 23.44584, max_Q = 8.1,  mse_true = 28.020>  \n",
      "Epoch 8 / 150  [t=34.04s]  <loss = 1.93999, ref_loss = 29.31461, max_Q = 10.1,  mse_true = 22.111> \n",
      "Epoch 9 / 150  [t=38.01s]  <loss = 1.57146, ref_loss = 26.26852, max_Q = 9.9,  mse_true = 17.400>  \n",
      "Epoch 10 / 150  [t=41.84s]  <loss = 1.79795, ref_loss = 27.13691, max_Q = 11.7,  mse_true = 13.494>\n",
      "Epoch 11 / 150  [t=48.59s]  <loss = 3.37759, ref_loss = 37.52398, max_Q = 14.4,  mse_true = 9.139> \n",
      "Epoch 12 / 150  [t=52.71s]  <loss = 2.43808, ref_loss = 41.59884, max_Q = 16.8,  mse_true = 9.169> \n",
      "Epoch 13 / 150  [t=56.74s]  <loss = 7.48891, ref_loss = 32.44447, max_Q = 21.1,  mse_true = 4.454> \n",
      "Epoch 14 / 150  [t=60.80s]  <loss = 182.44736, ref_loss = 205.67279, max_Q = 86.2,  mse_true = 39.915>\n",
      "Epoch 15 / 150  [t=65.23s]  <loss = 7.63208, ref_loss = 160.50189, max_Q = 14.5,  mse_true = 44.168>\n",
      "Epoch 16 / 150  [t=69.47s]  <loss = 8.87917, ref_loss = 188.46535, max_Q = 15.6,  mse_true = 54.053>\n",
      "Epoch 17 / 150  [t=73.69s]  <loss = 7.47661, ref_loss = 161.51309, max_Q = 14.6,  mse_true = 44.518>\n",
      "Epoch 18 / 150  [t=78.11s]  <loss = 8.55147, ref_loss = 186.93686, max_Q = 15.6,  mse_true = 54.495>\n",
      "Epoch 19 / 150  [t=82.15s]  <loss = 8.53317, ref_loss = 219.73444, max_Q = 16.8,  mse_true = 68.213>\n",
      "Epoch 20 / 150  [t=86.14s]  <loss = 12.44462, ref_loss = 247.60287, max_Q = 18.0,  mse_true = 82.260>\n",
      "Epoch 21 / 150  [t=93.06s]  <loss = 13.52784, ref_loss = 269.59396, max_Q = 18.6,  mse_true = 93.573>\n",
      "Epoch 22 / 150  [t=96.90s]  <loss = 15.80719, ref_loss = 302.13565, max_Q = 19.9,  mse_true = 110.838>\n",
      "Epoch 23 / 150  [t=100.81s]  <loss = 17.19502, ref_loss = 320.56717, max_Q = 20.2,  mse_true = 121.542>\n",
      "Epoch 24 / 150  [t=104.93s]  <loss = 19.62800, ref_loss = 355.42160, max_Q = 21.2,  mse_true = 141.836>\n",
      "Epoch 25 / 150  [t=108.91s]  <loss = 21.37222, ref_loss = 396.74982, max_Q = 22.2,  mse_true = 164.032>\n",
      "Epoch 26 / 150  [t=112.98s]  <loss = 16.36214, ref_loss = 319.03290, max_Q = 20.1,  mse_true = 120.630>\n",
      "Epoch 27 / 150  [t=117.45s]  <loss = 18.59221, ref_loss = 350.83136, max_Q = 20.6,  mse_true = 139.167>\n",
      "Epoch 28 / 150  [t=121.47s]  <loss = 20.77663, ref_loss = 387.59406, max_Q = 22.2,  mse_true = 161.121>\n",
      "Epoch 29 / 150  [t=125.44s]  <loss = 23.18554, ref_loss = 423.82675, max_Q = 23.2,  mse_true = 183.753>\n",
      "Epoch 30 / 150  [t=131.10s]  <loss = 25.80595, ref_loss = 463.71082, max_Q = 24.3,  mse_true = 209.395>\n",
      "Epoch 31 / 150  [t=136.73s]  <loss = 24.27032, ref_loss = 528.28595, max_Q = 25.1,  mse_true = 236.954>\n",
      "Epoch 32 / 150  [t=140.77s]  <loss = 6.93333, ref_loss = 168.00443, max_Q = 14.5,  mse_true = 45.344>\n",
      "Epoch 33 / 150  [t=144.72s]  <loss = 5.52100, ref_loss = 134.35757, max_Q = 13.2,  mse_true = 35.314>\n",
      "Epoch 34 / 150  [t=148.62s]  <loss = 6.03338, ref_loss = 141.71513, max_Q = 13.5,  mse_true = 38.148>\n",
      "Epoch 35 / 150  [t=152.63s]  <loss = 7.32931, ref_loss = 165.75624, max_Q = 14.6,  mse_true = 46.647>\n",
      "Epoch 36 / 150  [t=156.50s]  <loss = 8.29442, ref_loss = 191.16656, max_Q = 15.7,  mse_true = 56.524>\n",
      "Epoch 37 / 150  [t=160.52s]  <loss = 9.05555, ref_loss = 209.20148, max_Q = 16.2,  mse_true = 64.486>\n",
      "Epoch 38 / 150  [t=164.48s]  <loss = 10.41456, ref_loss = 231.66582, max_Q = 16.9,  mse_true = 75.214>\n",
      "Epoch 39 / 150  [t=170.23s]  <loss = 10.24666, ref_loss = 262.93823, max_Q = 18.2,  mse_true = 90.183>\n",
      "Epoch 40 / 150  [t=174.25s]  <loss = 14.24180, ref_loss = 300.72266, max_Q = 19.5,  mse_true = 111.025>\n",
      "Epoch 41 / 150  [t=179.56s]  <loss = 15.84636, ref_loss = 343.00079, max_Q = 20.5,  mse_true = 130.317>\n",
      "Epoch 42 / 150  [t=183.92s]  <loss = 10.76758, ref_loss = 236.40291, max_Q = 17.3,  mse_true = 77.777>\n",
      "Epoch 43 / 150  [t=188.10s]  <loss = 11.44160, ref_loss = 268.29367, max_Q = 18.4,  mse_true = 93.545>\n",
      "Epoch 44 / 150  [t=192.47s]  <loss = 13.72856, ref_loss = 314.80783, max_Q = 19.3,  mse_true = 113.526>\n",
      "Epoch 45 / 150  [t=196.43s]  <loss = 8.35367, ref_loss = 208.22166, max_Q = 16.3,  mse_true = 64.074>\n",
      "Epoch 46 / 150  [t=200.51s]  <loss = 10.19133, ref_loss = 231.45441, max_Q = 17.0,  mse_true = 74.232>\n",
      "Epoch 47 / 150  [t=204.60s]  <loss = 9.88226, ref_loss = 227.01973, max_Q = 16.7,  mse_true = 73.295>\n",
      "Epoch 48 / 150  [t=210.41s]  <loss = 11.41190, ref_loss = 255.82501, max_Q = 17.9,  mse_true = 87.629>\n",
      "Epoch 49 / 150  [t=214.37s]  <loss = 13.01281, ref_loss = 292.70651, max_Q = 19.0,  mse_true = 105.770>\n",
      "Epoch 50 / 150  [t=218.43s]  <loss = 13.48861, ref_loss = 292.46063, max_Q = 19.2,  mse_true = 107.195>\n",
      "Epoch 51 / 150  [t=223.76s]  <loss = 14.51905, ref_loss = 334.12784, max_Q = 20.5,  mse_true = 129.748>\n",
      "Epoch 52 / 150  [t=227.75s]  <loss = 17.21463, ref_loss = 369.19006, max_Q = 21.4,  mse_true = 150.747>\n",
      "Epoch 53 / 150  [t=231.60s]  <loss = 16.41289, ref_loss = 418.48065, max_Q = 22.5,  mse_true = 171.703>\n",
      "Epoch 54 / 150  [t=235.67s]  <loss = 11.13495, ref_loss = 253.89484, max_Q = 17.7,  mse_true = 86.930>\n",
      "Epoch 55 / 150  [t=239.68s]  <loss = 12.38774, ref_loss = 285.50311, max_Q = 18.7,  mse_true = 103.312>\n",
      "Epoch 56 / 150  [t=243.77s]  <loss = 13.42128, ref_loss = 320.17667, max_Q = 19.9,  mse_true = 122.048>\n",
      "Epoch 57 / 150  [t=249.63s]  <loss = 16.58101, ref_loss = 354.22964, max_Q = 21.0,  mse_true = 142.451>\n",
      "Epoch 58 / 150  [t=253.78s]  <loss = 18.15079, ref_loss = 388.44403, max_Q = 22.0,  mse_true = 163.054>\n",
      "Epoch 59 / 150  [t=257.88s]  <loss = 20.64715, ref_loss = 427.87109, max_Q = 23.0,  mse_true = 187.296>\n",
      "Epoch 60 / 150  [t=261.95s]  <loss = 21.77451, ref_loss = 452.51627, max_Q = 23.5,  mse_true = 200.722>\n",
      "Epoch 61 / 150  [t=267.37s]  <loss = 18.37092, ref_loss = 405.31689, max_Q = 22.4,  mse_true = 173.435>\n",
      "Epoch 62 / 150  [t=271.23s]  <loss = 20.84522, ref_loss = 447.32422, max_Q = 23.4,  mse_true = 196.944>\n",
      "Epoch 63 / 150  [t=275.33s]  <loss = 18.21261, ref_loss = 395.95206, max_Q = 22.1,  mse_true = 167.627>\n",
      "Epoch 64 / 150  [t=279.35s]  <loss = 18.55755, ref_loss = 430.57126, max_Q = 22.7,  mse_true = 181.679>\n",
      "Epoch 65 / 150  [t=283.31s]  <loss = 13.44247, ref_loss = 312.88708, max_Q = 19.5,  mse_true = 119.304>\n",
      "Epoch 66 / 150  [t=289.27s]  <loss = 14.62151, ref_loss = 355.54440, max_Q = 20.6,  mse_true = 137.815>\n",
      "Epoch 67 / 150  [t=293.34s]  <loss = 12.24240, ref_loss = 296.26117, max_Q = 19.0,  mse_true = 109.281>\n",
      "Epoch 68 / 150  [t=297.40s]  <loss = 13.03375, ref_loss = 318.59311, max_Q = 19.7,  mse_true = 119.063>\n",
      "Epoch 69 / 150  [t=301.51s]  <loss = 12.51076, ref_loss = 299.00095, max_Q = 19.1,  mse_true = 111.496>\n",
      "Epoch 70 / 150  [t=305.68s]  <loss = 13.58271, ref_loss = 329.05527, max_Q = 19.8,  mse_true = 124.788>\n",
      "Epoch 71 / 150  [t=311.01s]  <loss = 12.32517, ref_loss = 304.78308, max_Q = 19.3,  mse_true = 115.409>\n",
      "Epoch 72 / 150  [t=315.04s]  <loss = 13.48320, ref_loss = 340.04034, max_Q = 20.3,  mse_true = 134.911>\n",
      "Epoch 73 / 150  [t=319.11s]  <loss = 16.13367, ref_loss = 377.91721, max_Q = 21.5,  mse_true = 156.115>\n",
      "Epoch 74 / 150  [t=323.09s]  <loss = 16.61315, ref_loss = 383.95615, max_Q = 21.5,  mse_true = 161.622>\n",
      "Epoch 75 / 150  [t=327.21s]  <loss = 17.87682, ref_loss = 426.44318, max_Q = 22.6,  mse_true = 183.133>\n",
      "Epoch 76 / 150  [t=333.33s]  <loss = 15.60692, ref_loss = 386.79364, max_Q = 21.6,  mse_true = 163.584>\n",
      "Epoch 77 / 150  [t=337.45s]  <loss = 17.49433, ref_loss = 433.16751, max_Q = 23.1,  mse_true = 191.825>\n",
      "Epoch 78 / 150  [t=341.51s]  <loss = 21.07284, ref_loss = 473.14938, max_Q = 23.8,  mse_true = 218.824>\n",
      "Epoch 79 / 150  [t=345.64s]  <loss = 23.56434, ref_loss = 514.60651, max_Q = 25.1,  mse_true = 246.732>\n",
      "Epoch 80 / 150  [t=349.71s]  <loss = 25.43220, ref_loss = 564.09717, max_Q = 26.1,  mse_true = 274.812>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 / 150  [t=355.02s]  <loss = 21.16934, ref_loss = 500.09967, max_Q = 24.5,  mse_true = 236.479>\n",
      "Epoch 82 / 150  [t=359.14s]  <loss = 23.02880, ref_loss = 541.82043, max_Q = 25.7,  mse_true = 265.092>\n",
      "Epoch 83 / 150  [t=363.17s]  <loss = 26.89902, ref_loss = 605.57422, max_Q = 26.6,  mse_true = 302.052>\n",
      "Epoch 84 / 150  [t=367.23s]  <loss = 21.34974, ref_loss = 517.84253, max_Q = 25.1,  mse_true = 247.646>\n",
      "Epoch 85 / 150  [t=371.24s]  <loss = 22.62323, ref_loss = 541.81781, max_Q = 25.5,  mse_true = 265.534>\n",
      "Epoch 86 / 150  [t=377.44s]  <loss = 24.56201, ref_loss = 589.80304, max_Q = 26.5,  mse_true = 297.934>\n",
      "Epoch 87 / 150  [t=381.54s]  <loss = 27.69460, ref_loss = 626.10663, max_Q = 27.5,  mse_true = 325.604>\n",
      "Epoch 88 / 150  [t=385.58s]  <loss = 27.23139, ref_loss = 678.50464, max_Q = 28.5,  mse_true = 360.765>\n",
      "Epoch 89 / 150  [t=389.75s]  <loss = 30.72142, ref_loss = 730.92523, max_Q = 29.7,  mse_true = 400.206>\n",
      "Epoch 90 / 150  [t=393.87s]  <loss = 36.87233, ref_loss = 776.02490, max_Q = 30.5,  mse_true = 438.571>\n",
      "Epoch 91 / 150  [t=399.19s]  <loss = 36.59608, ref_loss = 873.33527, max_Q = 31.6,  mse_true = 478.677>\n",
      "Epoch 92 / 150  [t=403.36s]  <loss = 20.90884, ref_loss = 601.50519, max_Q = 25.9,  mse_true = 279.142>\n",
      "Epoch 93 / 150  [t=407.56s]  <loss = 19.26381, ref_loss = 506.80096, max_Q = 23.9,  mse_true = 236.416>\n",
      "Epoch 94 / 150  [t=411.50s]  <loss = 19.23275, ref_loss = 529.07800, max_Q = 24.4,  mse_true = 240.419>\n",
      "Epoch 95 / 150  [t=415.72s]  <loss = 18.86251, ref_loss = 505.57123, max_Q = 23.8,  mse_true = 231.519>\n",
      "Epoch 96 / 150  [t=419.88s]  <loss = 18.85500, ref_loss = 501.21655, max_Q = 23.7,  mse_true = 231.585>\n",
      "Epoch 97 / 150  [t=425.98s]  <loss = 19.04213, ref_loss = 507.55005, max_Q = 23.9,  mse_true = 235.218>\n",
      "Epoch 98 / 150  [t=430.12s]  <loss = 19.15021, ref_loss = 505.32227, max_Q = 23.8,  mse_true = 238.384>\n",
      "Epoch 99 / 150  [t=434.20s]  <loss = 19.70756, ref_loss = 528.04224, max_Q = 24.3,  mse_true = 246.920>\n",
      "Epoch 100 / 150  [t=438.18s]  <loss = 19.78114, ref_loss = 525.51581, max_Q = 24.1,  mse_true = 248.249>\n",
      "Epoch 101 / 150  [t=443.43s]  <loss = 19.95831, ref_loss = 528.61798, max_Q = 24.3,  mse_true = 252.994>\n",
      "Epoch 102 / 150  [t=447.46s]  <loss = 20.48064, ref_loss = 544.51135, max_Q = 24.6,  mse_true = 260.875>\n",
      "Epoch 103 / 150  [t=451.47s]  <loss = 20.68548, ref_loss = 547.66510, max_Q = 24.7,  mse_true = 265.777>\n",
      "Epoch 104 / 150  [t=455.48s]  <loss = 21.19191, ref_loss = 566.95752, max_Q = 25.1,  mse_true = 273.899>\n",
      "Epoch 105 / 150  [t=459.49s]  <loss = 21.32047, ref_loss = 574.43787, max_Q = 25.3,  mse_true = 276.695>\n",
      "Epoch 106 / 150  [t=463.40s]  <loss = 21.32460, ref_loss = 579.58868, max_Q = 25.3,  mse_true = 277.064>\n",
      "Epoch 107 / 150  [t=469.48s]  <loss = 21.08835, ref_loss = 558.41089, max_Q = 25.0,  mse_true = 274.036>\n",
      "Epoch 108 / 150  [t=473.48s]  <loss = 21.67018, ref_loss = 574.14111, max_Q = 25.3,  mse_true = 283.463>\n",
      "Epoch 109 / 150  [t=477.57s]  <loss = 22.15446, ref_loss = 589.49768, max_Q = 25.6,  mse_true = 291.622>\n",
      "Epoch 110 / 150  [t=481.67s]  <loss = 22.45834, ref_loss = 603.51245, max_Q = 25.9,  mse_true = 297.323>\n",
      "Epoch 111 / 150  [t=486.98s]  <loss = 22.51374, ref_loss = 597.64893, max_Q = 25.7,  mse_true = 298.818>\n",
      "Epoch 112 / 150  [t=490.92s]  <loss = 22.97349, ref_loss = 618.19031, max_Q = 26.1,  mse_true = 306.417>\n",
      "Epoch 113 / 150  [t=494.96s]  <loss = 22.98192, ref_loss = 613.62219, max_Q = 26.1,  mse_true = 306.893>\n",
      "Epoch 114 / 150  [t=499.16s]  <loss = 23.23708, ref_loss = 621.31384, max_Q = 26.3,  mse_true = 311.367>\n",
      "Epoch 115 / 150  [t=503.49s]  <loss = 23.40318, ref_loss = 626.05603, max_Q = 26.4,  mse_true = 314.966>\n",
      "Epoch 116 / 150  [t=507.98s]  <loss = 23.62310, ref_loss = 633.34137, max_Q = 26.6,  mse_true = 318.974>\n",
      "Epoch 117 / 150  [t=512.26s]  <loss = 23.80747, ref_loss = 640.66681, max_Q = 26.6,  mse_true = 321.877>\n",
      "Epoch 118 / 150  [t=518.93s]  <loss = 23.77996, ref_loss = 647.94971, max_Q = 26.7,  mse_true = 322.391>\n",
      "Epoch 119 / 150  [t=523.27s]  <loss = 23.50848, ref_loss = 625.78015, max_Q = 26.4,  mse_true = 317.968>\n",
      "Epoch 120 / 150  [t=527.47s]  <loss = 23.96814, ref_loss = 644.57166, max_Q = 26.8,  mse_true = 325.565>\n",
      "Epoch 121 / 150  [t=533.17s]  <loss = 24.06466, ref_loss = 647.86737, max_Q = 26.8,  mse_true = 327.207>\n",
      "Epoch 122 / 150  [t=537.52s]  <loss = 24.09848, ref_loss = 650.23004, max_Q = 26.9,  mse_true = 328.140>\n",
      "Epoch 123 / 150  [t=541.91s]  <loss = 24.15340, ref_loss = 645.66193, max_Q = 26.7,  mse_true = 328.311>\n",
      "Epoch 124 / 150  [t=546.17s]  <loss = 24.26192, ref_loss = 645.57239, max_Q = 26.8,  mse_true = 332.132>\n",
      "Epoch 125 / 150  [t=550.28s]  <loss = 24.71626, ref_loss = 671.65112, max_Q = 27.3,  mse_true = 340.338>\n",
      "Epoch 126 / 150  [t=554.38s]  <loss = 24.55458, ref_loss = 669.05701, max_Q = 27.3,  mse_true = 337.582>\n",
      "Epoch 127 / 150  [t=558.42s]  <loss = 24.39836, ref_loss = 662.43451, max_Q = 27.1,  mse_true = 333.793>\n",
      "Epoch 128 / 150  [t=562.44s]  <loss = 24.27815, ref_loss = 650.32684, max_Q = 26.9,  mse_true = 330.869>\n",
      "Epoch 129 / 150  [t=566.44s]  <loss = 24.29915, ref_loss = 645.02124, max_Q = 26.9,  mse_true = 333.961>\n",
      "Epoch 130 / 150  [t=572.93s]  <loss = 24.97553, ref_loss = 678.48169, max_Q = 27.4,  mse_true = 344.672>\n",
      "Epoch 131 / 150  [t=578.36s]  <loss = 24.83250, ref_loss = 662.94775, max_Q = 27.1,  mse_true = 341.420>\n",
      "Epoch 132 / 150  [t=582.59s]  <loss = 25.07216, ref_loss = 672.49634, max_Q = 27.3,  mse_true = 346.510>\n",
      "Epoch 133 / 150  [t=586.57s]  <loss = 25.29291, ref_loss = 675.76599, max_Q = 27.3,  mse_true = 349.899>\n",
      "Epoch 134 / 150  [t=590.63s]  <loss = 25.43417, ref_loss = 697.99200, max_Q = 27.7,  mse_true = 354.483>\n",
      "Epoch 135 / 150  [t=594.69s]  <loss = 25.09284, ref_loss = 672.93018, max_Q = 27.4,  mse_true = 347.033>\n",
      "Epoch 136 / 150  [t=598.73s]  <loss = 25.31116, ref_loss = 686.82300, max_Q = 27.5,  mse_true = 350.670>\n",
      "Epoch 137 / 150  [t=602.94s]  <loss = 25.14782, ref_loss = 669.89044, max_Q = 27.1,  mse_true = 347.583>\n",
      "Epoch 138 / 150  [t=607.10s]  <loss = 25.51676, ref_loss = 682.64386, max_Q = 27.4,  mse_true = 354.161>\n",
      "Epoch 139 / 150  [t=611.15s]  <loss = 25.68523, ref_loss = 688.39050, max_Q = 27.7,  mse_true = 358.142>\n",
      "Epoch 140 / 150  [t=615.43s]  <loss = 25.92425, ref_loss = 700.42981, max_Q = 27.8,  mse_true = 362.108>\n",
      "Epoch 141 / 150  [t=623.23s]  <loss = 25.88375, ref_loss = 693.14941, max_Q = 27.7,  mse_true = 361.090>\n",
      "Epoch 142 / 150  [t=627.34s]  <loss = 26.04743, ref_loss = 695.21106, max_Q = 27.7,  mse_true = 364.588>\n",
      "Epoch 143 / 150  [t=631.70s]  <loss = 26.36680, ref_loss = 708.50739, max_Q = 28.0,  mse_true = 370.373>\n",
      "Epoch 144 / 150  [t=636.07s]  <loss = 26.44317, ref_loss = 705.65808, max_Q = 27.9,  mse_true = 372.188>\n",
      "Epoch 145 / 150  [t=640.44s]  <loss = 26.70474, ref_loss = 711.08313, max_Q = 28.0,  mse_true = 378.248>\n",
      "Epoch 146 / 150  [t=644.76s]  <loss = 27.22197, ref_loss = 727.13696, max_Q = 28.2,  mse_true = 386.824>\n",
      "Epoch 147 / 150  [t=649.00s]  <loss = 27.49782, ref_loss = 734.53058, max_Q = 28.4,  mse_true = 392.254>\n",
      "Epoch 148 / 150  [t=653.49s]  <loss = 27.76737, ref_loss = 751.47278, max_Q = 28.8,  mse_true = 397.886>\n",
      "Epoch 149 / 150  [t=657.64s]  <loss = 27.66035, ref_loss = 755.02332, max_Q = 28.8,  mse_true = 396.421>\n",
      "Epoch 150 / 150  [t=661.79s]  <loss = 27.40950, ref_loss = 739.73932, max_Q = 28.6,  mse_true = 390.581>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_runs = 3\n",
    "\n",
    "for run_idx in range(num_runs) :\n",
    "    run_experiment(run_config_standard_Q, run_idx+1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cfd4142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory figures/Helicopter_NB0/clone_20 created\n",
      "Directory figures/Helicopter_NB0/clone_20/experiment_1 created\n",
      "==================================================================================================================\n",
      "Environment config:\n",
      "> distance_to_end: 13\n",
      "> game_board_pad_size: 3\n",
      "> horizontal_size: 20\n",
      "> reward_per_turn: -1.0\n",
      "> lambda_dx: 0.0\n",
      "> lambda_b: -1.0\n",
      "> gamma: 1.0\n",
      "> x_min: 0\n",
      "> x_max: 19\n",
      "> x_range: 19\n",
      "> x_start: 3\n",
      "> x_end: 16\n",
      "> action_list: [-1  0  1]\n",
      "==================================================================================================================\n",
      "Training config:\n",
      "> Stop training when mse_true exceeds 0.05\n",
      "> Using 1 step empirical returns\n",
      "> Using bootstrap method: clone\n",
      "> Using epochs of length None\n",
      "> Updating gradient every batch of size 10\n",
      "> Using optimizer_q1 <keras.optimizer_v2.gradient_descent.SGD object at 0x36ca9e0a0> with learning rate 0.01\n",
      "> Using optimizer_q2 None with learning rate 0.01\n",
      "> Swapping q1 and q2 every -1 epochs\n",
      "> Cloning q2 from q1 every 20 epochs\n",
      "> Assigning a weight of 0.3 to anchoring state/action pairs\n",
      "==================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/ipykernel_58834/1750174422.py:191: RuntimeWarning: All-NaN slice encountered\n",
      "  y_min   = np.nanmin([0, np.nanmin(true_q), np.nanmin(target_q), np.nanmin(q_model), np.nanmin(bs_model)])\n",
      "/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/ipykernel_58834/1750174422.py:192: RuntimeWarning: All-NaN slice encountered\n",
      "  y_max   = np.nanmax([0, np.nanmax(true_q), np.nanmax(target_q), np.nanmax(q_model), np.nanmax(bs_model)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 400  [t=3.20s]  <loss = 0.82902, ref_loss = 0.98630, max_Q = 0.2,  mse_true = 92.668>    \n",
      "Epoch 2 / 400  [t=5.13s]  <loss = 0.52303, ref_loss = 0.49684, max_Q = 0.4,  mse_true = 88.641>    \n",
      "Epoch 3 / 400  [t=6.92s]  <loss = 0.30445, ref_loss = 0.22834, max_Q = 0.6,  mse_true = 85.549>    \n",
      "Epoch 4 / 400  [t=8.71s]  <loss = 0.15454, ref_loss = 0.09193, max_Q = 0.8,  mse_true = 83.170>    \n",
      "Epoch 5 / 400  [t=10.61s]  <loss = 0.09641, ref_loss = 0.03274, max_Q = 0.9,  mse_true = 81.458>   \n",
      "Epoch 6 / 400  [t=12.58s]  <loss = 0.06741, ref_loss = 0.00950, max_Q = 1.0,  mse_true = 80.182>   \n",
      "Epoch 7 / 400  [t=14.41s]  <loss = 0.04173, ref_loss = 0.00198, max_Q = 1.0,  mse_true = 79.250>   \n",
      "Epoch 8 / 400  [t=16.23s]  <loss = 0.03525, ref_loss = 0.00159, max_Q = 1.1,  mse_true = 78.699>   \n",
      "Epoch 9 / 400  [t=17.99s]  <loss = 0.03793, ref_loss = 0.00220, max_Q = 1.1,  mse_true = 78.317>   \n",
      "Epoch 10 / 400  [t=19.77s]  <loss = 0.03058, ref_loss = 0.00323, max_Q = 1.1,  mse_true = 78.002>  \n",
      "Epoch 11 / 400  [t=22.98s]  <loss = 0.03439, ref_loss = 0.00382, max_Q = 1.1,  mse_true = 77.824>  \n",
      "Epoch 12 / 400  [t=24.83s]  <loss = 0.02816, ref_loss = 0.00393, max_Q = 1.1,  mse_true = 77.679>  \n",
      "Epoch 13 / 400  [t=26.67s]  <loss = 0.02698, ref_loss = 0.00366, max_Q = 1.1,  mse_true = 77.583>  \n",
      "Epoch 14 / 400  [t=28.44s]  <loss = 0.02631, ref_loss = 0.00351, max_Q = 1.1,  mse_true = 77.494>  \n",
      "Epoch 15 / 400  [t=30.19s]  <loss = 0.03112, ref_loss = 0.00337, max_Q = 1.1,  mse_true = 77.413>  \n",
      "Epoch 16 / 400  [t=32.14s]  <loss = 0.02517, ref_loss = 0.00333, max_Q = 1.1,  mse_true = 77.312>  \n",
      "Epoch 17 / 400  [t=33.91s]  <loss = 0.02477, ref_loss = 0.00308, max_Q = 1.1,  mse_true = 77.269>  \n",
      "Epoch 18 / 400  [t=35.81s]  <loss = 0.02444, ref_loss = 0.00311, max_Q = 1.1,  mse_true = 77.220>  \n",
      "Epoch 19 / 400  [t=42.89s]  <loss = 0.02420, ref_loss = 0.00295, max_Q = 1.1,  mse_true = 77.191>  \n",
      "Epoch 20 / 400  [t=44.66s]  <loss = 0.02379, ref_loss = 0.00212, max_Q = 1.1,  mse_true = 77.169>  \n",
      "Epoch 21 / 400  [t=48.55s]  <loss = 0.52729, ref_loss = 0.02962, max_Q = 1.3,  mse_true = 77.101>  \n",
      "Epoch 22 / 400  [t=50.53s]  <loss = 0.37130, ref_loss = 0.13038, max_Q = 1.5,  mse_true = 73.994>  \n",
      "Epoch 23 / 400  [t=52.33s]  <loss = 0.29509, ref_loss = 0.25054, max_Q = 1.6,  mse_true = 71.833>  \n",
      "Epoch 24 / 400  [t=54.11s]  <loss = 0.27358, ref_loss = 0.30837, max_Q = 1.6,  mse_true = 70.558>  \n",
      "Epoch 25 / 400  [t=56.29s]  <loss = 0.24774, ref_loss = 0.34295, max_Q = 1.6,  mse_true = 69.718>  \n",
      "Epoch 26 / 400  [t=58.26s]  <loss = 0.24371, ref_loss = 0.34813, max_Q = 1.6,  mse_true = 69.188>  \n",
      "Epoch 27 / 400  [t=60.03s]  <loss = 0.23124, ref_loss = 0.35885, max_Q = 1.6,  mse_true = 68.727>  \n",
      "Epoch 28 / 400  [t=62.10s]  <loss = 0.21615, ref_loss = 0.34261, max_Q = 1.7,  mse_true = 68.438>  \n",
      "Epoch 29 / 400  [t=63.93s]  <loss = 0.20867, ref_loss = 0.34030, max_Q = 1.7,  mse_true = 68.190>  \n",
      "Epoch 30 / 400  [t=65.80s]  <loss = 0.20232, ref_loss = 0.32938, max_Q = 1.7,  mse_true = 68.011>  \n",
      "Epoch 31 / 400  [t=69.33s]  <loss = 0.19434, ref_loss = 0.30694, max_Q = 1.7,  mse_true = 67.888>  \n",
      "Epoch 32 / 400  [t=71.23s]  <loss = 0.18859, ref_loss = 0.30172, max_Q = 1.7,  mse_true = 67.664>  \n",
      "Epoch 33 / 400  [t=73.00s]  <loss = 0.18369, ref_loss = 0.29623, max_Q = 1.8,  mse_true = 67.492>  \n",
      "Epoch 34 / 400  [t=75.10s]  <loss = 0.18051, ref_loss = 0.28442, max_Q = 1.8,  mse_true = 67.348>  \n",
      "Epoch 35 / 400  [t=76.97s]  <loss = 0.17995, ref_loss = 0.27355, max_Q = 1.8,  mse_true = 67.168>  \n",
      "Epoch 36 / 400  [t=78.86s]  <loss = 0.17569, ref_loss = 0.25872, max_Q = 1.8,  mse_true = 67.022>  \n",
      "Epoch 37 / 400  [t=80.81s]  <loss = 0.17045, ref_loss = 0.26025, max_Q = 1.8,  mse_true = 66.781>  \n",
      "Epoch 38 / 400  [t=82.90s]  <loss = 0.16255, ref_loss = 0.25180, max_Q = 1.8,  mse_true = 66.645>  \n",
      "Epoch 39 / 400  [t=84.66s]  <loss = 0.16063, ref_loss = 0.24504, max_Q = 1.9,  mse_true = 66.545>  \n",
      "Epoch 40 / 400  [t=86.49s]  <loss = 0.17004, ref_loss = 0.23559, max_Q = 1.9,  mse_true = 66.454>  \n",
      "Epoch 41 / 400  [t=90.15s]  <loss = 0.66528, ref_loss = 0.37962, max_Q = 2.1,  mse_true = 66.233>  \n",
      "Epoch 42 / 400  [t=91.98s]  <loss = 0.53769, ref_loss = 0.66442, max_Q = 2.3,  mse_true = 62.608>  \n",
      "Epoch 43 / 400  [t=93.62s]  <loss = 0.50074, ref_loss = 0.74197, max_Q = 2.4,  mse_true = 60.894>  \n",
      "Epoch 44 / 400  [t=95.76s]  <loss = 0.45734, ref_loss = 0.78739, max_Q = 2.5,  mse_true = 59.749>  \n",
      "Epoch 45 / 400  [t=97.42s]  <loss = 0.43324, ref_loss = 0.76336, max_Q = 2.5,  mse_true = 59.154>  \n",
      "Epoch 46 / 400  [t=99.24s]  <loss = 0.41565, ref_loss = 0.73881, max_Q = 2.6,  mse_true = 58.650>  \n",
      "Epoch 47 / 400  [t=100.96s]  <loss = 0.39300, ref_loss = 0.69824, max_Q = 2.6,  mse_true = 58.249> \n",
      "Epoch 48 / 400  [t=102.85s]  <loss = 0.38100, ref_loss = 0.63890, max_Q = 2.7,  mse_true = 57.915> \n",
      "Epoch 49 / 400  [t=104.49s]  <loss = 0.36919, ref_loss = 0.59137, max_Q = 2.7,  mse_true = 57.525> \n",
      "Epoch 50 / 400  [t=106.20s]  <loss = 0.35398, ref_loss = 0.59492, max_Q = 2.8,  mse_true = 56.861> \n",
      "Epoch 51 / 400  [t=109.71s]  <loss = 0.34218, ref_loss = 0.56614, max_Q = 2.8,  mse_true = 56.568> \n",
      "Epoch 52 / 400  [t=111.46s]  <loss = 0.33413, ref_loss = 0.51355, max_Q = 2.8,  mse_true = 56.403> \n",
      "Epoch 53 / 400  [t=113.08s]  <loss = 0.32578, ref_loss = 0.49668, max_Q = 2.9,  mse_true = 56.052> \n",
      "Epoch 54 / 400  [t=114.69s]  <loss = 0.33038, ref_loss = 0.47775, max_Q = 2.9,  mse_true = 55.707> \n",
      "Epoch 55 / 400  [t=116.65s]  <loss = 0.31537, ref_loss = 0.45016, max_Q = 2.9,  mse_true = 55.577> \n",
      "Epoch 56 / 400  [t=118.54s]  <loss = 0.29824, ref_loss = 0.46385, max_Q = 2.9,  mse_true = 55.198> \n",
      "Epoch 57 / 400  [t=120.29s]  <loss = 0.29702, ref_loss = 0.43513, max_Q = 3.0,  mse_true = 55.359> \n",
      "Epoch 58 / 400  [t=122.34s]  <loss = 0.29409, ref_loss = 0.36375, max_Q = 2.9,  mse_true = 55.436> \n",
      "Epoch 59 / 400  [t=123.95s]  <loss = 0.29023, ref_loss = 0.40017, max_Q = 3.0,  mse_true = 54.911> \n",
      "Epoch 60 / 400  [t=125.62s]  <loss = 0.30680, ref_loss = 0.35582, max_Q = 3.0,  mse_true = 54.922> \n",
      "Epoch 61 / 400  [t=129.00s]  <loss = 0.61026, ref_loss = 0.58467, max_Q = 3.3,  mse_true = 54.668> \n",
      "Epoch 62 / 400  [t=130.95s]  <loss = 0.47183, ref_loss = 0.75636, max_Q = 3.6,  mse_true = 50.490> \n",
      "Epoch 63 / 400  [t=132.67s]  <loss = 0.41143, ref_loss = 0.69322, max_Q = 3.7,  mse_true = 48.798> \n",
      "Epoch 64 / 400  [t=134.44s]  <loss = 0.37686, ref_loss = 0.64571, max_Q = 3.8,  mse_true = 47.619> \n",
      "Epoch 65 / 400  [t=136.28s]  <loss = 0.35363, ref_loss = 0.61093, max_Q = 3.9,  mse_true = 46.912> \n",
      "Epoch 66 / 400  [t=138.54s]  <loss = 0.33605, ref_loss = 0.52586, max_Q = 4.0,  mse_true = 46.404> \n",
      "Epoch 67 / 400  [t=140.24s]  <loss = 0.32640, ref_loss = 0.46310, max_Q = 4.0,  mse_true = 46.091> \n",
      "Epoch 68 / 400  [t=142.02s]  <loss = 0.34238, ref_loss = 0.42378, max_Q = 4.1,  mse_true = 45.528> \n",
      "Epoch 69 / 400  [t=143.67s]  <loss = 0.31123, ref_loss = 0.43158, max_Q = 4.1,  mse_true = 45.111> \n",
      "Epoch 70 / 400  [t=145.63s]  <loss = 0.31353, ref_loss = 0.38422, max_Q = 4.1,  mse_true = 45.517> \n",
      "Epoch 71 / 400  [t=148.93s]  <loss = 0.30800, ref_loss = 0.38244, max_Q = 4.1,  mse_true = 45.250> \n",
      "Epoch 72 / 400  [t=150.61s]  <loss = 0.30334, ref_loss = 0.35352, max_Q = 4.1,  mse_true = 45.263> \n",
      "Epoch 73 / 400  [t=152.30s]  <loss = 0.31347, ref_loss = 0.33666, max_Q = 4.2,  mse_true = 45.086> \n",
      "Epoch 74 / 400  [t=154.22s]  <loss = 0.31155, ref_loss = 0.33225, max_Q = 4.1,  mse_true = 44.609> \n",
      "Epoch 75 / 400  [t=155.92s]  <loss = 0.30574, ref_loss = 0.34503, max_Q = 4.1,  mse_true = 44.423> \n",
      "Epoch 76 / 400  [t=157.72s]  <loss = 0.29318, ref_loss = 0.35268, max_Q = 4.1,  mse_true = 44.551> \n",
      "Epoch 77 / 400  [t=159.31s]  <loss = 0.29155, ref_loss = 0.31370, max_Q = 4.2,  mse_true = 44.672> \n",
      "Epoch 78 / 400  [t=161.24s]  <loss = 0.29724, ref_loss = 0.33702, max_Q = 4.1,  mse_true = 44.661> \n",
      "Epoch 79 / 400  [t=162.84s]  <loss = 0.28757, ref_loss = 0.32232, max_Q = 4.1,  mse_true = 44.968> \n",
      "Epoch 80 / 400  [t=164.46s]  <loss = 0.28927, ref_loss = 0.29169, max_Q = 4.1,  mse_true = 45.012> \n",
      "Epoch 81 / 400  [t=167.86s]  <loss = 0.47317, ref_loss = 0.45594, max_Q = 4.5,  mse_true = 44.606> \n",
      "Epoch 82 / 400  [t=169.74s]  <loss = 0.32364, ref_loss = 0.52469, max_Q = 4.9,  mse_true = 39.693> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 / 400  [t=171.52s]  <loss = 0.28792, ref_loss = 0.43961, max_Q = 5.0,  mse_true = 38.345> \n",
      "Epoch 84 / 400  [t=173.18s]  <loss = 0.27953, ref_loss = 0.37422, max_Q = 5.1,  mse_true = 37.307> \n",
      "Epoch 85 / 400  [t=174.79s]  <loss = 0.27526, ref_loss = 0.33422, max_Q = 5.1,  mse_true = 36.937> \n",
      "Epoch 86 / 400  [t=176.66s]  <loss = 0.26036, ref_loss = 0.33558, max_Q = 5.2,  mse_true = 36.341> \n",
      "Epoch 87 / 400  [t=178.62s]  <loss = 0.26354, ref_loss = 0.31001, max_Q = 5.2,  mse_true = 36.634> \n",
      "Epoch 88 / 400  [t=180.24s]  <loss = 0.28019, ref_loss = 0.26474, max_Q = 5.2,  mse_true = 36.434> \n",
      "Epoch 89 / 400  [t=181.94s]  <loss = 0.29359, ref_loss = 0.26872, max_Q = 5.2,  mse_true = 35.956> \n",
      "Epoch 90 / 400  [t=183.59s]  <loss = 0.26468, ref_loss = 0.30872, max_Q = 5.2,  mse_true = 35.622> \n",
      "Epoch 91 / 400  [t=187.52s]  <loss = 0.24943, ref_loss = 0.28426, max_Q = 5.3,  mse_true = 36.450> \n",
      "Epoch 92 / 400  [t=189.26s]  <loss = 0.27196, ref_loss = 0.22915, max_Q = 5.2,  mse_true = 36.825> \n",
      "Epoch 93 / 400  [t=190.97s]  <loss = 0.25296, ref_loss = 0.24425, max_Q = 5.3,  mse_true = 36.448> \n",
      "Epoch 94 / 400  [t=192.69s]  <loss = 0.23976, ref_loss = 0.24856, max_Q = 5.2,  mse_true = 36.625> \n",
      "Epoch 95 / 400  [t=194.37s]  <loss = 0.24686, ref_loss = 0.24552, max_Q = 5.2,  mse_true = 36.823> \n",
      "Epoch 96 / 400  [t=196.64s]  <loss = 0.24239, ref_loss = 0.23407, max_Q = 5.2,  mse_true = 36.818> \n",
      "Epoch 97 / 400  [t=198.40s]  <loss = 0.24998, ref_loss = 0.22577, max_Q = 5.2,  mse_true = 36.561> \n",
      "Epoch 98 / 400  [t=200.39s]  <loss = 0.24258, ref_loss = 0.26329, max_Q = 5.3,  mse_true = 36.136> \n",
      "Epoch 99 / 400  [t=202.19s]  <loss = 0.25755, ref_loss = 0.22229, max_Q = 5.2,  mse_true = 36.638> \n",
      "Epoch 100 / 400  [t=203.94s]  <loss = 0.24980, ref_loss = 0.23467, max_Q = 5.2,  mse_true = 36.518>\n",
      "Epoch 101 / 400  [t=207.88s]  <loss = 0.37607, ref_loss = 0.37210, max_Q = 5.6,  mse_true = 36.304>\n",
      "Epoch 102 / 400  [t=209.58s]  <loss = 0.26883, ref_loss = 0.32592, max_Q = 6.1,  mse_true = 31.113>\n",
      "Epoch 103 / 400  [t=211.30s]  <loss = 0.24013, ref_loss = 0.30907, max_Q = 6.2,  mse_true = 29.397>\n",
      "Epoch 104 / 400  [t=212.99s]  <loss = 0.23059, ref_loss = 0.27913, max_Q = 6.4,  mse_true = 28.908>\n",
      "Epoch 105 / 400  [t=214.61s]  <loss = 0.22791, ref_loss = 0.23269, max_Q = 6.3,  mse_true = 29.299>\n",
      "Epoch 106 / 400  [t=216.83s]  <loss = 0.22602, ref_loss = 0.23535, max_Q = 6.3,  mse_true = 28.898>\n",
      "Epoch 107 / 400  [t=218.43s]  <loss = 0.22267, ref_loss = 0.22474, max_Q = 6.3,  mse_true = 29.336>\n",
      "Epoch 108 / 400  [t=220.04s]  <loss = 0.22244, ref_loss = 0.20246, max_Q = 6.3,  mse_true = 29.541>\n",
      "Epoch 109 / 400  [t=221.73s]  <loss = 0.22868, ref_loss = 0.19038, max_Q = 6.3,  mse_true = 29.596>\n",
      "Epoch 110 / 400  [t=223.42s]  <loss = 0.21843, ref_loss = 0.21416, max_Q = 6.3,  mse_true = 29.371>\n",
      "Epoch 111 / 400  [t=226.92s]  <loss = 0.23490, ref_loss = 0.16832, max_Q = 6.2,  mse_true = 29.523>\n",
      "Epoch 112 / 400  [t=228.87s]  <loss = 0.21937, ref_loss = 0.22081, max_Q = 6.3,  mse_true = 28.852>\n",
      "Epoch 113 / 400  [t=230.76s]  <loss = 0.21349, ref_loss = 0.20303, max_Q = 6.3,  mse_true = 29.415>\n",
      "Epoch 114 / 400  [t=232.56s]  <loss = 0.21672, ref_loss = 0.17907, max_Q = 6.2,  mse_true = 29.669>\n",
      "Epoch 115 / 400  [t=234.20s]  <loss = 0.22974, ref_loss = 0.18246, max_Q = 6.3,  mse_true = 29.117>\n",
      "Epoch 116 / 400  [t=236.07s]  <loss = 0.20825, ref_loss = 0.20206, max_Q = 6.2,  mse_true = 28.964>\n",
      "Epoch 117 / 400  [t=238.03s]  <loss = 0.20594, ref_loss = 0.20389, max_Q = 6.3,  mse_true = 28.928>\n",
      "Epoch 118 / 400  [t=239.63s]  <loss = 0.21288, ref_loss = 0.17908, max_Q = 6.3,  mse_true = 29.291>\n",
      "Epoch 119 / 400  [t=241.31s]  <loss = 0.20411, ref_loss = 0.17104, max_Q = 6.3,  mse_true = 29.426>\n",
      "Epoch 120 / 400  [t=242.93s]  <loss = 0.20849, ref_loss = 0.16841, max_Q = 6.3,  mse_true = 29.304>\n",
      "Epoch 121 / 400  [t=246.45s]  <loss = 0.32113, ref_loss = 0.28093, max_Q = 6.8,  mse_true = 29.605>\n",
      "Epoch 122 / 400  [t=248.08s]  <loss = 0.19765, ref_loss = 0.23786, max_Q = 7.2,  mse_true = 24.959>\n",
      "Epoch 123 / 400  [t=249.70s]  <loss = 0.18648, ref_loss = 0.21151, max_Q = 7.3,  mse_true = 23.900>\n",
      "Epoch 124 / 400  [t=251.71s]  <loss = 0.18827, ref_loss = 0.17869, max_Q = 7.2,  mse_true = 24.172>\n",
      "Epoch 125 / 400  [t=253.35s]  <loss = 0.18745, ref_loss = 0.15848, max_Q = 7.2,  mse_true = 23.957>\n",
      "Epoch 126 / 400  [t=255.41s]  <loss = 0.18404, ref_loss = 0.13796, max_Q = 7.2,  mse_true = 23.987>\n",
      "Epoch 127 / 400  [t=257.32s]  <loss = 0.18933, ref_loss = 0.13548, max_Q = 7.2,  mse_true = 23.931>\n",
      "Epoch 128 / 400  [t=259.09s]  <loss = 0.18272, ref_loss = 0.16322, max_Q = 7.2,  mse_true = 23.483>\n",
      "Epoch 129 / 400  [t=261.20s]  <loss = 0.18169, ref_loss = 0.13677, max_Q = 7.3,  mse_true = 24.061>\n",
      "Epoch 130 / 400  [t=263.02s]  <loss = 0.18353, ref_loss = 0.15053, max_Q = 7.3,  mse_true = 23.601>\n",
      "Epoch 131 / 400  [t=266.58s]  <loss = 0.18150, ref_loss = 0.15285, max_Q = 7.2,  mse_true = 23.885>\n",
      "Epoch 132 / 400  [t=268.25s]  <loss = 0.17777, ref_loss = 0.13181, max_Q = 7.3,  mse_true = 24.083>\n",
      "Epoch 133 / 400  [t=269.88s]  <loss = 0.18411, ref_loss = 0.12444, max_Q = 7.2,  mse_true = 23.804>\n",
      "Epoch 134 / 400  [t=271.58s]  <loss = 0.17480, ref_loss = 0.14950, max_Q = 7.3,  mse_true = 23.586>\n",
      "Epoch 135 / 400  [t=273.24s]  <loss = 0.17593, ref_loss = 0.12016, max_Q = 7.3,  mse_true = 23.736>\n",
      "Epoch 136 / 400  [t=275.44s]  <loss = 0.17785, ref_loss = 0.14042, max_Q = 7.2,  mse_true = 23.124>\n",
      "Epoch 137 / 400  [t=277.12s]  <loss = 0.17129, ref_loss = 0.13038, max_Q = 7.3,  mse_true = 23.688>\n",
      "Epoch 138 / 400  [t=278.73s]  <loss = 0.17551, ref_loss = 0.12122, max_Q = 7.3,  mse_true = 23.783>\n",
      "Epoch 139 / 400  [t=280.35s]  <loss = 0.17919, ref_loss = 0.12651, max_Q = 7.3,  mse_true = 23.640>\n",
      "Epoch 140 / 400  [t=282.02s]  <loss = 0.17521, ref_loss = 0.13612, max_Q = 7.3,  mse_true = 23.824>\n",
      "Epoch 141 / 400  [t=285.63s]  <loss = 0.25421, ref_loss = 0.22019, max_Q = 7.9,  mse_true = 23.637>\n",
      "Epoch 142 / 400  [t=287.27s]  <loss = 0.18117, ref_loss = 0.16898, max_Q = 8.2,  mse_true = 19.095>\n",
      "Epoch 143 / 400  [t=289.24s]  <loss = 0.17232, ref_loss = 0.15175, max_Q = 8.3,  mse_true = 18.270>\n",
      "Epoch 144 / 400  [t=290.93s]  <loss = 0.17160, ref_loss = 0.13950, max_Q = 8.4,  mse_true = 18.053>\n",
      "Epoch 145 / 400  [t=292.59s]  <loss = 0.17590, ref_loss = 0.12802, max_Q = 8.3,  mse_true = 18.418>\n",
      "Epoch 146 / 400  [t=294.38s]  <loss = 0.16976, ref_loss = 0.11922, max_Q = 8.3,  mse_true = 18.317>\n",
      "Epoch 147 / 400  [t=296.09s]  <loss = 0.16275, ref_loss = 0.13353, max_Q = 8.3,  mse_true = 18.232>\n",
      "Epoch 148 / 400  [t=297.83s]  <loss = 0.16486, ref_loss = 0.12105, max_Q = 8.2,  mse_true = 18.732>\n",
      "Epoch 149 / 400  [t=299.84s]  <loss = 0.16307, ref_loss = 0.11323, max_Q = 8.3,  mse_true = 18.296>\n",
      "Epoch 150 / 400  [t=301.52s]  <loss = 0.16708, ref_loss = 0.09688, max_Q = 8.3,  mse_true = 18.796>\n",
      "Epoch 151 / 400  [t=304.98s]  <loss = 0.16839, ref_loss = 0.11315, max_Q = 8.3,  mse_true = 18.471>\n",
      "Epoch 152 / 400  [t=306.67s]  <loss = 0.16740, ref_loss = 0.12115, max_Q = 8.3,  mse_true = 18.003>\n",
      "Epoch 153 / 400  [t=308.29s]  <loss = 0.16295, ref_loss = 0.11278, max_Q = 8.2,  mse_true = 18.123>\n",
      "Epoch 154 / 400  [t=309.90s]  <loss = 0.17308, ref_loss = 0.10568, max_Q = 8.3,  mse_true = 18.688>\n",
      "Epoch 155 / 400  [t=311.57s]  <loss = 0.15567, ref_loss = 0.11632, max_Q = 8.3,  mse_true = 18.418>\n",
      "Epoch 156 / 400  [t=313.36s]  <loss = 0.15924, ref_loss = 0.10658, max_Q = 8.2,  mse_true = 18.878>\n",
      "Epoch 157 / 400  [t=315.42s]  <loss = 0.15061, ref_loss = 0.11754, max_Q = 8.3,  mse_true = 18.447>\n",
      "Epoch 158 / 400  [t=317.10s]  <loss = 0.15787, ref_loss = 0.09646, max_Q = 8.2,  mse_true = 18.775>\n",
      "Epoch 159 / 400  [t=318.79s]  <loss = 0.15918, ref_loss = 0.11260, max_Q = 8.3,  mse_true = 18.634>\n",
      "Epoch 160 / 400  [t=320.50s]  <loss = 0.15372, ref_loss = 0.09943, max_Q = 8.2,  mse_true = 19.140>\n",
      "Epoch 161 / 400  [t=324.39s]  <loss = 0.24378, ref_loss = 0.15265, max_Q = 8.6,  mse_true = 18.492>\n",
      "Epoch 162 / 400  [t=326.25s]  <loss = 0.15918, ref_loss = 0.15666, max_Q = 9.3,  mse_true = 14.241>\n",
      "Epoch 163 / 400  [t=328.09s]  <loss = 0.15389, ref_loss = 0.11325, max_Q = 9.2,  mse_true = 14.654>\n",
      "Epoch 164 / 400  [t=329.94s]  <loss = 0.15144, ref_loss = 0.11043, max_Q = 9.2,  mse_true = 14.300>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165 / 400  [t=331.73s]  <loss = 0.15231, ref_loss = 0.09570, max_Q = 9.2,  mse_true = 14.688>\n",
      "Epoch 166 / 400  [t=334.08s]  <loss = 0.14923, ref_loss = 0.08827, max_Q = 9.3,  mse_true = 14.423>\n",
      "Epoch 167 / 400  [t=335.86s]  <loss = 0.15019, ref_loss = 0.09478, max_Q = 9.2,  mse_true = 14.794>\n",
      "Epoch 168 / 400  [t=337.87s]  <loss = 0.14690, ref_loss = 0.08986, max_Q = 9.3,  mse_true = 14.319>\n",
      "Epoch 169 / 400  [t=339.57s]  <loss = 0.15089, ref_loss = 0.10350, max_Q = 9.3,  mse_true = 13.969>\n",
      "Epoch 170 / 400  [t=341.34s]  <loss = 0.14816, ref_loss = 0.09842, max_Q = 9.2,  mse_true = 14.523>\n",
      "Epoch 171 / 400  [t=345.23s]  <loss = 0.16571, ref_loss = 0.07257, max_Q = 9.3,  mse_true = 14.874>\n",
      "Epoch 172 / 400  [t=347.13s]  <loss = 0.17086, ref_loss = 0.09716, max_Q = 9.2,  mse_true = 14.386>\n",
      "Epoch 173 / 400  [t=348.79s]  <loss = 0.14291, ref_loss = 0.13146, max_Q = 9.2,  mse_true = 13.993>\n",
      "Epoch 174 / 400  [t=350.94s]  <loss = 0.14685, ref_loss = 0.08444, max_Q = 9.2,  mse_true = 14.027>\n",
      "Epoch 175 / 400  [t=352.58s]  <loss = 0.14834, ref_loss = 0.09242, max_Q = 9.3,  mse_true = 14.061>\n",
      "Epoch 176 / 400  [t=354.47s]  <loss = 0.14132, ref_loss = 0.10831, max_Q = 9.2,  mse_true = 13.580>\n",
      "Epoch 177 / 400  [t=356.17s]  <loss = 0.16436, ref_loss = 0.07603, max_Q = 9.2,  mse_true = 14.473>\n",
      "Epoch 178 / 400  [t=357.81s]  <loss = 0.14620, ref_loss = 0.11706, max_Q = 9.2,  mse_true = 14.003>\n",
      "Epoch 179 / 400  [t=359.50s]  <loss = 0.14223, ref_loss = 0.08905, max_Q = 9.3,  mse_true = 13.875>\n",
      "Epoch 180 / 400  [t=361.20s]  <loss = 0.14190, ref_loss = 0.09971, max_Q = 9.2,  mse_true = 14.101>\n",
      "Epoch 181 / 400  [t=365.01s]  <loss = 0.19332, ref_loss = 0.14015, max_Q = 9.8,  mse_true = 14.439>\n",
      "Epoch 182 / 400  [t=367.40s]  <loss = 0.14026, ref_loss = 0.08803, max_Q = 10.1,  mse_true = 11.786>\n",
      "Epoch 183 / 400  [t=370.06s]  <loss = 0.14162, ref_loss = 0.09275, max_Q = 10.1,  mse_true = 11.035>\n",
      "Epoch 184 / 400  [t=371.96s]  <loss = 0.15045, ref_loss = 0.07424, max_Q = 10.1,  mse_true = 10.501>\n",
      "Epoch 185 / 400  [t=373.64s]  <loss = 0.13754, ref_loss = 0.07622, max_Q = 10.1,  mse_true = 10.914>\n",
      "Epoch 186 / 400  [t=375.60s]  <loss = 0.13177, ref_loss = 0.08383, max_Q = 10.2,  mse_true = 10.939>\n",
      "Epoch 187 / 400  [t=377.39s]  <loss = 0.13045, ref_loss = 0.08425, max_Q = 10.1,  mse_true = 11.092>\n",
      "Epoch 188 / 400  [t=379.16s]  <loss = 0.13285, ref_loss = 0.07127, max_Q = 10.2,  mse_true = 11.004>\n",
      "Epoch 189 / 400  [t=380.78s]  <loss = 0.13555, ref_loss = 0.08448, max_Q = 10.2,  mse_true = 11.023>\n",
      "Epoch 190 / 400  [t=382.93s]  <loss = 0.12803, ref_loss = 0.07292, max_Q = 10.3,  mse_true = 10.676>\n",
      "Epoch 191 / 400  [t=386.18s]  <loss = 0.12378, ref_loss = 0.07486, max_Q = 10.1,  mse_true = 11.108>\n",
      "Epoch 192 / 400  [t=388.24s]  <loss = 0.12924, ref_loss = 0.07021, max_Q = 10.1,  mse_true = 11.063>\n",
      "Epoch 193 / 400  [t=389.88s]  <loss = 0.12957, ref_loss = 0.07034, max_Q = 10.0,  mse_true = 10.918>\n",
      "Epoch 194 / 400  [t=391.52s]  <loss = 0.12620, ref_loss = 0.07088, max_Q = 10.2,  mse_true = 10.680>\n",
      "Epoch 195 / 400  [t=393.18s]  <loss = 0.13810, ref_loss = 0.07826, max_Q = 10.1,  mse_true = 10.741>\n",
      "Epoch 196 / 400  [t=395.01s]  <loss = 0.12357, ref_loss = 0.07294, max_Q = 10.2,  mse_true = 10.882>\n",
      "Epoch 197 / 400  [t=396.66s]  <loss = 0.12554, ref_loss = 0.08413, max_Q = 10.1,  mse_true = 11.028>\n",
      "Epoch 198 / 400  [t=398.29s]  <loss = 0.12511, ref_loss = 0.08015, max_Q = 10.2,  mse_true = 10.391>\n",
      "Epoch 199 / 400  [t=399.91s]  <loss = 0.11871, ref_loss = 0.08132, max_Q = 10.2,  mse_true = 11.213>\n",
      "Epoch 200 / 400  [t=402.07s]  <loss = 0.11975, ref_loss = 0.06085, max_Q = 10.2,  mse_true = 10.867>\n",
      "Epoch 201 / 400  [t=405.31s]  <loss = 0.16134, ref_loss = 0.12176, max_Q = 10.7,  mse_true = 10.477>\n",
      "Epoch 202 / 400  [t=407.39s]  <loss = 0.12697, ref_loss = 0.08755, max_Q = 11.2,  mse_true = 7.948>\n",
      "Epoch 203 / 400  [t=409.04s]  <loss = 0.12380, ref_loss = 0.06668, max_Q = 11.2,  mse_true = 7.600>\n",
      "Epoch 204 / 400  [t=410.68s]  <loss = 0.12344, ref_loss = 0.05705, max_Q = 11.2,  mse_true = 7.628>\n",
      "Epoch 205 / 400  [t=412.32s]  <loss = 0.12498, ref_loss = 0.07886, max_Q = 11.2,  mse_true = 7.580>\n",
      "Epoch 206 / 400  [t=414.13s]  <loss = 0.12616, ref_loss = 0.06545, max_Q = 11.1,  mse_true = 7.993>\n",
      "Epoch 207 / 400  [t=415.75s]  <loss = 0.14289, ref_loss = 0.05692, max_Q = 11.2,  mse_true = 7.466>\n",
      "Epoch 208 / 400  [t=417.38s]  <loss = 0.12230, ref_loss = 0.08273, max_Q = 11.1,  mse_true = 7.894>\n",
      "Epoch 209 / 400  [t=419.01s]  <loss = 0.12319, ref_loss = 0.07169, max_Q = 11.1,  mse_true = 7.886>\n",
      "Epoch 210 / 400  [t=421.21s]  <loss = 0.12137, ref_loss = 0.08383, max_Q = 11.2,  mse_true = 7.346>\n",
      "Epoch 211 / 400  [t=424.41s]  <loss = 0.13788, ref_loss = 0.05049, max_Q = 11.1,  mse_true = 7.595>\n",
      "Epoch 212 / 400  [t=426.51s]  <loss = 0.13530, ref_loss = 0.08758, max_Q = 11.1,  mse_true = 7.417>\n",
      "Epoch 213 / 400  [t=428.14s]  <loss = 0.12851, ref_loss = 0.06317, max_Q = 11.2,  mse_true = 7.637>\n",
      "Epoch 214 / 400  [t=429.76s]  <loss = 0.11287, ref_loss = 0.09744, max_Q = 11.2,  mse_true = 7.503>\n",
      "Epoch 215 / 400  [t=431.39s]  <loss = 0.11351, ref_loss = 0.06346, max_Q = 11.2,  mse_true = 8.015>\n",
      "Epoch 216 / 400  [t=433.20s]  <loss = 0.13627, ref_loss = 0.04047, max_Q = 11.3,  mse_true = 7.554>\n",
      "Epoch 217 / 400  [t=434.82s]  <loss = 0.10930, ref_loss = 0.10704, max_Q = 11.2,  mse_true = 7.690>\n",
      "Epoch 218 / 400  [t=436.44s]  <loss = 0.12654, ref_loss = 0.05197, max_Q = 11.0,  mse_true = 8.342>\n",
      "Epoch 219 / 400  [t=438.07s]  <loss = 0.13381, ref_loss = 0.05443, max_Q = 11.2,  mse_true = 7.820>\n",
      "Epoch 220 / 400  [t=439.69s]  <loss = 0.10715, ref_loss = 0.10883, max_Q = 11.3,  mse_true = 7.337>\n",
      "Epoch 221 / 400  [t=443.51s]  <loss = 0.14287, ref_loss = 0.10048, max_Q = 11.7,  mse_true = 7.932>\n",
      "Epoch 222 / 400  [t=445.14s]  <loss = 0.12373, ref_loss = 0.04209, max_Q = 11.9,  mse_true = 6.031>\n",
      "Epoch 223 / 400  [t=447.26s]  <loss = 0.10553, ref_loss = 0.07172, max_Q = 11.9,  mse_true = 5.754>\n",
      "Epoch 224 / 400  [t=448.90s]  <loss = 0.10196, ref_loss = 0.06785, max_Q = 12.0,  mse_true = 5.725>\n",
      "Epoch 225 / 400  [t=450.54s]  <loss = 0.10502, ref_loss = 0.04671, max_Q = 12.0,  mse_true = 5.985>\n",
      "Epoch 226 / 400  [t=452.34s]  <loss = 0.10111, ref_loss = 0.05059, max_Q = 12.0,  mse_true = 5.627>\n",
      "Epoch 227 / 400  [t=453.96s]  <loss = 0.09656, ref_loss = 0.07398, max_Q = 12.0,  mse_true = 5.762>\n",
      "Epoch 228 / 400  [t=455.59s]  <loss = 0.10959, ref_loss = 0.03647, max_Q = 12.0,  mse_true = 5.920>\n",
      "Epoch 229 / 400  [t=457.22s]  <loss = 0.10324, ref_loss = 0.07581, max_Q = 11.9,  mse_true = 5.375>\n",
      "Epoch 230 / 400  [t=458.85s]  <loss = 0.10948, ref_loss = 0.04399, max_Q = 11.8,  mse_true = 6.168>\n",
      "Epoch 231 / 400  [t=462.67s]  <loss = 0.11526, ref_loss = 0.04942, max_Q = 12.0,  mse_true = 5.511>\n",
      "Epoch 232 / 400  [t=464.31s]  <loss = 0.11006, ref_loss = 0.04913, max_Q = 11.9,  mse_true = 5.809>\n",
      "Epoch 233 / 400  [t=465.96s]  <loss = 0.09448, ref_loss = 0.07865, max_Q = 12.0,  mse_true = 5.479>\n",
      "Epoch 234 / 400  [t=467.60s]  <loss = 0.09088, ref_loss = 0.06354, max_Q = 12.0,  mse_true = 5.715>\n",
      "Epoch 235 / 400  [t=469.25s]  <loss = 0.09784, ref_loss = 0.04698, max_Q = 11.9,  mse_true = 5.531>\n",
      "Epoch 236 / 400  [t=471.64s]  <loss = 0.09086, ref_loss = 0.04854, max_Q = 12.0,  mse_true = 5.632>\n",
      "Epoch 237 / 400  [t=473.29s]  <loss = 0.09029, ref_loss = 0.04471, max_Q = 11.9,  mse_true = 5.487>\n",
      "Epoch 238 / 400  [t=474.92s]  <loss = 0.08532, ref_loss = 0.05608, max_Q = 11.9,  mse_true = 6.046>\n",
      "Epoch 239 / 400  [t=476.56s]  <loss = 0.08975, ref_loss = 0.04623, max_Q = 12.0,  mse_true = 5.735>\n",
      "Epoch 240 / 400  [t=478.19s]  <loss = 0.09086, ref_loss = 0.04166, max_Q = 11.9,  mse_true = 5.938>\n",
      "Epoch 241 / 400  [t=482.03s]  <loss = 0.12236, ref_loss = 0.06319, max_Q = 12.6,  mse_true = 5.724>\n",
      "Epoch 242 / 400  [t=483.67s]  <loss = 0.09396, ref_loss = 0.05676, max_Q = 12.7,  mse_true = 4.366>\n",
      "Epoch 243 / 400  [t=485.31s]  <loss = 0.09227, ref_loss = 0.05025, max_Q = 12.7,  mse_true = 3.824>\n",
      "Epoch 244 / 400  [t=486.95s]  <loss = 0.10292, ref_loss = 0.03105, max_Q = 12.8,  mse_true = 4.260>\n",
      "Epoch 245 / 400  [t=488.58s]  <loss = 0.10097, ref_loss = 0.04765, max_Q = 12.7,  mse_true = 4.086>\n",
      "Epoch 246 / 400  [t=490.39s]  <loss = 0.09184, ref_loss = 0.06244, max_Q = 12.7,  mse_true = 3.819>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247 / 400  [t=492.02s]  <loss = 0.08683, ref_loss = 0.05526, max_Q = 12.7,  mse_true = 4.012>\n",
      "Epoch 248 / 400  [t=493.64s]  <loss = 0.08693, ref_loss = 0.03704, max_Q = 12.8,  mse_true = 4.247>\n",
      "Epoch 249 / 400  [t=495.26s]  <loss = 0.09626, ref_loss = 0.03766, max_Q = 12.8,  mse_true = 4.186>\n",
      "Epoch 250 / 400  [t=497.56s]  <loss = 0.08511, ref_loss = 0.04489, max_Q = 12.7,  mse_true = 4.014>\n",
      "Epoch 251 / 400  [t=500.81s]  <loss = 0.08260, ref_loss = 0.04378, max_Q = 12.7,  mse_true = 4.211>\n",
      "Epoch 252 / 400  [t=502.43s]  <loss = 0.08638, ref_loss = 0.04233, max_Q = 12.7,  mse_true = 3.956>\n",
      "Epoch 253 / 400  [t=504.65s]  <loss = 0.08532, ref_loss = 0.04161, max_Q = 12.7,  mse_true = 3.739>\n",
      "Epoch 254 / 400  [t=506.28s]  <loss = 0.08195, ref_loss = 0.04312, max_Q = 12.7,  mse_true = 3.865>\n",
      "Epoch 255 / 400  [t=507.91s]  <loss = 0.08235, ref_loss = 0.05022, max_Q = 12.7,  mse_true = 4.051>\n",
      "Epoch 256 / 400  [t=509.72s]  <loss = 0.08741, ref_loss = 0.02290, max_Q = 12.7,  mse_true = 4.357>\n",
      "Epoch 257 / 400  [t=511.34s]  <loss = 0.07751, ref_loss = 0.04996, max_Q = 12.8,  mse_true = 4.050>\n",
      "Epoch 258 / 400  [t=512.96s]  <loss = 0.07443, ref_loss = 0.04872, max_Q = 12.7,  mse_true = 4.089>\n",
      "Epoch 259 / 400  [t=514.60s]  <loss = 0.08356, ref_loss = 0.02710, max_Q = 12.7,  mse_true = 4.124>\n",
      "Epoch 260 / 400  [t=516.24s]  <loss = 0.07594, ref_loss = 0.05100, max_Q = 12.7,  mse_true = 3.899>\n",
      "Epoch 261 / 400  [t=520.19s]  <loss = 0.10723, ref_loss = 0.06152, max_Q = 12.8,  mse_true = 4.103>\n",
      "Epoch 262 / 400  [t=521.83s]  <loss = 0.08659, ref_loss = 0.03331, max_Q = 13.4,  mse_true = 3.296>\n",
      "Epoch 263 / 400  [t=523.47s]  <loss = 0.08700, ref_loss = 0.04599, max_Q = 13.3,  mse_true = 2.897>\n",
      "Epoch 264 / 400  [t=525.11s]  <loss = 0.08242, ref_loss = 0.03249, max_Q = 13.5,  mse_true = 2.683>\n",
      "Epoch 265 / 400  [t=526.80s]  <loss = 0.08620, ref_loss = 0.03619, max_Q = 13.4,  mse_true = 2.811>\n",
      "Epoch 266 / 400  [t=528.61s]  <loss = 0.08060, ref_loss = 0.04646, max_Q = 13.5,  mse_true = 2.607>\n",
      "Epoch 267 / 400  [t=530.26s]  <loss = 0.07717, ref_loss = 0.04022, max_Q = 13.4,  mse_true = 3.211>\n",
      "Epoch 268 / 400  [t=532.57s]  <loss = 0.06997, ref_loss = 0.03269, max_Q = 13.5,  mse_true = 3.112>\n",
      "Epoch 269 / 400  [t=534.20s]  <loss = 0.08219, ref_loss = 0.02715, max_Q = 13.4,  mse_true = 2.969>\n",
      "Epoch 270 / 400  [t=535.84s]  <loss = 0.06816, ref_loss = 0.05665, max_Q = 13.4,  mse_true = 2.927>\n",
      "Epoch 271 / 400  [t=539.12s]  <loss = 0.07428, ref_loss = 0.02391, max_Q = 13.4,  mse_true = 2.909>\n",
      "Epoch 272 / 400  [t=540.75s]  <loss = 0.07069, ref_loss = 0.03960, max_Q = 13.5,  mse_true = 2.892>\n",
      "Epoch 273 / 400  [t=543.05s]  <loss = 0.06626, ref_loss = 0.03816, max_Q = 13.5,  mse_true = 3.059>\n",
      "Epoch 274 / 400  [t=544.70s]  <loss = 0.06519, ref_loss = 0.02599, max_Q = 13.5,  mse_true = 2.725>\n",
      "Epoch 275 / 400  [t=546.34s]  <loss = 0.07914, ref_loss = 0.02319, max_Q = 13.5,  mse_true = 2.649>\n",
      "Epoch 276 / 400  [t=548.15s]  <loss = 0.06765, ref_loss = 0.04754, max_Q = 13.4,  mse_true = 2.790>\n",
      "Epoch 277 / 400  [t=549.78s]  <loss = 0.06705, ref_loss = 0.03712, max_Q = 13.4,  mse_true = 2.898>\n",
      "Epoch 278 / 400  [t=551.40s]  <loss = 0.06306, ref_loss = 0.03140, max_Q = 13.4,  mse_true = 2.932>\n",
      "Epoch 279 / 400  [t=553.03s]  <loss = 0.06364, ref_loss = 0.03070, max_Q = 13.5,  mse_true = 2.933>\n",
      "Epoch 280 / 400  [t=554.65s]  <loss = 0.06044, ref_loss = 0.02828, max_Q = 13.6,  mse_true = 2.775>\n",
      "Epoch 281 / 400  [t=558.70s]  <loss = 0.09347, ref_loss = 0.03427, max_Q = 13.7,  mse_true = 3.056>\n",
      "Epoch 282 / 400  [t=560.35s]  <loss = 0.07398, ref_loss = 0.02148, max_Q = 14.1,  mse_true = 2.444>\n",
      "Epoch 283 / 400  [t=561.99s]  <loss = 0.06391, ref_loss = 0.04715, max_Q = 14.0,  mse_true = 2.075>\n",
      "Epoch 284 / 400  [t=563.62s]  <loss = 0.06285, ref_loss = 0.02448, max_Q = 14.0,  mse_true = 2.374>\n",
      "Epoch 285 / 400  [t=565.26s]  <loss = 0.06360, ref_loss = 0.02123, max_Q = 14.0,  mse_true = 1.936>\n",
      "Epoch 286 / 400  [t=567.07s]  <loss = 0.05842, ref_loss = 0.02910, max_Q = 14.1,  mse_true = 2.099>\n",
      "Epoch 287 / 400  [t=568.69s]  <loss = 0.05915, ref_loss = 0.02717, max_Q = 14.0,  mse_true = 2.277>\n",
      "Epoch 288 / 400  [t=570.30s]  <loss = 0.06306, ref_loss = 0.02717, max_Q = 14.1,  mse_true = 2.053>\n",
      "Epoch 289 / 400  [t=572.76s]  <loss = 0.05442, ref_loss = 0.02973, max_Q = 14.0,  mse_true = 2.089>\n",
      "Epoch 290 / 400  [t=574.38s]  <loss = 0.05321, ref_loss = 0.02007, max_Q = 14.1,  mse_true = 2.085>\n",
      "Epoch 291 / 400  [t=577.70s]  <loss = 0.05697, ref_loss = 0.02577, max_Q = 14.0,  mse_true = 2.165>\n",
      "Epoch 292 / 400  [t=579.32s]  <loss = 0.05785, ref_loss = 0.02120, max_Q = 14.1,  mse_true = 2.028>\n",
      "Epoch 293 / 400  [t=580.95s]  <loss = 0.05338, ref_loss = 0.03001, max_Q = 14.1,  mse_true = 2.091>\n",
      "Epoch 294 / 400  [t=583.29s]  <loss = 0.05444, ref_loss = 0.02329, max_Q = 14.1,  mse_true = 2.073>\n",
      "Epoch 295 / 400  [t=584.91s]  <loss = 0.05302, ref_loss = 0.02255, max_Q = 14.1,  mse_true = 2.095>\n",
      "Epoch 296 / 400  [t=586.75s]  <loss = 0.05466, ref_loss = 0.01957, max_Q = 14.0,  mse_true = 2.165>\n",
      "Epoch 297 / 400  [t=588.37s]  <loss = 0.04766, ref_loss = 0.03997, max_Q = 14.0,  mse_true = 1.999>\n",
      "Epoch 298 / 400  [t=589.99s]  <loss = 0.05314, ref_loss = 0.01593, max_Q = 14.1,  mse_true = 2.293>\n",
      "Epoch 299 / 400  [t=591.62s]  <loss = 0.04976, ref_loss = 0.02564, max_Q = 14.1,  mse_true = 2.103>\n",
      "Epoch 300 / 400  [t=593.24s]  <loss = 0.05113, ref_loss = 0.01743, max_Q = 14.1,  mse_true = 2.123>\n",
      "Epoch 301 / 400  [t=597.35s]  <loss = 0.08588, ref_loss = 0.02669, max_Q = 14.2,  mse_true = 2.082>\n",
      "Epoch 302 / 400  [t=599.00s]  <loss = 0.05947, ref_loss = 0.03345, max_Q = 14.5,  mse_true = 1.490>\n",
      "Epoch 303 / 400  [t=600.64s]  <loss = 0.05639, ref_loss = 0.02691, max_Q = 14.7,  mse_true = 1.601>\n",
      "Epoch 304 / 400  [t=602.28s]  <loss = 0.05477, ref_loss = 0.01879, max_Q = 14.7,  mse_true = 1.269>\n",
      "Epoch 305 / 400  [t=603.92s]  <loss = 0.05443, ref_loss = 0.01394, max_Q = 14.7,  mse_true = 1.478>\n",
      "Epoch 306 / 400  [t=605.73s]  <loss = 0.05210, ref_loss = 0.03285, max_Q = 14.5,  mse_true = 1.565>\n",
      "Epoch 307 / 400  [t=607.36s]  <loss = 0.04923, ref_loss = 0.02063, max_Q = 14.6,  mse_true = 1.317>\n",
      "Epoch 308 / 400  [t=608.98s]  <loss = 0.05109, ref_loss = 0.02091, max_Q = 14.8,  mse_true = 1.407>\n",
      "Epoch 309 / 400  [t=610.60s]  <loss = 0.04738, ref_loss = 0.01457, max_Q = 14.7,  mse_true = 1.467>\n",
      "Epoch 310 / 400  [t=612.22s]  <loss = 0.06981, ref_loss = 0.01556, max_Q = 14.5,  mse_true = 1.251>\n",
      "Epoch 311 / 400  [t=616.45s]  <loss = 0.05155, ref_loss = 0.04080, max_Q = 14.6,  mse_true = 1.244>\n",
      "Epoch 312 / 400  [t=618.09s]  <loss = 0.04442, ref_loss = 0.01816, max_Q = 14.7,  mse_true = 1.402>\n",
      "Epoch 313 / 400  [t=619.74s]  <loss = 0.04460, ref_loss = 0.01767, max_Q = 14.6,  mse_true = 1.475>\n",
      "Epoch 314 / 400  [t=621.38s]  <loss = 0.04329, ref_loss = 0.01998, max_Q = 14.7,  mse_true = 1.447>\n",
      "Epoch 315 / 400  [t=623.03s]  <loss = 0.04676, ref_loss = 0.01744, max_Q = 14.8,  mse_true = 1.357>\n",
      "Epoch 316 / 400  [t=624.85s]  <loss = 0.04294, ref_loss = 0.01694, max_Q = 14.6,  mse_true = 1.300>\n",
      "Epoch 317 / 400  [t=626.47s]  <loss = 0.04322, ref_loss = 0.01284, max_Q = 14.7,  mse_true = 1.355>\n",
      "Epoch 318 / 400  [t=628.09s]  <loss = 0.04013, ref_loss = 0.01744, max_Q = 14.7,  mse_true = 1.334>\n",
      "Epoch 319 / 400  [t=630.56s]  <loss = 0.04868, ref_loss = 0.01116, max_Q = 14.6,  mse_true = 1.438>\n",
      "Epoch 320 / 400  [t=632.20s]  <loss = 0.04228, ref_loss = 0.02690, max_Q = 14.8,  mse_true = 1.181>\n",
      "Epoch 321 / 400  [t=635.60s]  <loss = 0.06553, ref_loss = 0.02315, max_Q = 14.7,  mse_true = 1.416>\n",
      "Epoch 322 / 400  [t=637.24s]  <loss = 0.04628, ref_loss = 0.01132, max_Q = 15.2,  mse_true = 1.078>\n",
      "Epoch 323 / 400  [t=638.87s]  <loss = 0.04407, ref_loss = 0.01740, max_Q = 15.2,  mse_true = 1.021>\n",
      "Epoch 324 / 400  [t=640.50s]  <loss = 0.04549, ref_loss = 0.01538, max_Q = 15.3,  mse_true = 1.060>\n",
      "Epoch 325 / 400  [t=642.96s]  <loss = 0.04295, ref_loss = 0.00896, max_Q = 15.2,  mse_true = 1.095>\n",
      "Epoch 326 / 400  [t=644.76s]  <loss = 0.04288, ref_loss = 0.02048, max_Q = 15.3,  mse_true = 0.961>\n",
      "Epoch 327 / 400  [t=646.40s]  <loss = 0.04426, ref_loss = 0.01746, max_Q = 15.2,  mse_true = 0.986>\n",
      "Epoch 328 / 400  [t=648.03s]  <loss = 0.03683, ref_loss = 0.01392, max_Q = 15.2,  mse_true = 1.067>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329 / 400  [t=649.65s]  <loss = 0.03582, ref_loss = 0.01785, max_Q = 15.2,  mse_true = 0.989>\n",
      "Epoch 330 / 400  [t=651.28s]  <loss = 0.03696, ref_loss = 0.01183, max_Q = 15.3,  mse_true = 1.034>\n",
      "Epoch 331 / 400  [t=654.61s]  <loss = 0.03914, ref_loss = 0.01476, max_Q = 15.2,  mse_true = 0.905>\n",
      "Epoch 332 / 400  [t=657.09s]  <loss = 0.04761, ref_loss = 0.01047, max_Q = 15.2,  mse_true = 0.843>\n",
      "Epoch 333 / 400  [t=658.72s]  <loss = 0.03829, ref_loss = 0.01361, max_Q = 15.3,  mse_true = 0.783>\n",
      "Epoch 334 / 400  [t=660.36s]  <loss = 0.03563, ref_loss = 0.01279, max_Q = 15.3,  mse_true = 1.008>\n",
      "Epoch 335 / 400  [t=662.00s]  <loss = 0.04246, ref_loss = 0.00730, max_Q = 15.3,  mse_true = 0.972>\n",
      "Epoch 336 / 400  [t=663.80s]  <loss = 0.03402, ref_loss = 0.02010, max_Q = 15.1,  mse_true = 1.009>\n",
      "Epoch 337 / 400  [t=665.42s]  <loss = 0.03594, ref_loss = 0.00843, max_Q = 15.3,  mse_true = 0.940>\n",
      "Epoch 338 / 400  [t=667.04s]  <loss = 0.03358, ref_loss = 0.01694, max_Q = 15.2,  mse_true = 0.906>\n",
      "Epoch 339 / 400  [t=668.66s]  <loss = 0.03494, ref_loss = 0.00801, max_Q = 15.5,  mse_true = 1.040>\n",
      "Epoch 340 / 400  [t=670.29s]  <loss = 0.03905, ref_loss = 0.00903, max_Q = 15.3,  mse_true = 0.961>\n",
      "Epoch 341 / 400  [t=674.60s]  <loss = 0.07770, ref_loss = 0.03232, max_Q = 15.2,  mse_true = 0.974>\n",
      "Epoch 342 / 400  [t=676.26s]  <loss = 0.05406, ref_loss = 0.01702, max_Q = 15.5,  mse_true = 0.731>\n",
      "Epoch 343 / 400  [t=677.91s]  <loss = 0.05972, ref_loss = 0.02088, max_Q = 15.4,  mse_true = 0.856>\n",
      "Epoch 344 / 400  [t=679.55s]  <loss = 0.04859, ref_loss = 0.01903, max_Q = 15.6,  mse_true = 0.767>\n",
      "Epoch 345 / 400  [t=681.19s]  <loss = 0.04709, ref_loss = 0.01103, max_Q = 15.6,  mse_true = 0.688>\n",
      "Epoch 346 / 400  [t=683.00s]  <loss = 0.04409, ref_loss = 0.03142, max_Q = 15.7,  mse_true = 0.660>\n",
      "Epoch 347 / 400  [t=684.62s]  <loss = 0.04121, ref_loss = 0.01788, max_Q = 15.7,  mse_true = 0.592>\n",
      "Epoch 348 / 400  [t=686.24s]  <loss = 0.03880, ref_loss = 0.01626, max_Q = 15.7,  mse_true = 0.689>\n",
      "Epoch 349 / 400  [t=687.86s]  <loss = 0.04663, ref_loss = 0.00943, max_Q = 15.7,  mse_true = 0.628>\n",
      "Epoch 350 / 400  [t=689.48s]  <loss = 0.03888, ref_loss = 0.03215, max_Q = 15.7,  mse_true = 0.649>\n",
      "Epoch 351 / 400  [t=693.88s]  <loss = 0.04161, ref_loss = 0.01389, max_Q = 15.6,  mse_true = 0.643>\n",
      "Epoch 352 / 400  [t=695.52s]  <loss = 0.03676, ref_loss = 0.01488, max_Q = 15.8,  mse_true = 0.615>\n",
      "Epoch 353 / 400  [t=697.15s]  <loss = 0.03813, ref_loss = 0.01655, max_Q = 15.7,  mse_true = 0.688>\n",
      "Epoch 354 / 400  [t=698.80s]  <loss = 0.05103, ref_loss = 0.01540, max_Q = 15.5,  mse_true = 0.565>\n",
      "Epoch 355 / 400  [t=700.44s]  <loss = 0.03580, ref_loss = 0.01165, max_Q = 15.7,  mse_true = 0.582>\n",
      "Epoch 356 / 400  [t=702.24s]  <loss = 0.04107, ref_loss = 0.01310, max_Q = 15.8,  mse_true = 0.644>\n",
      "Epoch 357 / 400  [t=703.86s]  <loss = 0.03726, ref_loss = 0.01724, max_Q = 15.8,  mse_true = 0.685>\n",
      "Epoch 358 / 400  [t=705.48s]  <loss = 0.03269, ref_loss = 0.01083, max_Q = 15.7,  mse_true = 0.625>\n",
      "Epoch 359 / 400  [t=707.10s]  <loss = 0.03383, ref_loss = 0.01633, max_Q = 15.6,  mse_true = 0.589>\n",
      "Epoch 360 / 400  [t=708.73s]  <loss = 0.03669, ref_loss = 0.00742, max_Q = 15.7,  mse_true = 0.649>\n",
      "Epoch 361 / 400  [t=713.20s]  <loss = 0.05206, ref_loss = 0.01932, max_Q = 15.8,  mse_true = 0.578>\n",
      "Epoch 362 / 400  [t=714.85s]  <loss = 0.05188, ref_loss = 0.01439, max_Q = 16.1,  mse_true = 0.375>\n",
      "Epoch 363 / 400  [t=716.48s]  <loss = 0.03985, ref_loss = 0.01612, max_Q = 16.2,  mse_true = 0.451>\n",
      "Epoch 364 / 400  [t=718.10s]  <loss = 0.04004, ref_loss = 0.01108, max_Q = 16.3,  mse_true = 0.490>\n",
      "Epoch 365 / 400  [t=719.73s]  <loss = 0.03438, ref_loss = 0.01864, max_Q = 16.2,  mse_true = 0.469>\n",
      "Epoch 366 / 400  [t=721.54s]  <loss = 0.04521, ref_loss = 0.01170, max_Q = 16.3,  mse_true = 0.394>\n",
      "Epoch 367 / 400  [t=723.15s]  <loss = 0.03957, ref_loss = 0.01452, max_Q = 16.3,  mse_true = 0.324>\n",
      "Epoch 368 / 400  [t=724.77s]  <loss = 0.03736, ref_loss = 0.01000, max_Q = 16.3,  mse_true = 0.363>\n",
      "Epoch 369 / 400  [t=726.39s]  <loss = 0.03087, ref_loss = 0.01016, max_Q = 16.3,  mse_true = 0.359>\n",
      "Epoch 370 / 400  [t=729.03s]  <loss = 0.03529, ref_loss = 0.00891, max_Q = 16.2,  mse_true = 0.361>\n",
      "Epoch 371 / 400  [t=732.47s]  <loss = 0.03556, ref_loss = 0.01231, max_Q = 16.4,  mse_true = 0.329>\n",
      "Epoch 372 / 400  [t=734.10s]  <loss = 0.03084, ref_loss = 0.01154, max_Q = 16.3,  mse_true = 0.357>\n",
      "Epoch 373 / 400  [t=735.72s]  <loss = 0.03005, ref_loss = 0.01156, max_Q = 16.3,  mse_true = 0.354>\n",
      "Epoch 374 / 400  [t=737.34s]  <loss = 0.02886, ref_loss = 0.01159, max_Q = 16.2,  mse_true = 0.366>\n",
      "Epoch 375 / 400  [t=738.96s]  <loss = 0.02886, ref_loss = 0.01380, max_Q = 16.2,  mse_true = 0.342>\n",
      "Epoch 376 / 400  [t=740.77s]  <loss = 0.02995, ref_loss = 0.01137, max_Q = 16.4,  mse_true = 0.339>\n",
      "Epoch 377 / 400  [t=742.39s]  <loss = 0.03037, ref_loss = 0.00703, max_Q = 16.2,  mse_true = 0.351>\n",
      "Epoch 378 / 400  [t=745.04s]  <loss = 0.02979, ref_loss = 0.01047, max_Q = 16.2,  mse_true = 0.393>\n",
      "Epoch 379 / 400  [t=746.67s]  <loss = 0.02842, ref_loss = 0.00947, max_Q = 16.3,  mse_true = 0.333>\n",
      "Epoch 380 / 400  [t=748.31s]  <loss = 0.03229, ref_loss = 0.01148, max_Q = 16.1,  mse_true = 0.387>\n",
      "Epoch 381 / 400  [t=751.71s]  <loss = 0.07541, ref_loss = 0.01157, max_Q = 17.1,  mse_true = 0.321>\n",
      "Epoch 382 / 400  [t=753.36s]  <loss = 0.04722, ref_loss = 0.00869, max_Q = 17.0,  mse_true = 0.386>\n",
      "Epoch 383 / 400  [t=755.01s]  <loss = 0.04489, ref_loss = 0.00504, max_Q = 16.8,  mse_true = 0.275>\n",
      "Epoch 384 / 400  [t=756.66s]  <loss = 0.02675, ref_loss = 0.00628, max_Q = 16.7,  mse_true = 0.255>\n",
      "Epoch 385 / 400  [t=758.30s]  <loss = 0.02430, ref_loss = 0.00703, max_Q = 16.7,  mse_true = 0.273>\n",
      "Epoch 386 / 400  [t=760.12s]  <loss = 0.02910, ref_loss = 0.00350, max_Q = 16.7,  mse_true = 0.267>\n",
      "Epoch 387 / 400  [t=762.83s]  <loss = 0.06167, ref_loss = 0.01118, max_Q = 16.5,  mse_true = 0.287>\n",
      "Epoch 388 / 400  [t=764.45s]  <loss = 0.02944, ref_loss = 0.00704, max_Q = 16.8,  mse_true = 0.345>\n",
      "Epoch 389 / 400  [t=766.09s]  <loss = 0.02579, ref_loss = 0.00715, max_Q = 16.9,  mse_true = 0.243>\n",
      "Epoch 390 / 400  [t=767.72s]  <loss = 0.02828, ref_loss = 0.00427, max_Q = 17.0,  mse_true = 0.237>\n",
      "Epoch 391 / 400  [t=771.18s]  <loss = 0.02824, ref_loss = 0.00677, max_Q = 16.8,  mse_true = 0.256>\n",
      "Epoch 392 / 400  [t=772.83s]  <loss = 0.02213, ref_loss = 0.00603, max_Q = 16.7,  mse_true = 0.243>\n",
      "Epoch 393 / 400  [t=774.46s]  <loss = 0.02456, ref_loss = 0.00293, max_Q = 16.8,  mse_true = 0.250>\n",
      "Epoch 394 / 400  [t=776.10s]  <loss = 0.02192, ref_loss = 0.00547, max_Q = 16.8,  mse_true = 0.213>\n",
      "Epoch 395 / 400  [t=777.73s]  <loss = 0.02079, ref_loss = 0.00680, max_Q = 16.9,  mse_true = 0.210>\n",
      "Epoch 396 / 400  [t=779.56s]  <loss = 0.03458, ref_loss = 0.00345, max_Q = 16.6,  mse_true = 0.268>\n",
      "Epoch 397 / 400  [t=782.31s]  <loss = 0.02037, ref_loss = 0.00999, max_Q = 16.9,  mse_true = 0.200>\n",
      "Epoch 398 / 400  [t=783.92s]  <loss = 0.02319, ref_loss = 0.00408, max_Q = 16.7,  mse_true = 0.227>\n",
      "Epoch 399 / 400  [t=785.55s]  <loss = 0.03105, ref_loss = 0.00722, max_Q = 17.0,  mse_true = 0.207>\n",
      "Epoch 400 / 400  [t=787.18s]  <loss = 0.02872, ref_loss = 0.00919, max_Q = 16.7,  mse_true = 0.211>\n",
      "Directory figures/Helicopter_NB0/clone_20/experiment_2 created\n",
      "==================================================================================================================\n",
      "Environment config:\n",
      "> distance_to_end: 13\n",
      "> game_board_pad_size: 3\n",
      "> horizontal_size: 20\n",
      "> reward_per_turn: -1.0\n",
      "> lambda_dx: 0.0\n",
      "> lambda_b: -1.0\n",
      "> gamma: 1.0\n",
      "> x_min: 0\n",
      "> x_max: 19\n",
      "> x_range: 19\n",
      "> x_start: 3\n",
      "> x_end: 16\n",
      "> action_list: [-1  0  1]\n",
      "==================================================================================================================\n",
      "Training config:\n",
      "> Stop training when mse_true exceeds 0.05\n",
      "> Using 1 step empirical returns\n",
      "> Using bootstrap method: clone\n",
      "> Using epochs of length None\n",
      "> Updating gradient every batch of size 10\n",
      "> Using optimizer_q1 <keras.optimizer_v2.gradient_descent.SGD object at 0x2dec1a4f0> with learning rate 0.01\n",
      "> Using optimizer_q2 None with learning rate 0.01\n",
      "> Swapping q1 and q2 every -1 epochs\n",
      "> Cloning q2 from q1 every 20 epochs\n",
      "> Assigning a weight of 0.3 to anchoring state/action pairs\n",
      "==================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/ipykernel_58834/1750174422.py:191: RuntimeWarning: All-NaN slice encountered\n",
      "  y_min   = np.nanmin([0, np.nanmin(true_q), np.nanmin(target_q), np.nanmin(q_model), np.nanmin(bs_model)])\n",
      "/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/ipykernel_58834/1750174422.py:192: RuntimeWarning: All-NaN slice encountered\n",
      "  y_max   = np.nanmax([0, np.nanmax(true_q), np.nanmax(target_q), np.nanmax(q_model), np.nanmax(bs_model)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 400  [t=2.72s]  <loss = 0.83307, ref_loss = 0.98365, max_Q = 0.2,  mse_true = 92.668>    \n",
      "Epoch 2 / 400  [t=4.34s]  <loss = 0.51306, ref_loss = 0.48820, max_Q = 0.4,  mse_true = 88.620>    \n",
      "Epoch 3 / 400  [t=7.07s]  <loss = 0.28832, ref_loss = 0.22524, max_Q = 0.6,  mse_true = 85.554>    \n",
      "Epoch 4 / 400  [t=8.70s]  <loss = 0.15806, ref_loss = 0.09328, max_Q = 0.8,  mse_true = 83.234>    \n",
      "Epoch 5 / 400  [t=10.35s]  <loss = 0.09012, ref_loss = 0.03287, max_Q = 0.9,  mse_true = 81.507>   \n",
      "Epoch 6 / 400  [t=12.18s]  <loss = 0.05896, ref_loss = 0.00945, max_Q = 1.0,  mse_true = 80.258>   \n",
      "Epoch 7 / 400  [t=13.81s]  <loss = 0.04327, ref_loss = 0.00242, max_Q = 1.0,  mse_true = 79.385>   \n",
      "Epoch 8 / 400  [t=15.43s]  <loss = 0.03626, ref_loss = 0.00137, max_Q = 1.1,  mse_true = 78.790>   \n",
      "Epoch 9 / 400  [t=17.05s]  <loss = 0.03234, ref_loss = 0.00187, max_Q = 1.1,  mse_true = 78.360>   \n",
      "Epoch 10 / 400  [t=18.66s]  <loss = 0.03615, ref_loss = 0.00289, max_Q = 1.1,  mse_true = 78.062>  \n",
      "Epoch 11 / 400  [t=21.56s]  <loss = 0.02913, ref_loss = 0.00380, max_Q = 1.1,  mse_true = 77.818>  \n",
      "Epoch 12 / 400  [t=23.18s]  <loss = 0.02807, ref_loss = 0.00401, max_Q = 1.1,  mse_true = 77.690>  \n",
      "Epoch 13 / 400  [t=24.81s]  <loss = 0.02768, ref_loss = 0.00403, max_Q = 1.1,  mse_true = 77.602>  \n",
      "Epoch 14 / 400  [t=26.43s]  <loss = 0.02944, ref_loss = 0.00311, max_Q = 1.1,  mse_true = 77.531>  \n",
      "Epoch 15 / 400  [t=29.27s]  <loss = 0.02629, ref_loss = 0.00392, max_Q = 1.1,  mse_true = 77.406>  \n",
      "Epoch 16 / 400  [t=31.08s]  <loss = 0.02561, ref_loss = 0.00331, max_Q = 1.1,  mse_true = 77.361>  \n",
      "Epoch 17 / 400  [t=32.72s]  <loss = 0.02497, ref_loss = 0.00320, max_Q = 1.1,  mse_true = 77.312>  \n",
      "Epoch 18 / 400  [t=34.37s]  <loss = 0.02462, ref_loss = 0.00262, max_Q = 1.1,  mse_true = 77.272>  \n",
      "Epoch 19 / 400  [t=36.00s]  <loss = 0.02417, ref_loss = 0.00305, max_Q = 1.1,  mse_true = 77.209>  \n",
      "Epoch 20 / 400  [t=37.63s]  <loss = 0.02401, ref_loss = 0.00224, max_Q = 1.1,  mse_true = 77.191>  \n",
      "Epoch 21 / 400  [t=40.55s]  <loss = 0.55023, ref_loss = 0.02653, max_Q = 1.3,  mse_true = 77.132>  \n",
      "Epoch 22 / 400  [t=42.19s]  <loss = 0.36319, ref_loss = 0.14463, max_Q = 1.5,  mse_true = 73.914>  \n",
      "Epoch 23 / 400  [t=43.81s]  <loss = 0.29269, ref_loss = 0.23843, max_Q = 1.6,  mse_true = 71.857>  \n",
      "Epoch 24 / 400  [t=45.44s]  <loss = 0.26484, ref_loss = 0.31438, max_Q = 1.6,  mse_true = 70.514>  \n",
      "Epoch 25 / 400  [t=47.07s]  <loss = 0.24575, ref_loss = 0.33975, max_Q = 1.6,  mse_true = 69.723>  \n",
      "Epoch 26 / 400  [t=48.87s]  <loss = 0.23627, ref_loss = 0.34773, max_Q = 1.6,  mse_true = 69.184>  \n",
      "Epoch 27 / 400  [t=51.74s]  <loss = 0.22428, ref_loss = 0.35560, max_Q = 1.6,  mse_true = 68.765>  \n",
      "Epoch 28 / 400  [t=53.35s]  <loss = 0.21653, ref_loss = 0.34677, max_Q = 1.6,  mse_true = 68.497>  \n",
      "Epoch 29 / 400  [t=54.99s]  <loss = 0.20800, ref_loss = 0.33367, max_Q = 1.7,  mse_true = 68.276>  \n",
      "Epoch 30 / 400  [t=56.63s]  <loss = 0.20062, ref_loss = 0.32754, max_Q = 1.7,  mse_true = 68.051>  \n",
      "Epoch 31 / 400  [t=59.60s]  <loss = 0.19601, ref_loss = 0.31225, max_Q = 1.7,  mse_true = 67.878>  \n",
      "Epoch 32 / 400  [t=61.24s]  <loss = 0.19836, ref_loss = 0.29352, max_Q = 1.7,  mse_true = 67.724>  \n",
      "Epoch 33 / 400  [t=62.87s]  <loss = 0.18362, ref_loss = 0.30669, max_Q = 1.8,  mse_true = 67.442>  \n",
      "Epoch 34 / 400  [t=64.50s]  <loss = 0.18102, ref_loss = 0.28001, max_Q = 1.8,  mse_true = 67.384>  \n",
      "Epoch 35 / 400  [t=66.13s]  <loss = 0.17484, ref_loss = 0.27524, max_Q = 1.8,  mse_true = 67.219>  \n",
      "Epoch 36 / 400  [t=67.94s]  <loss = 0.17240, ref_loss = 0.26855, max_Q = 1.8,  mse_true = 67.070>  \n",
      "Epoch 37 / 400  [t=69.56s]  <loss = 0.16681, ref_loss = 0.25912, max_Q = 1.8,  mse_true = 66.923>  \n",
      "Epoch 38 / 400  [t=71.17s]  <loss = 0.16201, ref_loss = 0.25089, max_Q = 1.8,  mse_true = 66.801>  \n",
      "Epoch 39 / 400  [t=72.79s]  <loss = 0.17356, ref_loss = 0.24114, max_Q = 1.8,  mse_true = 66.694>  \n",
      "Epoch 40 / 400  [t=75.70s]  <loss = 0.17232, ref_loss = 0.24878, max_Q = 1.9,  mse_true = 66.433>  \n",
      "Epoch 41 / 400  [t=78.69s]  <loss = 0.66734, ref_loss = 0.39574, max_Q = 2.1,  mse_true = 66.304>  \n",
      "Epoch 42 / 400  [t=80.33s]  <loss = 0.54304, ref_loss = 0.65723, max_Q = 2.3,  mse_true = 62.858>  \n",
      "Epoch 43 / 400  [t=81.97s]  <loss = 0.50450, ref_loss = 0.72760, max_Q = 2.4,  mse_true = 61.120>  \n",
      "Epoch 44 / 400  [t=83.60s]  <loss = 0.47132, ref_loss = 0.76844, max_Q = 2.5,  mse_true = 59.892>  \n",
      "Epoch 45 / 400  [t=85.27s]  <loss = 0.45114, ref_loss = 0.76593, max_Q = 2.5,  mse_true = 59.146>  \n",
      "Epoch 46 / 400  [t=87.10s]  <loss = 0.41451, ref_loss = 0.75636, max_Q = 2.6,  mse_true = 58.566>  \n",
      "Epoch 47 / 400  [t=88.72s]  <loss = 0.39653, ref_loss = 0.69084, max_Q = 2.6,  mse_true = 58.269>  \n",
      "Epoch 48 / 400  [t=90.36s]  <loss = 0.38324, ref_loss = 0.65005, max_Q = 2.6,  mse_true = 57.855>  \n",
      "Epoch 49 / 400  [t=91.99s]  <loss = 0.36816, ref_loss = 0.63219, max_Q = 2.7,  mse_true = 57.392>  \n",
      "Epoch 50 / 400  [t=93.61s]  <loss = 0.35654, ref_loss = 0.59336, max_Q = 2.8,  mse_true = 57.026>  \n",
      "Epoch 51 / 400  [t=97.83s]  <loss = 0.34348, ref_loss = 0.59331, max_Q = 2.8,  mse_true = 56.642>  \n",
      "Epoch 52 / 400  [t=99.48s]  <loss = 0.33535, ref_loss = 0.52546, max_Q = 2.8,  mse_true = 56.530>  \n",
      "Epoch 53 / 400  [t=101.12s]  <loss = 0.32346, ref_loss = 0.50679, max_Q = 2.8,  mse_true = 56.106> \n",
      "Epoch 54 / 400  [t=102.77s]  <loss = 0.31333, ref_loss = 0.51422, max_Q = 2.9,  mse_true = 55.842> \n",
      "Epoch 55 / 400  [t=104.42s]  <loss = 0.30442, ref_loss = 0.46009, max_Q = 2.9,  mse_true = 55.849> \n",
      "Epoch 56 / 400  [t=106.27s]  <loss = 0.30183, ref_loss = 0.43442, max_Q = 2.9,  mse_true = 55.681> \n",
      "Epoch 57 / 400  [t=107.90s]  <loss = 0.32234, ref_loss = 0.39854, max_Q = 2.9,  mse_true = 55.465> \n",
      "Epoch 58 / 400  [t=109.53s]  <loss = 0.29823, ref_loss = 0.42879, max_Q = 3.0,  mse_true = 55.071> \n",
      "Epoch 59 / 400  [t=111.16s]  <loss = 0.29354, ref_loss = 0.40477, max_Q = 3.0,  mse_true = 55.090> \n",
      "Epoch 60 / 400  [t=112.78s]  <loss = 0.29185, ref_loss = 0.37288, max_Q = 3.0,  mse_true = 55.105> \n",
      "Epoch 61 / 400  [t=117.01s]  <loss = 0.61317, ref_loss = 0.57445, max_Q = 3.2,  mse_true = 54.853> \n",
      "Epoch 62 / 400  [t=118.65s]  <loss = 0.46521, ref_loss = 0.69555, max_Q = 3.5,  mse_true = 50.906> \n",
      "Epoch 63 / 400  [t=120.28s]  <loss = 0.40857, ref_loss = 0.69461, max_Q = 3.7,  mse_true = 48.895> \n",
      "Epoch 64 / 400  [t=121.93s]  <loss = 0.38822, ref_loss = 0.65714, max_Q = 3.8,  mse_true = 47.679> \n",
      "Epoch 65 / 400  [t=123.57s]  <loss = 0.35173, ref_loss = 0.59662, max_Q = 3.9,  mse_true = 47.139> \n",
      "Epoch 66 / 400  [t=125.40s]  <loss = 0.33740, ref_loss = 0.52990, max_Q = 3.9,  mse_true = 46.565> \n",
      "Epoch 67 / 400  [t=127.03s]  <loss = 0.33173, ref_loss = 0.48178, max_Q = 4.0,  mse_true = 46.425> \n",
      "Epoch 68 / 400  [t=128.65s]  <loss = 0.32190, ref_loss = 0.40180, max_Q = 4.0,  mse_true = 46.371> \n",
      "Epoch 69 / 400  [t=130.27s]  <loss = 0.31333, ref_loss = 0.41281, max_Q = 4.1,  mse_true = 45.510> \n",
      "Epoch 70 / 400  [t=131.90s]  <loss = 0.30349, ref_loss = 0.39186, max_Q = 4.1,  mse_true = 45.357> \n",
      "Epoch 71 / 400  [t=134.89s]  <loss = 0.32947, ref_loss = 0.35133, max_Q = 4.1,  mse_true = 45.491> \n",
      "Epoch 72 / 400  [t=136.53s]  <loss = 0.30254, ref_loss = 0.37808, max_Q = 4.1,  mse_true = 45.050> \n",
      "Epoch 73 / 400  [t=139.49s]  <loss = 0.29607, ref_loss = 0.34312, max_Q = 4.1,  mse_true = 45.264> \n",
      "Epoch 74 / 400  [t=141.13s]  <loss = 0.30277, ref_loss = 0.32361, max_Q = 4.1,  mse_true = 45.023> \n",
      "Epoch 75 / 400  [t=142.77s]  <loss = 0.30035, ref_loss = 0.38122, max_Q = 4.1,  mse_true = 44.555> \n",
      "Epoch 76 / 400  [t=144.60s]  <loss = 0.29481, ref_loss = 0.33238, max_Q = 4.1,  mse_true = 45.186> \n",
      "Epoch 77 / 400  [t=146.25s]  <loss = 0.28874, ref_loss = 0.32571, max_Q = 4.1,  mse_true = 45.076> \n",
      "Epoch 78 / 400  [t=147.90s]  <loss = 0.28691, ref_loss = 0.31671, max_Q = 4.1,  mse_true = 45.106> \n",
      "Epoch 79 / 400  [t=149.53s]  <loss = 0.29840, ref_loss = 0.29289, max_Q = 4.1,  mse_true = 45.128> \n",
      "Epoch 80 / 400  [t=151.16s]  <loss = 0.28872, ref_loss = 0.30538, max_Q = 4.1,  mse_true = 44.928> \n",
      "Epoch 81 / 400  [t=154.18s]  <loss = 0.45876, ref_loss = 0.44867, max_Q = 4.5,  mse_true = 44.990> \n",
      "Epoch 82 / 400  [t=155.83s]  <loss = 0.32443, ref_loss = 0.53575, max_Q = 4.9,  mse_true = 40.022> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 / 400  [t=157.47s]  <loss = 0.28499, ref_loss = 0.42299, max_Q = 5.0,  mse_true = 38.912> \n",
      "Epoch 84 / 400  [t=159.10s]  <loss = 0.27181, ref_loss = 0.39955, max_Q = 5.1,  mse_true = 37.740> \n",
      "Epoch 85 / 400  [t=160.72s]  <loss = 0.29399, ref_loss = 0.29123, max_Q = 5.1,  mse_true = 37.737> \n",
      "Epoch 86 / 400  [t=163.88s]  <loss = 0.26006, ref_loss = 0.33968, max_Q = 5.2,  mse_true = 36.648> \n",
      "Epoch 87 / 400  [t=165.49s]  <loss = 0.25523, ref_loss = 0.30478, max_Q = 5.2,  mse_true = 37.069> \n",
      "Epoch 88 / 400  [t=167.12s]  <loss = 0.25439, ref_loss = 0.29537, max_Q = 5.2,  mse_true = 37.017> \n",
      "Epoch 89 / 400  [t=168.76s]  <loss = 0.25982, ref_loss = 0.22665, max_Q = 5.2,  mse_true = 37.169> \n",
      "Epoch 90 / 400  [t=170.42s]  <loss = 0.25175, ref_loss = 0.26405, max_Q = 5.2,  mse_true = 36.482> \n",
      "Epoch 91 / 400  [t=173.44s]  <loss = 0.24994, ref_loss = 0.26437, max_Q = 5.2,  mse_true = 36.788> \n",
      "Epoch 92 / 400  [t=175.09s]  <loss = 0.27248, ref_loss = 0.23773, max_Q = 5.2,  mse_true = 37.005> \n",
      "Epoch 93 / 400  [t=176.73s]  <loss = 0.27175, ref_loss = 0.22321, max_Q = 5.2,  mse_true = 36.811> \n",
      "Epoch 94 / 400  [t=178.37s]  <loss = 0.25162, ref_loss = 0.27588, max_Q = 5.2,  mse_true = 36.317> \n",
      "Epoch 95 / 400  [t=179.99s]  <loss = 0.25429, ref_loss = 0.22641, max_Q = 5.1,  mse_true = 36.834> \n",
      "Epoch 96 / 400  [t=181.80s]  <loss = 0.26912, ref_loss = 0.23975, max_Q = 5.2,  mse_true = 36.532> \n",
      "Epoch 97 / 400  [t=183.42s]  <loss = 0.24970, ref_loss = 0.26238, max_Q = 5.2,  mse_true = 36.271> \n",
      "Epoch 98 / 400  [t=185.04s]  <loss = 0.24291, ref_loss = 0.25174, max_Q = 5.2,  mse_true = 36.362> \n",
      "Epoch 99 / 400  [t=186.66s]  <loss = 0.23627, ref_loss = 0.25524, max_Q = 5.2,  mse_true = 36.709> \n",
      "Epoch 100 / 400  [t=189.64s]  <loss = 0.23370, ref_loss = 0.22664, max_Q = 5.2,  mse_true = 36.802>\n",
      "Epoch 101 / 400  [t=192.70s]  <loss = 0.37299, ref_loss = 0.33896, max_Q = 5.8,  mse_true = 36.745>\n",
      "Epoch 102 / 400  [t=194.33s]  <loss = 0.24357, ref_loss = 0.36016, max_Q = 6.0,  mse_true = 31.320>\n",
      "Epoch 103 / 400  [t=195.96s]  <loss = 0.22594, ref_loss = 0.30082, max_Q = 6.1,  mse_true = 30.640>\n",
      "Epoch 104 / 400  [t=197.59s]  <loss = 0.21808, ref_loss = 0.27024, max_Q = 6.2,  mse_true = 30.044>\n",
      "Epoch 105 / 400  [t=199.23s]  <loss = 0.22750, ref_loss = 0.20438, max_Q = 6.3,  mse_true = 30.375>\n",
      "Epoch 106 / 400  [t=201.09s]  <loss = 0.21702, ref_loss = 0.24695, max_Q = 6.2,  mse_true = 29.458>\n",
      "Epoch 107 / 400  [t=202.73s]  <loss = 0.21497, ref_loss = 0.20288, max_Q = 6.2,  mse_true = 29.789>\n",
      "Epoch 108 / 400  [t=204.37s]  <loss = 0.22669, ref_loss = 0.17893, max_Q = 6.2,  mse_true = 29.722>\n",
      "Epoch 109 / 400  [t=206.00s]  <loss = 0.22197, ref_loss = 0.20856, max_Q = 6.2,  mse_true = 29.476>\n",
      "Epoch 110 / 400  [t=207.62s]  <loss = 0.23940, ref_loss = 0.17872, max_Q = 6.2,  mse_true = 30.002>\n",
      "Epoch 111 / 400  [t=212.00s]  <loss = 0.21010, ref_loss = 0.22174, max_Q = 6.2,  mse_true = 29.812>\n",
      "Epoch 112 / 400  [t=213.64s]  <loss = 0.21364, ref_loss = 0.20156, max_Q = 6.2,  mse_true = 30.221>\n",
      "Epoch 113 / 400  [t=215.29s]  <loss = 0.20926, ref_loss = 0.20173, max_Q = 6.2,  mse_true = 29.755>\n",
      "Epoch 114 / 400  [t=216.96s]  <loss = 0.22966, ref_loss = 0.18008, max_Q = 6.3,  mse_true = 29.456>\n",
      "Epoch 115 / 400  [t=218.61s]  <loss = 0.20591, ref_loss = 0.20519, max_Q = 6.2,  mse_true = 29.834>\n",
      "Epoch 116 / 400  [t=220.43s]  <loss = 0.21042, ref_loss = 0.17785, max_Q = 6.2,  mse_true = 29.932>\n",
      "Epoch 117 / 400  [t=222.05s]  <loss = 0.20426, ref_loss = 0.18890, max_Q = 6.2,  mse_true = 29.938>\n",
      "Epoch 118 / 400  [t=223.66s]  <loss = 0.20264, ref_loss = 0.16886, max_Q = 6.2,  mse_true = 30.072>\n",
      "Epoch 119 / 400  [t=225.28s]  <loss = 0.20171, ref_loss = 0.15687, max_Q = 6.2,  mse_true = 30.211>\n",
      "Epoch 120 / 400  [t=226.91s]  <loss = 0.23800, ref_loss = 0.15356, max_Q = 6.2,  mse_true = 29.723>\n",
      "Epoch 121 / 400  [t=229.97s]  <loss = 0.34404, ref_loss = 0.32084, max_Q = 6.7,  mse_true = 29.503>\n",
      "Epoch 122 / 400  [t=231.63s]  <loss = 0.22270, ref_loss = 0.28715, max_Q = 7.1,  mse_true = 24.413>\n",
      "Epoch 123 / 400  [t=234.65s]  <loss = 0.21524, ref_loss = 0.22955, max_Q = 7.2,  mse_true = 23.626>\n",
      "Epoch 124 / 400  [t=236.27s]  <loss = 0.22665, ref_loss = 0.19729, max_Q = 7.3,  mse_true = 23.654>\n",
      "Epoch 125 / 400  [t=237.90s]  <loss = 0.21553, ref_loss = 0.20461, max_Q = 7.3,  mse_true = 23.346>\n",
      "Epoch 126 / 400  [t=239.72s]  <loss = 0.20822, ref_loss = 0.17268, max_Q = 7.3,  mse_true = 23.673>\n",
      "Epoch 127 / 400  [t=241.35s]  <loss = 0.21247, ref_loss = 0.22041, max_Q = 7.3,  mse_true = 22.524>\n",
      "Epoch 128 / 400  [t=242.98s]  <loss = 0.19879, ref_loss = 0.17785, max_Q = 7.3,  mse_true = 23.428>\n",
      "Epoch 129 / 400  [t=244.60s]  <loss = 0.20255, ref_loss = 0.16492, max_Q = 7.3,  mse_true = 23.752>\n",
      "Epoch 130 / 400  [t=246.23s]  <loss = 0.20181, ref_loss = 0.17481, max_Q = 7.3,  mse_true = 23.084>\n",
      "Epoch 131 / 400  [t=249.28s]  <loss = 0.19876, ref_loss = 0.17719, max_Q = 7.2,  mse_true = 23.557>\n",
      "Epoch 132 / 400  [t=250.91s]  <loss = 0.19429, ref_loss = 0.16559, max_Q = 7.3,  mse_true = 22.961>\n",
      "Epoch 133 / 400  [t=252.52s]  <loss = 0.19526, ref_loss = 0.15653, max_Q = 7.3,  mse_true = 23.487>\n",
      "Epoch 134 / 400  [t=254.13s]  <loss = 0.19105, ref_loss = 0.14466, max_Q = 7.3,  mse_true = 23.182>\n",
      "Epoch 135 / 400  [t=255.73s]  <loss = 0.19579, ref_loss = 0.15453, max_Q = 7.3,  mse_true = 23.490>\n",
      "Epoch 136 / 400  [t=257.52s]  <loss = 0.19303, ref_loss = 0.13662, max_Q = 7.3,  mse_true = 24.207>\n",
      "Epoch 137 / 400  [t=260.53s]  <loss = 0.18921, ref_loss = 0.15186, max_Q = 7.3,  mse_true = 23.452>\n",
      "Epoch 138 / 400  [t=262.13s]  <loss = 0.19120, ref_loss = 0.14281, max_Q = 7.3,  mse_true = 24.004>\n",
      "Epoch 139 / 400  [t=263.73s]  <loss = 0.19549, ref_loss = 0.14191, max_Q = 7.3,  mse_true = 23.706>\n",
      "Epoch 140 / 400  [t=265.36s]  <loss = 0.21166, ref_loss = 0.13213, max_Q = 7.3,  mse_true = 23.410>\n",
      "Epoch 141 / 400  [t=268.44s]  <loss = 0.28177, ref_loss = 0.28062, max_Q = 8.0,  mse_true = 22.899>\n",
      "Epoch 142 / 400  [t=270.05s]  <loss = 0.19637, ref_loss = 0.19109, max_Q = 8.3,  mse_true = 18.628>\n",
      "Epoch 143 / 400  [t=271.65s]  <loss = 0.20746, ref_loss = 0.16129, max_Q = 8.4,  mse_true = 17.926>\n",
      "Epoch 144 / 400  [t=273.26s]  <loss = 0.18523, ref_loss = 0.17768, max_Q = 8.3,  mse_true = 17.345>\n",
      "Epoch 145 / 400  [t=274.86s]  <loss = 0.18967, ref_loss = 0.14092, max_Q = 8.4,  mse_true = 17.737>\n",
      "Epoch 146 / 400  [t=276.64s]  <loss = 0.18517, ref_loss = 0.14924, max_Q = 8.4,  mse_true = 17.842>\n",
      "Epoch 147 / 400  [t=278.23s]  <loss = 0.18284, ref_loss = 0.13153, max_Q = 8.4,  mse_true = 18.309>\n",
      "Epoch 148 / 400  [t=279.83s]  <loss = 0.18155, ref_loss = 0.13263, max_Q = 8.4,  mse_true = 17.931>\n",
      "Epoch 149 / 400  [t=281.42s]  <loss = 0.18052, ref_loss = 0.14277, max_Q = 8.4,  mse_true = 17.603>\n",
      "Epoch 150 / 400  [t=283.01s]  <loss = 0.17939, ref_loss = 0.13405, max_Q = 8.4,  mse_true = 18.193>\n",
      "Epoch 151 / 400  [t=287.51s]  <loss = 0.18443, ref_loss = 0.12706, max_Q = 8.4,  mse_true = 18.115>\n",
      "Epoch 152 / 400  [t=289.12s]  <loss = 0.17374, ref_loss = 0.13119, max_Q = 8.4,  mse_true = 17.708>\n",
      "Epoch 153 / 400  [t=290.74s]  <loss = 0.17935, ref_loss = 0.10906, max_Q = 8.4,  mse_true = 18.122>\n",
      "Epoch 154 / 400  [t=292.34s]  <loss = 0.17343, ref_loss = 0.13420, max_Q = 8.5,  mse_true = 17.423>\n",
      "Epoch 155 / 400  [t=293.94s]  <loss = 0.18285, ref_loss = 0.10791, max_Q = 8.4,  mse_true = 17.886>\n",
      "Epoch 156 / 400  [t=295.74s]  <loss = 0.18969, ref_loss = 0.12358, max_Q = 8.4,  mse_true = 17.786>\n",
      "Epoch 157 / 400  [t=297.33s]  <loss = 0.17982, ref_loss = 0.12478, max_Q = 8.3,  mse_true = 17.947>\n",
      "Epoch 158 / 400  [t=298.93s]  <loss = 0.18446, ref_loss = 0.15313, max_Q = 8.4,  mse_true = 17.091>\n",
      "Epoch 159 / 400  [t=300.53s]  <loss = 0.17510, ref_loss = 0.13310, max_Q = 8.4,  mse_true = 17.410>\n",
      "Epoch 160 / 400  [t=302.14s]  <loss = 0.17127, ref_loss = 0.10884, max_Q = 8.4,  mse_true = 17.703>\n",
      "Epoch 161 / 400  [t=306.63s]  <loss = 0.22229, ref_loss = 0.17172, max_Q = 9.2,  mse_true = 17.785>\n",
      "Epoch 162 / 400  [t=308.23s]  <loss = 0.16371, ref_loss = 0.11759, max_Q = 9.4,  mse_true = 13.743>\n",
      "Epoch 163 / 400  [t=309.85s]  <loss = 0.16396, ref_loss = 0.11231, max_Q = 9.4,  mse_true = 13.317>\n",
      "Epoch 164 / 400  [t=311.47s]  <loss = 0.15998, ref_loss = 0.11568, max_Q = 9.3,  mse_true = 13.595>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165 / 400  [t=313.08s]  <loss = 0.15926, ref_loss = 0.09659, max_Q = 9.5,  mse_true = 13.434>\n",
      "Epoch 166 / 400  [t=314.87s]  <loss = 0.15395, ref_loss = 0.10152, max_Q = 9.4,  mse_true = 13.713>\n",
      "Epoch 167 / 400  [t=316.47s]  <loss = 0.16365, ref_loss = 0.10455, max_Q = 9.4,  mse_true = 13.525>\n",
      "Epoch 168 / 400  [t=318.06s]  <loss = 0.15378, ref_loss = 0.09327, max_Q = 9.4,  mse_true = 13.948>\n",
      "Epoch 169 / 400  [t=319.65s]  <loss = 0.15235, ref_loss = 0.09967, max_Q = 9.3,  mse_true = 13.912>\n",
      "Epoch 170 / 400  [t=321.25s]  <loss = 0.14776, ref_loss = 0.10525, max_Q = 9.4,  mse_true = 13.846>\n",
      "Epoch 171 / 400  [t=324.35s]  <loss = 0.14641, ref_loss = 0.09415, max_Q = 9.4,  mse_true = 13.619>\n",
      "Epoch 172 / 400  [t=325.96s]  <loss = 0.15017, ref_loss = 0.08122, max_Q = 9.3,  mse_true = 14.106>\n",
      "Epoch 173 / 400  [t=327.57s]  <loss = 0.14837, ref_loss = 0.09262, max_Q = 9.4,  mse_true = 13.778>\n",
      "Epoch 174 / 400  [t=329.18s]  <loss = 0.14304, ref_loss = 0.10072, max_Q = 9.4,  mse_true = 13.922>\n",
      "Epoch 175 / 400  [t=330.79s]  <loss = 0.15299, ref_loss = 0.08337, max_Q = 9.4,  mse_true = 13.885>\n",
      "Epoch 176 / 400  [t=334.12s]  <loss = 0.14752, ref_loss = 0.09173, max_Q = 9.4,  mse_true = 14.024>\n",
      "Epoch 177 / 400  [t=335.73s]  <loss = 0.14313, ref_loss = 0.10087, max_Q = 9.5,  mse_true = 13.273>\n",
      "Epoch 178 / 400  [t=337.35s]  <loss = 0.14165, ref_loss = 0.07951, max_Q = 9.4,  mse_true = 13.804>\n",
      "Epoch 179 / 400  [t=338.97s]  <loss = 0.14586, ref_loss = 0.08132, max_Q = 9.4,  mse_true = 14.124>\n",
      "Epoch 180 / 400  [t=340.60s]  <loss = 0.15415, ref_loss = 0.08207, max_Q = 9.4,  mse_true = 13.388>\n",
      "Epoch 181 / 400  [t=343.71s]  <loss = 0.20593, ref_loss = 0.15661, max_Q = 10.3,  mse_true = 13.211>\n",
      "Epoch 182 / 400  [t=345.32s]  <loss = 0.15771, ref_loss = 0.11588, max_Q = 10.4,  mse_true = 10.275>\n",
      "Epoch 183 / 400  [t=346.93s]  <loss = 0.16408, ref_loss = 0.10195, max_Q = 10.4,  mse_true = 10.154>\n",
      "Epoch 184 / 400  [t=348.54s]  <loss = 0.14814, ref_loss = 0.11113, max_Q = 10.4,  mse_true = 10.050>\n",
      "Epoch 185 / 400  [t=350.15s]  <loss = 0.14618, ref_loss = 0.09443, max_Q = 10.4,  mse_true = 10.132>\n",
      "Epoch 186 / 400  [t=351.95s]  <loss = 0.14437, ref_loss = 0.10085, max_Q = 10.4,  mse_true = 10.184>\n",
      "Epoch 187 / 400  [t=353.54s]  <loss = 0.14702, ref_loss = 0.06723, max_Q = 10.5,  mse_true = 9.922>\n",
      "Epoch 188 / 400  [t=355.14s]  <loss = 0.14617, ref_loss = 0.09563, max_Q = 10.7,  mse_true = 9.254>\n",
      "Epoch 189 / 400  [t=356.73s]  <loss = 0.13857, ref_loss = 0.09210, max_Q = 10.4,  mse_true = 9.717>\n",
      "Epoch 190 / 400  [t=358.34s]  <loss = 0.14155, ref_loss = 0.07995, max_Q = 10.4,  mse_true = 9.738>\n",
      "Epoch 191 / 400  [t=362.98s]  <loss = 0.13740, ref_loss = 0.08680, max_Q = 10.4,  mse_true = 10.129>\n",
      "Epoch 192 / 400  [t=364.59s]  <loss = 0.13489, ref_loss = 0.08632, max_Q = 10.4,  mse_true = 10.147>\n",
      "Epoch 193 / 400  [t=366.20s]  <loss = 0.13312, ref_loss = 0.08606, max_Q = 10.4,  mse_true = 10.103>\n",
      "Epoch 194 / 400  [t=367.81s]  <loss = 0.13339, ref_loss = 0.08008, max_Q = 10.3,  mse_true = 10.388>\n",
      "Epoch 195 / 400  [t=369.43s]  <loss = 0.13665, ref_loss = 0.08705, max_Q = 10.4,  mse_true = 9.996>\n",
      "Epoch 196 / 400  [t=371.23s]  <loss = 0.13530, ref_loss = 0.06591, max_Q = 10.5,  mse_true = 9.750>\n",
      "Epoch 197 / 400  [t=372.83s]  <loss = 0.13417, ref_loss = 0.08015, max_Q = 10.4,  mse_true = 9.664>\n",
      "Epoch 198 / 400  [t=374.43s]  <loss = 0.14700, ref_loss = 0.07591, max_Q = 10.4,  mse_true = 9.691>\n",
      "Epoch 199 / 400  [t=376.08s]  <loss = 0.12884, ref_loss = 0.08730, max_Q = 10.4,  mse_true = 9.770>\n",
      "Epoch 200 / 400  [t=377.68s]  <loss = 0.14231, ref_loss = 0.06401, max_Q = 10.5,  mse_true = 9.897>\n",
      "Epoch 201 / 400  [t=382.29s]  <loss = 0.19396, ref_loss = 0.13014, max_Q = 11.1,  mse_true = 9.553>\n",
      "Epoch 202 / 400  [t=383.88s]  <loss = 0.13484, ref_loss = 0.11693, max_Q = 11.3,  mse_true = 6.943>\n",
      "Epoch 203 / 400  [t=385.52s]  <loss = 0.13176, ref_loss = 0.07878, max_Q = 11.5,  mse_true = 7.227>\n",
      "Epoch 204 / 400  [t=387.14s]  <loss = 0.13337, ref_loss = 0.07645, max_Q = 11.4,  mse_true = 7.251>\n",
      "Epoch 205 / 400  [t=388.76s]  <loss = 0.12499, ref_loss = 0.07634, max_Q = 11.4,  mse_true = 7.189>\n",
      "Epoch 206 / 400  [t=390.56s]  <loss = 0.12600, ref_loss = 0.07018, max_Q = 11.4,  mse_true = 7.176>\n",
      "Epoch 207 / 400  [t=392.16s]  <loss = 0.13251, ref_loss = 0.07477, max_Q = 11.3,  mse_true = 7.423>\n",
      "Epoch 208 / 400  [t=393.76s]  <loss = 0.13202, ref_loss = 0.07786, max_Q = 11.3,  mse_true = 7.179>\n",
      "Epoch 209 / 400  [t=395.38s]  <loss = 0.12531, ref_loss = 0.08014, max_Q = 11.5,  mse_true = 6.977>\n",
      "Epoch 210 / 400  [t=396.96s]  <loss = 0.12169, ref_loss = 0.06729, max_Q = 11.4,  mse_true = 7.370>\n",
      "Epoch 211 / 400  [t=400.08s]  <loss = 0.12095, ref_loss = 0.07708, max_Q = 11.5,  mse_true = 7.064>\n",
      "Epoch 212 / 400  [t=401.68s]  <loss = 0.11699, ref_loss = 0.06112, max_Q = 11.4,  mse_true = 7.125>\n",
      "Epoch 213 / 400  [t=403.29s]  <loss = 0.12469, ref_loss = 0.06605, max_Q = 11.4,  mse_true = 6.502>\n",
      "Epoch 214 / 400  [t=404.90s]  <loss = 0.12061, ref_loss = 0.09216, max_Q = 11.4,  mse_true = 7.169>\n",
      "Epoch 215 / 400  [t=406.50s]  <loss = 0.12490, ref_loss = 0.05700, max_Q = 11.5,  mse_true = 6.893>\n",
      "Epoch 216 / 400  [t=408.28s]  <loss = 0.11681, ref_loss = 0.07456, max_Q = 11.4,  mse_true = 6.920>\n",
      "Epoch 217 / 400  [t=411.54s]  <loss = 0.12063, ref_loss = 0.05688, max_Q = 11.4,  mse_true = 7.105>\n",
      "Epoch 218 / 400  [t=413.14s]  <loss = 0.11687, ref_loss = 0.06802, max_Q = 11.3,  mse_true = 7.216>\n",
      "Epoch 219 / 400  [t=414.74s]  <loss = 0.11802, ref_loss = 0.06330, max_Q = 11.3,  mse_true = 7.223>\n",
      "Epoch 220 / 400  [t=416.36s]  <loss = 0.11375, ref_loss = 0.06346, max_Q = 11.4,  mse_true = 7.004>\n",
      "Epoch 221 / 400  [t=419.51s]  <loss = 0.15209, ref_loss = 0.09619, max_Q = 12.1,  mse_true = 7.132>\n",
      "Epoch 222 / 400  [t=421.12s]  <loss = 0.10728, ref_loss = 0.05703, max_Q = 12.1,  mse_true = 5.347>\n",
      "Epoch 223 / 400  [t=422.73s]  <loss = 0.12404, ref_loss = 0.04116, max_Q = 12.2,  mse_true = 5.335>\n",
      "Epoch 224 / 400  [t=424.33s]  <loss = 0.10740, ref_loss = 0.06911, max_Q = 12.3,  mse_true = 5.081>\n",
      "Epoch 225 / 400  [t=425.93s]  <loss = 0.11699, ref_loss = 0.05487, max_Q = 12.2,  mse_true = 5.084>\n",
      "Epoch 226 / 400  [t=427.72s]  <loss = 0.10806, ref_loss = 0.06118, max_Q = 12.1,  mse_true = 5.474>\n",
      "Epoch 227 / 400  [t=429.32s]  <loss = 0.09883, ref_loss = 0.06380, max_Q = 12.2,  mse_true = 5.348>\n",
      "Epoch 228 / 400  [t=430.91s]  <loss = 0.10330, ref_loss = 0.04550, max_Q = 12.2,  mse_true = 5.210>\n",
      "Epoch 229 / 400  [t=432.50s]  <loss = 0.09826, ref_loss = 0.06446, max_Q = 12.2,  mse_true = 5.304>\n",
      "Epoch 230 / 400  [t=434.09s]  <loss = 0.11154, ref_loss = 0.03633, max_Q = 12.1,  mse_true = 5.405>\n",
      "Epoch 231 / 400  [t=438.88s]  <loss = 0.10407, ref_loss = 0.05982, max_Q = 12.2,  mse_true = 4.952>\n",
      "Epoch 232 / 400  [t=440.49s]  <loss = 0.09893, ref_loss = 0.04833, max_Q = 12.1,  mse_true = 5.100>\n",
      "Epoch 233 / 400  [t=442.10s]  <loss = 0.09653, ref_loss = 0.05403, max_Q = 12.3,  mse_true = 4.907>\n",
      "Epoch 234 / 400  [t=443.71s]  <loss = 0.09650, ref_loss = 0.05965, max_Q = 12.2,  mse_true = 5.350>\n",
      "Epoch 235 / 400  [t=445.33s]  <loss = 0.09249, ref_loss = 0.04941, max_Q = 12.1,  mse_true = 5.378>\n",
      "Epoch 236 / 400  [t=447.14s]  <loss = 0.08982, ref_loss = 0.04484, max_Q = 12.3,  mse_true = 5.062>\n",
      "Epoch 237 / 400  [t=448.74s]  <loss = 0.08945, ref_loss = 0.05174, max_Q = 12.2,  mse_true = 5.212>\n",
      "Epoch 238 / 400  [t=450.34s]  <loss = 0.09601, ref_loss = 0.04075, max_Q = 12.0,  mse_true = 5.651>\n",
      "Epoch 239 / 400  [t=451.93s]  <loss = 0.08605, ref_loss = 0.05073, max_Q = 12.2,  mse_true = 5.401>\n",
      "Epoch 240 / 400  [t=453.53s]  <loss = 0.09325, ref_loss = 0.03407, max_Q = 12.2,  mse_true = 5.269>\n",
      "Epoch 241 / 400  [t=456.68s]  <loss = 0.12677, ref_loss = 0.09367, max_Q = 13.1,  mse_true = 4.739>\n",
      "Epoch 242 / 400  [t=458.29s]  <loss = 0.11632, ref_loss = 0.04187, max_Q = 13.0,  mse_true = 3.621>\n",
      "Epoch 243 / 400  [t=459.90s]  <loss = 0.09684, ref_loss = 0.07202, max_Q = 13.1,  mse_true = 3.334>\n",
      "Epoch 244 / 400  [t=461.50s]  <loss = 0.09972, ref_loss = 0.04676, max_Q = 13.1,  mse_true = 3.398>\n",
      "Epoch 245 / 400  [t=463.10s]  <loss = 0.09682, ref_loss = 0.05643, max_Q = 13.1,  mse_true = 3.384>\n",
      "Epoch 246 / 400  [t=466.60s]  <loss = 0.09872, ref_loss = 0.04830, max_Q = 13.2,  mse_true = 3.459>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247 / 400  [t=468.20s]  <loss = 0.10154, ref_loss = 0.04559, max_Q = 13.2,  mse_true = 3.229>\n",
      "Epoch 248 / 400  [t=469.81s]  <loss = 0.09090, ref_loss = 0.06504, max_Q = 13.3,  mse_true = 3.202>\n",
      "Epoch 249 / 400  [t=471.44s]  <loss = 0.09406, ref_loss = 0.03988, max_Q = 13.1,  mse_true = 3.448>\n",
      "Epoch 250 / 400  [t=473.06s]  <loss = 0.09046, ref_loss = 0.05209, max_Q = 13.1,  mse_true = 3.381>\n",
      "Epoch 251 / 400  [t=476.25s]  <loss = 0.08799, ref_loss = 0.04005, max_Q = 13.3,  mse_true = 3.177>\n",
      "Epoch 252 / 400  [t=477.86s]  <loss = 0.10325, ref_loss = 0.03806, max_Q = 13.1,  mse_true = 3.648>\n",
      "Epoch 253 / 400  [t=479.47s]  <loss = 0.08980, ref_loss = 0.04794, max_Q = 13.1,  mse_true = 3.293>\n",
      "Epoch 254 / 400  [t=481.08s]  <loss = 0.08704, ref_loss = 0.05465, max_Q = 13.1,  mse_true = 3.315>\n",
      "Epoch 255 / 400  [t=482.69s]  <loss = 0.08438, ref_loss = 0.05235, max_Q = 13.2,  mse_true = 3.449>\n",
      "Epoch 256 / 400  [t=484.48s]  <loss = 0.08772, ref_loss = 0.03935, max_Q = 13.2,  mse_true = 3.368>\n",
      "Epoch 257 / 400  [t=486.07s]  <loss = 0.08476, ref_loss = 0.04370, max_Q = 13.0,  mse_true = 3.464>\n",
      "Epoch 258 / 400  [t=487.66s]  <loss = 0.07978, ref_loss = 0.04116, max_Q = 13.1,  mse_true = 3.281>\n",
      "Epoch 259 / 400  [t=489.26s]  <loss = 0.07986, ref_loss = 0.04161, max_Q = 13.2,  mse_true = 3.272>\n",
      "Epoch 260 / 400  [t=490.86s]  <loss = 0.08640, ref_loss = 0.04444, max_Q = 13.1,  mse_true = 3.085>\n",
      "Epoch 261 / 400  [t=495.78s]  <loss = 0.11330, ref_loss = 0.03908, max_Q = 13.0,  mse_true = 3.505>\n",
      "Epoch 262 / 400  [t=497.38s]  <loss = 0.07705, ref_loss = 0.04399, max_Q = 13.7,  mse_true = 2.625>\n",
      "Epoch 263 / 400  [t=498.99s]  <loss = 0.07512, ref_loss = 0.03715, max_Q = 13.8,  mse_true = 2.587>\n",
      "Epoch 264 / 400  [t=500.62s]  <loss = 0.07588, ref_loss = 0.03536, max_Q = 13.7,  mse_true = 2.615>\n",
      "Epoch 265 / 400  [t=502.24s]  <loss = 0.07200, ref_loss = 0.02836, max_Q = 13.8,  mse_true = 2.595>\n",
      "Epoch 266 / 400  [t=504.04s]  <loss = 0.07585, ref_loss = 0.02906, max_Q = 13.7,  mse_true = 2.658>\n",
      "Epoch 267 / 400  [t=505.64s]  <loss = 0.07262, ref_loss = 0.03536, max_Q = 13.8,  mse_true = 2.503>\n",
      "Epoch 268 / 400  [t=507.25s]  <loss = 0.06637, ref_loss = 0.02903, max_Q = 13.8,  mse_true = 2.408>\n",
      "Epoch 269 / 400  [t=508.84s]  <loss = 0.06577, ref_loss = 0.03222, max_Q = 13.8,  mse_true = 2.280>\n",
      "Epoch 270 / 400  [t=510.44s]  <loss = 0.06597, ref_loss = 0.02256, max_Q = 13.8,  mse_true = 2.479>\n",
      "Epoch 271 / 400  [t=513.63s]  <loss = 0.06235, ref_loss = 0.03480, max_Q = 13.8,  mse_true = 2.459>\n",
      "Epoch 272 / 400  [t=515.24s]  <loss = 0.06396, ref_loss = 0.02482, max_Q = 13.8,  mse_true = 2.503>\n",
      "Epoch 273 / 400  [t=516.85s]  <loss = 0.06216, ref_loss = 0.02929, max_Q = 13.9,  mse_true = 2.458>\n",
      "Epoch 274 / 400  [t=518.45s]  <loss = 0.06715, ref_loss = 0.03168, max_Q = 13.8,  mse_true = 2.450>\n",
      "Epoch 275 / 400  [t=520.08s]  <loss = 0.06361, ref_loss = 0.02861, max_Q = 13.8,  mse_true = 2.423>\n",
      "Epoch 276 / 400  [t=521.89s]  <loss = 0.07082, ref_loss = 0.02157, max_Q = 13.9,  mse_true = 2.431>\n",
      "Epoch 277 / 400  [t=525.28s]  <loss = 0.06072, ref_loss = 0.05045, max_Q = 13.8,  mse_true = 2.286>\n",
      "Epoch 278 / 400  [t=526.88s]  <loss = 0.05934, ref_loss = 0.01924, max_Q = 13.8,  mse_true = 2.511>\n",
      "Epoch 279 / 400  [t=528.47s]  <loss = 0.05729, ref_loss = 0.03195, max_Q = 13.8,  mse_true = 2.376>\n",
      "Epoch 280 / 400  [t=530.09s]  <loss = 0.05550, ref_loss = 0.02618, max_Q = 13.8,  mse_true = 2.465>\n",
      "Epoch 281 / 400  [t=533.34s]  <loss = 0.07845, ref_loss = 0.02981, max_Q = 14.2,  mse_true = 2.322>\n",
      "Epoch 282 / 400  [t=534.96s]  <loss = 0.06381, ref_loss = 0.02200, max_Q = 14.4,  mse_true = 1.759>\n",
      "Epoch 283 / 400  [t=536.57s]  <loss = 0.06309, ref_loss = 0.03082, max_Q = 14.8,  mse_true = 1.458>\n",
      "Epoch 284 / 400  [t=538.17s]  <loss = 0.06024, ref_loss = 0.02963, max_Q = 14.6,  mse_true = 1.644>\n",
      "Epoch 285 / 400  [t=539.81s]  <loss = 0.06408, ref_loss = 0.02661, max_Q = 14.4,  mse_true = 1.631>\n",
      "Epoch 286 / 400  [t=541.59s]  <loss = 0.06202, ref_loss = 0.01399, max_Q = 14.6,  mse_true = 1.861>\n",
      "Epoch 287 / 400  [t=543.18s]  <loss = 0.05527, ref_loss = 0.03628, max_Q = 14.5,  mse_true = 1.647>\n",
      "Epoch 288 / 400  [t=544.77s]  <loss = 0.05542, ref_loss = 0.02336, max_Q = 14.6,  mse_true = 1.590>\n",
      "Epoch 289 / 400  [t=546.36s]  <loss = 0.05294, ref_loss = 0.02578, max_Q = 14.5,  mse_true = 1.606>\n",
      "Epoch 290 / 400  [t=547.95s]  <loss = 0.05275, ref_loss = 0.01861, max_Q = 14.6,  mse_true = 1.557>\n",
      "Epoch 291 / 400  [t=552.96s]  <loss = 0.05285, ref_loss = 0.02088, max_Q = 14.5,  mse_true = 1.579>\n",
      "Epoch 292 / 400  [t=554.56s]  <loss = 0.05278, ref_loss = 0.03306, max_Q = 14.5,  mse_true = 1.481>\n",
      "Epoch 293 / 400  [t=556.17s]  <loss = 0.05997, ref_loss = 0.01679, max_Q = 14.4,  mse_true = 1.522>\n",
      "Epoch 294 / 400  [t=557.78s]  <loss = 0.04870, ref_loss = 0.02681, max_Q = 14.5,  mse_true = 1.591>\n",
      "Epoch 295 / 400  [t=559.39s]  <loss = 0.05558, ref_loss = 0.01629, max_Q = 14.5,  mse_true = 1.599>\n",
      "Epoch 296 / 400  [t=561.18s]  <loss = 0.04815, ref_loss = 0.02493, max_Q = 14.5,  mse_true = 1.702>\n",
      "Epoch 297 / 400  [t=562.79s]  <loss = 0.05087, ref_loss = 0.01608, max_Q = 14.6,  mse_true = 1.571>\n",
      "Epoch 298 / 400  [t=564.40s]  <loss = 0.04839, ref_loss = 0.02225, max_Q = 14.5,  mse_true = 1.571>\n",
      "Epoch 299 / 400  [t=566.00s]  <loss = 0.04735, ref_loss = 0.02321, max_Q = 14.6,  mse_true = 1.608>\n",
      "Epoch 300 / 400  [t=567.60s]  <loss = 0.05332, ref_loss = 0.01467, max_Q = 14.4,  mse_true = 1.511>\n",
      "Epoch 301 / 400  [t=570.84s]  <loss = 0.07163, ref_loss = 0.01808, max_Q = 14.8,  mse_true = 1.662>\n",
      "Epoch 302 / 400  [t=572.46s]  <loss = 0.06173, ref_loss = 0.02513, max_Q = 15.1,  mse_true = 1.060>\n",
      "Epoch 303 / 400  [t=574.06s]  <loss = 0.06263, ref_loss = 0.01301, max_Q = 15.0,  mse_true = 1.288>\n",
      "Epoch 304 / 400  [t=575.66s]  <loss = 0.05890, ref_loss = 0.02631, max_Q = 15.1,  mse_true = 1.334>\n",
      "Epoch 305 / 400  [t=577.28s]  <loss = 0.05765, ref_loss = 0.02627, max_Q = 14.9,  mse_true = 1.079>\n",
      "Epoch 306 / 400  [t=579.07s]  <loss = 0.04856, ref_loss = 0.02213, max_Q = 15.2,  mse_true = 1.086>\n",
      "Epoch 307 / 400  [t=580.67s]  <loss = 0.04760, ref_loss = 0.01898, max_Q = 15.0,  mse_true = 1.101>\n",
      "Epoch 308 / 400  [t=582.26s]  <loss = 0.04863, ref_loss = 0.01106, max_Q = 14.9,  mse_true = 1.093>\n",
      "Epoch 309 / 400  [t=585.81s]  <loss = 0.05177, ref_loss = 0.01931, max_Q = 15.1,  mse_true = 1.112>\n",
      "Epoch 310 / 400  [t=587.40s]  <loss = 0.04413, ref_loss = 0.02158, max_Q = 15.0,  mse_true = 1.129>\n",
      "Epoch 311 / 400  [t=590.67s]  <loss = 0.04538, ref_loss = 0.02385, max_Q = 15.0,  mse_true = 1.091>\n",
      "Epoch 312 / 400  [t=592.29s]  <loss = 0.05380, ref_loss = 0.01294, max_Q = 14.8,  mse_true = 1.323>\n",
      "Epoch 313 / 400  [t=593.89s]  <loss = 0.04557, ref_loss = 0.00840, max_Q = 15.1,  mse_true = 1.256>\n",
      "Epoch 314 / 400  [t=595.49s]  <loss = 0.04161, ref_loss = 0.01945, max_Q = 15.1,  mse_true = 0.982>\n",
      "Epoch 315 / 400  [t=597.09s]  <loss = 0.03823, ref_loss = 0.02070, max_Q = 15.2,  mse_true = 1.000>\n",
      "Epoch 316 / 400  [t=598.88s]  <loss = 0.04696, ref_loss = 0.01166, max_Q = 15.0,  mse_true = 1.138>\n",
      "Epoch 317 / 400  [t=600.47s]  <loss = 0.03970, ref_loss = 0.01035, max_Q = 15.2,  mse_true = 1.028>\n",
      "Epoch 318 / 400  [t=602.09s]  <loss = 0.03807, ref_loss = 0.02070, max_Q = 15.1,  mse_true = 1.208>\n",
      "Epoch 319 / 400  [t=603.69s]  <loss = 0.04613, ref_loss = 0.00823, max_Q = 15.0,  mse_true = 1.268>\n",
      "Epoch 320 / 400  [t=605.28s]  <loss = 0.04695, ref_loss = 0.01389, max_Q = 15.1,  mse_true = 1.073>\n",
      "Epoch 321 / 400  [t=608.56s]  <loss = 0.07125, ref_loss = 0.02942, max_Q = 15.4,  mse_true = 1.021>\n",
      "Epoch 322 / 400  [t=610.16s]  <loss = 0.05482, ref_loss = 0.01629, max_Q = 15.7,  mse_true = 0.681>\n",
      "Epoch 323 / 400  [t=613.68s]  <loss = 0.05670, ref_loss = 0.02246, max_Q = 15.8,  mse_true = 0.803>\n",
      "Epoch 324 / 400  [t=615.28s]  <loss = 0.05543, ref_loss = 0.02429, max_Q = 15.5,  mse_true = 0.671>\n",
      "Epoch 325 / 400  [t=616.88s]  <loss = 0.05229, ref_loss = 0.01859, max_Q = 15.9,  mse_true = 0.833>\n",
      "Epoch 326 / 400  [t=618.68s]  <loss = 0.04505, ref_loss = 0.01431, max_Q = 15.7,  mse_true = 0.749>\n",
      "Epoch 327 / 400  [t=620.28s]  <loss = 0.04319, ref_loss = 0.01501, max_Q = 15.6,  mse_true = 0.728>\n",
      "Epoch 328 / 400  [t=621.89s]  <loss = 0.04443, ref_loss = 0.01266, max_Q = 15.8,  mse_true = 0.690>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329 / 400  [t=623.49s]  <loss = 0.04817, ref_loss = 0.02208, max_Q = 15.8,  mse_true = 0.664>\n",
      "Epoch 330 / 400  [t=625.09s]  <loss = 0.04205, ref_loss = 0.02159, max_Q = 15.8,  mse_true = 0.751>\n",
      "Epoch 331 / 400  [t=628.37s]  <loss = 0.03788, ref_loss = 0.01657, max_Q = 15.7,  mse_true = 0.685>\n",
      "Epoch 332 / 400  [t=629.98s]  <loss = 0.04146, ref_loss = 0.01106, max_Q = 15.8,  mse_true = 0.714>\n",
      "Epoch 333 / 400  [t=631.59s]  <loss = 0.03990, ref_loss = 0.01596, max_Q = 15.7,  mse_true = 0.665>\n",
      "Epoch 334 / 400  [t=633.19s]  <loss = 0.03679, ref_loss = 0.02043, max_Q = 15.7,  mse_true = 0.653>\n",
      "Epoch 335 / 400  [t=634.80s]  <loss = 0.03582, ref_loss = 0.01316, max_Q = 15.8,  mse_true = 0.619>\n",
      "Epoch 336 / 400  [t=636.59s]  <loss = 0.03899, ref_loss = 0.01443, max_Q = 15.7,  mse_true = 0.656>\n",
      "Epoch 337 / 400  [t=638.18s]  <loss = 0.05412, ref_loss = 0.01453, max_Q = 15.7,  mse_true = 0.818>\n",
      "Epoch 338 / 400  [t=639.77s]  <loss = 0.03937, ref_loss = 0.01271, max_Q = 15.7,  mse_true = 0.744>\n",
      "Epoch 339 / 400  [t=641.38s]  <loss = 0.05353, ref_loss = 0.01110, max_Q = 15.6,  mse_true = 0.788>\n",
      "Epoch 340 / 400  [t=642.97s]  <loss = 0.03739, ref_loss = 0.01556, max_Q = 15.8,  mse_true = 0.643>\n",
      "Epoch 341 / 400  [t=648.28s]  <loss = 0.07365, ref_loss = 0.00779, max_Q = 15.8,  mse_true = 0.657>\n",
      "Epoch 342 / 400  [t=649.89s]  <loss = 0.03967, ref_loss = 0.02047, max_Q = 16.1,  mse_true = 0.546>\n",
      "Epoch 343 / 400  [t=651.50s]  <loss = 0.04282, ref_loss = 0.00492, max_Q = 16.3,  mse_true = 0.550>\n",
      "Epoch 344 / 400  [t=653.12s]  <loss = 0.03325, ref_loss = 0.01685, max_Q = 16.2,  mse_true = 0.470>\n",
      "Epoch 345 / 400  [t=654.78s]  <loss = 0.04032, ref_loss = 0.00935, max_Q = 15.9,  mse_true = 0.505>\n",
      "Epoch 346 / 400  [t=656.60s]  <loss = 0.03570, ref_loss = 0.00910, max_Q = 16.2,  mse_true = 0.488>\n",
      "Epoch 347 / 400  [t=658.20s]  <loss = 0.03727, ref_loss = 0.01474, max_Q = 16.1,  mse_true = 0.461>\n",
      "Epoch 348 / 400  [t=659.85s]  <loss = 0.03276, ref_loss = 0.00854, max_Q = 16.3,  mse_true = 0.493>\n",
      "Epoch 349 / 400  [t=661.46s]  <loss = 0.03248, ref_loss = 0.01058, max_Q = 16.3,  mse_true = 0.480>\n",
      "Epoch 350 / 400  [t=663.05s]  <loss = 0.02945, ref_loss = 0.00811, max_Q = 16.2,  mse_true = 0.479>\n",
      "Epoch 351 / 400  [t=666.37s]  <loss = 0.03035, ref_loss = 0.01039, max_Q = 16.3,  mse_true = 0.444>\n",
      "Epoch 352 / 400  [t=667.99s]  <loss = 0.03231, ref_loss = 0.00976, max_Q = 16.3,  mse_true = 0.458>\n",
      "Epoch 353 / 400  [t=669.61s]  <loss = 0.02897, ref_loss = 0.00884, max_Q = 16.3,  mse_true = 0.450>\n",
      "Epoch 354 / 400  [t=671.22s]  <loss = 0.02777, ref_loss = 0.00736, max_Q = 16.2,  mse_true = 0.459>\n",
      "Epoch 355 / 400  [t=672.83s]  <loss = 0.02932, ref_loss = 0.00563, max_Q = 16.3,  mse_true = 0.459>\n",
      "Epoch 356 / 400  [t=674.63s]  <loss = 0.03241, ref_loss = 0.00990, max_Q = 16.3,  mse_true = 0.413>\n",
      "Epoch 357 / 400  [t=676.23s]  <loss = 0.03198, ref_loss = 0.01222, max_Q = 16.1,  mse_true = 0.433>\n",
      "Epoch 358 / 400  [t=679.90s]  <loss = 0.03762, ref_loss = 0.00963, max_Q = 16.3,  mse_true = 0.431>\n",
      "Epoch 359 / 400  [t=681.50s]  <loss = 0.02650, ref_loss = 0.01057, max_Q = 16.4,  mse_true = 0.413>\n",
      "Epoch 360 / 400  [t=683.10s]  <loss = 0.02782, ref_loss = 0.00369, max_Q = 16.3,  mse_true = 0.447>\n",
      "Epoch 361 / 400  [t=686.43s]  <loss = 0.04952, ref_loss = 0.01841, max_Q = 16.3,  mse_true = 0.411>\n",
      "Epoch 362 / 400  [t=688.05s]  <loss = 0.04509, ref_loss = 0.01473, max_Q = 16.6,  mse_true = 0.407>\n",
      "Epoch 363 / 400  [t=689.65s]  <loss = 0.04235, ref_loss = 0.01120, max_Q = 16.9,  mse_true = 0.364>\n",
      "Epoch 364 / 400  [t=691.26s]  <loss = 0.03521, ref_loss = 0.01002, max_Q = 16.7,  mse_true = 0.346>\n",
      "Epoch 365 / 400  [t=692.87s]  <loss = 0.04152, ref_loss = 0.00868, max_Q = 16.6,  mse_true = 0.356>\n",
      "Epoch 366 / 400  [t=694.65s]  <loss = 0.03356, ref_loss = 0.01519, max_Q = 16.6,  mse_true = 0.308>\n",
      "Epoch 367 / 400  [t=696.24s]  <loss = 0.03190, ref_loss = 0.00475, max_Q = 16.7,  mse_true = 0.325>\n",
      "Epoch 368 / 400  [t=697.84s]  <loss = 0.03588, ref_loss = 0.01622, max_Q = 16.6,  mse_true = 0.307>\n",
      "Epoch 369 / 400  [t=699.43s]  <loss = 0.04457, ref_loss = 0.01415, max_Q = 16.5,  mse_true = 0.313>\n",
      "Epoch 370 / 400  [t=701.04s]  <loss = 0.03941, ref_loss = 0.01197, max_Q = 16.8,  mse_true = 0.326>\n",
      "Epoch 371 / 400  [t=704.35s]  <loss = 0.03109, ref_loss = 0.00449, max_Q = 16.6,  mse_true = 0.309>\n",
      "Epoch 372 / 400  [t=705.96s]  <loss = 0.02600, ref_loss = 0.01514, max_Q = 16.8,  mse_true = 0.270>\n",
      "Epoch 373 / 400  [t=707.56s]  <loss = 0.02996, ref_loss = 0.00812, max_Q = 16.6,  mse_true = 0.299>\n",
      "Epoch 374 / 400  [t=711.26s]  <loss = 0.03063, ref_loss = 0.01373, max_Q = 16.7,  mse_true = 0.289>\n",
      "Epoch 375 / 400  [t=712.86s]  <loss = 0.04008, ref_loss = 0.01094, max_Q = 16.5,  mse_true = 0.299>\n",
      "Epoch 376 / 400  [t=714.65s]  <loss = 0.02918, ref_loss = 0.00420, max_Q = 16.7,  mse_true = 0.304>\n",
      "Epoch 377 / 400  [t=716.26s]  <loss = 0.02391, ref_loss = 0.01677, max_Q = 16.6,  mse_true = 0.273>\n",
      "Epoch 378 / 400  [t=717.87s]  <loss = 0.02918, ref_loss = 0.00822, max_Q = 17.1,  mse_true = 0.319>\n",
      "Epoch 379 / 400  [t=719.49s]  <loss = 0.02628, ref_loss = 0.00645, max_Q = 16.8,  mse_true = 0.283>\n",
      "Epoch 380 / 400  [t=721.11s]  <loss = 0.02473, ref_loss = 0.00639, max_Q = 16.7,  mse_true = 0.279>\n",
      "Epoch 381 / 400  [t=724.44s]  <loss = 0.06918, ref_loss = 0.00923, max_Q = 17.6,  mse_true = 0.278>\n",
      "Epoch 382 / 400  [t=726.05s]  <loss = 0.04754, ref_loss = 0.01367, max_Q = 17.1,  mse_true = 0.268>\n",
      "Epoch 383 / 400  [t=727.65s]  <loss = 0.03656, ref_loss = 0.00666, max_Q = 17.3,  mse_true = 0.271>\n",
      "Epoch 384 / 400  [t=729.26s]  <loss = 0.04748, ref_loss = 0.00556, max_Q = 17.0,  mse_true = 0.258>\n",
      "Epoch 385 / 400  [t=730.87s]  <loss = 0.03192, ref_loss = 0.00874, max_Q = 17.1,  mse_true = 0.256>\n",
      "Epoch 386 / 400  [t=732.66s]  <loss = 0.02751, ref_loss = 0.00787, max_Q = 17.2,  mse_true = 0.251>\n",
      "Epoch 387 / 400  [t=734.26s]  <loss = 0.03008, ref_loss = 0.00519, max_Q = 17.3,  mse_true = 0.280>\n",
      "Epoch 388 / 400  [t=735.85s]  <loss = 0.04525, ref_loss = 0.01390, max_Q = 17.0,  mse_true = 0.227>\n",
      "Epoch 389 / 400  [t=737.44s]  <loss = 0.02539, ref_loss = 0.00779, max_Q = 17.0,  mse_true = 0.241>\n",
      "Epoch 390 / 400  [t=739.03s]  <loss = 0.02917, ref_loss = 0.00654, max_Q = 17.1,  mse_true = 0.311>\n",
      "Epoch 391 / 400  [t=744.57s]  <loss = 0.02048, ref_loss = 0.00554, max_Q = 17.1,  mse_true = 0.233>\n",
      "Epoch 392 / 400  [t=746.16s]  <loss = 0.03004, ref_loss = 0.00613, max_Q = 17.0,  mse_true = 0.227>\n",
      "Epoch 393 / 400  [t=747.76s]  <loss = 0.02247, ref_loss = 0.00618, max_Q = 17.2,  mse_true = 0.206>\n",
      "Epoch 394 / 400  [t=749.37s]  <loss = 0.02001, ref_loss = 0.00802, max_Q = 17.2,  mse_true = 0.208>\n",
      "Epoch 395 / 400  [t=750.99s]  <loss = 0.02176, ref_loss = 0.00643, max_Q = 17.3,  mse_true = 0.217>\n",
      "Epoch 396 / 400  [t=752.78s]  <loss = 0.02245, ref_loss = 0.00581, max_Q = 17.1,  mse_true = 0.218>\n",
      "Epoch 397 / 400  [t=754.39s]  <loss = 0.02355, ref_loss = 0.00296, max_Q = 17.2,  mse_true = 0.212>\n",
      "Epoch 398 / 400  [t=755.99s]  <loss = 0.01844, ref_loss = 0.00828, max_Q = 17.2,  mse_true = 0.206>\n",
      "Epoch 399 / 400  [t=757.58s]  <loss = 0.05149, ref_loss = 0.00891, max_Q = 17.1,  mse_true = 0.211>\n",
      "Epoch 400 / 400  [t=759.19s]  <loss = 0.02990, ref_loss = 0.00659, max_Q = 17.1,  mse_true = 0.202>\n",
      "Directory figures/Helicopter_NB0/clone_20/experiment_3 created\n",
      "==================================================================================================================\n",
      "Environment config:\n",
      "> distance_to_end: 13\n",
      "> game_board_pad_size: 3\n",
      "> horizontal_size: 20\n",
      "> reward_per_turn: -1.0\n",
      "> lambda_dx: 0.0\n",
      "> lambda_b: -1.0\n",
      "> gamma: 1.0\n",
      "> x_min: 0\n",
      "> x_max: 19\n",
      "> x_range: 19\n",
      "> x_start: 3\n",
      "> x_end: 16\n",
      "> action_list: [-1  0  1]\n",
      "==================================================================================================================\n",
      "Training config:\n",
      "> Stop training when mse_true exceeds 0.05\n",
      "> Using 1 step empirical returns\n",
      "> Using bootstrap method: clone\n",
      "> Using epochs of length None\n",
      "> Updating gradient every batch of size 10\n",
      "> Using optimizer_q1 <keras.optimizer_v2.gradient_descent.SGD object at 0x3371d0760> with learning rate 0.01\n",
      "> Using optimizer_q2 None with learning rate 0.01\n",
      "> Swapping q1 and q2 every -1 epochs\n",
      "> Cloning q2 from q1 every 20 epochs\n",
      "> Assigning a weight of 0.3 to anchoring state/action pairs\n",
      "==================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/ipykernel_58834/1750174422.py:191: RuntimeWarning: All-NaN slice encountered\n",
      "  y_min   = np.nanmin([0, np.nanmin(true_q), np.nanmin(target_q), np.nanmin(q_model), np.nanmin(bs_model)])\n",
      "/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/ipykernel_58834/1750174422.py:192: RuntimeWarning: All-NaN slice encountered\n",
      "  y_max   = np.nanmax([0, np.nanmax(true_q), np.nanmax(target_q), np.nanmax(q_model), np.nanmax(bs_model)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 400  [t=2.70s]  <loss = 0.82893, ref_loss = 0.97736, max_Q = 0.2,  mse_true = 92.668>    \n",
      "Epoch 2 / 400  [t=4.31s]  <loss = 0.50334, ref_loss = 0.49446, max_Q = 0.4,  mse_true = 88.623>    \n",
      "Epoch 3 / 400  [t=5.91s]  <loss = 0.29315, ref_loss = 0.22970, max_Q = 0.6,  mse_true = 85.601>    \n",
      "Epoch 4 / 400  [t=7.54s]  <loss = 0.15975, ref_loss = 0.09492, max_Q = 0.8,  mse_true = 83.265>    \n",
      "Epoch 5 / 400  [t=9.17s]  <loss = 0.09153, ref_loss = 0.03479, max_Q = 0.9,  mse_true = 81.528>    \n",
      "Epoch 6 / 400  [t=10.96s]  <loss = 0.05771, ref_loss = 0.00951, max_Q = 1.0,  mse_true = 80.245>   \n",
      "Epoch 7 / 400  [t=12.56s]  <loss = 0.04908, ref_loss = 0.00250, max_Q = 1.0,  mse_true = 79.381>   \n",
      "Epoch 8 / 400  [t=14.20s]  <loss = 0.03518, ref_loss = 0.00127, max_Q = 1.1,  mse_true = 78.732>   \n",
      "Epoch 9 / 400  [t=18.10s]  <loss = 0.03216, ref_loss = 0.00192, max_Q = 1.1,  mse_true = 78.328>   \n",
      "Epoch 10 / 400  [t=19.72s]  <loss = 0.03045, ref_loss = 0.00278, max_Q = 1.1,  mse_true = 78.041>  \n",
      "Epoch 11 / 400  [t=22.62s]  <loss = 0.02897, ref_loss = 0.00330, max_Q = 1.1,  mse_true = 77.838>  \n",
      "Epoch 12 / 400  [t=24.23s]  <loss = 0.02786, ref_loss = 0.00413, max_Q = 1.1,  mse_true = 77.678>  \n",
      "Epoch 13 / 400  [t=25.83s]  <loss = 0.03011, ref_loss = 0.00343, max_Q = 1.1,  mse_true = 77.592>  \n",
      "Epoch 14 / 400  [t=27.43s]  <loss = 0.02663, ref_loss = 0.00438, max_Q = 1.1,  mse_true = 77.473>  \n",
      "Epoch 15 / 400  [t=29.04s]  <loss = 0.02582, ref_loss = 0.00352, max_Q = 1.1,  mse_true = 77.431>  \n",
      "Epoch 16 / 400  [t=30.83s]  <loss = 0.02557, ref_loss = 0.00361, max_Q = 1.1,  mse_true = 77.374>  \n",
      "Epoch 17 / 400  [t=32.47s]  <loss = 0.02520, ref_loss = 0.00328, max_Q = 1.1,  mse_true = 77.330>  \n",
      "Epoch 18 / 400  [t=34.07s]  <loss = 0.02477, ref_loss = 0.00276, max_Q = 1.1,  mse_true = 77.282>  \n",
      "Epoch 19 / 400  [t=35.67s]  <loss = 0.02406, ref_loss = 0.00259, max_Q = 1.1,  mse_true = 77.237>  \n",
      "Epoch 20 / 400  [t=37.27s]  <loss = 0.02694, ref_loss = 0.00213, max_Q = 1.1,  mse_true = 77.192>  \n",
      "Epoch 21 / 400  [t=40.20s]  <loss = 0.54109, ref_loss = 0.02930, max_Q = 1.3,  mse_true = 77.113>  \n",
      "Epoch 22 / 400  [t=41.80s]  <loss = 0.36546, ref_loss = 0.14377, max_Q = 1.5,  mse_true = 73.965>  \n",
      "Epoch 23 / 400  [t=43.39s]  <loss = 0.29672, ref_loss = 0.24712, max_Q = 1.6,  mse_true = 71.947>  \n",
      "Epoch 24 / 400  [t=44.99s]  <loss = 0.28238, ref_loss = 0.29740, max_Q = 1.6,  mse_true = 70.651>  \n",
      "Epoch 25 / 400  [t=46.59s]  <loss = 0.25589, ref_loss = 0.34078, max_Q = 1.6,  mse_true = 69.721>  \n",
      "Epoch 26 / 400  [t=48.38s]  <loss = 0.23633, ref_loss = 0.36765, max_Q = 1.7,  mse_true = 69.131>  \n",
      "Epoch 27 / 400  [t=49.96s]  <loss = 0.22596, ref_loss = 0.34921, max_Q = 1.6,  mse_true = 68.873>  \n",
      "Epoch 28 / 400  [t=51.56s]  <loss = 0.21851, ref_loss = 0.34784, max_Q = 1.6,  mse_true = 68.548>  \n",
      "Epoch 29 / 400  [t=55.53s]  <loss = 0.20870, ref_loss = 0.32266, max_Q = 1.7,  mse_true = 68.362>  \n",
      "Epoch 30 / 400  [t=57.12s]  <loss = 0.20144, ref_loss = 0.33051, max_Q = 1.7,  mse_true = 68.071>  \n",
      "Epoch 31 / 400  [t=60.04s]  <loss = 0.20488, ref_loss = 0.30801, max_Q = 1.7,  mse_true = 67.904>  \n",
      "Epoch 32 / 400  [t=61.65s]  <loss = 0.19998, ref_loss = 0.30839, max_Q = 1.7,  mse_true = 67.634>  \n",
      "Epoch 33 / 400  [t=63.26s]  <loss = 0.18508, ref_loss = 0.29974, max_Q = 1.7,  mse_true = 67.476>  \n",
      "Epoch 34 / 400  [t=64.87s]  <loss = 0.18005, ref_loss = 0.28966, max_Q = 1.8,  mse_true = 67.349>  \n",
      "Epoch 35 / 400  [t=66.48s]  <loss = 0.17560, ref_loss = 0.27446, max_Q = 1.8,  mse_true = 67.213>  \n",
      "Epoch 36 / 400  [t=68.28s]  <loss = 0.17225, ref_loss = 0.27044, max_Q = 1.8,  mse_true = 67.045>  \n",
      "Epoch 37 / 400  [t=69.88s]  <loss = 0.16857, ref_loss = 0.26285, max_Q = 1.8,  mse_true = 66.899>  \n",
      "Epoch 38 / 400  [t=71.48s]  <loss = 0.16493, ref_loss = 0.24773, max_Q = 1.8,  mse_true = 66.771>  \n",
      "Epoch 39 / 400  [t=73.08s]  <loss = 0.16231, ref_loss = 0.24760, max_Q = 1.8,  mse_true = 66.606>  \n",
      "Epoch 40 / 400  [t=74.68s]  <loss = 0.16660, ref_loss = 0.23484, max_Q = 1.8,  mse_true = 66.537>  \n",
      "Epoch 41 / 400  [t=77.62s]  <loss = 0.66496, ref_loss = 0.37869, max_Q = 2.1,  mse_true = 66.327>  \n",
      "Epoch 42 / 400  [t=79.23s]  <loss = 0.53543, ref_loss = 0.66679, max_Q = 2.3,  mse_true = 62.708>  \n",
      "Epoch 43 / 400  [t=80.83s]  <loss = 0.49341, ref_loss = 0.78445, max_Q = 2.4,  mse_true = 60.959>  \n",
      "Epoch 44 / 400  [t=82.43s]  <loss = 0.46066, ref_loss = 0.75521, max_Q = 2.5,  mse_true = 60.154>  \n",
      "Epoch 45 / 400  [t=84.03s]  <loss = 0.43572, ref_loss = 0.76394, max_Q = 2.5,  mse_true = 59.369>  \n",
      "Epoch 46 / 400  [t=85.82s]  <loss = 0.41410, ref_loss = 0.75160, max_Q = 2.6,  mse_true = 58.856>  \n",
      "Epoch 47 / 400  [t=87.41s]  <loss = 0.39921, ref_loss = 0.66202, max_Q = 2.6,  mse_true = 58.528>  \n",
      "Epoch 48 / 400  [t=89.01s]  <loss = 0.38293, ref_loss = 0.66044, max_Q = 2.7,  mse_true = 57.916>  \n",
      "Epoch 49 / 400  [t=90.61s]  <loss = 0.36945, ref_loss = 0.63303, max_Q = 2.7,  mse_true = 57.551>  \n",
      "Epoch 50 / 400  [t=94.65s]  <loss = 0.35457, ref_loss = 0.59334, max_Q = 2.7,  mse_true = 57.253>  \n",
      "Epoch 51 / 400  [t=97.70s]  <loss = 0.34327, ref_loss = 0.57033, max_Q = 2.8,  mse_true = 57.001>  \n",
      "Epoch 52 / 400  [t=99.38s]  <loss = 0.33532, ref_loss = 0.51780, max_Q = 2.8,  mse_true = 56.818>  \n",
      "Epoch 53 / 400  [t=101.04s]  <loss = 0.32197, ref_loss = 0.48475, max_Q = 2.8,  mse_true = 56.481> \n",
      "Epoch 54 / 400  [t=102.72s]  <loss = 0.31430, ref_loss = 0.47573, max_Q = 2.9,  mse_true = 56.069> \n",
      "Epoch 55 / 400  [t=104.42s]  <loss = 0.31386, ref_loss = 0.42487, max_Q = 2.9,  mse_true = 56.014> \n",
      "Epoch 56 / 400  [t=106.27s]  <loss = 0.30308, ref_loss = 0.44339, max_Q = 2.9,  mse_true = 55.477> \n",
      "Epoch 57 / 400  [t=107.95s]  <loss = 0.29697, ref_loss = 0.41600, max_Q = 2.9,  mse_true = 55.390> \n",
      "Epoch 58 / 400  [t=110.19s]  <loss = 0.29382, ref_loss = 0.40297, max_Q = 2.9,  mse_true = 55.235> \n",
      "Epoch 59 / 400  [t=112.10s]  <loss = 0.29043, ref_loss = 0.39287, max_Q = 3.0,  mse_true = 55.162> \n",
      "Epoch 60 / 400  [t=113.82s]  <loss = 0.29286, ref_loss = 0.35052, max_Q = 3.0,  mse_true = 55.244> \n",
      "Epoch 61 / 400  [t=117.06s]  <loss = 0.61204, ref_loss = 0.55965, max_Q = 3.4,  mse_true = 54.762> \n",
      "Epoch 62 / 400  [t=118.90s]  <loss = 0.46945, ref_loss = 0.74033, max_Q = 3.5,  mse_true = 50.315> \n",
      "Epoch 63 / 400  [t=120.73s]  <loss = 0.41269, ref_loss = 0.72155, max_Q = 3.7,  mse_true = 48.578> \n",
      "Epoch 64 / 400  [t=122.58s]  <loss = 0.37262, ref_loss = 0.63519, max_Q = 3.8,  mse_true = 47.762> \n",
      "Epoch 65 / 400  [t=124.40s]  <loss = 0.35274, ref_loss = 0.57658, max_Q = 3.9,  mse_true = 47.012> \n",
      "Epoch 66 / 400  [t=126.33s]  <loss = 0.33286, ref_loss = 0.50424, max_Q = 4.0,  mse_true = 46.626> \n",
      "Epoch 67 / 400  [t=127.96s]  <loss = 0.33111, ref_loss = 0.46798, max_Q = 4.0,  mse_true = 45.989> \n",
      "Epoch 68 / 400  [t=129.72s]  <loss = 0.31832, ref_loss = 0.44333, max_Q = 4.0,  mse_true = 45.776> \n",
      "Epoch 69 / 400  [t=131.50s]  <loss = 0.31535, ref_loss = 0.38329, max_Q = 4.1,  mse_true = 45.400> \n",
      "Epoch 70 / 400  [t=133.30s]  <loss = 0.31348, ref_loss = 0.39210, max_Q = 4.1,  mse_true = 44.944> \n",
      "Epoch 71 / 400  [t=139.02s]  <loss = 0.31228, ref_loss = 0.38470, max_Q = 4.1,  mse_true = 44.757> \n",
      "Epoch 72 / 400  [t=140.79s]  <loss = 0.32182, ref_loss = 0.37218, max_Q = 4.1,  mse_true = 44.791> \n",
      "Epoch 73 / 400  [t=142.60s]  <loss = 0.31534, ref_loss = 0.34427, max_Q = 4.1,  mse_true = 44.954> \n",
      "Epoch 74 / 400  [t=144.38s]  <loss = 0.30820, ref_loss = 0.38055, max_Q = 4.1,  mse_true = 44.387> \n",
      "Epoch 75 / 400  [t=146.08s]  <loss = 0.31557, ref_loss = 0.32049, max_Q = 4.1,  mse_true = 45.276> \n",
      "Epoch 76 / 400  [t=148.00s]  <loss = 0.30333, ref_loss = 0.32343, max_Q = 4.1,  mse_true = 44.876> \n",
      "Epoch 77 / 400  [t=149.67s]  <loss = 0.28896, ref_loss = 0.33614, max_Q = 4.1,  mse_true = 44.797> \n",
      "Epoch 78 / 400  [t=151.40s]  <loss = 0.28945, ref_loss = 0.32422, max_Q = 4.1,  mse_true = 44.901> \n",
      "Epoch 79 / 400  [t=153.05s]  <loss = 0.28632, ref_loss = 0.32453, max_Q = 4.1,  mse_true = 44.906> \n",
      "Epoch 80 / 400  [t=154.71s]  <loss = 0.28993, ref_loss = 0.28492, max_Q = 4.1,  mse_true = 45.156> \n",
      "Epoch 81 / 400  [t=157.74s]  <loss = 0.47186, ref_loss = 0.48258, max_Q = 4.6,  mse_true = 44.632> \n",
      "Epoch 82 / 400  [t=159.40s]  <loss = 0.33122, ref_loss = 0.49346, max_Q = 4.9,  mse_true = 40.162> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 / 400  [t=161.06s]  <loss = 0.30188, ref_loss = 0.44335, max_Q = 5.1,  mse_true = 38.347> \n",
      "Epoch 84 / 400  [t=162.72s]  <loss = 0.27168, ref_loss = 0.41853, max_Q = 5.2,  mse_true = 37.045> \n",
      "Epoch 85 / 400  [t=164.74s]  <loss = 0.26897, ref_loss = 0.33936, max_Q = 5.2,  mse_true = 37.206> \n",
      "Epoch 86 / 400  [t=166.58s]  <loss = 0.26748, ref_loss = 0.28345, max_Q = 5.2,  mse_true = 37.148> \n",
      "Epoch 87 / 400  [t=168.28s]  <loss = 0.28551, ref_loss = 0.29237, max_Q = 5.2,  mse_true = 36.385> \n",
      "Epoch 88 / 400  [t=170.08s]  <loss = 0.25697, ref_loss = 0.29656, max_Q = 5.3,  mse_true = 36.348> \n",
      "Epoch 89 / 400  [t=171.87s]  <loss = 0.25535, ref_loss = 0.26134, max_Q = 5.2,  mse_true = 36.890> \n",
      "Epoch 90 / 400  [t=173.67s]  <loss = 0.26122, ref_loss = 0.25696, max_Q = 5.2,  mse_true = 36.288> \n",
      "Epoch 91 / 400  [t=179.53s]  <loss = 0.25260, ref_loss = 0.26852, max_Q = 5.2,  mse_true = 36.199> \n",
      "Epoch 92 / 400  [t=181.32s]  <loss = 0.25291, ref_loss = 0.23738, max_Q = 5.2,  mse_true = 36.853> \n",
      "Epoch 93 / 400  [t=183.16s]  <loss = 0.25465, ref_loss = 0.25921, max_Q = 5.2,  mse_true = 36.241> \n",
      "Epoch 94 / 400  [t=184.87s]  <loss = 0.26669, ref_loss = 0.23793, max_Q = 5.2,  mse_true = 36.447> \n",
      "Epoch 95 / 400  [t=186.61s]  <loss = 0.24710, ref_loss = 0.23793, max_Q = 5.2,  mse_true = 36.335> \n",
      "Epoch 96 / 400  [t=188.77s]  <loss = 0.24477, ref_loss = 0.23805, max_Q = 5.2,  mse_true = 36.487> \n",
      "Epoch 97 / 400  [t=190.46s]  <loss = 0.24533, ref_loss = 0.22793, max_Q = 5.2,  mse_true = 36.415> \n",
      "Epoch 98 / 400  [t=192.13s]  <loss = 0.24313, ref_loss = 0.23711, max_Q = 5.2,  mse_true = 36.419> \n",
      "Epoch 99 / 400  [t=193.94s]  <loss = 0.23709, ref_loss = 0.23856, max_Q = 5.2,  mse_true = 36.450> \n",
      "Epoch 100 / 400  [t=195.79s]  <loss = 0.24146, ref_loss = 0.23729, max_Q = 5.2,  mse_true = 36.665>\n",
      "Epoch 101 / 400  [t=199.09s]  <loss = 0.35963, ref_loss = 0.34491, max_Q = 5.6,  mse_true = 36.354>\n",
      "Epoch 102 / 400  [t=200.91s]  <loss = 0.24159, ref_loss = 0.33217, max_Q = 6.0,  mse_true = 31.536>\n",
      "Epoch 103 / 400  [t=202.75s]  <loss = 0.22070, ref_loss = 0.29557, max_Q = 6.2,  mse_true = 29.798>\n",
      "Epoch 104 / 400  [t=204.56s]  <loss = 0.22474, ref_loss = 0.21953, max_Q = 6.2,  mse_true = 30.005>\n",
      "Epoch 105 / 400  [t=206.20s]  <loss = 0.21490, ref_loss = 0.23675, max_Q = 6.3,  mse_true = 29.078>\n",
      "Epoch 106 / 400  [t=208.03s]  <loss = 0.21376, ref_loss = 0.21425, max_Q = 6.3,  mse_true = 29.596>\n",
      "Epoch 107 / 400  [t=209.71s]  <loss = 0.21805, ref_loss = 0.18969, max_Q = 6.2,  mse_true = 29.757>\n",
      "Epoch 108 / 400  [t=211.34s]  <loss = 0.20984, ref_loss = 0.20532, max_Q = 6.3,  mse_true = 29.675>\n",
      "Epoch 109 / 400  [t=212.98s]  <loss = 0.21720, ref_loss = 0.18534, max_Q = 6.2,  mse_true = 29.702>\n",
      "Epoch 110 / 400  [t=214.71s]  <loss = 0.21211, ref_loss = 0.20313, max_Q = 6.3,  mse_true = 29.422>\n",
      "Epoch 111 / 400  [t=220.61s]  <loss = 0.22547, ref_loss = 0.18061, max_Q = 6.3,  mse_true = 29.134>\n",
      "Epoch 112 / 400  [t=222.56s]  <loss = 0.20564, ref_loss = 0.21622, max_Q = 6.3,  mse_true = 29.107>\n",
      "Epoch 113 / 400  [t=224.45s]  <loss = 0.22759, ref_loss = 0.17640, max_Q = 6.2,  mse_true = 29.940>\n",
      "Epoch 114 / 400  [t=226.38s]  <loss = 0.21016, ref_loss = 0.18811, max_Q = 6.3,  mse_true = 29.482>\n",
      "Epoch 115 / 400  [t=228.21s]  <loss = 0.21161, ref_loss = 0.17593, max_Q = 6.2,  mse_true = 29.681>\n",
      "Epoch 116 / 400  [t=230.31s]  <loss = 0.22477, ref_loss = 0.17676, max_Q = 6.3,  mse_true = 29.542>\n",
      "Epoch 117 / 400  [t=232.12s]  <loss = 0.20103, ref_loss = 0.19926, max_Q = 6.3,  mse_true = 29.252>\n",
      "Epoch 118 / 400  [t=233.84s]  <loss = 0.19758, ref_loss = 0.18438, max_Q = 6.2,  mse_true = 29.395>\n",
      "Epoch 119 / 400  [t=235.57s]  <loss = 0.19578, ref_loss = 0.17838, max_Q = 6.3,  mse_true = 29.377>\n",
      "Epoch 120 / 400  [t=237.23s]  <loss = 0.19559, ref_loss = 0.17571, max_Q = 6.2,  mse_true = 29.662>\n",
      "Epoch 121 / 400  [t=240.30s]  <loss = 0.27327, ref_loss = 0.24299, max_Q = 6.9,  mse_true = 29.751>\n",
      "Epoch 122 / 400  [t=241.93s]  <loss = 0.18556, ref_loss = 0.20448, max_Q = 7.1,  mse_true = 25.150>\n",
      "Epoch 123 / 400  [t=243.56s]  <loss = 0.17717, ref_loss = 0.16990, max_Q = 7.2,  mse_true = 23.695>\n",
      "Epoch 124 / 400  [t=245.19s]  <loss = 0.19449, ref_loss = 0.14136, max_Q = 7.2,  mse_true = 24.209>\n",
      "Epoch 125 / 400  [t=246.97s]  <loss = 0.19448, ref_loss = 0.14498, max_Q = 7.2,  mse_true = 23.871>\n",
      "Epoch 126 / 400  [t=248.89s]  <loss = 0.16905, ref_loss = 0.17728, max_Q = 7.3,  mse_true = 23.291>\n",
      "Epoch 127 / 400  [t=250.69s]  <loss = 0.17396, ref_loss = 0.13925, max_Q = 7.2,  mse_true = 23.979>\n",
      "Epoch 128 / 400  [t=252.63s]  <loss = 0.17281, ref_loss = 0.12153, max_Q = 7.2,  mse_true = 23.910>\n",
      "Epoch 129 / 400  [t=254.36s]  <loss = 0.17484, ref_loss = 0.14244, max_Q = 7.2,  mse_true = 23.164>\n",
      "Epoch 130 / 400  [t=256.16s]  <loss = 0.19208, ref_loss = 0.11408, max_Q = 7.2,  mse_true = 23.904>\n",
      "Epoch 131 / 400  [t=262.21s]  <loss = 0.18952, ref_loss = 0.12807, max_Q = 7.2,  mse_true = 23.638>\n",
      "Epoch 132 / 400  [t=263.84s]  <loss = 0.17343, ref_loss = 0.14499, max_Q = 7.2,  mse_true = 23.710>\n",
      "Epoch 133 / 400  [t=265.51s]  <loss = 0.16709, ref_loss = 0.14614, max_Q = 7.2,  mse_true = 23.827>\n",
      "Epoch 134 / 400  [t=267.17s]  <loss = 0.16715, ref_loss = 0.12820, max_Q = 7.2,  mse_true = 23.714>\n",
      "Epoch 135 / 400  [t=269.05s]  <loss = 0.16230, ref_loss = 0.13183, max_Q = 7.3,  mse_true = 23.509>\n",
      "Epoch 136 / 400  [t=270.98s]  <loss = 0.18091, ref_loss = 0.11619, max_Q = 7.2,  mse_true = 23.910>\n",
      "Epoch 137 / 400  [t=272.67s]  <loss = 0.16201, ref_loss = 0.12094, max_Q = 7.3,  mse_true = 23.649>\n",
      "Epoch 138 / 400  [t=274.35s]  <loss = 0.16565, ref_loss = 0.12224, max_Q = 7.2,  mse_true = 23.825>\n",
      "Epoch 139 / 400  [t=276.00s]  <loss = 0.15978, ref_loss = 0.12584, max_Q = 7.2,  mse_true = 23.481>\n",
      "Epoch 140 / 400  [t=277.65s]  <loss = 0.15679, ref_loss = 0.13557, max_Q = 7.3,  mse_true = 23.365>\n",
      "Epoch 141 / 400  [t=280.77s]  <loss = 0.24571, ref_loss = 0.16158, max_Q = 7.8,  mse_true = 24.221>\n",
      "Epoch 142 / 400  [t=282.43s]  <loss = 0.17943, ref_loss = 0.14100, max_Q = 8.0,  mse_true = 20.075>\n",
      "Epoch 143 / 400  [t=284.11s]  <loss = 0.16051, ref_loss = 0.11935, max_Q = 8.1,  mse_true = 19.537>\n",
      "Epoch 144 / 400  [t=285.76s]  <loss = 0.15142, ref_loss = 0.13141, max_Q = 8.2,  mse_true = 18.783>\n",
      "Epoch 145 / 400  [t=287.42s]  <loss = 0.15171, ref_loss = 0.09533, max_Q = 8.2,  mse_true = 19.218>\n",
      "Epoch 146 / 400  [t=289.27s]  <loss = 0.15837, ref_loss = 0.09492, max_Q = 8.2,  mse_true = 19.190>\n",
      "Epoch 147 / 400  [t=291.04s]  <loss = 0.15202, ref_loss = 0.11004, max_Q = 8.2,  mse_true = 18.966>\n",
      "Epoch 148 / 400  [t=292.77s]  <loss = 0.14954, ref_loss = 0.11513, max_Q = 8.2,  mse_true = 19.423>\n",
      "Epoch 149 / 400  [t=294.54s]  <loss = 0.15076, ref_loss = 0.08716, max_Q = 8.2,  mse_true = 19.430>\n",
      "Epoch 150 / 400  [t=296.27s]  <loss = 0.14812, ref_loss = 0.10562, max_Q = 8.3,  mse_true = 18.470>\n",
      "Epoch 151 / 400  [t=299.54s]  <loss = 0.15086, ref_loss = 0.09839, max_Q = 8.2,  mse_true = 19.116>\n",
      "Epoch 152 / 400  [t=301.31s]  <loss = 0.15181, ref_loss = 0.10846, max_Q = 8.1,  mse_true = 18.910>\n",
      "Epoch 153 / 400  [t=305.83s]  <loss = 0.14050, ref_loss = 0.09750, max_Q = 8.2,  mse_true = 19.227>\n",
      "Epoch 154 / 400  [t=307.59s]  <loss = 0.13981, ref_loss = 0.10266, max_Q = 8.2,  mse_true = 18.847>\n",
      "Epoch 155 / 400  [t=309.42s]  <loss = 0.16426, ref_loss = 0.07433, max_Q = 8.2,  mse_true = 19.256>\n",
      "Epoch 156 / 400  [t=311.32s]  <loss = 0.14017, ref_loss = 0.11540, max_Q = 8.2,  mse_true = 18.833>\n",
      "Epoch 157 / 400  [t=313.06s]  <loss = 0.15003, ref_loss = 0.08802, max_Q = 8.2,  mse_true = 19.304>\n",
      "Epoch 158 / 400  [t=314.79s]  <loss = 0.13840, ref_loss = 0.10788, max_Q = 8.2,  mse_true = 18.751>\n",
      "Epoch 159 / 400  [t=316.51s]  <loss = 0.15981, ref_loss = 0.07581, max_Q = 8.2,  mse_true = 19.285>\n",
      "Epoch 160 / 400  [t=318.26s]  <loss = 0.15878, ref_loss = 0.10334, max_Q = 8.1,  mse_true = 18.844>\n",
      "Epoch 161 / 400  [t=321.51s]  <loss = 0.25343, ref_loss = 0.17494, max_Q = 9.0,  mse_true = 18.436>\n",
      "Epoch 162 / 400  [t=323.37s]  <loss = 0.17630, ref_loss = 0.16488, max_Q = 9.2,  mse_true = 14.198>\n",
      "Epoch 163 / 400  [t=325.12s]  <loss = 0.16736, ref_loss = 0.15436, max_Q = 9.4,  mse_true = 13.619>\n",
      "Epoch 164 / 400  [t=326.88s]  <loss = 0.16408, ref_loss = 0.11507, max_Q = 9.2,  mse_true = 13.926>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165 / 400  [t=328.65s]  <loss = 0.16307, ref_loss = 0.11132, max_Q = 9.3,  mse_true = 14.154>\n",
      "Epoch 166 / 400  [t=330.62s]  <loss = 0.16654, ref_loss = 0.12072, max_Q = 9.3,  mse_true = 13.424>\n",
      "Epoch 167 / 400  [t=332.40s]  <loss = 0.15292, ref_loss = 0.12158, max_Q = 9.4,  mse_true = 13.915>\n",
      "Epoch 168 / 400  [t=334.18s]  <loss = 0.15506, ref_loss = 0.09682, max_Q = 9.3,  mse_true = 14.187>\n",
      "Epoch 169 / 400  [t=335.97s]  <loss = 0.15411, ref_loss = 0.10312, max_Q = 9.3,  mse_true = 13.992>\n",
      "Epoch 170 / 400  [t=337.73s]  <loss = 0.15357, ref_loss = 0.10294, max_Q = 9.3,  mse_true = 14.571>\n",
      "Epoch 171 / 400  [t=341.00s]  <loss = 0.16166, ref_loss = 0.10126, max_Q = 9.3,  mse_true = 14.311>\n",
      "Epoch 172 / 400  [t=342.73s]  <loss = 0.15326, ref_loss = 0.10345, max_Q = 9.3,  mse_true = 14.571>\n",
      "Epoch 173 / 400  [t=344.48s]  <loss = 0.14918, ref_loss = 0.11025, max_Q = 9.3,  mse_true = 13.958>\n",
      "Epoch 174 / 400  [t=346.24s]  <loss = 0.16670, ref_loss = 0.08593, max_Q = 9.3,  mse_true = 14.356>\n",
      "Epoch 175 / 400  [t=350.98s]  <loss = 0.14871, ref_loss = 0.11342, max_Q = 9.3,  mse_true = 13.864>\n",
      "Epoch 176 / 400  [t=352.99s]  <loss = 0.14502, ref_loss = 0.10457, max_Q = 9.3,  mse_true = 14.196>\n",
      "Epoch 177 / 400  [t=354.59s]  <loss = 0.17096, ref_loss = 0.08808, max_Q = 9.3,  mse_true = 14.388>\n",
      "Epoch 178 / 400  [t=356.25s]  <loss = 0.14314, ref_loss = 0.12304, max_Q = 9.3,  mse_true = 13.780>\n",
      "Epoch 179 / 400  [t=357.89s]  <loss = 0.15151, ref_loss = 0.11744, max_Q = 9.2,  mse_true = 14.550>\n",
      "Epoch 180 / 400  [t=359.53s]  <loss = 0.14460, ref_loss = 0.07760, max_Q = 9.3,  mse_true = 14.322>\n",
      "Epoch 181 / 400  [t=362.69s]  <loss = 0.19943, ref_loss = 0.16302, max_Q = 10.1,  mse_true = 14.028>\n",
      "Epoch 182 / 400  [t=364.31s]  <loss = 0.15237, ref_loss = 0.09647, max_Q = 10.2,  mse_true = 11.115>\n",
      "Epoch 183 / 400  [t=365.94s]  <loss = 0.15477, ref_loss = 0.10378, max_Q = 10.3,  mse_true = 10.139>\n",
      "Epoch 184 / 400  [t=367.68s]  <loss = 0.14388, ref_loss = 0.09679, max_Q = 10.2,  mse_true = 10.781>\n",
      "Epoch 185 / 400  [t=369.60s]  <loss = 0.13937, ref_loss = 0.08851, max_Q = 10.2,  mse_true = 10.833>\n",
      "Epoch 186 / 400  [t=371.88s]  <loss = 0.13821, ref_loss = 0.07438, max_Q = 10.2,  mse_true = 10.574>\n",
      "Epoch 187 / 400  [t=373.59s]  <loss = 0.14140, ref_loss = 0.07793, max_Q = 10.3,  mse_true = 10.839>\n",
      "Epoch 188 / 400  [t=375.41s]  <loss = 0.13957, ref_loss = 0.08561, max_Q = 10.2,  mse_true = 10.948>\n",
      "Epoch 189 / 400  [t=377.19s]  <loss = 0.16661, ref_loss = 0.05242, max_Q = 10.2,  mse_true = 10.698>\n",
      "Epoch 190 / 400  [t=378.85s]  <loss = 0.13913, ref_loss = 0.09941, max_Q = 10.3,  mse_true = 10.114>\n",
      "Epoch 191 / 400  [t=382.05s]  <loss = 0.13445, ref_loss = 0.09403, max_Q = 10.3,  mse_true = 10.587>\n",
      "Epoch 192 / 400  [t=383.85s]  <loss = 0.14443, ref_loss = 0.07681, max_Q = 10.2,  mse_true = 11.016>\n",
      "Epoch 193 / 400  [t=385.48s]  <loss = 0.14012, ref_loss = 0.07982, max_Q = 10.2,  mse_true = 11.039>\n",
      "Epoch 194 / 400  [t=387.08s]  <loss = 0.13548, ref_loss = 0.08370, max_Q = 10.2,  mse_true = 10.580>\n",
      "Epoch 195 / 400  [t=388.69s]  <loss = 0.13129, ref_loss = 0.08126, max_Q = 10.2,  mse_true = 10.639>\n",
      "Epoch 196 / 400  [t=390.50s]  <loss = 0.13118, ref_loss = 0.08029, max_Q = 10.3,  mse_true = 10.584>\n",
      "Epoch 197 / 400  [t=392.12s]  <loss = 0.13159, ref_loss = 0.07713, max_Q = 10.2,  mse_true = 10.609>\n",
      "Epoch 198 / 400  [t=396.54s]  <loss = 0.12700, ref_loss = 0.08184, max_Q = 10.2,  mse_true = 10.705>\n",
      "Epoch 199 / 400  [t=398.17s]  <loss = 0.12481, ref_loss = 0.08146, max_Q = 10.2,  mse_true = 10.887>\n",
      "Epoch 200 / 400  [t=399.80s]  <loss = 0.12518, ref_loss = 0.07737, max_Q = 10.2,  mse_true = 10.544>\n",
      "Epoch 201 / 400  [t=402.99s]  <loss = 0.18741, ref_loss = 0.10163, max_Q = 10.9,  mse_true = 10.421>\n",
      "Epoch 202 / 400  [t=404.64s]  <loss = 0.12832, ref_loss = 0.07959, max_Q = 11.1,  mse_true = 8.057>\n",
      "Epoch 203 / 400  [t=406.26s]  <loss = 0.13037, ref_loss = 0.07255, max_Q = 11.2,  mse_true = 7.770>\n",
      "Epoch 204 / 400  [t=407.89s]  <loss = 0.12233, ref_loss = 0.09454, max_Q = 11.2,  mse_true = 7.374>\n",
      "Epoch 205 / 400  [t=409.61s]  <loss = 0.12378, ref_loss = 0.06880, max_Q = 11.2,  mse_true = 7.602>\n",
      "Epoch 206 / 400  [t=411.56s]  <loss = 0.12139, ref_loss = 0.08475, max_Q = 11.2,  mse_true = 7.736>\n",
      "Epoch 207 / 400  [t=413.16s]  <loss = 0.12231, ref_loss = 0.06018, max_Q = 11.2,  mse_true = 7.551>\n",
      "Epoch 208 / 400  [t=414.76s]  <loss = 0.11661, ref_loss = 0.06309, max_Q = 11.2,  mse_true = 7.637>\n",
      "Epoch 209 / 400  [t=416.37s]  <loss = 0.11619, ref_loss = 0.05953, max_Q = 11.2,  mse_true = 7.877>\n",
      "Epoch 210 / 400  [t=418.02s]  <loss = 0.11873, ref_loss = 0.05587, max_Q = 11.1,  mse_true = 7.896>\n",
      "Epoch 211 / 400  [t=421.33s]  <loss = 0.11928, ref_loss = 0.07330, max_Q = 11.2,  mse_true = 7.637>\n",
      "Epoch 212 / 400  [t=423.16s]  <loss = 0.11567, ref_loss = 0.06325, max_Q = 11.2,  mse_true = 7.468>\n",
      "Epoch 213 / 400  [t=424.91s]  <loss = 0.11795, ref_loss = 0.06274, max_Q = 11.1,  mse_true = 8.017>\n",
      "Epoch 214 / 400  [t=426.55s]  <loss = 0.12632, ref_loss = 0.06008, max_Q = 11.2,  mse_true = 7.735>\n",
      "Epoch 215 / 400  [t=428.17s]  <loss = 0.12656, ref_loss = 0.07767, max_Q = 11.2,  mse_true = 7.676>\n",
      "Epoch 216 / 400  [t=429.96s]  <loss = 0.13026, ref_loss = 0.06319, max_Q = 11.2,  mse_true = 7.663>\n",
      "Epoch 217 / 400  [t=431.57s]  <loss = 0.10896, ref_loss = 0.08816, max_Q = 11.3,  mse_true = 7.571>\n",
      "Epoch 218 / 400  [t=433.30s]  <loss = 0.10849, ref_loss = 0.07932, max_Q = 11.1,  mse_true = 7.845>\n",
      "Epoch 219 / 400  [t=435.20s]  <loss = 0.11079, ref_loss = 0.04375, max_Q = 11.2,  mse_true = 7.439>\n",
      "Epoch 220 / 400  [t=436.97s]  <loss = 0.10994, ref_loss = 0.06770, max_Q = 11.3,  mse_true = 7.560>\n",
      "Epoch 221 / 400  [t=443.17s]  <loss = 0.14625, ref_loss = 0.08894, max_Q = 11.7,  mse_true = 7.905>\n",
      "Epoch 222 / 400  [t=444.92s]  <loss = 0.10712, ref_loss = 0.06180, max_Q = 11.9,  mse_true = 5.851>\n",
      "Epoch 223 / 400  [t=446.58s]  <loss = 0.11488, ref_loss = 0.04598, max_Q = 11.9,  mse_true = 5.936>\n",
      "Epoch 224 / 400  [t=448.35s]  <loss = 0.10940, ref_loss = 0.06107, max_Q = 11.9,  mse_true = 5.698>\n",
      "Epoch 225 / 400  [t=450.21s]  <loss = 0.10730, ref_loss = 0.05357, max_Q = 12.0,  mse_true = 5.595>\n",
      "Epoch 226 / 400  [t=452.09s]  <loss = 0.10441, ref_loss = 0.06358, max_Q = 11.9,  mse_true = 5.384>\n",
      "Epoch 227 / 400  [t=453.76s]  <loss = 0.10645, ref_loss = 0.04912, max_Q = 12.0,  mse_true = 5.591>\n",
      "Epoch 228 / 400  [t=455.39s]  <loss = 0.10478, ref_loss = 0.05769, max_Q = 12.0,  mse_true = 5.669>\n",
      "Epoch 229 / 400  [t=457.03s]  <loss = 0.10613, ref_loss = 0.04344, max_Q = 11.9,  mse_true = 5.895>\n",
      "Epoch 230 / 400  [t=458.67s]  <loss = 0.11274, ref_loss = 0.04879, max_Q = 11.9,  mse_true = 5.906>\n",
      "Epoch 231 / 400  [t=461.88s]  <loss = 0.09964, ref_loss = 0.05467, max_Q = 11.9,  mse_true = 5.820>\n",
      "Epoch 232 / 400  [t=463.52s]  <loss = 0.10043, ref_loss = 0.05201, max_Q = 11.9,  mse_true = 5.690>\n",
      "Epoch 233 / 400  [t=465.16s]  <loss = 0.10889, ref_loss = 0.05292, max_Q = 11.9,  mse_true = 5.977>\n",
      "Epoch 234 / 400  [t=466.80s]  <loss = 0.09429, ref_loss = 0.07090, max_Q = 12.0,  mse_true = 5.649>\n",
      "Epoch 235 / 400  [t=468.45s]  <loss = 0.09442, ref_loss = 0.04889, max_Q = 11.9,  mse_true = 6.209>\n",
      "Epoch 236 / 400  [t=470.26s]  <loss = 0.09202, ref_loss = 0.05309, max_Q = 12.1,  mse_true = 5.537>\n",
      "Epoch 237 / 400  [t=471.88s]  <loss = 0.09021, ref_loss = 0.04784, max_Q = 11.9,  mse_true = 6.058>\n",
      "Epoch 238 / 400  [t=473.49s]  <loss = 0.09417, ref_loss = 0.04531, max_Q = 11.9,  mse_true = 5.578>\n",
      "Epoch 239 / 400  [t=475.10s]  <loss = 0.10619, ref_loss = 0.03876, max_Q = 11.9,  mse_true = 5.932>\n",
      "Epoch 240 / 400  [t=476.71s]  <loss = 0.10295, ref_loss = 0.05975, max_Q = 12.0,  mse_true = 5.385>\n",
      "Epoch 241 / 400  [t=482.68s]  <loss = 0.12665, ref_loss = 0.07335, max_Q = 12.6,  mse_true = 5.901>\n",
      "Epoch 242 / 400  [t=484.32s]  <loss = 0.09889, ref_loss = 0.07462, max_Q = 12.6,  mse_true = 4.227>\n",
      "Epoch 243 / 400  [t=485.96s]  <loss = 0.09869, ref_loss = 0.04710, max_Q = 12.6,  mse_true = 4.241>\n",
      "Epoch 244 / 400  [t=487.60s]  <loss = 0.09287, ref_loss = 0.04863, max_Q = 12.7,  mse_true = 4.369>\n",
      "Epoch 245 / 400  [t=489.25s]  <loss = 0.10862, ref_loss = 0.03058, max_Q = 12.7,  mse_true = 4.338>\n",
      "Epoch 246 / 400  [t=491.08s]  <loss = 0.09880, ref_loss = 0.06275, max_Q = 12.7,  mse_true = 4.066>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247 / 400  [t=492.73s]  <loss = 0.09316, ref_loss = 0.05532, max_Q = 12.6,  mse_true = 4.137>\n",
      "Epoch 248 / 400  [t=494.38s]  <loss = 0.08830, ref_loss = 0.06553, max_Q = 12.6,  mse_true = 4.246>\n",
      "Epoch 249 / 400  [t=496.03s]  <loss = 0.08834, ref_loss = 0.04037, max_Q = 12.7,  mse_true = 4.348>\n",
      "Epoch 250 / 400  [t=497.67s]  <loss = 0.09259, ref_loss = 0.05055, max_Q = 12.6,  mse_true = 4.738>\n",
      "Epoch 251 / 400  [t=500.90s]  <loss = 0.09055, ref_loss = 0.04982, max_Q = 12.7,  mse_true = 4.520>\n",
      "Epoch 252 / 400  [t=502.56s]  <loss = 0.08937, ref_loss = 0.04536, max_Q = 12.7,  mse_true = 4.590>\n",
      "Epoch 253 / 400  [t=504.21s]  <loss = 0.08460, ref_loss = 0.03654, max_Q = 12.7,  mse_true = 4.247>\n",
      "Epoch 254 / 400  [t=505.85s]  <loss = 0.08666, ref_loss = 0.04325, max_Q = 12.6,  mse_true = 4.296>\n",
      "Epoch 255 / 400  [t=507.49s]  <loss = 0.08281, ref_loss = 0.04674, max_Q = 12.7,  mse_true = 4.305>\n",
      "Epoch 256 / 400  [t=509.32s]  <loss = 0.09176, ref_loss = 0.03233, max_Q = 12.6,  mse_true = 4.578>\n",
      "Epoch 257 / 400  [t=510.95s]  <loss = 0.08243, ref_loss = 0.05265, max_Q = 12.7,  mse_true = 4.046>\n",
      "Epoch 258 / 400  [t=512.58s]  <loss = 0.08443, ref_loss = 0.04323, max_Q = 12.7,  mse_true = 4.383>\n",
      "Epoch 259 / 400  [t=514.20s]  <loss = 0.08187, ref_loss = 0.04733, max_Q = 12.6,  mse_true = 4.021>\n",
      "Epoch 260 / 400  [t=515.82s]  <loss = 0.08057, ref_loss = 0.03354, max_Q = 12.7,  mse_true = 4.243>\n",
      "Epoch 261 / 400  [t=519.03s]  <loss = 0.12421, ref_loss = 0.06159, max_Q = 13.5,  mse_true = 4.030>\n",
      "Epoch 262 / 400  [t=520.69s]  <loss = 0.09282, ref_loss = 0.05971, max_Q = 13.4,  mse_true = 2.984>\n",
      "Epoch 263 / 400  [t=522.32s]  <loss = 0.09182, ref_loss = 0.04675, max_Q = 13.5,  mse_true = 2.919>\n",
      "Epoch 264 / 400  [t=523.97s]  <loss = 0.08435, ref_loss = 0.04338, max_Q = 13.5,  mse_true = 3.042>\n",
      "Epoch 265 / 400  [t=528.68s]  <loss = 0.08146, ref_loss = 0.04306, max_Q = 13.4,  mse_true = 2.998>\n",
      "Epoch 266 / 400  [t=530.49s]  <loss = 0.09431, ref_loss = 0.04122, max_Q = 13.4,  mse_true = 2.921>\n",
      "Epoch 267 / 400  [t=532.13s]  <loss = 0.07825, ref_loss = 0.05562, max_Q = 13.5,  mse_true = 2.891>\n",
      "Epoch 268 / 400  [t=533.79s]  <loss = 0.08716, ref_loss = 0.02748, max_Q = 13.5,  mse_true = 2.784>\n",
      "Epoch 269 / 400  [t=535.45s]  <loss = 0.07698, ref_loss = 0.05904, max_Q = 13.6,  mse_true = 2.755>\n",
      "Epoch 270 / 400  [t=537.12s]  <loss = 0.08281, ref_loss = 0.03123, max_Q = 13.5,  mse_true = 2.922>\n",
      "Epoch 271 / 400  [t=540.38s]  <loss = 0.07320, ref_loss = 0.05064, max_Q = 13.5,  mse_true = 2.732>\n",
      "Epoch 272 / 400  [t=542.04s]  <loss = 0.08035, ref_loss = 0.03795, max_Q = 13.5,  mse_true = 2.909>\n",
      "Epoch 273 / 400  [t=543.68s]  <loss = 0.06847, ref_loss = 0.05159, max_Q = 13.5,  mse_true = 2.831>\n",
      "Epoch 274 / 400  [t=545.33s]  <loss = 0.07511, ref_loss = 0.02694, max_Q = 13.5,  mse_true = 2.855>\n",
      "Epoch 275 / 400  [t=546.97s]  <loss = 0.07805, ref_loss = 0.03725, max_Q = 13.6,  mse_true = 2.928>\n",
      "Epoch 276 / 400  [t=548.79s]  <loss = 0.06934, ref_loss = 0.05416, max_Q = 13.5,  mse_true = 2.844>\n",
      "Epoch 277 / 400  [t=550.42s]  <loss = 0.06938, ref_loss = 0.02827, max_Q = 13.5,  mse_true = 2.961>\n",
      "Epoch 278 / 400  [t=552.04s]  <loss = 0.06578, ref_loss = 0.04561, max_Q = 13.5,  mse_true = 2.873>\n",
      "Epoch 279 / 400  [t=553.66s]  <loss = 0.06979, ref_loss = 0.03221, max_Q = 13.7,  mse_true = 2.913>\n",
      "Epoch 280 / 400  [t=555.29s]  <loss = 0.07890, ref_loss = 0.02315, max_Q = 13.6,  mse_true = 2.778>\n",
      "Epoch 281 / 400  [t=558.51s]  <loss = 0.11203, ref_loss = 0.07048, max_Q = 14.3,  mse_true = 2.759>\n",
      "Epoch 282 / 400  [t=560.14s]  <loss = 0.07609, ref_loss = 0.04829, max_Q = 14.1,  mse_true = 2.103>\n",
      "Epoch 283 / 400  [t=561.76s]  <loss = 0.07743, ref_loss = 0.03662, max_Q = 14.2,  mse_true = 2.102>\n",
      "Epoch 284 / 400  [t=563.39s]  <loss = 0.07878, ref_loss = 0.04023, max_Q = 14.2,  mse_true = 2.240>\n",
      "Epoch 285 / 400  [t=565.03s]  <loss = 0.08338, ref_loss = 0.03261, max_Q = 14.1,  mse_true = 1.900>\n",
      "Epoch 286 / 400  [t=566.83s]  <loss = 0.07107, ref_loss = 0.04812, max_Q = 14.2,  mse_true = 1.972>\n",
      "Epoch 287 / 400  [t=568.45s]  <loss = 0.07108, ref_loss = 0.03526, max_Q = 14.2,  mse_true = 2.127>\n",
      "Epoch 288 / 400  [t=570.08s]  <loss = 0.06876, ref_loss = 0.04038, max_Q = 14.1,  mse_true = 2.007>\n",
      "Epoch 289 / 400  [t=571.70s]  <loss = 0.06604, ref_loss = 0.03112, max_Q = 14.3,  mse_true = 2.036>\n",
      "Epoch 290 / 400  [t=573.31s]  <loss = 0.07156, ref_loss = 0.03483, max_Q = 14.1,  mse_true = 1.955>\n",
      "Epoch 291 / 400  [t=579.57s]  <loss = 0.06959, ref_loss = 0.03728, max_Q = 14.1,  mse_true = 2.144>\n",
      "Epoch 292 / 400  [t=581.21s]  <loss = 0.06686, ref_loss = 0.03153, max_Q = 14.2,  mse_true = 1.940>\n",
      "Epoch 293 / 400  [t=582.85s]  <loss = 0.06702, ref_loss = 0.03617, max_Q = 14.3,  mse_true = 1.833>\n",
      "Epoch 294 / 400  [t=584.49s]  <loss = 0.06382, ref_loss = 0.03311, max_Q = 14.2,  mse_true = 2.038>\n",
      "Epoch 295 / 400  [t=586.14s]  <loss = 0.06424, ref_loss = 0.03379, max_Q = 14.1,  mse_true = 1.901>\n",
      "Epoch 296 / 400  [t=587.96s]  <loss = 0.06973, ref_loss = 0.02191, max_Q = 14.2,  mse_true = 1.971>\n",
      "Epoch 297 / 400  [t=589.60s]  <loss = 0.06352, ref_loss = 0.04875, max_Q = 14.1,  mse_true = 1.822>\n",
      "Epoch 298 / 400  [t=591.24s]  <loss = 0.06516, ref_loss = 0.02310, max_Q = 14.3,  mse_true = 1.781>\n",
      "Epoch 299 / 400  [t=592.87s]  <loss = 0.05898, ref_loss = 0.03515, max_Q = 14.2,  mse_true = 1.868>\n",
      "Epoch 300 / 400  [t=594.53s]  <loss = 0.06368, ref_loss = 0.02187, max_Q = 14.2,  mse_true = 1.996>\n",
      "Epoch 301 / 400  [t=597.83s]  <loss = 0.10567, ref_loss = 0.05943, max_Q = 14.4,  mse_true = 1.718>\n",
      "Epoch 302 / 400  [t=599.48s]  <loss = 0.07439, ref_loss = 0.04440, max_Q = 14.9,  mse_true = 1.244>\n",
      "Epoch 303 / 400  [t=601.11s]  <loss = 0.06852, ref_loss = 0.03482, max_Q = 14.9,  mse_true = 1.220>\n",
      "Epoch 304 / 400  [t=602.75s]  <loss = 0.06419, ref_loss = 0.03166, max_Q = 14.9,  mse_true = 1.213>\n",
      "Epoch 305 / 400  [t=604.42s]  <loss = 0.06960, ref_loss = 0.02793, max_Q = 15.0,  mse_true = 1.383>\n",
      "Epoch 306 / 400  [t=606.41s]  <loss = 0.06439, ref_loss = 0.02162, max_Q = 15.1,  mse_true = 1.161>\n",
      "Epoch 307 / 400  [t=608.29s]  <loss = 0.05852, ref_loss = 0.04110, max_Q = 15.0,  mse_true = 1.124>\n",
      "Epoch 308 / 400  [t=610.13s]  <loss = 0.05891, ref_loss = 0.03175, max_Q = 15.0,  mse_true = 1.171>\n",
      "Epoch 309 / 400  [t=611.74s]  <loss = 0.06182, ref_loss = 0.02156, max_Q = 15.1,  mse_true = 1.122>\n",
      "Epoch 310 / 400  [t=613.41s]  <loss = 0.05711, ref_loss = 0.03234, max_Q = 15.0,  mse_true = 1.122>\n",
      "Epoch 311 / 400  [t=619.74s]  <loss = 0.05544, ref_loss = 0.01938, max_Q = 15.0,  mse_true = 1.254>\n",
      "Epoch 312 / 400  [t=621.55s]  <loss = 0.05648, ref_loss = 0.02670, max_Q = 14.9,  mse_true = 1.264>\n",
      "Epoch 313 / 400  [t=623.18s]  <loss = 0.05563, ref_loss = 0.02823, max_Q = 14.9,  mse_true = 1.284>\n",
      "Epoch 314 / 400  [t=624.82s]  <loss = 0.05522, ref_loss = 0.02504, max_Q = 14.9,  mse_true = 1.254>\n",
      "Epoch 315 / 400  [t=626.45s]  <loss = 0.04799, ref_loss = 0.02365, max_Q = 15.0,  mse_true = 1.220>\n",
      "Epoch 316 / 400  [t=628.35s]  <loss = 0.05138, ref_loss = 0.01745, max_Q = 15.0,  mse_true = 1.148>\n",
      "Epoch 317 / 400  [t=630.01s]  <loss = 0.04922, ref_loss = 0.02864, max_Q = 14.9,  mse_true = 1.166>\n",
      "Epoch 318 / 400  [t=631.64s]  <loss = 0.05054, ref_loss = 0.02435, max_Q = 15.0,  mse_true = 1.113>\n",
      "Epoch 319 / 400  [t=633.31s]  <loss = 0.04999, ref_loss = 0.02191, max_Q = 15.0,  mse_true = 1.134>\n",
      "Epoch 320 / 400  [t=634.93s]  <loss = 0.05042, ref_loss = 0.01516, max_Q = 14.9,  mse_true = 1.248>\n",
      "Epoch 321 / 400  [t=638.25s]  <loss = 0.06070, ref_loss = 0.02614, max_Q = 15.5,  mse_true = 1.003>\n",
      "Epoch 322 / 400  [t=639.89s]  <loss = 0.05142, ref_loss = 0.01639, max_Q = 15.8,  mse_true = 0.731>\n",
      "Epoch 323 / 400  [t=641.52s]  <loss = 0.05160, ref_loss = 0.01796, max_Q = 15.8,  mse_true = 0.708>\n",
      "Epoch 324 / 400  [t=643.17s]  <loss = 0.04676, ref_loss = 0.02113, max_Q = 15.8,  mse_true = 0.675>\n",
      "Epoch 325 / 400  [t=644.86s]  <loss = 0.05250, ref_loss = 0.01099, max_Q = 15.7,  mse_true = 0.687>\n",
      "Epoch 326 / 400  [t=647.01s]  <loss = 0.04423, ref_loss = 0.02465, max_Q = 15.7,  mse_true = 0.671>\n",
      "Epoch 327 / 400  [t=648.87s]  <loss = 0.04142, ref_loss = 0.02036, max_Q = 15.8,  mse_true = 0.701>\n",
      "Epoch 328 / 400  [t=650.72s]  <loss = 0.04730, ref_loss = 0.01014, max_Q = 15.7,  mse_true = 0.705>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329 / 400  [t=652.35s]  <loss = 0.05147, ref_loss = 0.01944, max_Q = 15.7,  mse_true = 0.694>\n",
      "Epoch 330 / 400  [t=653.96s]  <loss = 0.04172, ref_loss = 0.01584, max_Q = 15.9,  mse_true = 0.639>\n",
      "Epoch 331 / 400  [t=657.66s]  <loss = 0.04019, ref_loss = 0.01334, max_Q = 15.7,  mse_true = 0.691>\n",
      "Epoch 332 / 400  [t=659.32s]  <loss = 0.05480, ref_loss = 0.01942, max_Q = 16.1,  mse_true = 0.617>\n",
      "Epoch 333 / 400  [t=660.99s]  <loss = 0.04231, ref_loss = 0.01033, max_Q = 15.7,  mse_true = 0.681>\n",
      "Epoch 334 / 400  [t=662.63s]  <loss = 0.03993, ref_loss = 0.01790, max_Q = 15.9,  mse_true = 0.648>\n",
      "Epoch 335 / 400  [t=664.26s]  <loss = 0.03658, ref_loss = 0.01248, max_Q = 15.8,  mse_true = 0.663>\n",
      "Epoch 336 / 400  [t=666.09s]  <loss = 0.03749, ref_loss = 0.01258, max_Q = 15.8,  mse_true = 0.655>\n",
      "Epoch 337 / 400  [t=667.70s]  <loss = 0.03609, ref_loss = 0.01381, max_Q = 15.8,  mse_true = 0.656>\n",
      "Epoch 338 / 400  [t=672.54s]  <loss = 0.03716, ref_loss = 0.01139, max_Q = 15.7,  mse_true = 0.650>\n",
      "Epoch 339 / 400  [t=674.17s]  <loss = 0.04292, ref_loss = 0.01185, max_Q = 15.7,  mse_true = 0.681>\n",
      "Epoch 340 / 400  [t=675.91s]  <loss = 0.03357, ref_loss = 0.01644, max_Q = 15.8,  mse_true = 0.634>\n",
      "Epoch 341 / 400  [t=679.31s]  <loss = 0.04908, ref_loss = 0.01262, max_Q = 16.2,  mse_true = 0.659>\n",
      "Epoch 342 / 400  [t=680.96s]  <loss = 0.03986, ref_loss = 0.00468, max_Q = 16.2,  mse_true = 0.550>\n",
      "Epoch 343 / 400  [t=682.62s]  <loss = 0.04099, ref_loss = 0.01137, max_Q = 16.3,  mse_true = 0.497>\n",
      "Epoch 344 / 400  [t=684.24s]  <loss = 0.03901, ref_loss = 0.00749, max_Q = 16.2,  mse_true = 0.486>\n",
      "Epoch 345 / 400  [t=685.88s]  <loss = 0.03619, ref_loss = 0.01348, max_Q = 16.3,  mse_true = 0.471>\n",
      "Epoch 346 / 400  [t=687.70s]  <loss = 0.03420, ref_loss = 0.00752, max_Q = 16.3,  mse_true = 0.479>\n",
      "Epoch 347 / 400  [t=689.37s]  <loss = 0.03692, ref_loss = 0.00580, max_Q = 16.3,  mse_true = 0.473>\n",
      "Epoch 348 / 400  [t=691.10s]  <loss = 0.03023, ref_loss = 0.01367, max_Q = 16.3,  mse_true = 0.457>\n",
      "Epoch 349 / 400  [t=692.83s]  <loss = 0.03040, ref_loss = 0.00413, max_Q = 16.3,  mse_true = 0.464>\n",
      "Epoch 350 / 400  [t=694.53s]  <loss = 0.02904, ref_loss = 0.00871, max_Q = 16.4,  mse_true = 0.450>\n",
      "Epoch 351 / 400  [t=697.90s]  <loss = 0.02883, ref_loss = 0.01375, max_Q = 16.3,  mse_true = 0.446>\n",
      "Epoch 352 / 400  [t=699.52s]  <loss = 0.02763, ref_loss = 0.00582, max_Q = 16.3,  mse_true = 0.458>\n",
      "Epoch 353 / 400  [t=701.32s]  <loss = 0.02754, ref_loss = 0.01295, max_Q = 16.3,  mse_true = 0.442>\n",
      "Epoch 354 / 400  [t=702.94s]  <loss = 0.03239, ref_loss = 0.00489, max_Q = 16.3,  mse_true = 0.466>\n",
      "Epoch 355 / 400  [t=704.67s]  <loss = 0.02565, ref_loss = 0.00825, max_Q = 16.4,  mse_true = 0.455>\n",
      "Epoch 356 / 400  [t=706.46s]  <loss = 0.02774, ref_loss = 0.00734, max_Q = 16.4,  mse_true = 0.441>\n",
      "Epoch 357 / 400  [t=708.04s]  <loss = 0.02318, ref_loss = 0.00569, max_Q = 16.4,  mse_true = 0.447>\n",
      "Epoch 358 / 400  [t=709.64s]  <loss = 0.02543, ref_loss = 0.00512, max_Q = 16.3,  mse_true = 0.435>\n",
      "Epoch 359 / 400  [t=711.28s]  <loss = 0.02550, ref_loss = 0.00720, max_Q = 16.4,  mse_true = 0.432>\n",
      "Epoch 360 / 400  [t=712.88s]  <loss = 0.02803, ref_loss = 0.00872, max_Q = 16.2,  mse_true = 0.417>\n",
      "Epoch 361 / 400  [t=719.59s]  <loss = 0.07165, ref_loss = 0.00807, max_Q = 16.4,  mse_true = 0.439>\n",
      "Epoch 362 / 400  [t=721.19s]  <loss = 0.08514, ref_loss = 0.01487, max_Q = 16.3,  mse_true = 0.475>\n",
      "Epoch 363 / 400  [t=722.80s]  <loss = 0.04456, ref_loss = 0.01000, max_Q = 16.7,  mse_true = 0.395>\n",
      "Epoch 364 / 400  [t=724.52s]  <loss = 0.04251, ref_loss = 0.00732, max_Q = 16.5,  mse_true = 0.355>\n",
      "Epoch 365 / 400  [t=726.33s]  <loss = 0.03982, ref_loss = 0.00535, max_Q = 16.5,  mse_true = 0.384>\n",
      "Epoch 366 / 400  [t=728.34s]  <loss = 0.02933, ref_loss = 0.01156, max_Q = 16.7,  mse_true = 0.337>\n",
      "Epoch 367 / 400  [t=730.02s]  <loss = 0.04305, ref_loss = 0.00247, max_Q = 16.6,  mse_true = 0.342>\n",
      "Epoch 368 / 400  [t=731.86s]  <loss = 0.03163, ref_loss = 0.01648, max_Q = 16.7,  mse_true = 0.302>\n",
      "Epoch 369 / 400  [t=733.81s]  <loss = 0.03105, ref_loss = 0.01000, max_Q = 16.6,  mse_true = 0.327>\n",
      "Epoch 370 / 400  [t=735.59s]  <loss = 0.02454, ref_loss = 0.00483, max_Q = 16.8,  mse_true = 0.344>\n",
      "Epoch 371 / 400  [t=739.07s]  <loss = 0.02406, ref_loss = 0.00614, max_Q = 16.8,  mse_true = 0.320>\n",
      "Epoch 372 / 400  [t=740.76s]  <loss = 0.02647, ref_loss = 0.00605, max_Q = 16.9,  mse_true = 0.320>\n",
      "Epoch 373 / 400  [t=742.39s]  <loss = 0.02282, ref_loss = 0.00563, max_Q = 16.8,  mse_true = 0.328>\n",
      "Epoch 374 / 400  [t=744.03s]  <loss = 0.02621, ref_loss = 0.00688, max_Q = 16.7,  mse_true = 0.307>\n",
      "Epoch 375 / 400  [t=745.64s]  <loss = 0.02307, ref_loss = 0.00729, max_Q = 16.8,  mse_true = 0.315>\n",
      "Epoch 376 / 400  [t=747.42s]  <loss = 0.02103, ref_loss = 0.00644, max_Q = 16.8,  mse_true = 0.304>\n",
      "Epoch 377 / 400  [t=749.03s]  <loss = 0.02031, ref_loss = 0.00526, max_Q = 16.7,  mse_true = 0.316>\n",
      "Epoch 378 / 400  [t=750.66s]  <loss = 0.02488, ref_loss = 0.00537, max_Q = 16.8,  mse_true = 0.315>\n",
      "Epoch 379 / 400  [t=752.28s]  <loss = 0.02676, ref_loss = 0.00584, max_Q = 16.6,  mse_true = 0.309>\n",
      "Epoch 380 / 400  [t=753.91s]  <loss = 0.02546, ref_loss = 0.00623, max_Q = 16.7,  mse_true = 0.303>\n",
      "Epoch 381 / 400  [t=757.27s]  <loss = 0.05409, ref_loss = 0.00709, max_Q = 16.8,  mse_true = 0.311>\n",
      "Epoch 382 / 400  [t=758.90s]  <loss = 0.03723, ref_loss = 0.01055, max_Q = 16.9,  mse_true = 0.266>\n",
      "Epoch 383 / 400  [t=760.63s]  <loss = 0.03407, ref_loss = 0.00699, max_Q = 16.9,  mse_true = 0.317>\n",
      "Epoch 384 / 400  [t=762.50s]  <loss = 0.02838, ref_loss = 0.01059, max_Q = 16.8,  mse_true = 0.264>\n",
      "Epoch 385 / 400  [t=764.42s]  <loss = 0.02171, ref_loss = 0.00360, max_Q = 17.2,  mse_true = 0.274>\n",
      "Epoch 386 / 400  [t=766.60s]  <loss = 0.02181, ref_loss = 0.00517, max_Q = 17.2,  mse_true = 0.266>\n",
      "Epoch 387 / 400  [t=768.41s]  <loss = 0.02180, ref_loss = 0.00638, max_Q = 17.1,  mse_true = 0.301>\n",
      "Epoch 388 / 400  [t=774.47s]  <loss = 0.02419, ref_loss = 0.00906, max_Q = 17.2,  mse_true = 0.271>\n",
      "Epoch 389 / 400  [t=776.23s]  <loss = 0.02501, ref_loss = 0.00219, max_Q = 17.1,  mse_true = 0.271>\n",
      "Epoch 390 / 400  [t=778.20s]  <loss = 0.02142, ref_loss = 0.01019, max_Q = 17.2,  mse_true = 0.233>\n",
      "Epoch 391 / 400  [t=782.48s]  <loss = 0.01992, ref_loss = 0.00818, max_Q = 17.1,  mse_true = 0.260>\n",
      "Epoch 392 / 400  [t=784.45s]  <loss = 0.02655, ref_loss = 0.00348, max_Q = 17.2,  mse_true = 0.243>\n",
      "Epoch 393 / 400  [t=786.36s]  <loss = 0.04259, ref_loss = 0.00739, max_Q = 17.4,  mse_true = 0.317>\n",
      "Epoch 394 / 400  [t=788.25s]  <loss = 0.01936, ref_loss = 0.01100, max_Q = 17.2,  mse_true = 0.240>\n",
      "Epoch 395 / 400  [t=790.09s]  <loss = 0.01985, ref_loss = 0.00339, max_Q = 17.3,  mse_true = 0.277>\n",
      "Epoch 396 / 400  [t=792.07s]  <loss = 0.03562, ref_loss = 0.00624, max_Q = 17.0,  mse_true = 0.230>\n",
      "Epoch 397 / 400  [t=793.84s]  <loss = 0.04352, ref_loss = 0.01065, max_Q = 17.5,  mse_true = 0.254>\n",
      "Epoch 398 / 400  [t=795.62s]  <loss = 0.01883, ref_loss = 0.00401, max_Q = 17.2,  mse_true = 0.241>\n",
      "Epoch 399 / 400  [t=797.42s]  <loss = 0.02341, ref_loss = 0.00678, max_Q = 17.1,  mse_true = 0.236>\n",
      "Epoch 400 / 400  [t=799.18s]  <loss = 0.03166, ref_loss = 0.00532, max_Q = 17.2,  mse_true = 0.329>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_runs = 3\n",
    "\n",
    "for run_idx in range(num_runs) :\n",
    "    run_experiment(run_config_clone_20, run_idx+1, verbose=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80573ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e7fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f771124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46551470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
