{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884dc59d",
   "metadata": {},
   "source": [
    "#  Unsupervised learning addition model with generator  -  using loopy encoder and decoder method\n",
    "\n",
    "Author: S. Menary [sbmenary@gmail.com]\n",
    "\n",
    "Date: 15/6/2023  (last update: 15/6/2023)\n",
    "\n",
    "Overview: Train a `sequence -> sequence` model where the input sequence is a text representation of a simple sum $\\sum_{i=1}^N A_i$ for a configurable number $N$ of integers $A_i\\in\\mathbb{Z}$, and the output is a set of logits representing the probability of each token in the output sequence. Integers may have a configurable number of digits. At inference time, chains of text are generated auto-regressively until the terminate-sequence token is reached. The loss function is a sparse categorical entropy.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Set up program\n",
    "\n",
    "###  Import\n",
    "\n",
    "All imports go here at the top of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48f1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "##=========================##\n",
    "##   All imports go here   ##\n",
    "##=========================##\n",
    "\n",
    "##  Import entire python stdlib packages\n",
    "import logging, os, sys\n",
    "\n",
    "##  Import entire pypi packages\n",
    "import tensorflow as tf\n",
    "\n",
    "##  Remove tensorflow INFO messages\n",
    "tf.get_logger().setLevel('WARNING')\n",
    "\n",
    "##  Add directory above this to system path to expose mathsformer package location\n",
    "sys.path.append(\"/\".join(os.getcwd().split(\"/\")[:-1]))\n",
    "\n",
    "##  Import individual modules/objects from local packages\n",
    "from tensorflow.keras.optimizers.legacy import Adam, SGD\n",
    "from mathsformer import config, data, transformers, utils\n",
    "from mathsformer import selfsupervised_learning_addition_model_backend as backend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320886f9",
   "metadata": {},
   "source": [
    "## 1. Configure run\n",
    "\n",
    "Set configuration variables for entire program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701cef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##==============================##\n",
    "##   Set custom config values   ##\n",
    "##==============================##\n",
    "\n",
    "custom_config = {\n",
    "    \"global\" : {\n",
    "        \"base_seed\"        : -1,\n",
    "        \"working_dir\"      : \"SSL_loopy_gredenc_dec_notebook_[global>problem_tag]_embed[model>ndim_embedding]_enc_[model>encoder>num_blocks]blocks_[model>encoder>num_loops]loops_width[model>encoder>ndim_ff_hidden]_dec_[model>decoder>num_blocks]blocks_[model>decoder>num_loops]loops_width[model>decoder>ndim_ff_hidden]_post[model>post_decoder>num_layers]_width[model>post_decoder>ndim]_idem[model>idempotent_size]_[date]\",\n",
    "        \"problem_tag\"      : \"int1234_num1245\",\n",
    "        \"log_lvl_iostream\" : logging.INFO,\n",
    "        \"log_lvl_fstream\"  : logging.DEBUG,\n",
    "    },\n",
    "    \"data\" : {\n",
    "        \"train_data\" : {\n",
    "            \"int_lengths\"      : [1, 2, 3, 4],\n",
    "            \"num_ints\"         : [1, 2, 4, 5],\n",
    "            \"batch_size\"       : 32,\n",
    "            \"num_batches\"      : 1000,\n",
    "            \"gen_base_seed\"    : 101,\n",
    "            \"gen_reproducible\" : False, \n",
    "        },\n",
    "        \"val_data\" : {\n",
    "            \"int_lengths\"      : [1, 2, 3, 4],\n",
    "            \"num_ints\"         : [3],\n",
    "            \"batch_size\"       : 32,\n",
    "            \"num_batches\"      : 50,\n",
    "            \"gen_base_seed\"    : 102,\n",
    "            \"gen_reproducible\" : True,\n",
    "        },\n",
    "        \"test_data\" : {\n",
    "            \"int_lengths\"      : [1, 2, 3, 4],\n",
    "            \"num_ints\"         : [6],\n",
    "            \"batch_size\"       : 32,\n",
    "            \"num_batches\"      : 100,\n",
    "            \"gen_base_seed\"    : 103,\n",
    "            \"gen_reproducible\" : True,\n",
    "        },\n",
    "        \"characters\"              : ['M', 'B', 'E', 'N', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-'],\n",
    "        \"mask_char\"               : 'M',\n",
    "        \"seq_start_char\"          : 'B',\n",
    "        \"seq_end_char\"            : 'E',\n",
    "        \"negative_char\"           : 'N',\n",
    "        \"dtype\"                   : \"int32\",\n",
    "    },\n",
    "    \"model\" : {\n",
    "        \"load_pretrained_model\" : None,\n",
    "        \"name\"                  : \"mathsformer_LLM\",\n",
    "        \"dtype\"                 : \"float32\",\n",
    "        \"dropout\"               : 0.1,\n",
    "        \"jit_compile\"           : False,\n",
    "        \"use_old_loss\"          : True,\n",
    "        \"optimizer\"             : Adam,\n",
    "        \"optimizer_args\"        : {\"learning_rate\":1e-4},\n",
    "        \"idempotent_size\"       : -1,\n",
    "        \"positional_encoding\" : {\n",
    "            \"num_freqs\"         : 64,\n",
    "            \"min_period\"        : 4,\n",
    "            \"max_period\"        : 1000,\n",
    "            \"learnable\"         : True,\n",
    "        },\n",
    "        \"ndim_embedding\"        : 128,\n",
    "        \"comb_type\"             : 'average',\n",
    "        \"pre_encoder\"           : {\n",
    "            \"num_layers\"        : -1,\n",
    "            \"ndim\"              : 256,\n",
    "            \"skip_connect\"      : True,\n",
    "        },\n",
    "        \"pre_decoder\" : {\n",
    "            \"num_layers\"        : -1,\n",
    "            \"ndim\"              : 256,\n",
    "            \"skip_connect\"      : True,\n",
    "        },\n",
    "        \"encoder\" : {\n",
    "            \"num_blocks\"        : 1,\n",
    "            \"num_loops\"         : 7,\n",
    "            \"num_heads\"         : 8,\n",
    "            \"ndim\"              : 128,\n",
    "            \"ndim_att_hidden\"   : 128,\n",
    "            \"ndim_ff_hidden\"    : 128,\n",
    "            \"skip_connect\"      : True,\n",
    "        },\n",
    "        \"decoder\" : {\n",
    "            \"num_blocks\"        : 2,\n",
    "            \"num_loops\"         : 1,\n",
    "            \"num_heads\"         : 8,\n",
    "            \"ndim\"              : 128,\n",
    "            \"ndim_att_hidden\"   : 128,\n",
    "            \"ndim_ff_hidden\"    : 128,\n",
    "            \"skip_connect\"      : True,\n",
    "        },\n",
    "        \"post_decoder\" : {\n",
    "            \"num_layers\"        : 3,\n",
    "            \"ndim\"              : 128,\n",
    "        },\n",
    "    },\n",
    "    \"training\" : {\n",
    "        \"train\"          : True,\n",
    "        \"max_epochs\"     : 100000,\n",
    "        \"log_after_epoch\" : {\n",
    "            \"do\"          : True,\n",
    "            \"log_lvl\"     : logging.DEBUG,\n",
    "        },\n",
    "        \"early_stopping\" : {\n",
    "            \"do\"                   : False,\n",
    "            \"patience\"             : 4,\n",
    "            \"monitor\"              : \"loss\",\n",
    "            \"mode\"                 : \"min\",\n",
    "            \"restore_best_weights\" : True,\n",
    "        },\n",
    "        \"model_checkpoint\" : {\n",
    "            \"do\"       : True,\n",
    "            \"filename\" : \"model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.keras\",\n",
    "        },\n",
    "        \"layer_weights_record\" : {\n",
    "            \"do\"               : True,\n",
    "            \"batch_frequency\"  : 2000,\n",
    "            \"recursive\"        : True,\n",
    "        },\n",
    "        \"adaptive_learning_rate\" : {\n",
    "            \"do\"                 : True,\n",
    "            \"decay_factor\"       : 0.2,\n",
    "            \"monitor\"            : \"loss\",\n",
    "            \"mode\"               : \"min\",\n",
    "            \"patience\"           : 3,\n",
    "            \"log_lvl\"            : logging.DEBUG,\n",
    "        },\n",
    "        \"print_tables_during_training\" : {\n",
    "            \"do\"        : True,\n",
    "            \"num_print\" : 10,\n",
    "        },\n",
    "    },\n",
    "    \"evaluate\" : {\n",
    "        \"num_print\"            : 50,\n",
    "        \"save_model\"           : True,\n",
    "        \"plot_weights\"         : False,\n",
    "        \"plot_training_curves\" : True,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e15977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "===   Config created   ===\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "##===================================##\n",
    "##   Load and validate full config   ##\n",
    "##===================================##\n",
    "\n",
    "##  Create config object containing default values\n",
    "cfg = config.Config(backend.DEFAULT_CONFIG)\n",
    "\n",
    "##  Override with custom values\n",
    "cfg.load_dict(custom_config)\n",
    "\n",
    "##  Validate config\n",
    "backend.validate_config(cfg)\n",
    "\n",
    "##  Print success\n",
    "print(utils.fancy_message(f\"Config created\"))\n",
    "\n",
    "##  For convenience, split configs for different sections\n",
    "cfg_global   = cfg[\"global\"  ]\n",
    "cfg_data     = cfg[\"data\"    ]\n",
    "cfg_model    = cfg[\"model\"   ]\n",
    "cfg_training = cfg[\"training\"]\n",
    "cfg_evaluate = cfg[\"evaluate\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af05439",
   "metadata": {},
   "source": [
    "##  2. Set up environment\n",
    "\n",
    "- Create working directory\n",
    "- Create logger\n",
    "- Log package versions for reproducibility\n",
    "- Log config values for reproducibility\n",
    "- Set random seeds for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f7cc532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================================================================\n",
      "===   Working directory created at SSL_loopy_gredenc_dec_notebook_int1234_num1245_embed128_enc_1blocks_7loops_width128_dec_2blocks_1loops_width128_post3_width128_idemm1_2023_06_25_v3   ===\n",
      "============================================================================================================================================================================================\n",
      "   INFO initialise_logging: Begin logging on 2023-06-25 at 16:09:34\n",
      "   INFO initialise_program: Program description: unsupervised_learning_addition_model_generator (notebook)\n",
      "   INFO initialise_program: Working directory: SSL_loopy_gredenc_dec_notebook_int1234_num1245_embed128_enc_1blocks_7loops_width128_dec_2blocks_1loops_width128_post3_width128_idemm1_2023_06_25_v3\n",
      "   INFO log_versions: ------------------------------------------------------+----------------------------------------------------------------------------------\n",
      "   INFO log_versions:                                              PACKAGE  |  VERSION\n",
      "   INFO log_versions: ------------------------------------------------------+----------------------------------------------------------------------------------\n",
      "   INFO log_versions:                                               Python  |  3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]\n",
      "   INFO log_versions:                                              IPython  |  8.14.0\n",
      "   INFO log_versions:                                 IPython.core.release  |  8.14.0\n",
      "   INFO log_versions:                                                  PIL  |  9.5.0\n",
      "   INFO log_versions:                                            PIL.Image  |  9.5.0\n",
      "   INFO log_versions:                                       PIL._deprecate  |  9.5.0\n",
      "   INFO log_versions:                                         PIL._version  |  9.5.0\n",
      "   INFO log_versions:                                                 _csv  |  1.0\n",
      "   INFO log_versions:                                              _ctypes  |  1.1.0\n",
      "   INFO log_versions:                                              _curses  |  b'2.2'\n",
      "   INFO log_versions:                                              decimal  |  1.70\n",
      "   INFO log_versions:                               _pydev_bundle.fsnotify  |  0.1.5\n",
      "   INFO log_versions:                 _pydevd_frame_eval.vendored.bytecode  |  0.13.0.dev\n",
      "   INFO log_versions:                                              appnope  |  0.1.3\n",
      "   INFO log_versions:                                             argparse  |  1.1\n",
      "   INFO log_versions:                                           astunparse  |  1.6.3\n",
      "   INFO log_versions:                                             backcall  |  0.2.0\n",
      "   INFO log_versions:                                              certifi  |  2023.05.07\n",
      "   INFO log_versions:                                                 cffi  |  1.15.1\n",
      "   INFO log_versions:                                   charset_normalizer  |  3.1.0\n",
      "   INFO log_versions:                           charset_normalizer.version  |  3.1.0\n",
      "   INFO log_versions:                                                 comm  |  0.1.3\n",
      "   INFO log_versions:                                                  csv  |  1.0\n",
      "   INFO log_versions:                                               ctypes  |  1.1.0\n",
      "   INFO log_versions:                                      ctypes.macholib  |  1.0\n",
      "   INFO log_versions:                                               cycler  |  0.10.0\n",
      "   INFO log_versions:                                             dateutil  |  2.8.2\n",
      "   INFO log_versions:                                              debugpy  |  1.6.7\n",
      "   INFO log_versions:                                   debugpy.public_api  |  1.6.7\n",
      "   INFO log_versions:                                              decimal  |  1.70\n",
      "   INFO log_versions:                                            decorator  |  5.1.1\n",
      "   INFO log_versions:                                           defusedxml  |  0.7.1\n",
      "   INFO log_versions:                                            distutils  |  3.11.4\n",
      "   INFO log_versions:                                            executing  |  1.2.0\n",
      "   INFO log_versions:                                    executing.version  |  1.2.0\n",
      "   INFO log_versions:                                          flatbuffers  |  23.5.26\n",
      "   INFO log_versions:                                 flatbuffers._version  |  23.5.26\n",
      "   INFO log_versions:                                      google.protobuf  |  4.23.3\n",
      "   INFO log_versions:                                                 h5py  |  3.9.0\n",
      "   INFO log_versions:                                          http.server  |  0.6\n",
      "   INFO log_versions:                                                 idna  |  3.4\n",
      "   INFO log_versions:                                        idna.idnadata  |  15.0.0\n",
      "   INFO log_versions:                                    idna.package_data  |  3.4\n",
      "   INFO log_versions:                                            ipaddress  |  1.0\n",
      "   INFO log_versions:                                            ipykernel  |  6.23.2\n",
      "   INFO log_versions:                                   ipykernel._version  |  6.23.2\n",
      "   INFO log_versions:                                                 jedi  |  0.18.2\n",
      "   INFO log_versions:                                                 json  |  2.0.9\n",
      "   INFO log_versions:                                       jupyter_client  |  8.2.0\n",
      "   INFO log_versions:                              jupyter_client._version  |  8.2.0\n",
      "   INFO log_versions:                                         jupyter_core  |  5.3.1\n",
      "   INFO log_versions:                                 jupyter_core.version  |  5.3.1\n",
      "   INFO log_versions:                                                keras  |  2.12.0\n",
      "   INFO log_versions:                                  keras.api._v2.keras  |  2.12.0\n",
      "   INFO log_versions:                                      keras.api.keras  |  2.12.0\n",
      "   INFO log_versions:                                           kiwisolver  |  1.4.4\n",
      "   INFO log_versions:                                     kiwisolver._cext  |  1.4.4\n",
      "   INFO log_versions:                                              logging  |  0.5.1.2\n",
      "   INFO log_versions:                                           matplotlib  |  3.7.1\n",
      "   INFO log_versions:                                  matplotlib._version  |  3.7.1\n",
      "   INFO log_versions:                                                numpy  |  1.23.5\n",
      "   INFO log_versions:                                           numpy.core  |  1.23.5\n",
      "   INFO log_versions:                         numpy.core._multiarray_umath  |  3.1\n",
      "   INFO log_versions:                                            numpy.lib  |  1.23.5\n",
      "   INFO log_versions:                           numpy.linalg._umath_linalg  |  0.1.5\n",
      "   INFO log_versions:                                        numpy.version  |  1.23.5\n",
      "   INFO log_versions:                                           opt_einsum  |  v3.3.0\n",
      "   INFO log_versions:                                            packaging  |  23.1\n",
      "   INFO log_versions:                                                parso  |  0.8.3\n",
      "   INFO log_versions:                                              pexpect  |  4.8.0\n",
      "   INFO log_versions:                                          pickleshare  |  0.7.5\n",
      "   INFO log_versions:                 pkg_resources._vendor.more_itertools  |  9.0.0\n",
      "   INFO log_versions:                      pkg_resources._vendor.packaging  |  23.0\n",
      "   INFO log_versions:                   pkg_resources._vendor.platformdirs  |  2.6.2\n",
      "   INFO log_versions:           pkg_resources._vendor.platformdirs.version  |  2.6.2\n",
      "   INFO log_versions:                 pkg_resources._vendor.more_itertools  |  9.0.0\n",
      "   INFO log_versions:                      pkg_resources._vendor.packaging  |  23.0\n",
      "   INFO log_versions:                   pkg_resources._vendor.platformdirs  |  2.6.2\n",
      "   INFO log_versions:                                             platform  |  1.0.8\n",
      "   INFO log_versions:                                         platformdirs  |  3.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO log_versions:                                 platformdirs.version  |  3.6.0\n",
      "   INFO log_versions:                                       prompt_toolkit  |  3.0.38\n",
      "   INFO log_versions:                                               psutil  |  5.9.5\n",
      "   INFO log_versions:                                           ptyprocess  |  0.7.0\n",
      "   INFO log_versions:                                            pure_eval  |  0.2.2\n",
      "   INFO log_versions:                                    pure_eval.version  |  0.2.2\n",
      "   INFO log_versions:                                               pydevd  |  2.9.5\n",
      "   INFO log_versions:                                             pygments  |  2.15.1\n",
      "   INFO log_versions:                                            pyparsing  |  3.1.0\n",
      "   INFO log_versions:                                                   re  |  2.2.1\n",
      "   INFO log_versions:                                             requests  |  2.31.0\n",
      "   INFO log_versions:                                 requests.__version__  |  2.31.0\n",
      "   INFO log_versions:                                                 idna  |  3.4\n",
      "   INFO log_versions:                                        idna.idnadata  |  15.0.0\n",
      "   INFO log_versions:                                    idna.package_data  |  3.4\n",
      "   INFO log_versions:                                              urllib3  |  1.26.16\n",
      "   INFO log_versions:                                     urllib3._version  |  1.26.16\n",
      "   INFO log_versions:                                   urllib3.connection  |  1.26.16\n",
      "   INFO log_versions:                                 urllib3.packages.six  |  1.16.0\n",
      "   INFO log_versions:                      urllib3.util.ssl_match_hostname  |  3.5.0.1\n",
      "   INFO log_versions:                                       requests.utils  |  2.31.0\n",
      "   INFO log_versions:                                                scipy  |  1.10.1\n",
      "   INFO log_versions:                                 scipy._lib.decorator  |  4.0.5\n",
      "   INFO log_versions:                                  scipy.linalg._fblas  |  1.23.2\n",
      "   INFO log_versions:                                scipy.linalg._flapack  |  1.23.2\n",
      "   INFO log_versions:                                scipy.linalg._flinalg  |  1.23.2\n",
      "   INFO log_versions:            scipy.sparse.linalg._eigen.arpack._arpack  |  1.23.2\n",
      "   INFO log_versions:               scipy.sparse.linalg._isolve._iterative  |  1.23.2\n",
      "   INFO log_versions:                               scipy.special._specfun  |  1.23.2\n",
      "   INFO log_versions:                                           setuptools  |  67.7.2\n",
      "   INFO log_versions:                                            distutils  |  3.11.4\n",
      "   INFO log_versions:                    setuptools._vendor.more_itertools  |  8.8.0\n",
      "   INFO log_versions:                       setuptools._vendor.ordered_set  |  3.1\n",
      "   INFO log_versions:                         setuptools._vendor.packaging  |  23.0\n",
      "   INFO log_versions:                    setuptools._vendor.more_itertools  |  8.8.0\n",
      "   INFO log_versions:                       setuptools._vendor.ordered_set  |  3.1\n",
      "   INFO log_versions:                         setuptools._vendor.packaging  |  23.0\n",
      "   INFO log_versions:                                   setuptools.version  |  67.7.2\n",
      "   INFO log_versions:                                                  six  |  1.16.0\n",
      "   INFO log_versions:                                         socketserver  |  0.4\n",
      "   INFO log_versions:                                           stack_data  |  0.6.2\n",
      "   INFO log_versions:                                   stack_data.version  |  0.6.2\n",
      "   INFO log_versions:                                          tensorboard  |  2.12.3\n",
      "   INFO log_versions:                   tensorboard.compat.tensorflow_stub  |  stub\n",
      "   INFO log_versions: tensorboard.compat.tensorflow_stub.pywrap_tensorflow  |  0\n",
      "   INFO log_versions:                                           tensorflow  |  2.12.0\n",
      "   INFO log_versions:                         tensorflow._api.v2.compat.v1  |  2.12.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v1.compat.v1  |  2.12.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v1.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                         tensorflow._api.v2.compat.v2  |  2.12.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v2.compat.v1  |  2.12.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v2.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                                 tensorflow.compat.v1  |  2.12.0\n",
      "   INFO log_versions:                       tensorflow.compat.v1.compat.v1  |  2.12.0\n",
      "   INFO log_versions:                       tensorflow.compat.v1.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                                 tensorflow.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                       tensorflow.compat.v2.compat.v1  |  2.12.0\n",
      "   INFO log_versions:                       tensorflow.compat.v2.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                                     tensorflow.keras  |  2.12.0\n",
      "   INFO log_versions:           tensorflow.python.client.pywrap_tf_session  |  2.12.0\n",
      "   INFO log_versions:                 tensorflow.python.framework.versions  |  2.12.0\n",
      "   INFO log_versions:                              tensorflow.python.keras  |  2.6.0\n",
      "   INFO log_versions:                                            traitlets  |  5.9.0\n",
      "   INFO log_versions:                                   traitlets._version  |  5.9.0\n",
      "   INFO log_versions:                                       urllib.request  |  3.11\n",
      "   INFO log_versions:                                              urllib3  |  1.26.16\n",
      "   INFO log_versions:                                     urllib3._version  |  1.26.16\n",
      "   INFO log_versions:                                   urllib3.connection  |  1.26.16\n",
      "   INFO log_versions:                                 urllib3.packages.six  |  1.16.0\n",
      "   INFO log_versions:                      urllib3.util.ssl_match_hostname  |  3.5.0.1\n",
      "   INFO log_versions:                                              wcwidth  |  0.2.6\n",
      "   INFO log_versions:                                                wrapt  |  1.14.1\n",
      "   INFO log_versions:                                        xmlrpc.client  |  3.11\n",
      "   INFO log_versions:                                                 zlib  |  1.0\n",
      "   INFO log_versions:                                                  zmq  |  25.1.0\n",
      "   INFO log_versions:                                            zmq.sugar  |  25.1.0\n",
      "   INFO log_versions:                                    zmq.sugar.version  |  25.1.0\n",
      "   INFO log_versions: ------------------------------------------------------+----------------------------------------------------------------------------------\n",
      "   INFO initialise_program: Registered config value global > base_seed: -1\n",
      "   INFO initialise_program: Registered config value global > working_dir: SSL_loopy_gredenc_dec_notebook_[global>problem_tag]_embed[model>ndim_embedding]_enc_[model>encoder>num_blocks]blocks_[model>encoder>num_loops]loops_width[model>encoder>ndim_ff_hidden]_dec_[model>decoder>num_blocks]blocks_[model>decoder>num_loops]loops_width[model>decoder>ndim_ff_hidden]_post[model>post_decoder>num_layers]_width[model>post_decoder>ndim]_idem[model>idempotent_size]_[date]\n",
      "   INFO initialise_program: Registered config value global > problem_tag: int1234_num1245\n",
      "   INFO initialise_program: Registered config value global > model_tag: baseline\n",
      "   INFO initialise_program: Registered config value global > log_lvl_iostream: 20\n",
      "   INFO initialise_program: Registered config value global > log_lvl_fstream: 10\n",
      "   INFO initialise_program: Registered config value data > train_data > int_lengths: [1, 2, 3, 4]\n",
      "   INFO initialise_program: Registered config value data > train_data > num_ints: [1, 2, 4, 5]\n",
      "   INFO initialise_program: Registered config value data > train_data > batch_size: 32\n",
      "   INFO initialise_program: Registered config value data > train_data > num_batches: 1000\n",
      "   INFO initialise_program: Registered config value data > train_data > gen_base_seed: 101\n",
      "   INFO initialise_program: Registered config value data > train_data > gen_reproducible: False\n",
      "   INFO initialise_program: Registered config value data > val_data > int_lengths: [1, 2, 3, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO initialise_program: Registered config value data > val_data > num_ints: [3]\n",
      "   INFO initialise_program: Registered config value data > val_data > batch_size: 32\n",
      "   INFO initialise_program: Registered config value data > val_data > num_batches: 50\n",
      "   INFO initialise_program: Registered config value data > val_data > gen_base_seed: 102\n",
      "   INFO initialise_program: Registered config value data > val_data > gen_reproducible: True\n",
      "   INFO initialise_program: Registered config value data > test_data > int_lengths: [1, 2, 3, 4]\n",
      "   INFO initialise_program: Registered config value data > test_data > num_ints: [6]\n",
      "   INFO initialise_program: Registered config value data > test_data > batch_size: 32\n",
      "   INFO initialise_program: Registered config value data > test_data > num_batches: 100\n",
      "   INFO initialise_program: Registered config value data > test_data > gen_base_seed: 103\n",
      "   INFO initialise_program: Registered config value data > test_data > gen_reproducible: True\n",
      "   INFO initialise_program: Registered config value data > characters: ['M', 'B', 'E', 'N', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-']\n",
      "   INFO initialise_program: Registered config value data > mask_char: M\n",
      "   INFO initialise_program: Registered config value data > seq_start_char: B\n",
      "   INFO initialise_program: Registered config value data > seq_end_char: E\n",
      "   INFO initialise_program: Registered config value data > negative_char: N\n",
      "   INFO initialise_program: Registered config value data > dtype: int32\n",
      "   INFO initialise_program: Registered config value model > load_pretrained_model: None\n",
      "   INFO initialise_program: Registered config value model > name: mathsformer_LLM\n",
      "   INFO initialise_program: Registered config value model > dtype: float32\n",
      "   INFO initialise_program: Registered config value model > dropout: 0.1\n",
      "   INFO initialise_program: Registered config value model > learning_rate: 0.001\n",
      "   INFO initialise_program: Registered config value model > jit_compile: False\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > num_freqs: 64\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > min_period: 4\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > max_period: 1000\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > learnable: True\n",
      "   INFO initialise_program: Registered config value model > ndim_embedding: 128\n",
      "   INFO initialise_program: Registered config value model > comb_type: average\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > num_layers: -1\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > ndim: 256\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > pre_decoder > num_layers: -1\n",
      "   INFO initialise_program: Registered config value model > pre_decoder > ndim: 256\n",
      "   INFO initialise_program: Registered config value model > pre_decoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > encoder > num_blocks: 1\n",
      "   INFO initialise_program: Registered config value model > encoder > num_heads: 8\n",
      "   INFO initialise_program: Registered config value model > encoder > ndim: 128\n",
      "   INFO initialise_program: Registered config value model > encoder > ndim_att_hidden: 128\n",
      "   INFO initialise_program: Registered config value model > encoder > ndim_ff_hidden: 128\n",
      "   INFO initialise_program: Registered config value model > encoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > encoder > num_loops: 7\n",
      "   INFO initialise_program: Registered config value model > decoder > num_blocks: 2\n",
      "   INFO initialise_program: Registered config value model > decoder > num_heads: 8\n",
      "   INFO initialise_program: Registered config value model > decoder > ndim: 128\n",
      "   INFO initialise_program: Registered config value model > decoder > ndim_att_hidden: 128\n",
      "   INFO initialise_program: Registered config value model > decoder > ndim_ff_hidden: 128\n",
      "   INFO initialise_program: Registered config value model > decoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > decoder > num_loops: 1\n",
      "   INFO initialise_program: Registered config value model > post_decoder > num_layers: 3\n",
      "   INFO initialise_program: Registered config value model > post_decoder > ndim: 128\n",
      "   INFO initialise_program: Registered config value model > use_old_loss: True\n",
      "   INFO initialise_program: Registered config value model > optimizer: <class 'keras.optimizers.legacy.adam.Adam'>\n",
      "   INFO initialise_program: Registered config value model > optimizer_args > learning_rate: 0.0001\n",
      "   INFO initialise_program: Registered config value model > idempotent_size: -1\n",
      "   INFO initialise_program: Registered config value training > train: True\n",
      "   INFO initialise_program: Registered config value training > max_epochs: 100000\n",
      "   INFO initialise_program: Registered config value training > log_after_epoch > do: True\n",
      "   INFO initialise_program: Registered config value training > log_after_epoch > log_lvl: 10\n",
      "   INFO initialise_program: Registered config value training > early_stopping > do: False\n",
      "   INFO initialise_program: Registered config value training > early_stopping > patience: 4\n",
      "   INFO initialise_program: Registered config value training > early_stopping > monitor: loss\n",
      "   INFO initialise_program: Registered config value training > early_stopping > mode: min\n",
      "   INFO initialise_program: Registered config value training > early_stopping > restore_best_weights: True\n",
      "   INFO initialise_program: Registered config value training > model_checkpoint > do: True\n",
      "   INFO initialise_program: Registered config value training > model_checkpoint > filename: model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.keras\n",
      "   INFO initialise_program: Registered config value training > layer_weights_record > do: True\n",
      "   INFO initialise_program: Registered config value training > layer_weights_record > batch_frequency: 2000\n",
      "   INFO initialise_program: Registered config value training > layer_weights_record > recursive: True\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > do: True\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > decay_factor: 0.2\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > monitor: loss\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > mode: min\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > patience: 3\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > log_lvl: 10\n",
      "   INFO initialise_program: Registered config value training > print_tables_during_training > do: True\n",
      "   INFO initialise_program: Registered config value training > print_tables_during_training > num_print: 10\n",
      "   INFO initialise_program: Registered config value evaluate > num_print: 50\n",
      "   INFO initialise_program: Registered config value evaluate > save_model: True\n",
      "   INFO initialise_program: Registered config value evaluate > plot_weights: False\n",
      "   INFO initialise_program: Registered config value evaluate > plot_training_curves: True\n",
      "   INFO initialise_program: Python random seed set: 1687705774\n",
      "   INFO initialise_program: Numpy random seed set: 1687705775\n",
      "   INFO initialise_program: TensorFlow random seed set: 1687705776\n"
     ]
    }
   ],
   "source": [
    "##==============================##\n",
    "##   Create working directory   ##\n",
    "##==============================##\n",
    "\n",
    "##  Report success\n",
    "working_dir, logger, base_seed, np_seed, tf_seed = utils.initialise_program(\n",
    "    \"unsupervised_learning_addition_model_generator (notebook)\", \n",
    "    working_dir       = cfg_global[\"working_dir\"], \n",
    "    cfg               = cfg,\n",
    "    base_seed         = cfg_global[\"base_seed\"],\n",
    "    log_lvl_iostream  = cfg_global[\"log_lvl_iostream\"],\n",
    "    log_lvl_fstream   = cfg_global[\"log_lvl_fstream\" ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960860d",
   "metadata": {},
   "source": [
    "##  3. Create training data\n",
    "\n",
    "###  Create tokeniser\n",
    "\n",
    "Tokeniser object handles the transformation from strings to tensors and back again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db11d6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO summary: TokenTransform of dtype int32 with 16 characters: ['M', 'B', 'E', 'N', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-']\n",
      "   INFO summary: Special characters are seq_start_char (B), seq_end_char (E), mask_char (M)\n",
      "   INFO summary: Tokeniser dictionary is {'M': 0, 'B': 1, 'E': 2, 'N': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, '+': 14, '-': 15}\n",
      "   INFO summary: Detokeniser dictionary is {0: 'M', 1: 'B', 2: 'E', 3: 'N', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: '+', 15: '-'}\n"
     ]
    }
   ],
   "source": [
    "##======================##\n",
    "##   Create tokeniser   ##\n",
    "##======================##\n",
    "\n",
    "token_transform = data.TokenTransform.from_dictionary(cfg_data)\n",
    "token_transform.summary(print_fn=logger.info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5367bdd7",
   "metadata": {},
   "source": [
    "###  Create data generators for train/val/test sets\n",
    "\n",
    "Data generators create tensor inputs/outputs for the model on-the-fly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d87b308d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO get_data_generators: Training data generator created with the following config: Generator of [1, 2, 4, 5] integers of length [1, 2, 3, 4] in 1000 batches of size 32 (base_seed=101, reproducible=False)\n",
      "   INFO get_data_generators: Output shapes for a test batch are ((32, 27), (32, 6)), (32, 6)\n",
      "   INFO get_data_generators: Validation data generator created with the following config: Generator of [3] integers of length [1, 2, 3, 4] in 50 batches of size 32 (base_seed=102, reproducible=True)\n",
      "   INFO get_data_generators: Output shapes for a test batch are ((32, 18), (32, 6)), (32, 6)\n",
      "   INFO get_data_generators: Test data generator created with the following config: Generator of [6] integers of length [1, 2, 3, 4] in 100 batches of size 32 (base_seed=103, reproducible=True)\n",
      "   INFO get_data_generators: Output shapes for a test batch are ((32, 29), (32, 7)), (32, 7)\n"
     ]
    }
   ],
   "source": [
    "##============================##\n",
    "##   Create data generators   ##\n",
    "##============================##\n",
    "\n",
    "negative_char = cfg_data.get(\"negative_char\")\n",
    "train_gen, train_gen_reproducible, val_gen, test_gen = backend.get_data_generators(cfg_data, token_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa78cf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Saving distribution of token frequencies to file SSL_loopy_gredenc_dec_notebook_int1234_num1245_embed128_enc_1blocks_7loops_width128_dec_2blocks_1loops_width128_post3_width128_idemm1_2023_06_25_v3/token_distribution.pdf\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##=========================================================##\n",
    "##   Quickly visualise distribution of token frequencies   ##\n",
    "##=========================================================##\n",
    "\n",
    "##  Imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "##  Get sample of train data labels\n",
    "train_data_sample = np.concatenate([train_gen[i][1].numpy().flatten() for i in range(1000)])\n",
    "\n",
    "##  Ignore masked tokens\n",
    "train_data_sample = train_data_sample[train_data_sample != 0]\n",
    "\n",
    "##  Count number for each token\n",
    "chars, freqs = [], []\n",
    "for token, char in train_gen.token_transform.detokeniser_dict.items() :\n",
    "    chars.append(char)\n",
    "    freqs.append(len(train_data_sample[train_data_sample==token]))\n",
    "    \n",
    "##  Normalise counts to frequency\n",
    "freqs     = np.array(freqs).astype(np.float32)\n",
    "freqs_err = np.sqrt(freqs)\n",
    "freqs_tot = np.sum(freqs)\n",
    "freqs     /= freqs_tot\n",
    "freqs_err /= freqs_tot\n",
    "\n",
    "##  Log token frequencies\n",
    "for char, freq, freq_err in zip(chars, freqs, freqs_err) :\n",
    "    logger.debug(f\"Token '{char}' in training data with frequency {100.*freq:.1f} +- {100.*freq_err:.1f} % (masked)\")\n",
    "\n",
    "##  Plot quick bar chart of frequencies\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax  = fig.add_subplot(1, 1, 1)\n",
    "ax.tick_params(which=\"both\", axis=\"both\", right=True, top=True, labelsize=10, direction=\"in\")\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"Character\", fontsize=14, va=\"top\"  , labelpad=15)\n",
    "ax.set_ylabel(\"Frequency in\\ntrain data\", fontsize=14, ha=\"right\", rotation=0, labelpad=20)\n",
    "\n",
    "ax.bar(chars, freqs, yerr=freqs_err)\n",
    "\n",
    "fig_fname = f\"{working_dir}/token_distribution.pdf\"\n",
    "logger.info(f\"Saving distribution of token frequencies to file {fig_fname}\")\n",
    "\n",
    "plt.savefig(fig_fname, bbox_inches=\"tight\")\n",
    "plt.show(fig)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39db1bb",
   "metadata": {},
   "source": [
    "##  4.  Create model\n",
    "\n",
    "Create the keras model object that handles sequence-sequence transformations from alread-tokenised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae1868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers     import Add, Average, Concatenate, Embedding, Input, LayerNormalization\n",
    "from tensorflow.keras.models     import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from mathsformer.tf_objects import (DecoderBlock, EncoderBlock, Enumerate, FeedForwardBlock, LearnableMixture, MaskedCategoricalAccuracy,\n",
    "                                    MaskedSparseCategoricalCrossentropy, PositionalEncoding)\n",
    "from mathsformer.tf_objects import scalar_masked_sparse_categorical_crossentropy, scalar_masked_categorical_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f7c3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x) :\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def inv_sigmoid(x) :\n",
    "    return -np.log(1/x - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bef85f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GradientFlowEncoder(EncoderBlock) :\n",
    "    def __init__(self, *args, **kwargs) :\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def build(self, x) :\n",
    "        self._weight = self.add_weight(f\"{self.name}_weight\", \n",
    "                                       shape=(1,), \n",
    "                                       initializer=tf.constant_initializer(inv_sigmoid(0.05)), \n",
    "                                       trainable=True, \n",
    "                                       dtype=self.dtype)\n",
    "        \n",
    "    def call(self, x, mask=None) :\n",
    "                        \n",
    "        with tf.GradientTape() as tape :\n",
    "            tape.watch(x)\n",
    "            y = super().call(x, mask=mask)\n",
    "            y = tf.reduce_sum(y, axis=-1)\n",
    "            y = tf.reduce_sum(y, axis=-1)\n",
    "            y = tf.nn.sigmoid(y)\n",
    "            y = y[..., tf.newaxis]\n",
    "            \n",
    "        div = tape.batch_jacobian(y, x)\n",
    "        div = div[:,0,:,:]       \n",
    "        lam = tf.nn.sigmoid(self._weight)\n",
    "        return x - lam*div\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98368f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_text_to_text_model(vocab_length:int, \n",
    "                              name:str, \n",
    "                              do_compile:bool       = True,\n",
    "                              use_old_loss:bool     = False,\n",
    "                              dtype_in              = tf.int32, \n",
    "                              dtype                 = tf.float32, \n",
    "                              dropout:float         = 0.1, \n",
    "                              jit_compile:bool      = None,\n",
    "                              optimizer             = Adam,\n",
    "                              optimizer_args:dict   = None,\n",
    "                              idempotent_size:int   = 1,\n",
    "                              pos_enc_num_freqs:int = 32, pos_enc_min_period:float = 4, pos_enc_max_period:float = 500 , pos_enc_learnable:bool = False,\n",
    "                              ndim_embedding:int          = 64, comb_type:str                = \"average\",\n",
    "                              num_encoder_blocks:int      = 5 , ndim_encoder:int             = 64 , skip_connect_encoder:bool  = True,\n",
    "                              num_decoder_blocks:int      = 5 , ndim_decoder:int             = 64 , skip_connect_decoder:bool  = True,\n",
    "                              num_heads_encoder:int       = 8 , ndim_att_hidden_encoder:int  = 128, ndim_ff_hidden_encoder:int = 128, \n",
    "                              num_heads_decoder:int       = 8 , ndim_att_hidden_decoder:int  = 128, ndim_ff_hidden_decoder:int = 128, \n",
    "                              num_encoder_loops:int       = 1 , num_decoder_loops:int        = 1  ,\n",
    "                              num_post_layers_decoder:int = 3 , ndim_post_layers_decoder:int = 512, \n",
    "                             ) :\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ##  Resolve mutable default args\n",
    "    if optimizer_args is None :\n",
    "        optimizer_args = {'learning_rate': 1e-3}\n",
    "    \n",
    "    ##=============================================##\n",
    "    ##===   Input layer - Output shape [B, S]   ===##\n",
    "    ##=============================================##\n",
    "    x_in_enc = Input((None,), dtype=dtype_in, name=f\"{name}_encoder_input_layer\")\n",
    "    x_in_dec = Input((None,), dtype=dtype_in, name=f\"{name}_decoder_input_layer\")\n",
    "            \n",
    "    ##===========================================================================##\n",
    "    ##===  Token embedding, masking 0s - Output shape [B, S, ndim_embedding]  ===##\n",
    "    ##===========================================================================##\n",
    "    x_embed_enc = Embedding(vocab_length, \n",
    "                            ndim_embedding, \n",
    "                            mask_zero=True, \n",
    "                            dtype=dtype, \n",
    "                            name=f\"{name}_encoder_embedding\")(x_in_enc)\n",
    "    x_embed_dec = Embedding(vocab_length, \n",
    "                            ndim_embedding, \n",
    "                            mask_zero=True, \n",
    "                            dtype=dtype, \n",
    "                            name=f\"{name}_decoder_embedding\")(x_in_dec)\n",
    "    \n",
    "    ##=========================================================================##\n",
    "    ##===  Enumerate indices for positional encoding - Output shape [B, S]  ===##\n",
    "    ##=========================================================================##\n",
    "    x_pos_enc = Enumerate(name=f\"{name}_encoder_enumerate\", dtype=dtype)(x_in_enc, minimal_dims=False)\n",
    "    x_pos_dec = Enumerate(name=f\"{name}_decoder_enumerate\", dtype=dtype)(x_in_dec, minimal_dims=False)\n",
    "    \n",
    "    ##========================================================================##\n",
    "    ##===  Positional encoding - Output shape [B, S, 2*pos_enc_num_freqs]  ===##\n",
    "    ##========================================================================##\n",
    "    x_pos_enc = PositionalEncoding(num_freqs  = pos_enc_num_freqs, \n",
    "                                   min_period = pos_enc_min_period, \n",
    "                                   max_period = pos_enc_max_period, \n",
    "                                   learnable  = pos_enc_learnable,\n",
    "                                   dtype      = dtype, \n",
    "                                   name       = f\"{name}_encoder_position_encoding\")(x_pos_enc)\n",
    "    x_pos_dec = PositionalEncoding(num_freqs  = pos_enc_num_freqs, \n",
    "                                   min_period = pos_enc_min_period, \n",
    "                                   max_period = pos_enc_max_period, \n",
    "                                   learnable  = pos_enc_learnable,\n",
    "                                   dtype      = dtype, \n",
    "                                   name       = f\"{name}_decoder_position_encoding\")(x_pos_dec)\n",
    "\n",
    "    ##==============================================================================================##\n",
    "    ##===  Combine embeddings end pos enc - Output shape [B, S, N] where N depends on comb_type  ===##\n",
    "    ##==============================================================================================##\n",
    "    allowed_comb_types = [\"add\", \"sum\", \"average\", \"mean\", \"concat\", \"concatenate\", \"mixture\"]\n",
    "    match comb_type.lower() :\n",
    "        case \"add\" | \"sum\" :\n",
    "            x_enc = Add(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = Add(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case \"average\" | \"mean\" :\n",
    "            x_enc = Average(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = Average(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case \"concat\" | \"concatenate\" :\n",
    "            x_enc = Concatenate(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = Concatenate(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case \"mixture\" :\n",
    "            x_enc = LearnableMixture(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = LearnableMixture(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case _ :\n",
    "            raise RuntimeError(f\"comb_type '{comb_type}' not recognised, recognised keywords are {allowed_comb_types}\")\n",
    "    \n",
    "    ##============================================================##\n",
    "    ##===  Encoder blocks - Output shape [B, S, ndim_encoder]  ===##\n",
    "    ##============================================================##\n",
    "    encoder_blocks = []\n",
    "    for layer_idx in range(num_encoder_blocks) :\n",
    "        encoder_blocks.append(GradientFlowEncoder(\n",
    "                                 ndim_encoder, \n",
    "                                 num_heads_encoder, \n",
    "                                 ndim_att_hidden_encoder, \n",
    "                                 ndim_ff_hidden_encoder, \n",
    "                                 dropout_mha     = dropout, \n",
    "                                 dtype           = dtype, \n",
    "                                 pre_layer_norm  = True, \n",
    "                                 post_layer_norm = False, \n",
    "                                 skip_connect    = skip_connect_encoder, \n",
    "                                 name            = f\"{name}_encoder_block_{layer_idx+1}\"))\n",
    "        \n",
    "    for loop_idx in range(num_encoder_loops) :\n",
    "        for encoder_block in encoder_blocks :\n",
    "            x_enc = encoder_block(x_enc)\n",
    "    x_enc = LayerNormalization(name=f\"{name}_encoder_output_norm\")(x_enc)\n",
    "           \n",
    "    x_post_enc = x_enc\n",
    "    for loop_idx in range(idempotent_size) :\n",
    "        for encoder_block in encoder_blocks :\n",
    "            x_post_enc = encoder_block(x_post_enc)\n",
    "    x_post_enc = LayerNormalization(name=f\"{name}_encoder_idem_output_norm\")(x_post_enc)\n",
    "    \n",
    "    ##============================================================##\n",
    "    ##===  Decoder blocks - Output shape [B, S, ndim_decoder]  ===##\n",
    "    ##============================================================##\n",
    "    decoder_blocks = []\n",
    "    for layer_idx in range(num_decoder_blocks) :\n",
    "        decoder_blocks.append(DecoderBlock(\n",
    "                                 ndim_decoder, \n",
    "                                 num_heads_decoder, \n",
    "                                 ndim_att_hidden_decoder, \n",
    "                                 ndim_ff_hidden_decoder, \n",
    "                                 dropout_mha     = dropout, \n",
    "                                 dtype           = dtype, \n",
    "                                 pre_layer_norm  = True, \n",
    "                                 post_layer_norm = False, \n",
    "                                 skip_connect    = skip_connect_decoder, \n",
    "                                 name            = f\"{name}_decoder_block_{layer_idx+1}\"))\n",
    "        \n",
    "    x_post_dec = x_dec\n",
    "    for loop_idx in range(num_decoder_loops) :\n",
    "        for decoder_block in decoder_blocks :\n",
    "            x_dec      = decoder_block([x_dec, x_enc])\n",
    "            x_post_dec = decoder_block([x_post_dec, x_post_enc])\n",
    "        \n",
    "    ##==================================================================================================##\n",
    "    ##===  Predict logit probabilities using feed-forward block - Output shape [B, S, vocab_length]  ===##\n",
    "    ##==================================================================================================##\n",
    "    ##  - use layer_norm instead of batch_norm because elements in sequence are not independent\n",
    "    ff_block = FeedForwardBlock(vocab_length, \n",
    "                         ndim_hidden       = ndim_post_layers_decoder, \n",
    "                         num_hidden_layers = num_post_layers_decoder, \n",
    "                         skip_connect      = False, \n",
    "                         pre_layer_norm    = True, \n",
    "                         post_layer_norm   = False, \n",
    "                         batch_norm        = False, \n",
    "                         dtype             = dtype, \n",
    "                         name              = f\"{name}_output\")\n",
    "    x, x2 = ff_block(x_dec), ff_block(x_post_dec)\n",
    "    \n",
    "    ##  Create model\n",
    "    if idempotent_size > 0 :\n",
    "        model = Model([x_in_enc, x_in_dec], [x, x2], name=name)\n",
    "    else :\n",
    "        model = Model([x_in_enc, x_in_dec], x, name=name)\n",
    "    \n",
    "    ##  Compile model with sparse categorical crossentropy loss and accuracy metric\n",
    "    if do_compile :\n",
    "        acc  = MaskedCategoricalAccuracy(scalar_output=True, equal_token_weight=True, use_keras_mask=False, mask_value=0)\n",
    "        loss = MaskedSparseCategoricalCrossentropy(scalar_output=True, equal_token_weight=True, use_keras_mask=False, mask_value=0, from_logits=True)\n",
    "        model.compile(loss        = loss, \n",
    "                      optimizer   = optimizer(**optimizer_args), \n",
    "                      metrics     = [acc],\n",
    "                      jit_compile = jit_compile)\n",
    "    \n",
    "    ##  Return model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "942355eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_to_text_model_from_config(cfg_model, token_transform) :\n",
    "    \"\"\"\n",
    "    Create a text-to-text transformer model\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "        >  cfg_model, Config\n",
    "           Model configuration\n",
    "           \n",
    "        >  token_transform, TokenTransform\n",
    "           Tokeniser\n",
    "    \"\"\"\n",
    "    return create_text_to_text_model(\n",
    "                          vocab_length                = token_transform.vocab_length, \n",
    "                          name                        = cfg_model[\"name\"],\n",
    "                          do_compile                  = True,\n",
    "                          use_old_loss                = cfg_model[\"use_old_loss\"],\n",
    "                          dtype_in                    = token_transform.dtype,\n",
    "                          dtype                       = cfg_model[\"dtype\"],\n",
    "                          dropout                     = cfg_model[\"dropout\"],\n",
    "                          jit_compile                 = cfg_model[\"jit_compile\"],\n",
    "                          optimizer                   = cfg_model.get(\"optimizer\", Adam),\n",
    "                          optimizer_args              = cfg_model.get(\"optimizer_args\", {}),\n",
    "                          idempotent_size             = cfg_model[\"idempotent_size\"],\n",
    "                          pos_enc_num_freqs           = cfg_model[\"positional_encoding\"][\"num_freqs\"],\n",
    "                          pos_enc_min_period          = cfg_model[\"positional_encoding\"][\"min_period\"],\n",
    "                          pos_enc_max_period          = cfg_model[\"positional_encoding\"][\"max_period\"],\n",
    "                          pos_enc_learnable           = cfg_model[\"positional_encoding\"][\"learnable\"],\n",
    "                          ndim_embedding              = cfg_model[\"ndim_embedding\"],\n",
    "                          num_encoder_blocks          = cfg_model[\"encoder\"][\"num_blocks\"],\n",
    "                          num_encoder_loops           = cfg_model[\"encoder\"][\"num_loops\"],\n",
    "                          ndim_encoder                = cfg_model[\"encoder\"][\"ndim\"],\n",
    "                          num_heads_encoder           = cfg_model[\"encoder\"][\"num_heads\"],\n",
    "                          ndim_att_hidden_encoder     = cfg_model[\"encoder\"][\"ndim_att_hidden\"],\n",
    "                          ndim_ff_hidden_encoder      = cfg_model[\"encoder\"][\"ndim_ff_hidden\"],\n",
    "                          skip_connect_encoder        = cfg_model[\"encoder\"][\"skip_connect\"],\n",
    "                          num_decoder_blocks          = cfg_model[\"decoder\"][\"num_blocks\"],\n",
    "                          num_decoder_loops           = cfg_model[\"decoder\"][\"num_loops\"],\n",
    "                          ndim_decoder                = cfg_model[\"decoder\"][\"ndim\"],\n",
    "                          num_heads_decoder           = cfg_model[\"decoder\"][\"num_heads\"],\n",
    "                          ndim_att_hidden_decoder     = cfg_model[\"decoder\"][\"ndim_att_hidden\"],\n",
    "                          ndim_ff_hidden_decoder      = cfg_model[\"decoder\"][\"ndim_ff_hidden\"],\n",
    "                          skip_connect_decoder        = cfg_model[\"decoder\"][\"skip_connect\"],\n",
    "                          num_post_layers_decoder     = cfg_model[\"post_decoder\"][\"num_layers\"],\n",
    "                          ndim_post_layers_decoder    = cfg_model[\"post_decoder\"][\"ndim\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bb6a53e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Creating new text-to-text model\n",
      "   INFO <module>: Model created with summary:\n",
      "   INFO <module>: Model: \"mathsformer_LLM\"\n",
      "   INFO <module>: __________________________________________________________________________________________________\n",
      "   INFO <module>:  Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "   INFO <module>: ==================================================================================================\n",
      "   INFO <module>:  mathsformer_LLM_encoder_input_  [(None, None)]      0           []                               \n",
      "   INFO <module>:  layer (InputLayer)                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_enumer  (None, None)        0           ['mathsformer_LLM_encoder_input_l\n",
      "   INFO <module>:  ate (Enumerate)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_embedd  (None, None, 128)   2048        ['mathsformer_LLM_encoder_input_l\n",
      "   INFO <module>:  ing (Embedding)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_positi  (None, None, 128)   64          ['mathsformer_LLM_encoder_enumera\n",
      "   INFO <module>:  on_encoding (PositionalEncodin                                  te[0][0]']                       \n",
      "   INFO <module>:  g)                                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_emb_an  (None, None, 128)   0           ['mathsformer_LLM_encoder_embeddi\n",
      "   INFO <module>:  d_pos (Average)                                                 ng[0][0]',                       \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_positio\n",
      "   INFO <module>:                                                                  n_encoding[0][0]']               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_block_  (None, None, 128)   561025      ['mathsformer_LLM_encoder_emb_and\n",
      "   INFO <module>:  1 (GradientFlowEncoder)                                         _pos[0][0]',                     \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n",
      "   INFO <module>:                                                                  [0][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n",
      "   INFO <module>:                                                                  [1][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n",
      "   INFO <module>:                                                                  [2][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n",
      "   INFO <module>:                                                                  [3][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n",
      "   INFO <module>:                                                                  [4][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n",
      "   INFO <module>:                                                                  [5][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_input_  [(None, None)]      0           []                               \n",
      "   INFO <module>:  layer (InputLayer)                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_enumer  (None, None)        0           ['mathsformer_LLM_decoder_input_l\n",
      "   INFO <module>:  ate (Enumerate)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_embedd  (None, None, 128)   2048        ['mathsformer_LLM_decoder_input_l\n",
      "   INFO <module>:  ing (Embedding)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_positi  (None, None, 128)   64          ['mathsformer_LLM_decoder_enumera\n",
      "   INFO <module>:  on_encoding (PositionalEncodin                                  te[0][0]']                       \n",
      "   INFO <module>:  g)                                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_emb_an  (None, None, 128)   0           ['mathsformer_LLM_decoder_embeddi\n",
      "   INFO <module>:  d_pos (Average)                                                 ng[0][0]',                       \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_positio\n",
      "   INFO <module>:                                                                  n_encoding[0][0]']               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_output  (None, None, 128)   256         ['mathsformer_LLM_encoder_block_1\n",
      "   INFO <module>:  _norm (LayerNormalization)                                      [6][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_block_  (None, None, 128)   1088768     ['mathsformer_LLM_decoder_emb_and\n",
      "   INFO <module>:  1 (DecoderBlock)                                                _pos[0][0]',                     \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_output_\n",
      "   INFO <module>:                                                                  norm[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_block_  (None, None, 128)   1088768     ['mathsformer_LLM_decoder_block_1\n",
      "   INFO <module>:  2 (DecoderBlock)                                                [0][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_output_\n",
      "   INFO <module>:                                                                  norm[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_output (FeedFo  (None, None, 16)    51856       ['mathsformer_LLM_decoder_block_2\n",
      "   INFO <module>:  rwardBlock)                                                     [0][0]']                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>: ==================================================================================================\n",
      "   INFO <module>: Total params: 2,794,897\n",
      "   INFO <module>: Trainable params: 2,794,897\n",
      "   INFO <module>: Non-trainable params: 0\n",
      "   INFO <module>: __________________________________________________________________________________________________\n",
      "   INFO <module>: Optimizer is <keras.optimizers.legacy.adam.Adam object at 0x281d71290>\n",
      "   INFO <module>: Learning rate is <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n"
     ]
    }
   ],
   "source": [
    "##===================================================##\n",
    "##   Load or create self-supervised learning model   ##\n",
    "##===================================================##\n",
    "\n",
    "##  Get filename for load model\n",
    "fname = cfg_model.get(\"load_pretrained_model\", None)\n",
    "\n",
    "##  Load model if fname is not None, otherwise create from scratch\n",
    "if fname is not None :\n",
    "    logger.info   (f\"Loading model from: {fname}\")\n",
    "    logger.warning(\"Loading a pretrained model will disregard model config!\")\n",
    "    model = backend.load_text_to_text_model(fname)\n",
    "    model.optimizer.learning_rate.assign(cfg_model[\"optimizer_args\"][\"learning_rate\"])  ## Reset LR to config value\n",
    "else :\n",
    "    logger.info(f\"Creating new text-to-text model\")\n",
    "    model = create_text_to_text_model_from_config(cfg_model, token_transform)\n",
    "\n",
    "##  Create hack to catch model summary\n",
    "model_summary = []\n",
    "model.summary(print_fn = lambda s : model_summary.append(s))\n",
    "\n",
    "##  Print model summary\n",
    "logger.info(\"Model created with summary:\")\n",
    "for s in model_summary : logger.info(s)\n",
    "    \n",
    "##  Print optimizer summary\n",
    "logger.info(f\"Optimizer is {model.optimizer}\")\n",
    "if hasattr(model.optimizer, \"learning_rate\") : logger.info(f\"Learning rate is {model.optimizer.learning_rate}\")\n",
    "if hasattr(model.optimizer, \"weight_decay\" ) : logger.info(f\"Weight decay is {model.optimizer.weight_decay}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "793493a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##==============================================================##\n",
    "##   Create transformer wrapper for model and token_transform   ##\n",
    "##==============================================================##\n",
    "\n",
    "transformer = transformers.Transformer_Text_to_Text(model, token_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "956e30a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO test_transformer: Running text --> text mathsformer inference on some training data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-25 16:09:40.258355: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x2842ea020> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x2842e9a80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m##=========================================##\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m##   Test transformer on data generators   ##\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m##=========================================##\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_char\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnegative_char\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PROJECTS/misc/ML-sandbox/ML-sandbox/Project_Maths_Transformer/mathsformer/selfsupervised_learning_addition_model_backend.py:715\u001b[0m, in \u001b[0;36mtest_transformer\u001b[0;34m(transformer, train_gen, val_gen, test_gen, num_print, max_tokens, max_col_length, negative_char, print_fn)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_gen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m :\n\u001b[1;32m    714\u001b[0m     print_fn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning text --> text mathsformer inference on some training data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 715\u001b[0m     \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_predictions_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_print\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_col_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_col_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_char\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnegative_char\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m##  Test transformer with validation generator\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_gen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m :\n",
      "File \u001b[0;32m~/PROJECTS/misc/ML-sandbox/ML-sandbox/Project_Maths_Transformer/mathsformer/transformers.py:437\u001b[0m, in \u001b[0;36mTransformer_Text_to_Text.print_predictions_table\u001b[0;34m(self, data_gen, num_print, print_fn, max_tokens, min_col_length, max_col_length, negative_char)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y_in, x_str, true_y_str \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X   [:num_print], \n\u001b[1;32m    433\u001b[0m                                       Y_in[:num_print],\n\u001b[1;32m    434\u001b[0m                                       X_str,\n\u001b[1;32m    435\u001b[0m                                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_transform\u001b[38;5;241m.\u001b[39mdetokenise_strings(Y_out[:num_print  ]\u001b[38;5;241m.\u001b[39mnumpy())) :\n\u001b[1;32m    436\u001b[0m     pred_y_str_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasked_transform_from_data_tensor(x, y_in, max_tokens\u001b[38;5;241m=\u001b[39mmax_tokens)\n\u001b[0;32m--> 437\u001b[0m     pred_y_str_gen  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_from_data_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX  \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pred_y_str_gen \u001b[38;5;241m==\u001b[39m true_y_str \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m    : residual \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(pred_y_str_gen\u001b[38;5;241m.\u001b[39mreplace(negative_char, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mint\u001b[39m(true_y_str\u001b[38;5;241m.\u001b[39mreplace(negative_char, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n",
      "File \u001b[0;32m~/PROJECTS/misc/ML-sandbox/ML-sandbox/Project_Maths_Transformer/mathsformer/transformers.py:523\u001b[0m, in \u001b[0;36mTransformer_Text_to_Text.transform_from_data_tensor\u001b[0;34m(self, X, max_tokens, device, strategy)\u001b[0m\n\u001b[1;32m    519\u001b[0m best_token, num_tokens \u001b[38;5;241m=\u001b[39m start_token, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m best_token \u001b[38;5;241m!=\u001b[39m end_token \u001b[38;5;129;01mand\u001b[39;00m (max_tokens \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m num_tokens \u001b[38;5;241m<\u001b[39m max_tokens) :\n\u001b[1;32m    521\u001b[0m     \n\u001b[1;32m    522\u001b[0m     \u001b[38;5;66;03m##  Generate logit predictions for all indices; slice logits for first sequence & final index\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m     token_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(token_logits) \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mset\u001b[39m, \u001b[38;5;28mtuple\u001b[39m] :\n\u001b[1;32m    525\u001b[0m         token_logits \u001b[38;5;241m=\u001b[39m token_logits[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/keras/engine/training.py:558\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    556\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[0;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/keras/engine/base_layer.py:1145\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1144\u001b[0m ):\n\u001b[0;32m-> 1145\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/keras/engine/functional.py:512\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    495\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \n\u001b[1;32m    497\u001b[0m \u001b[38;5;124;03m    In this case `call` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/keras/engine/functional.py:669\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[0;32m--> 669\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    673\u001b[0m     node\u001b[38;5;241m.\u001b[39mflat_output_ids, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(outputs)\n\u001b[1;32m    674\u001b[0m ):\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/keras/engine/base_layer.py:1145\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1144\u001b[0m ):\n\u001b[0;32m-> 1145\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 22\u001b[0m, in \u001b[0;36mGradientFlowEncoder.call\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m     y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msigmoid(y)\n\u001b[1;32m     20\u001b[0m     y \u001b[38;5;241m=\u001b[39m y[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, tf\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m---> 22\u001b[0m div \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m div \u001b[38;5;241m=\u001b[39m div[:,\u001b[38;5;241m0\u001b[39m,:,:]       \n\u001b[1;32m     24\u001b[0m lam \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weight)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py:1314\u001b[0m, in \u001b[0;36mGradientTape.batch_jacobian\u001b[0;34m(self, target, source, unconnected_gradients, parallel_iterations, experimental_use_pfor)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experimental_use_pfor:\n\u001b[1;32m   1313\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1314\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mpfor_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpfor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_row_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered an exception while vectorizing the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_jacobian computation. Vectorization can be disabled by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetting experimental_use_pfor to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:214\u001b[0m, in \u001b[0;36mpfor\u001b[0;34m(loop_fn, iters, fallback_to_while_loop, parallel_iterations, warn)\u001b[0m\n\u001b[1;32m    211\u001b[0m     def_function\u001b[38;5;241m.\u001b[39mrun_functions_eagerly(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    212\u001b[0m   f \u001b[38;5;241m=\u001b[39m def_function\u001b[38;5;241m.\u001b[39mfunction(f)\n\u001b[0;32m--> 214\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m functions_run_eagerly \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m   def_function\u001b[38;5;241m.\u001b[39mrun_functions_eagerly(functions_run_eagerly)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 942\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    768\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 171\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:667\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    664\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    665\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 667\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1189\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/__autograph_generated_filem5t3pij0.py:17\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__f\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_pfor_impl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfallback_to_while_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfallback_to_while_loop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwarn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:340\u001b[0m, in \u001b[0;36m_pfor_impl\u001b[0;34m(loop_fn, iters, fallback_to_while_loop, parallel_iterations, pfor_config, warn)\u001b[0m\n\u001b[1;32m    338\u001b[0m     flattened_output_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loop_fn_output \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten(loop_fn_output_tensors):\n\u001b[0;32m--> 340\u001b[0m       output \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop_fn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m       flattened_output_tensors\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1424\u001b[0m, in \u001b[0;36mPFor.convert\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_sparse(y)\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, (ops\u001b[38;5;241m.\u001b[39mTensor, ops\u001b[38;5;241m.\u001b[39mOperation)), y\n\u001b[0;32m-> 1424\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, WrappedTensor):\n\u001b[1;32m   1426\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, ops\u001b[38;5;241m.\u001b[39mTensor)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1625\u001b[0m, in \u001b[0;36mPFor._convert_helper\u001b[0;34m(self, op_or_tensor)\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1624\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1625\u001b[0m     new_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpfor_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1626\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConversionNotImplementedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1627\u001b[0m     has_vectorized_variant_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m   1628\u001b[0m         _is_variant_with_internal_stacking(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m         y_op\u001b[38;5;241m.\u001b[39minputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3105\u001b[0m, in \u001b[0;36m_convert_cwise\u001b[0;34m(pfor_input)\u001b[0m\n\u001b[1;32m   2996\u001b[0m \u001b[38;5;129m@RegisterPFor\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2997\u001b[0m \u001b[38;5;129m@RegisterPFor\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2998\u001b[0m \u001b[38;5;129m@RegisterPFor\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcosh\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;129m@RegisterPFor\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZeta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_cwise\u001b[39m(pfor_input):\n\u001b[1;32m   3104\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m pfor_input\u001b[38;5;241m.\u001b[39mnum_inputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 3105\u001b[0m     \u001b[43mpfor_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpanddim_inputs_for_broadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3107\u001b[0m   out \u001b[38;5;241m=\u001b[39m _create_op(\n\u001b[1;32m   3108\u001b[0m       pfor_input\u001b[38;5;241m.\u001b[39mop_type, [x\u001b[38;5;241m.\u001b[39mt \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m pfor_input\u001b[38;5;241m.\u001b[39minputs],\n\u001b[1;32m   3109\u001b[0m       [x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m pfor_input\u001b[38;5;241m.\u001b[39moutputs],\n\u001b[1;32m   3110\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mpfor_input\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mnode_def\u001b[38;5;241m.\u001b[39mattr)\u001b[38;5;241m.\u001b[39moutputs\n\u001b[1;32m   3111\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/ops/parallel_for/pfor.py:844\u001b[0m, in \u001b[0;36m_PforInput.expanddim_inputs_for_broadcast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    841\u001b[0m     rank \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    842\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m rank\n\u001b[0;32m--> 844\u001b[0m ranks \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m_get_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inputs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m max_rank \u001b[38;5;241m=\u001b[39m ranks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rank \u001b[38;5;129;01min\u001b[39;00m ranks[\u001b[38;5;241m1\u001b[39m:]:\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/ops/parallel_for/pfor.py:844\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    841\u001b[0m     rank \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    842\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m rank\n\u001b[0;32m--> 844\u001b[0m ranks \u001b[38;5;241m=\u001b[39m [\u001b[43m_get_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs]\n\u001b[1;32m    845\u001b[0m max_rank \u001b[38;5;241m=\u001b[39m ranks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rank \u001b[38;5;129;01min\u001b[39;00m ranks[\u001b[38;5;241m1\u001b[39m:]:\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/ops/parallel_for/pfor.py:839\u001b[0m, in \u001b[0;36m_PforInput.expanddim_inputs_for_broadcast.<locals>._get_rank\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_rank\u001b[39m(x):\n\u001b[0;32m--> 839\u001b[0m   rank \u001b[38;5;241m=\u001b[39m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    840\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mis_stacked:\n\u001b[1;32m    841\u001b[0m     rank \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/ops/array_ops.py:875\u001b[0m, in \u001b[0;36mrank\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    843\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrank\u001b[39m(\u001b[38;5;28minput\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    845\u001b[0m   \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the rank of a tensor.\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \n\u001b[1;32m    848\u001b[0m \u001b[38;5;124;03m  See also `tf.shape`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;124;03m  @end_compatibility\u001b[39;00m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 875\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrank_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/ops/array_ops.py:898\u001b[0m, in \u001b[0;36mrank_internal\u001b[0;34m(input, name, optimize)\u001b[0m\n\u001b[1;32m    896\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mget_shape()\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimize \u001b[38;5;129;01mand\u001b[39;00m input_shape\u001b[38;5;241m.\u001b[39mndims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 898\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gen_array_ops\u001b[38;5;241m.\u001b[39mrank(\u001b[38;5;28minput\u001b[39m, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:268\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    173\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:290\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    288\u001b[0m dtype_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    289\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: tensor_value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype_value}\n\u001b[0;32m--> 290\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_callbacks\u001b[38;5;241m.\u001b[39mshould_invoke_op_callbacks():\n\u001b[1;32m    294\u001b[0m   \u001b[38;5;66;03m# TODO(b/147670703): Once the special-op creation code paths\u001b[39;00m\n\u001b[1;32m    295\u001b[0m   \u001b[38;5;66;03m# are unified. Remove this `if` block.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m   callback_outputs \u001b[38;5;241m=\u001b[39m op_callbacks\u001b[38;5;241m.\u001b[39minvoke_op_callbacks(\n\u001b[1;32m    297\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(), attrs, (const_tensor,), op_name\u001b[38;5;241m=\u001b[39mname, graph\u001b[38;5;241m=\u001b[39mg)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:707\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    705\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[1;32m    706\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[0;32m--> 707\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:3814\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 3814\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3815\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3816\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3817\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3818\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3819\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3820\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3821\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3822\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3823\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[1;32m   3824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:2122\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_control_flow_post_processing(input_tensors\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m   2120\u001b[0m \u001b[38;5;66;03m# Removes this frame from the Python traceback.\u001b[39;00m\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;66;03m# We adjust stacklevel directly to avoid triggering serialization.\u001b[39;00m\n\u001b[0;32m-> 2122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraceback\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2123\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraceback\u001b[38;5;241m.\u001b[39m_stacklevel \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_macos_2p12_modified_230623/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:2631\u001b[0m, in \u001b[0;36mOperation.traceback\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2628\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the call stack from when this operation was constructed.\"\"\"\u001b[39;00m\n\u001b[1;32m   2629\u001b[0m \u001b[38;5;66;03m# FIXME(b/225423591): This object contains a dangling reference if _c_op\u001b[39;00m\n\u001b[1;32m   2630\u001b[0m \u001b[38;5;66;03m# goes out of scope.\u001b[39;00m\n\u001b[0;32m-> 2631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_OperationGetStackTrace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_op\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##=========================================##\n",
    "##   Test transformer on data generators   ##\n",
    "##=========================================##\n",
    "\n",
    "backend.test_transformer(transformer, train_gen, val_gen, test_gen, negative_char=negative_char)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f7a52",
   "metadata": {},
   "source": [
    "##  5.  Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aea411fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO get_callbacks: Registered training callback: LoggerCallback with loglvl=10\n",
      "   INFO get_callbacks: Registered training callback: AdaptiveLearningRate with decay_factor=0.2, patience=3, monitor=loss, mode=min, log_lvl=10\n",
      "   INFO get_callbacks: Registered training callback: ModelCheckpoint with filepath=SSL_loopy_gredenc_dec_notebook_int1234_num1245_embed128_enc_1blocks_7loops_width128_dec_2blocks_1loops_width128_post3_width128_idemm1_2023_06_25_v3/model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.keras\n",
      "   INFO get_callbacks: Registered training callback: LayerWeightsRecord with batch_frequency=2000, recursive=True\n",
      "   INFO get_callbacks: Registered training callback: LambdaCallback for test_transformer with num_print=10, negative_char='N'\n"
     ]
    }
   ],
   "source": [
    "##===================================##\n",
    "##   Create callbacks for training   ##\n",
    "##===================================##\n",
    "\n",
    "callbacks = backend.get_callbacks(cfg_training, working_dir, transformer=transformer, train_gen=train_gen_reproducible, \n",
    "                                  val_gen=val_gen, negative_char=negative_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21d1736d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Begin model training with max_epochs=100000\n",
      "Epoch 1/100000\n",
      "1000/1000 [==============================] - 720s 705ms/step - loss: 1.9155 - masked_categorical_accuracy: 0.3530 - val_loss: 1.9793 - val_masked_categorical_accuracy: 0.3272\n",
      "Epoch 2/100000\n",
      "1000/1000 [==============================] - 723s 723ms/step - loss: 1.7911 - masked_categorical_accuracy: 0.3657 - val_loss: 2.0211 - val_masked_categorical_accuracy: 0.3284\n",
      "Epoch 3/100000\n",
      "1000/1000 [==============================] - 724s 724ms/step - loss: 1.7366 - masked_categorical_accuracy: 0.3880 - val_loss: 1.9784 - val_masked_categorical_accuracy: 0.3246\n",
      "Epoch 4/100000\n",
      "1000/1000 [==============================] - 642s 642ms/step - loss: 1.4626 - masked_categorical_accuracy: 0.4967 - val_loss: 1.9365 - val_masked_categorical_accuracy: 0.3370\n",
      "Epoch 5/100000\n",
      "1000/1000 [==============================] - 521s 521ms/step - loss: 1.4188 - masked_categorical_accuracy: 0.5046 - val_loss: 1.9314 - val_masked_categorical_accuracy: 0.3436\n",
      "Epoch 6/100000\n",
      "1000/1000 [==============================] - 506s 507ms/step - loss: 1.3892 - masked_categorical_accuracy: 0.5132 - val_loss: 1.8925 - val_masked_categorical_accuracy: 0.3504\n",
      "Epoch 7/100000\n",
      "1000/1000 [==============================] - 514s 514ms/step - loss: 1.3693 - masked_categorical_accuracy: 0.5179 - val_loss: 1.8905 - val_masked_categorical_accuracy: 0.3607\n",
      "Epoch 8/100000\n",
      "1000/1000 [==============================] - 512s 513ms/step - loss: 1.3549 - masked_categorical_accuracy: 0.5210 - val_loss: 1.8882 - val_masked_categorical_accuracy: 0.3660\n",
      "Epoch 9/100000\n",
      "1000/1000 [==============================] - 509s 509ms/step - loss: 1.3404 - masked_categorical_accuracy: 0.5247 - val_loss: 1.9092 - val_masked_categorical_accuracy: 0.3720\n",
      "Epoch 10/100000\n",
      "1000/1000 [==============================] - 515s 515ms/step - loss: 1.3306 - masked_categorical_accuracy: 0.5257 - val_loss: 1.8319 - val_masked_categorical_accuracy: 0.3741\n",
      "Epoch 11/100000\n",
      "1000/1000 [==============================] - 520s 520ms/step - loss: 1.3119 - masked_categorical_accuracy: 0.5326 - val_loss: 1.7878 - val_masked_categorical_accuracy: 0.3765\n",
      "Epoch 12/100000\n",
      "1000/1000 [==============================] - 512s 513ms/step - loss: 1.3165 - masked_categorical_accuracy: 0.5287 - val_loss: 1.7904 - val_masked_categorical_accuracy: 0.3904\n",
      "Epoch 13/100000\n",
      "1000/1000 [==============================] - 514s 514ms/step - loss: 1.3063 - masked_categorical_accuracy: 0.5309 - val_loss: 1.7794 - val_masked_categorical_accuracy: 0.3902\n",
      "Epoch 14/100000\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 1.3079 - masked_categorical_accuracy: 0.5303 - val_loss: 1.7276 - val_masked_categorical_accuracy: 0.3986\n",
      "Epoch 15/100000\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 1.2894 - masked_categorical_accuracy: 0.5378 - val_loss: 1.7555 - val_masked_categorical_accuracy: 0.3978\n",
      "Epoch 16/100000\n",
      "1000/1000 [==============================] - 517s 517ms/step - loss: 1.2875 - masked_categorical_accuracy: 0.5363 - val_loss: 1.7095 - val_masked_categorical_accuracy: 0.4055\n",
      "Epoch 17/100000\n",
      "1000/1000 [==============================] - 522s 522ms/step - loss: 1.2761 - masked_categorical_accuracy: 0.5397 - val_loss: 1.7161 - val_masked_categorical_accuracy: 0.4069\n",
      "Epoch 18/100000\n",
      "1000/1000 [==============================] - 522s 522ms/step - loss: 1.2696 - masked_categorical_accuracy: 0.5398 - val_loss: 1.6893 - val_masked_categorical_accuracy: 0.4093\n",
      "Epoch 19/100000\n",
      "1000/1000 [==============================] - 519s 519ms/step - loss: 1.2720 - masked_categorical_accuracy: 0.5387 - val_loss: 1.6972 - val_masked_categorical_accuracy: 0.4070\n",
      "Epoch 20/100000\n",
      "1000/1000 [==============================] - 521s 521ms/step - loss: 1.2627 - masked_categorical_accuracy: 0.5423 - val_loss: 1.7003 - val_masked_categorical_accuracy: 0.4051\n",
      "Epoch 21/100000\n",
      "1000/1000 [==============================] - 519s 519ms/step - loss: 1.2553 - masked_categorical_accuracy: 0.5439 - val_loss: 1.6599 - val_masked_categorical_accuracy: 0.4185\n",
      "Epoch 22/100000\n",
      "1000/1000 [==============================] - 523s 523ms/step - loss: 1.2524 - masked_categorical_accuracy: 0.5443 - val_loss: 1.6616 - val_masked_categorical_accuracy: 0.4144\n",
      "Epoch 23/100000\n",
      "1000/1000 [==============================] - 523s 524ms/step - loss: 1.2541 - masked_categorical_accuracy: 0.5434 - val_loss: 1.6151 - val_masked_categorical_accuracy: 0.4208\n",
      "Epoch 24/100000\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 1.2533 - masked_categorical_accuracy: 0.5426 - val_loss: 1.6333 - val_masked_categorical_accuracy: 0.4153\n",
      "Epoch 25/100000\n",
      "1000/1000 [==============================] - 517s 517ms/step - loss: 1.2421 - masked_categorical_accuracy: 0.5461 - val_loss: 1.6115 - val_masked_categorical_accuracy: 0.4199\n",
      "Epoch 26/100000\n",
      "1000/1000 [==============================] - 522s 522ms/step - loss: 1.2447 - masked_categorical_accuracy: 0.5445 - val_loss: 1.6463 - val_masked_categorical_accuracy: 0.4269\n",
      "Epoch 27/100000\n",
      "1000/1000 [==============================] - 521s 521ms/step - loss: 1.2433 - masked_categorical_accuracy: 0.5448 - val_loss: 1.5888 - val_masked_categorical_accuracy: 0.4267\n",
      "Epoch 28/100000\n",
      "1000/1000 [==============================] - 520s 520ms/step - loss: 1.2326 - masked_categorical_accuracy: 0.5479 - val_loss: 1.5799 - val_masked_categorical_accuracy: 0.4326\n",
      "Epoch 29/100000\n",
      "1000/1000 [==============================] - 522s 522ms/step - loss: 1.2358 - masked_categorical_accuracy: 0.5465 - val_loss: 1.6046 - val_masked_categorical_accuracy: 0.4274\n",
      "Epoch 30/100000\n",
      "1000/1000 [==============================] - 520s 521ms/step - loss: 1.2210 - masked_categorical_accuracy: 0.5516 - val_loss: 1.5661 - val_masked_categorical_accuracy: 0.4359\n",
      "Epoch 31/100000\n",
      "1000/1000 [==============================] - 517s 517ms/step - loss: 1.2223 - masked_categorical_accuracy: 0.5514 - val_loss: 1.5854 - val_masked_categorical_accuracy: 0.4341\n",
      "Epoch 32/100000\n",
      "1000/1000 [==============================] - 574s 575ms/step - loss: 1.2195 - masked_categorical_accuracy: 0.5518 - val_loss: 1.5625 - val_masked_categorical_accuracy: 0.4360\n",
      "Epoch 33/100000\n",
      "1000/1000 [==============================] - 642s 642ms/step - loss: 1.2084 - masked_categorical_accuracy: 0.5567 - val_loss: 1.5224 - val_masked_categorical_accuracy: 0.4474\n",
      "Epoch 34/100000\n",
      "1000/1000 [==============================] - 643s 643ms/step - loss: 1.2034 - masked_categorical_accuracy: 0.5571 - val_loss: 1.5305 - val_masked_categorical_accuracy: 0.4428\n",
      "Epoch 35/100000\n",
      "1000/1000 [==============================] - 647s 647ms/step - loss: 1.2094 - masked_categorical_accuracy: 0.5562 - val_loss: 1.5365 - val_masked_categorical_accuracy: 0.4471\n",
      "Epoch 36/100000\n",
      "1000/1000 [==============================] - 654s 654ms/step - loss: 1.1955 - masked_categorical_accuracy: 0.5595 - val_loss: 1.5355 - val_masked_categorical_accuracy: 0.4432\n",
      "Epoch 37/100000\n",
      "1000/1000 [==============================] - 652s 652ms/step - loss: 1.1891 - masked_categorical_accuracy: 0.5613 - val_loss: 1.4949 - val_masked_categorical_accuracy: 0.4543\n",
      "Epoch 38/100000\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 1.1846 - masked_categorical_accuracy: 0.5621 - val_loss: 1.5041 - val_masked_categorical_accuracy: 0.4499\n",
      "Epoch 39/100000\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 1.1821 - masked_categorical_accuracy: 0.5643 - val_loss: 1.4788 - val_masked_categorical_accuracy: 0.4535\n",
      "Epoch 40/100000\n",
      "1000/1000 [==============================] - 649s 650ms/step - loss: 1.1759 - masked_categorical_accuracy: 0.5646 - val_loss: 1.4891 - val_masked_categorical_accuracy: 0.4540\n",
      "Epoch 41/100000\n",
      "1000/1000 [==============================] - 651s 651ms/step - loss: 1.1814 - masked_categorical_accuracy: 0.5628 - val_loss: 1.4805 - val_masked_categorical_accuracy: 0.4584\n",
      "Epoch 42/100000\n",
      "1000/1000 [==============================] - 645s 645ms/step - loss: 1.1767 - masked_categorical_accuracy: 0.5656 - val_loss: 1.4899 - val_masked_categorical_accuracy: 0.4540\n",
      "Epoch 43/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 662s 662ms/step - loss: 1.1719 - masked_categorical_accuracy: 0.5657 - val_loss: 1.4998 - val_masked_categorical_accuracy: 0.4567\n",
      "Epoch 44/100000\n",
      "1000/1000 [==============================] - 650s 651ms/step - loss: 1.1661 - masked_categorical_accuracy: 0.5682 - val_loss: 1.4862 - val_masked_categorical_accuracy: 0.4553\n",
      "Epoch 45/100000\n",
      "1000/1000 [==============================] - 647s 647ms/step - loss: 1.1627 - masked_categorical_accuracy: 0.5689 - val_loss: 1.4942 - val_masked_categorical_accuracy: 0.4558\n",
      "Epoch 46/100000\n",
      "1000/1000 [==============================] - 651s 651ms/step - loss: 1.1523 - masked_categorical_accuracy: 0.5726 - val_loss: 1.4764 - val_masked_categorical_accuracy: 0.4616\n",
      "Epoch 47/100000\n",
      "1000/1000 [==============================] - 654s 654ms/step - loss: 1.1626 - masked_categorical_accuracy: 0.5689 - val_loss: 1.4668 - val_masked_categorical_accuracy: 0.4626\n",
      "Epoch 48/100000\n",
      "1000/1000 [==============================] - 654s 654ms/step - loss: 1.1541 - masked_categorical_accuracy: 0.5707 - val_loss: 1.4472 - val_masked_categorical_accuracy: 0.4634\n",
      "Epoch 49/100000\n",
      "1000/1000 [==============================] - 647s 648ms/step - loss: 1.1486 - masked_categorical_accuracy: 0.5739 - val_loss: 1.4684 - val_masked_categorical_accuracy: 0.4665\n",
      "Epoch 50/100000\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 1.1433 - masked_categorical_accuracy: 0.5748 - val_loss: 1.4521 - val_masked_categorical_accuracy: 0.4643\n",
      "Epoch 51/100000\n",
      "1000/1000 [==============================] - 660s 660ms/step - loss: 1.1429 - masked_categorical_accuracy: 0.5748 - val_loss: 1.4388 - val_masked_categorical_accuracy: 0.4682\n",
      "Epoch 52/100000\n",
      "1000/1000 [==============================] - 648s 649ms/step - loss: 1.1404 - masked_categorical_accuracy: 0.5765 - val_loss: 1.4337 - val_masked_categorical_accuracy: 0.4770\n",
      "Epoch 53/100000\n",
      "1000/1000 [==============================] - 645s 645ms/step - loss: 1.1354 - masked_categorical_accuracy: 0.5783 - val_loss: 1.4446 - val_masked_categorical_accuracy: 0.4674\n",
      "Epoch 54/100000\n",
      "1000/1000 [==============================] - 654s 654ms/step - loss: 1.1359 - masked_categorical_accuracy: 0.5778 - val_loss: 1.4475 - val_masked_categorical_accuracy: 0.4705\n",
      "Epoch 55/100000\n",
      "1000/1000 [==============================] - 655s 655ms/step - loss: 1.1311 - masked_categorical_accuracy: 0.5793 - val_loss: 1.4313 - val_masked_categorical_accuracy: 0.4690\n",
      "Epoch 56/100000\n",
      "1000/1000 [==============================] - 652s 653ms/step - loss: 1.1269 - masked_categorical_accuracy: 0.5834 - val_loss: 1.4598 - val_masked_categorical_accuracy: 0.4631\n",
      "Epoch 57/100000\n",
      "1000/1000 [==============================] - 662s 662ms/step - loss: 1.1182 - masked_categorical_accuracy: 0.5850 - val_loss: 1.4416 - val_masked_categorical_accuracy: 0.4642\n",
      "Epoch 58/100000\n",
      "1000/1000 [==============================] - 652s 652ms/step - loss: 1.1141 - masked_categorical_accuracy: 0.5862 - val_loss: 1.4325 - val_masked_categorical_accuracy: 0.4687\n",
      "Epoch 59/100000\n",
      "1000/1000 [==============================] - 655s 655ms/step - loss: 1.1158 - masked_categorical_accuracy: 0.5854 - val_loss: 1.4331 - val_masked_categorical_accuracy: 0.4690\n",
      "Epoch 60/100000\n",
      "1000/1000 [==============================] - 652s 652ms/step - loss: 1.1026 - masked_categorical_accuracy: 0.5911 - val_loss: 1.4297 - val_masked_categorical_accuracy: 0.4709\n",
      "Epoch 61/100000\n",
      " 425/1000 [===========>..................] - ETA: 4:01 - loss: 1.0962 - masked_categorical_accuracy: 0.5942"
     ]
    }
   ],
   "source": [
    "##=================##\n",
    "##   Train model   ##\n",
    "##=================##\n",
    "\n",
    "do_train = cfg_training.get(\"train\", True)\n",
    "\n",
    "if do_train :\n",
    "    max_epochs = cfg_training[\"max_epochs\"]\n",
    "    logger.info(f\"Begin model training with max_epochs={max_epochs}\")\n",
    "    model.fit(train_gen, \n",
    "              epochs          = max_epochs,\n",
    "              validation_data = val_gen,\n",
    "              callbacks       = callbacks\n",
    "             )\n",
    "else :\n",
    "    logger.warning(\"Skipping model training following global config instructions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fb38943",
   "metadata": {},
   "outputs": [],
   "source": [
    "##================##\n",
    "##   Save model   ##\n",
    "##================##\n",
    "\n",
    "do_save = cfg_evaluate.get(\"save_model\", True)\n",
    "\n",
    "if do_save :\n",
    "    save_fname = f\"{working_dir}/final_model.keras\"\n",
    "    model.save(save_fname)\n",
    "    logger.info(f\"Model saved to file {save_fname}\")\n",
    "else :\n",
    "    logger.warning(\"Not saving model because no training was done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc69448",
   "metadata": {},
   "source": [
    "## 6.  Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04c425ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "  \n",
    "##  Find out how many datapoints to print predictions for \n",
    "num_print = cfg_evaluate.get(\"num_print\", 20)\n",
    "\n",
    "##  Print tables\n",
    "backend.test_transformer(transformer, train_gen, val_gen, test_gen, num_print=num_print, \n",
    "                         negative_char=negative_char)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfb55b",
   "metadata": {},
   "source": [
    "##  7. Additional visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e385e68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##=============================================##\n",
    "##   Visualise layer weights during training   ##\n",
    "##=============================================##\n",
    "\n",
    "if cfg_evaluate[\"plot_weights\"] :\n",
    "    \n",
    "    logger.info(\"Plotting weights\")\n",
    "    backend.plot_weights(callbacks, show=True, close=True, savefig=f\"{working_dir}/layer_weights.pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0508f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "##===============================##\n",
    "##   Visualise training curves   ##\n",
    "##===============================##\n",
    "\n",
    "if cfg_evaluate[\"plot_training_curves\"] :\n",
    "    \n",
    "    if not hasattr(model, \"history\") :\n",
    "        logger.error(\"Cannot print training curves because no model history exists - perhaps you skipped training?\")\n",
    "    else :\n",
    "        logger.info(\"Plotting training curves\")\n",
    "        backend.plot_training_curves(model.history.history, show=True, close=True, savefig=f\"{working_dir}/training_curves.pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44387f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
