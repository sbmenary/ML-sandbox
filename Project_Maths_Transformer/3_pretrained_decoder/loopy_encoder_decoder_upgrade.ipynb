{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884dc59d",
   "metadata": {},
   "source": [
    "#  Unsupervised learning addition model with generator  -  using loopy encoder and decoder method\n",
    "\n",
    "Author: S. Menary [sbmenary@gmail.com]\n",
    "\n",
    "Date: 15/6/2023  (last update: 28/6/2023)\n",
    "\n",
    "Overview: Train a `sequence -> sequence` model where the input sequence is a text representation of a simple sum $\\sum_{i=1}^N A_i$ for a configurable number $N$ of integers $A_i\\in\\mathbb{Z}$, and the output is a set of logits representing the probability of each token in the output sequence. Integers may have a configurable number of digits. At inference time, chains of text are generated auto-regressively until the terminate-sequence token is reached. The loss function is a sparse categorical entropy.\n",
    "\n",
    "In this notebook, we implement transformer loops, idempotent mappings and extra configuration options such as encoder pre-loop layers (intended to govern representational shift).\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Set up program\n",
    "\n",
    "###  Import\n",
    "\n",
    "All imports go here at the top of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48f1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "##=========================##\n",
    "##   All imports go here   ##\n",
    "##=========================##\n",
    "\n",
    "##  Import entire python stdlib packages\n",
    "import logging, os, sys\n",
    "\n",
    "##  Import entire pypi packages\n",
    "import tensorflow as tf\n",
    "\n",
    "##  Remove tensorflow INFO messages\n",
    "tf.get_logger().setLevel('WARNING')\n",
    "\n",
    "##  Add directory above this to system path to expose mathsformer package location\n",
    "sys.path.append(\"/\".join(os.getcwd().split(\"/\")[:-1]))\n",
    "\n",
    "##  Import individual modules/objects from local packages\n",
    "from tensorflow.keras.optimizers.legacy import Adam, SGD\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from mathsformer import config, data, transformers, utils\n",
    "from mathsformer import selfsupervised_learning_addition_model_backend as backend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320886f9",
   "metadata": {},
   "source": [
    "## 1. Configure run\n",
    "\n",
    "Set configuration variables for entire program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701cef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##==============================##\n",
    "##   Set custom config values   ##\n",
    "##==============================##\n",
    "\n",
    "custom_config = {\n",
    "    \"global\" : {\n",
    "        \"base_seed\"        : -1,\n",
    "        \"working_dir\"      : \"SSL_loopy_enc_dec_notebook_[global>problem_tag]_embed[model>ndim_embedding]_enc_[model>encoder>num_blocks]blocks_[model>encoder>num_loops]loops_width[model>encoder>ndim_ff_hidden]_dec_[model>decoder>num_blocks]blocks_[model>decoder>num_loops]loops_width[model>decoder>ndim_ff_hidden]_post[model>post_decoder>num_layers]_width[model>post_decoder>ndim]_idem[model>idempotent_size]_[date]\",\n",
    "        \"problem_tag\"      : \"int1234_num1245\",\n",
    "        \"log_lvl_iostream\" : logging.INFO,\n",
    "        \"log_lvl_fstream\"  : logging.DEBUG,\n",
    "    },\n",
    "    \"data\" : {\n",
    "        \"train_data\" : {\n",
    "            \"int_lengths\"      : [1, 2, 3, 4],\n",
    "            \"num_ints\"         : [1, 2, 4, 5],\n",
    "            \"batch_size\"       : 16,\n",
    "            \"num_batches\"      : 1000,\n",
    "            \"gen_base_seed\"    : 104,\n",
    "            \"gen_reproducible\" : False, \n",
    "        },\n",
    "        \"val_data\" : {\n",
    "            \"int_lengths\"      : [1, 2, 3, 4],\n",
    "            \"num_ints\"         : [3, 6],\n",
    "            \"batch_size\"       : 32,\n",
    "            \"num_batches\"      : 40,\n",
    "            \"gen_base_seed\"    : 105,\n",
    "            \"gen_reproducible\" : True,\n",
    "        },\n",
    "        \"test_data\" : {\n",
    "            \"int_lengths\"      : [1, 2, 3, 4],\n",
    "            \"num_ints\"         : [7, 8],\n",
    "            \"batch_size\"       : 32,\n",
    "            \"num_batches\"      : 100,\n",
    "            \"gen_base_seed\"    : 106,\n",
    "            \"gen_reproducible\" : True,\n",
    "        },\n",
    "        \"characters\"              : ['M', 'B', 'E', 'N', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-'],\n",
    "        \"mask_char\"               : 'M',\n",
    "        \"seq_start_char\"          : 'B',\n",
    "        \"seq_end_char\"            : 'E',\n",
    "        \"negative_char\"           : 'N',\n",
    "        \"dtype\"                   : \"int32\",\n",
    "    },\n",
    "    \"model\" : {\n",
    "        \"load_pretrained_model\" : None,\n",
    "        \"name\"                  : \"mathsformer_LLM\",\n",
    "        \"dtype\"                 : \"float32\",\n",
    "        \"dropout\"               : 0.1,\n",
    "        \"jit_compile\"           : False,\n",
    "        \"use_old_loss\"          : True,\n",
    "        \"optimizer\"             : AdamW,\n",
    "        \"optimizer_args\"        : {\"learning_rate\":5e-4, \"weight_decay\":2e-2},\n",
    "        \"idempotent_size\"       : 2,\n",
    "        \"positional_encoding\" : {\n",
    "            \"num_freqs\"         : 80,\n",
    "            \"min_period\"        : 4,\n",
    "            \"max_period\"        : 1000,\n",
    "            \"learnable\"         : False,\n",
    "        },\n",
    "        \"ndim_embedding\"        : 160,\n",
    "        \"comb_type\"             : 'mixture',\n",
    "        \"pre_encoder\" : {\n",
    "            \"num_blocks\"           : 2,\n",
    "            \"num_loops\"            : 1,\n",
    "            \"num_heads\"            : 8,\n",
    "            \"ndim\"                 : 160,\n",
    "            \"ndim_att_hidden\"      : 160,\n",
    "            \"ndim_ff_hidden\"       : 800,\n",
    "            \"skip_connect\"         : True,\n",
    "            \"mixture_skip_connect\" : True,\n",
    "        },\n",
    "        \"encoder\" : {\n",
    "            \"num_blocks\"           : 2,\n",
    "            \"num_loops\"            : 8,\n",
    "            \"num_heads\"            : 8,\n",
    "            \"ndim\"                 : 160,\n",
    "            \"ndim_att_hidden\"      : 160,\n",
    "            \"ndim_ff_hidden\"       : 800,\n",
    "            \"skip_connect\"         : True,\n",
    "            \"mixture_skip_connect\" : True,\n",
    "        },\n",
    "        \"decoder\" : {\n",
    "            \"num_blocks\"           : 2,\n",
    "            \"num_loops\"            : 1,\n",
    "            \"num_heads\"            : 8,\n",
    "            \"ndim\"                 : 160,\n",
    "            \"ndim_att_hidden\"      : 160,\n",
    "            \"ndim_ff_hidden\"       : 800,\n",
    "            \"skip_connect\"         : True,\n",
    "            \"mixture_skip_connect\" : True,\n",
    "        },\n",
    "        \"post_decoder\" : {\n",
    "            \"num_layers\"        : 3,\n",
    "            \"ndim\"              : 800,\n",
    "        },\n",
    "    },\n",
    "    \"training\" : {\n",
    "        \"train\"          : True,\n",
    "        \"max_epochs\"     : 100000,\n",
    "        \"log_after_epoch\" : {\n",
    "            \"do\"          : True,\n",
    "            \"log_lvl\"     : logging.DEBUG,\n",
    "        },\n",
    "        \"early_stopping\" : {\n",
    "            \"do\"                   : False,\n",
    "            \"patience\"             : 6,\n",
    "            \"monitor\"              : \"loss\",\n",
    "            \"mode\"                 : \"min\",\n",
    "            \"restore_best_weights\" : True,\n",
    "        },\n",
    "        \"model_checkpoint\" : {\n",
    "            \"do\"       : True,\n",
    "            \"filename\" : \"model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.keras\",\n",
    "        },\n",
    "        \"layer_weights_record\" : {\n",
    "            \"do\"               : True,\n",
    "            \"batch_frequency\"  : 2000,\n",
    "            \"recursive\"        : True,\n",
    "        },\n",
    "        \"adaptive_learning_rate\" : {\n",
    "            \"do\"                 : True,\n",
    "            \"decay_factor\"       : 0.2,\n",
    "            \"monitor\"            : \"loss\",\n",
    "            \"mode\"               : \"min\",\n",
    "            \"patience\"           : 2,\n",
    "            \"log_lvl\"            : logging.DEBUG,\n",
    "        },\n",
    "        \"print_tables_during_training\" : {\n",
    "            \"do\"        : True,\n",
    "            \"num_print\" : 10,\n",
    "        },\n",
    "    },\n",
    "    \"evaluate\" : {\n",
    "        \"num_print\"            : 50,\n",
    "        \"save_model\"           : True,\n",
    "        \"plot_weights\"         : False,\n",
    "        \"plot_training_curves\" : True,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e15977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "===   Config created   ===\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "##===================================##\n",
    "##   Load and validate full config   ##\n",
    "##===================================##\n",
    "\n",
    "##  Create config object containing default values\n",
    "cfg = config.Config(backend.DEFAULT_CONFIG)\n",
    "\n",
    "##  Override with custom values\n",
    "cfg.load_dict(custom_config)\n",
    "\n",
    "##  Validate config\n",
    "backend.validate_config(cfg)\n",
    "\n",
    "##  Print success\n",
    "print(utils.fancy_message(f\"Config created\"))\n",
    "\n",
    "##  For convenience, split configs for different sections\n",
    "cfg_global   = cfg[\"global\"  ]\n",
    "cfg_data     = cfg[\"data\"    ]\n",
    "cfg_model    = cfg[\"model\"   ]\n",
    "cfg_training = cfg[\"training\"]\n",
    "cfg_evaluate = cfg[\"evaluate\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af05439",
   "metadata": {},
   "source": [
    "##  2. Set up environment\n",
    "\n",
    "- Create working directory\n",
    "- Create logger\n",
    "- Log package versions for reproducibility\n",
    "- Log config values for reproducibility\n",
    "- Set random seeds for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f7cc532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================================================================================================\n",
      "===   Working directory created at SSL_loopy_enc_dec_notebook_int1234_num1245_embed160_enc_2blocks_8loops_width800_dec_2blocks_1loops_width800_post3_width800_idem2_2023_06_28   ===\n",
      "====================================================================================================================================================================================\n",
      "   INFO initialise_logging: Begin logging on 2023-06-28 at 18:51:27\n",
      "   INFO initialise_program: Program description: unsupervised_learning_addition_model_generator (notebook)\n",
      "   INFO initialise_program: Working directory: SSL_loopy_enc_dec_notebook_int1234_num1245_embed160_enc_2blocks_8loops_width800_dec_2blocks_1loops_width800_post3_width800_idem2_2023_06_28\n",
      "   INFO log_versions: ------------------------------------------------------+------------------------------------------------------\n",
      "   INFO log_versions:                                              PACKAGE  |  VERSION\n",
      "   INFO log_versions: ------------------------------------------------------+------------------------------------------------------\n",
      "   INFO log_versions:                                               Python  |  3.11.3 (main, May 15 2023, 18:01:31) [Clang 14.0.6 ]\n",
      "   INFO log_versions:                                              IPython  |  8.14.0\n",
      "   INFO log_versions:                                 IPython.core.release  |  8.14.0\n",
      "   INFO log_versions:                                                  PIL  |  9.5.0\n",
      "   INFO log_versions:                                            PIL.Image  |  9.5.0\n",
      "   INFO log_versions:                                       PIL._deprecate  |  9.5.0\n",
      "   INFO log_versions:                                         PIL._version  |  9.5.0\n",
      "   INFO log_versions:                                                 _csv  |  1.0\n",
      "   INFO log_versions:                                              _ctypes  |  1.1.0\n",
      "   INFO log_versions:                                              _curses  |  b'2.2'\n",
      "   INFO log_versions:                                              decimal  |  1.70\n",
      "   INFO log_versions:                               _pydev_bundle.fsnotify  |  0.1.5\n",
      "   INFO log_versions:                 _pydevd_frame_eval.vendored.bytecode  |  0.13.0.dev\n",
      "   INFO log_versions:                                              appnope  |  0.1.3\n",
      "   INFO log_versions:                                             argparse  |  1.1\n",
      "   INFO log_versions:                                           astunparse  |  1.6.3\n",
      "   INFO log_versions:                                             backcall  |  0.2.0\n",
      "   INFO log_versions:                                              certifi  |  2023.05.07\n",
      "   INFO log_versions:                                                 cffi  |  1.15.1\n",
      "   INFO log_versions:                                   charset_normalizer  |  3.1.0\n",
      "   INFO log_versions:                           charset_normalizer.version  |  3.1.0\n",
      "   INFO log_versions:                                                 comm  |  0.1.3\n",
      "   INFO log_versions:                                                  csv  |  1.0\n",
      "   INFO log_versions:                                               ctypes  |  1.1.0\n",
      "   INFO log_versions:                                      ctypes.macholib  |  1.0\n",
      "   INFO log_versions:                                               cycler  |  0.10.0\n",
      "   INFO log_versions:                                             dateutil  |  2.8.2\n",
      "   INFO log_versions:                                              debugpy  |  1.6.7\n",
      "   INFO log_versions:                                   debugpy.public_api  |  1.6.7\n",
      "   INFO log_versions:                                              decimal  |  1.70\n",
      "   INFO log_versions:                                            decorator  |  5.1.1\n",
      "   INFO log_versions:                                           defusedxml  |  0.7.1\n",
      "   INFO log_versions:                                            distutils  |  3.11.3\n",
      "   INFO log_versions:                                            executing  |  1.2.0\n",
      "   INFO log_versions:                                    executing.version  |  1.2.0\n",
      "   INFO log_versions:                                          flatbuffers  |  23.5.26\n",
      "   INFO log_versions:                                 flatbuffers._version  |  23.5.26\n",
      "   INFO log_versions:                                      google.protobuf  |  4.23.3\n",
      "   INFO log_versions:                                                 h5py  |  3.9.0\n",
      "   INFO log_versions:                                          http.server  |  0.6\n",
      "   INFO log_versions:                                                 idna  |  3.4\n",
      "   INFO log_versions:                                        idna.idnadata  |  15.0.0\n",
      "   INFO log_versions:                                    idna.package_data  |  3.4\n",
      "   INFO log_versions:                                            ipaddress  |  1.0\n",
      "   INFO log_versions:                                            ipykernel  |  6.23.3\n",
      "   INFO log_versions:                                   ipykernel._version  |  6.23.3\n",
      "   INFO log_versions:                                                 jedi  |  0.18.2\n",
      "   INFO log_versions:                                                 json  |  2.0.9\n",
      "   INFO log_versions:                                       jupyter_client  |  8.3.0\n",
      "   INFO log_versions:                              jupyter_client._version  |  8.3.0\n",
      "   INFO log_versions:                                         jupyter_core  |  5.3.1\n",
      "   INFO log_versions:                                 jupyter_core.version  |  5.3.1\n",
      "   INFO log_versions:                                                keras  |  2.12.0\n",
      "   INFO log_versions:                                  keras.api._v2.keras  |  2.12.0\n",
      "   INFO log_versions:                                      keras.api.keras  |  2.12.0\n",
      "   INFO log_versions:                                           kiwisolver  |  1.4.4\n",
      "   INFO log_versions:                                     kiwisolver._cext  |  1.4.4\n",
      "   INFO log_versions:                                              logging  |  0.5.1.2\n",
      "   INFO log_versions:                                           matplotlib  |  3.7.1\n",
      "   INFO log_versions:                                  matplotlib._version  |  3.7.1\n",
      "   INFO log_versions:                                                numpy  |  1.23.5\n",
      "   INFO log_versions:                                           numpy.core  |  1.23.5\n",
      "   INFO log_versions:                         numpy.core._multiarray_umath  |  3.1\n",
      "   INFO log_versions:                                            numpy.lib  |  1.23.5\n",
      "   INFO log_versions:                           numpy.linalg._umath_linalg  |  0.1.5\n",
      "   INFO log_versions:                                        numpy.version  |  1.23.5\n",
      "   INFO log_versions:                                           opt_einsum  |  v3.3.0\n",
      "   INFO log_versions:                                            packaging  |  23.1\n",
      "   INFO log_versions:                                                parso  |  0.8.3\n",
      "   INFO log_versions:                                              pexpect  |  4.8.0\n",
      "   INFO log_versions:                                          pickleshare  |  0.7.5\n",
      "   INFO log_versions:                 pkg_resources._vendor.more_itertools  |  9.0.0\n",
      "   INFO log_versions:                      pkg_resources._vendor.packaging  |  23.0\n",
      "   INFO log_versions:                   pkg_resources._vendor.platformdirs  |  2.6.2\n",
      "   INFO log_versions:           pkg_resources._vendor.platformdirs.version  |  2.6.2\n",
      "   INFO log_versions:                 pkg_resources._vendor.more_itertools  |  9.0.0\n",
      "   INFO log_versions:                      pkg_resources._vendor.packaging  |  23.0\n",
      "   INFO log_versions:                   pkg_resources._vendor.platformdirs  |  2.6.2\n",
      "   INFO log_versions:                                             platform  |  1.0.8\n",
      "   INFO log_versions:                                         platformdirs  |  3.8.0\n",
      "   INFO log_versions:                                 platformdirs.version  |  3.8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO log_versions:                                       prompt_toolkit  |  3.0.38\n",
      "   INFO log_versions:                                               psutil  |  5.9.5\n",
      "   INFO log_versions:                                           ptyprocess  |  0.7.0\n",
      "   INFO log_versions:                                            pure_eval  |  0.2.2\n",
      "   INFO log_versions:                                    pure_eval.version  |  0.2.2\n",
      "   INFO log_versions:                                               pydevd  |  2.9.5\n",
      "   INFO log_versions:                                             pygments  |  2.15.1\n",
      "   INFO log_versions:                                            pyparsing  |  3.1.0\n",
      "   INFO log_versions:                                                   re  |  2.2.1\n",
      "   INFO log_versions:                                             requests  |  2.31.0\n",
      "   INFO log_versions:                                 requests.__version__  |  2.31.0\n",
      "   INFO log_versions:                                                 idna  |  3.4\n",
      "   INFO log_versions:                                        idna.idnadata  |  15.0.0\n",
      "   INFO log_versions:                                    idna.package_data  |  3.4\n",
      "   INFO log_versions:                                              urllib3  |  1.26.16\n",
      "   INFO log_versions:                                     urllib3._version  |  1.26.16\n",
      "   INFO log_versions:                                   urllib3.connection  |  1.26.16\n",
      "   INFO log_versions:                                 urllib3.packages.six  |  1.16.0\n",
      "   INFO log_versions:                      urllib3.util.ssl_match_hostname  |  3.5.0.1\n",
      "   INFO log_versions:                                       requests.utils  |  2.31.0\n",
      "   INFO log_versions:                                                scipy  |  1.11.0\n",
      "   INFO log_versions:                                 scipy._lib.decorator  |  4.0.5\n",
      "   INFO log_versions:                                  scipy.linalg._fblas  |  1.23.2\n",
      "   INFO log_versions:                                scipy.linalg._flapack  |  1.23.2\n",
      "   INFO log_versions:                                scipy.linalg._flinalg  |  1.23.2\n",
      "   INFO log_versions:            scipy.sparse.linalg._eigen.arpack._arpack  |  1.23.2\n",
      "   INFO log_versions:               scipy.sparse.linalg._isolve._iterative  |  1.23.2\n",
      "   INFO log_versions:                               scipy.special._specfun  |  1.23.2\n",
      "   INFO log_versions:                                           setuptools  |  67.8.0\n",
      "   INFO log_versions:                                            distutils  |  3.11.3\n",
      "   INFO log_versions:                    setuptools._vendor.more_itertools  |  8.8.0\n",
      "   INFO log_versions:                       setuptools._vendor.ordered_set  |  3.1\n",
      "   INFO log_versions:                         setuptools._vendor.packaging  |  23.0\n",
      "   INFO log_versions:                    setuptools._vendor.more_itertools  |  8.8.0\n",
      "   INFO log_versions:                       setuptools._vendor.ordered_set  |  3.1\n",
      "   INFO log_versions:                         setuptools._vendor.packaging  |  23.0\n",
      "   INFO log_versions:                                   setuptools.version  |  67.8.0\n",
      "   INFO log_versions:                                                  six  |  1.16.0\n",
      "   INFO log_versions:                                         socketserver  |  0.4\n",
      "   INFO log_versions:                                           stack_data  |  0.6.2\n",
      "   INFO log_versions:                                   stack_data.version  |  0.6.2\n",
      "   INFO log_versions:                                          tensorboard  |  2.12.3\n",
      "   INFO log_versions:                   tensorboard.compat.tensorflow_stub  |  stub\n",
      "   INFO log_versions: tensorboard.compat.tensorflow_stub.pywrap_tensorflow  |  0\n",
      "   INFO log_versions:                                           tensorflow  |  2.12.0\n",
      "   INFO log_versions:                         tensorflow._api.v2.compat.v1  |  2.12.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v1.compat.v1  |  2.12.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v1.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                         tensorflow._api.v2.compat.v2  |  2.12.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v2.compat.v1  |  2.12.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v2.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                                 tensorflow.compat.v1  |  2.12.0\n",
      "   INFO log_versions:                       tensorflow.compat.v1.compat.v1  |  2.12.0\n",
      "   INFO log_versions:                       tensorflow.compat.v1.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                                 tensorflow.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                       tensorflow.compat.v2.compat.v1  |  2.12.0\n",
      "   INFO log_versions:                       tensorflow.compat.v2.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                                     tensorflow.keras  |  2.12.0\n",
      "   INFO log_versions:           tensorflow.python.client.pywrap_tf_session  |  2.12.0\n",
      "   INFO log_versions:                 tensorflow.python.framework.versions  |  2.12.0\n",
      "   INFO log_versions:                              tensorflow.python.keras  |  2.6.0\n",
      "   INFO log_versions:                                            traitlets  |  5.9.0\n",
      "   INFO log_versions:                                   traitlets._version  |  5.9.0\n",
      "   INFO log_versions:                                       urllib.request  |  3.11\n",
      "   INFO log_versions:                                              urllib3  |  1.26.16\n",
      "   INFO log_versions:                                     urllib3._version  |  1.26.16\n",
      "   INFO log_versions:                                   urllib3.connection  |  1.26.16\n",
      "   INFO log_versions:                                 urllib3.packages.six  |  1.16.0\n",
      "   INFO log_versions:                      urllib3.util.ssl_match_hostname  |  3.5.0.1\n",
      "   INFO log_versions:                                              wcwidth  |  0.2.6\n",
      "   INFO log_versions:                                                wrapt  |  1.14.1\n",
      "   INFO log_versions:                                        xmlrpc.client  |  3.11\n",
      "   INFO log_versions:                                                 zlib  |  1.0\n",
      "   INFO log_versions:                                                  zmq  |  25.1.0\n",
      "   INFO log_versions:                                            zmq.sugar  |  25.1.0\n",
      "   INFO log_versions:                                    zmq.sugar.version  |  25.1.0\n",
      "   INFO log_versions: ------------------------------------------------------+------------------------------------------------------\n",
      "   INFO initialise_program: Registered config value global > base_seed: -1\n",
      "   INFO initialise_program: Registered config value global > working_dir: SSL_loopy_enc_dec_notebook_[global>problem_tag]_embed[model>ndim_embedding]_enc_[model>encoder>num_blocks]blocks_[model>encoder>num_loops]loops_width[model>encoder>ndim_ff_hidden]_dec_[model>decoder>num_blocks]blocks_[model>decoder>num_loops]loops_width[model>decoder>ndim_ff_hidden]_post[model>post_decoder>num_layers]_width[model>post_decoder>ndim]_idem[model>idempotent_size]_[date]\n",
      "   INFO initialise_program: Registered config value global > problem_tag: int1234_num1245\n",
      "   INFO initialise_program: Registered config value global > log_lvl_iostream: 20\n",
      "   INFO initialise_program: Registered config value global > log_lvl_fstream: 10\n",
      "   INFO initialise_program: Registered config value data > train_data > int_lengths: [1, 2, 3, 4]\n",
      "   INFO initialise_program: Registered config value data > train_data > num_ints: [1, 2, 4, 5]\n",
      "   INFO initialise_program: Registered config value data > train_data > batch_size: 32\n",
      "   INFO initialise_program: Registered config value data > train_data > num_batches: 2000\n",
      "   INFO initialise_program: Registered config value data > train_data > gen_base_seed: 104\n",
      "   INFO initialise_program: Registered config value data > train_data > gen_reproducible: False\n",
      "   INFO initialise_program: Registered config value data > val_data > int_lengths: [1, 2, 3, 4]\n",
      "   INFO initialise_program: Registered config value data > val_data > num_ints: [3, 6]\n",
      "   INFO initialise_program: Registered config value data > val_data > batch_size: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO initialise_program: Registered config value data > val_data > num_batches: 50\n",
      "   INFO initialise_program: Registered config value data > val_data > gen_base_seed: 105\n",
      "   INFO initialise_program: Registered config value data > val_data > gen_reproducible: True\n",
      "   INFO initialise_program: Registered config value data > test_data > int_lengths: [1, 2, 3, 4]\n",
      "   INFO initialise_program: Registered config value data > test_data > num_ints: [7, 8]\n",
      "   INFO initialise_program: Registered config value data > test_data > batch_size: 32\n",
      "   INFO initialise_program: Registered config value data > test_data > num_batches: 100\n",
      "   INFO initialise_program: Registered config value data > test_data > gen_base_seed: 106\n",
      "   INFO initialise_program: Registered config value data > test_data > gen_reproducible: True\n",
      "   INFO initialise_program: Registered config value data > characters: ['M', 'B', 'E', 'N', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-']\n",
      "   INFO initialise_program: Registered config value data > mask_char: M\n",
      "   INFO initialise_program: Registered config value data > seq_start_char: B\n",
      "   INFO initialise_program: Registered config value data > seq_end_char: E\n",
      "   INFO initialise_program: Registered config value data > negative_char: N\n",
      "   INFO initialise_program: Registered config value data > dtype: int32\n",
      "   INFO initialise_program: Registered config value model > load_pretrained_model: None\n",
      "   INFO initialise_program: Registered config value model > name: mathsformer_LLM\n",
      "   INFO initialise_program: Registered config value model > dtype: float32\n",
      "   INFO initialise_program: Registered config value model > dropout: 0.1\n",
      "   INFO initialise_program: Registered config value model > jit_compile: False\n",
      "   INFO initialise_program: Registered config value model > use_old_loss: True\n",
      "   INFO initialise_program: Registered config value model > optimizer: <class 'keras.optimizers.adamw.AdamW'>\n",
      "   INFO initialise_program: Registered config value model > optimizer_args > learning_rate: 0.0001\n",
      "   INFO initialise_program: Registered config value model > optimizer_args > weight_decay: 0.02\n",
      "   INFO initialise_program: Registered config value model > idempotent_size: 2\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > num_freqs: 80\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > min_period: 4\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > max_period: 1000\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > learnable: False\n",
      "   INFO initialise_program: Registered config value model > ndim_embedding: 160\n",
      "   INFO initialise_program: Registered config value model > comb_type: mixture\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > num_blocks: 2\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > num_loops: 1\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > num_heads: 8\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > ndim: 160\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > ndim_att_hidden: 160\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > ndim_ff_hidden: 800\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > mixture_skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > encoder > num_blocks: 2\n",
      "   INFO initialise_program: Registered config value model > encoder > num_loops: 8\n",
      "   INFO initialise_program: Registered config value model > encoder > num_heads: 8\n",
      "   INFO initialise_program: Registered config value model > encoder > ndim: 160\n",
      "   INFO initialise_program: Registered config value model > encoder > ndim_att_hidden: 160\n",
      "   INFO initialise_program: Registered config value model > encoder > ndim_ff_hidden: 800\n",
      "   INFO initialise_program: Registered config value model > encoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > encoder > mixture_skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > decoder > num_blocks: 2\n",
      "   INFO initialise_program: Registered config value model > decoder > num_loops: 1\n",
      "   INFO initialise_program: Registered config value model > decoder > num_heads: 8\n",
      "   INFO initialise_program: Registered config value model > decoder > ndim: 160\n",
      "   INFO initialise_program: Registered config value model > decoder > ndim_att_hidden: 160\n",
      "   INFO initialise_program: Registered config value model > decoder > ndim_ff_hidden: 800\n",
      "   INFO initialise_program: Registered config value model > decoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > decoder > mixture_skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > post_decoder > num_layers: 3\n",
      "   INFO initialise_program: Registered config value model > post_decoder > ndim: 800\n",
      "   INFO initialise_program: Registered config value training > train: True\n",
      "   INFO initialise_program: Registered config value training > max_epochs: 100000\n",
      "   INFO initialise_program: Registered config value training > log_after_epoch > do: True\n",
      "   INFO initialise_program: Registered config value training > log_after_epoch > log_lvl: 10\n",
      "   INFO initialise_program: Registered config value training > early_stopping > do: False\n",
      "   INFO initialise_program: Registered config value training > early_stopping > patience: 6\n",
      "   INFO initialise_program: Registered config value training > early_stopping > monitor: loss\n",
      "   INFO initialise_program: Registered config value training > early_stopping > mode: min\n",
      "   INFO initialise_program: Registered config value training > early_stopping > restore_best_weights: True\n",
      "   INFO initialise_program: Registered config value training > model_checkpoint > do: True\n",
      "   INFO initialise_program: Registered config value training > model_checkpoint > filename: model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.keras\n",
      "   INFO initialise_program: Registered config value training > layer_weights_record > do: True\n",
      "   INFO initialise_program: Registered config value training > layer_weights_record > batch_frequency: 2000\n",
      "   INFO initialise_program: Registered config value training > layer_weights_record > recursive: True\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > do: True\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > decay_factor: 0.2\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > monitor: loss\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > mode: min\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > patience: 2\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > log_lvl: 10\n",
      "   INFO initialise_program: Registered config value training > print_tables_during_training > do: True\n",
      "   INFO initialise_program: Registered config value training > print_tables_during_training > num_print: 10\n",
      "   INFO initialise_program: Registered config value evaluate > num_print: 50\n",
      "   INFO initialise_program: Registered config value evaluate > save_model: True\n",
      "   INFO initialise_program: Registered config value evaluate > plot_weights: False\n",
      "   INFO initialise_program: Registered config value evaluate > plot_training_curves: True\n",
      "   INFO initialise_program: Python random seed set: 1687974687\n",
      "   INFO initialise_program: Numpy random seed set: 1687974688\n",
      "   INFO initialise_program: TensorFlow random seed set: 1687974689\n"
     ]
    }
   ],
   "source": [
    "##==============================##\n",
    "##   Create working directory   ##\n",
    "##==============================##\n",
    "\n",
    "##  Report success\n",
    "working_dir, logger, base_seed, np_seed, tf_seed = utils.initialise_program(\n",
    "    \"unsupervised_learning_addition_model_generator (notebook)\", \n",
    "    working_dir       = cfg_global[\"working_dir\"], \n",
    "    cfg               = cfg,\n",
    "    base_seed         = cfg_global[\"base_seed\"],\n",
    "    log_lvl_iostream  = cfg_global[\"log_lvl_iostream\"],\n",
    "    log_lvl_fstream   = cfg_global[\"log_lvl_fstream\" ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960860d",
   "metadata": {},
   "source": [
    "##  3. Create training data\n",
    "\n",
    "###  Create tokeniser\n",
    "\n",
    "Tokeniser object handles the transformation from strings to tensors and back again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db11d6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO summary: TokenTransform of dtype int32 with 16 characters: ['M', 'B', 'E', 'N', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-']\n",
      "   INFO summary: Special characters are seq_start_char (B), seq_end_char (E), mask_char (M)\n",
      "   INFO summary: Tokeniser dictionary is {'M': 0, 'B': 1, 'E': 2, 'N': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, '+': 14, '-': 15}\n",
      "   INFO summary: Detokeniser dictionary is {0: 'M', 1: 'B', 2: 'E', 3: 'N', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: '+', 15: '-'}\n"
     ]
    }
   ],
   "source": [
    "##======================##\n",
    "##   Create tokeniser   ##\n",
    "##======================##\n",
    "\n",
    "token_transform = data.TokenTransform.from_dictionary(cfg_data)\n",
    "token_transform.summary(print_fn=logger.info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5367bdd7",
   "metadata": {},
   "source": [
    "###  Create data generators for train/val/test sets\n",
    "\n",
    "Data generators create tensor inputs/outputs for the model on-the-fly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d87b308d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO get_data_generators: Training data generator created with the following config: Generator of [1, 2, 4, 5] integers of length [1, 2, 3, 4] in 2000 batches of size 32 (base_seed=104, reproducible=False)\n",
      "   INFO get_data_generators: Output shapes for a test batch are ((32, 25), (32, 6)), (32, 6)\n",
      "   INFO get_data_generators: Validation data generator created with the following config: Generator of [3, 6] integers of length [1, 2, 3, 4] in 50 batches of size 32 (base_seed=105, reproducible=True)\n",
      "   INFO get_data_generators: Output shapes for a test batch are ((32, 31), (32, 7)), (32, 7)\n",
      "   INFO get_data_generators: Test data generator created with the following config: Generator of [7, 8] integers of length [1, 2, 3, 4] in 100 batches of size 32 (base_seed=106, reproducible=True)\n",
      "   INFO get_data_generators: Output shapes for a test batch are ((32, 37), (32, 7)), (32, 7)\n"
     ]
    }
   ],
   "source": [
    "##============================##\n",
    "##   Create data generators   ##\n",
    "##============================##\n",
    "\n",
    "negative_char = cfg_data.get(\"negative_char\")\n",
    "train_gen, train_gen_reproducible, val_gen, test_gen = backend.get_data_generators(cfg_data, token_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa78cf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Saving distribution of token frequencies to file SSL_loopy_enc_dec_notebook_int1234_num1245_embed160_enc_2blocks_8loops_width800_dec_2blocks_1loops_width800_post3_width800_idem2_2023_06_28/token_distribution.pdf\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqkAAAGCCAYAAADDpVqvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABUMElEQVR4nO3dfVzN9/8/8Mc5qVO6IkkXpFzGXEQpjS0UMTO2PqTZJIYhX/QZG3ORsZWrlhG+ru1LCh/zcbUsbWVWQtjGsDFpk8qWLmROcd6/P/x6z9k5XeCc09vxuN9u56b36/18v57v1zkcz17vK5kgCAKIiIiIiCREXt87QERERET0TyxSiYiIiEhyWKQSERERkeSwSCUiIiIiyWGRSkRERESSwyKViIiIiCSHRSoRERERSU6D+t4BomeRSqVCXl4erK2tIZPJ6nt3iIiInhmCIKCsrAzOzs6Qy6ufL2WRSvQE8vLy0KJFi/reDSIiomfWb7/9hubNm1e7nkUq0ROwtrYG8PAfmI2NjcHzFxUVwd3dHdeuXYOdnd0zn4e5nq1cxjgmY81ljGMy1lzGOKbqlJaWokWLFuL/pdVhkUr0BKoO8dvY2NRLkVpZWQngYbGsz/yGysNcz1YuYxyTseYyxjEZay5jHFNtajtdjhdOEREREZHksEglIiIiIslhkUr0DFIoFAgJCYFCoTCKPMz1bOUyxjEZay5jHJOx5jLGMT0tFqlEzyCFQoHQ0FCDfGkaIg9zPVu5jHFMxprLGMdkrLmMcUxPi0UqEREREUkOi1QiIiIikhwWqUREREQkOSxSiYiIiEhyWKQSERERkeSwSCUiIiIiyWGRSkRERESSwyKViIiIiCSnQX3vABFReXk5rKysAAC3b99Go0aN6neHiIio3nEmlYiIiIgkhzOpRKR3bh8cqnG9quKe+HOPj4+i0sSi1j5zYgY/9X4REZF0cSaViOqd3Mwc7eYcwL59+yA3M6/v3SEiIglgkUpEREREksMilYiIiIgkh0UqEREREUkOi1QiIiIikhwWqUREREQkOSxSSZLi4+Ph5uYGc3Nz+Pr64uTJk9XGbtiwAS+99BIaN26Mxo0bIzAwUCNeEATMnz8fTk5OsLCwQGBgIH755Re1mKKiIowaNQo2NjZo1KgRxo0bhzt37uhlfERERFQzFqkkOUlJSYiMjMSCBQtw5swZdO3aFUFBQSgsLNQan5aWhtDQUHzzzTfIzMxEixYtMGDAANy4cUOMWbp0KT777DOsW7cOWVlZsLS0RFBQEO7d+/v+nKNGjcKFCxeQkpKCgwcP4tixY5gwYYLex0tERESaWKSS5MTGxmL8+PEIDw9Hx44dsW7dOjRs2BCbN2/WGr9jxw5MnjwZnp6e8PDwwMaNG6FSqZCamgrg4SxqXFwc5s6di6FDh6JLly74/PPPkZeXh3379gEALl68iOTkZGzcuBG+vr7o3bs3Vq1ahcTEROTl5Rlq6ERERPT/8YlTJCkVFRXIzs7G7NmzxTa5XI7AwEBkZmbWqY+7d++isrISdnZ2AIBr164hPz8fgYGBYoytrS18fX2RmZmJkSNHIjMzE40aNYK3t7cYExgYCLlcjqysLLz++utacxUVFaGyslJcVigUUCgUjzXmJ1GV89HcUs6jMBFqj5ELan/W5mn2yVDvn7HmMsYxGWsuYxyTseYyxjFVUSqVUCqV4nJZWVmdtpMJglC3/xGIDCAvLw8uLi7IyMiAn5+f2D5r1iykp6cjKyur1j4mT56MI0eO4MKFCzA3N0dGRgZ69eqFvLw8ODk5iXEjRoyATCZDUlISPvnkE2zbtg2XL19W68vBwQELFy7EpEmT1NpLS0tha2urkTskJAShoaGPO2wiIiKjtXPnTiQlJWm0l5SUwMbGptrtOJNKRiUmJgaJiYlIS0uDubn+H6957do1WFtbi8uGnElNSUlB//79YWpqKvk8naKO1BqjkAtY5K3CvNNyKFWyWuPPRwU98f4Y6v0z1lzGOCZjzWWMYzLWXMY4pioBAQGIj48Xl8vKyuDu7l7rdixSSVLs7e1hYmKCgoICtfaCggI4OjrWuO3y5csRExODo0ePokuXLmJ71XYFBQVqM6kFBQXw9PQUY/55Ydb9+/dRVFRUY147O7safwvUN1NTU4N8wTxtHuWD2otOMVYlq1O8LsZtqPfPWHMZ45iMNZcxjslYcxnrmKysrNSW64IXTpGkmJmZwcvLS7zoCYB4EdSjh///aenSpVi0aBGSk5PVzisFAHd3dzg6Oqr1WVpaiqysLLFPPz8/FBcXIzs7W4z5+uuvoVKp4Ovrq6vhERERUR1xJpUkJzIyEmFhYfD29oaPjw/i4uJQXl6O8PBwAMDo0aPh4uKC6OhoAMCSJUswf/58JCQkwM3NDfn5+QAAKysrWFlZQSaTYfr06Vi8eDHatm0Ld3d3zJs3D87Ozhg2bBgAoEOHDhg4cCDGjx+PdevWobKyEhERERg5ciScnZ3r5X0gIiJ6nrFIJckJCQnBrVu3MH/+fOTn58PT0xPJyclo1qwZACA3Nxdy+d8HAdauXYuKigr861//UutnwYIFiIqKAvDwwqvy8nJMmDABxcXF6N27N5KTk9XOW92xYwciIiIQEBAAuVyO4OBgfPbZZ/ofMBEREWlgkUqSFBERgYiICK3r0tLS1JZzcnJq7U8mk+Gjjz7CRx99VG2MnZ0dEhISHmc3iYiISE94TioRERERSQ6LVCIiIiKSHBapRERERCQ5LFKJiIiISHJYpBIRERGR5LBIJSIiIiLJYZFKRERERJLDIpWIiIiIJIdFKhERERFJDotUIiIiIpIcFqlEREREJDksUomIiIhIclikEhEREZHksEglIiIiIslhkUpEREREksMilYiIiIgkh0UqEREREUkOi1QiIiIikhwWqUREREQkOSxSiYiIiEhyWKQSERERkeSwSCUiIiIiyWGRSkRERESSwyKViIiIiCSHRSpJTnx8PNzc3GBubg5fX1+cPHmy2tgLFy4gODgYbm5ukMlkiIuL04ipWvfP15QpU8SYPn36aKx/99139TE8IiIiqgMWqSQpSUlJiIyMxIIFC3DmzBl07doVQUFBKCws1Bp/9+5dtGrVCjExMXB0dNQac+rUKdy8eVN8paSkAACGDx+uFjd+/Hi1uKVLl+p2cERERFRnLFJJUmJjYzF+/HiEh4ejY8eOWLduHRo2bIjNmzdrje/RoweWLVuGkSNHQqFQaI1p2rQpHB0dxdfBgwfRunVr+Pv7q8U1bNhQLc7Gxkbn4yMiIqK6aVDfO0BUpaKiAtnZ2Zg9e7bYJpfLERgYiMzMTJ3l2L59OyIjIyGTydTW7dixA9u3b4ejoyOGDBmCefPmoWHDhjX2V1RUhMrKSnFZoVBUWyzrUlXOR3NLOY/CRKg9Ri6o/Vmbp9knQ71/xprLGMdkrLmMcUzGmssYx1RFqVRCqVSKy2VlZXXaTiYIQt3+RyDSs7y8PLi4uCAjIwN+fn5i+6xZs5Ceno6srKwat3dzc8P06dMxffr0amN27dqFN998E7m5uXB2dhbb169fj5YtW8LZ2Rk//PAD3n//ffj4+GDv3r1a+yktLYWtra1Ge0hICEJDQ2sZKRER0fNj586dSEpK0mgvKSmp8aglZ1LpubJp0yYMGjRIrUAFgAkTJog/d+7cGU5OTggICMDVq1fRunXravu7du0arK2txWVDzqSmpKSgf//+MDU1lXyeTlFHao1RyAUs8lZh3mk5lCpZrfHno4KeeH8M9f4Zay5jHJOx5jLGMRlrLmMcU5WAgADEx8eLy2VlZXB3d691OxapJBn29vYwMTFBQUGBWntBQUG1F0U9juvXr+Po0aPVzo4+ytfXFwBw5cqVGotUOzu7ej131dTU1CBfME+bR/mg9qJTjFXJ6hSvi3Eb6v0z1lzGOCZjzWWMYzLWXMY6JisrK7XluuCFUyQZZmZm8PLyQmpqqtimUqmQmpqqdvj/SW3ZsgUODg4YPHhwrbHnzp0DADg5OT11XiIiInp8nEklSYmMjERYWBi8vb3h4+ODuLg4lJeXIzw8HAAwevRouLi4IDo6GsDDC6F++ukn8ecbN27g3LlzsLKyQps2bcR+VSoVtmzZgrCwMDRooP7X/urVq0hISMArr7yCJk2a4IcffsCMGTPw8ssvo0uXLgYaORERET2KRSpJSkhICG7duoX58+cjPz8fnp6eSE5ORrNmzQAAubm5kMv/PgCQl5eHbt26icvLly/H8uXL4e/vj7S0NLH96NGjyM3NxdixYzVympmZ4ejRo2JB3KJFCwQHB2Pu3Ln6GygRERHViEUqSU5ERAQiIiK0rnu08AQeXtFflxtUDBgwoNq4Fi1aID09/bH3k4iIiPSH56QSERERkeSwSCUiIiIiyWGRSkRERESSwyKViIiIiCSHRSoRERERSQ6LVCIiIiKSHBapRERERCQ5LFKJiIiISHJYpBIRERGR5LBIJSIiIiLJYZFKRERERJLDIpWIiIiIJIdFKhERERFJDotUIiIiIpIcFqlEREREJDksUomIiIhIclikEhEREZHksEglIiIiIslhkUpEREREksMilYiIiIgkh0UqEREREUkOi1QiIiIikhwWqUREREQkOSxSiYiIiEhyWKSS5MTHx8PNzQ3m5ubw9fXFyZMnq429cOECgoOD4ebmBplMhri4OI2YqKgoyGQytZeHh4dazL179zBlyhQ0adIEVlZWCA4ORkFBga6HRkRERHXEIpUkJSkpCZGRkViwYAHOnDmDrl27IigoCIWFhVrj7969i1atWiEmJgaOjo7V9vvCCy/g5s2b4uv48eNq62fMmIEDBw5g9+7dSE9PR15eHt544w2djo2IiIjqjkUqSUpsbCzGjx+P8PBwdOzYEevWrUPDhg2xefNmrfE9evTAsmXLMHLkSCgUimr7bdCgARwdHcWXvb29uK6kpASbNm1CbGws+vXrBy8vL2zZsgUZGRk4ceKEzsdIREREtWtQ3ztAVKWiogLZ2dmYPXu22CaXyxEYGIjMzMyn6vuXX36Bs7MzzM3N4efnh+joaLi6ugIAsrOzUVlZicDAQDHew8MDrq6uyMzMRM+ePavtt6ioCJWVleKyQqGosVjWlaqcj+aWch6FiVB7jFxQ+7M2T7NPhnr/jDWXMY7JWHMZ45iMNZcxjqmKUqmEUqkUl8vKyuq0nUwQhLr9j0CkZ3l5eXBxcUFGRgb8/PzE9lmzZiE9PR1ZWVk1bu/m5obp06dj+vTpau1ffvkl7ty5g/bt2+PmzZtYuHAhbty4gfPnz8Pa2hoJCQkIDw9X+wcEAD4+Pujbty+WLFmikau0tBS2trYa7SEhIQgNDX2MURMRERm3nTt3IikpSaO9pKQENjY21W7HmVQyeoMGDRJ/7tKlC3x9fdGyZUvs2rUL48aNe6q+r127Bmtra3HZkDOpKSkp6N+/P0xNTSWfp1PUkVpjFHIBi7xVmHdaDqVKVmv8+aigJ94fQ71/xprLGMdkrLmMcUzGmssYx1QlICAA8fHx4nJZWRnc3d1r3Y5FKkmGvb09TExMNK6qLygoqPGiqMfVqFEjtGvXDleuXAEAODo6oqKiAsXFxWjUqNFj5bWzs6vxt0B9MzU1NcgXzNPmUT6ovegUY1WyOsXrYtyGev+MNZcxjslYcxnjmIw1l7GOycrKSm25LnjhFEmGmZkZvLy8kJqaKrapVCqkpqaqHf5/Wnfu3MHVq1fh5OQEAPDy8oKpqala3suXLyM3N1eneYmIiKjuOJNKkhIZGYmwsDB4e3vDx8cHcXFxKC8vR3h4OABg9OjRcHFxQXR0NICHF1v99NNP4s83btzAuXPnYGVlhTZt2gAA3nvvPQwZMgQtW7ZEXl4eFixYABMTE/HcUVtbW4wbNw6RkZHizOjUqVPh5+dX40VTREREpD8sUklSQkJCcOvWLcyfPx/5+fnw9PREcnIymjVrBgDIzc2FXP73AYC8vDx069ZNXF6+fDmWL18Of39/pKWlAQB+//13hIaG4s8//0TTpk3Ru3dvnDhxAk2bNhW3+/TTTyGXyxEcHAylUomgoCCsWbPGMIMmIiIiDSxSSXIiIiIQERGhdV1V4VnFzc0Ntd2gIjExsdac5ubmiI+PVzuxm4iIiOoPz0klIiIiIslhkUpEREREksMilYiIiIgkh0UqEREREUkOi1QiIiIikhwWqUREREQkOSxSiYiIiEhyWKQSERERkeSwSCUiIiIiyWGRaqRycnIgk8kwZsyY+t4VIiIiosf2WEVqVeFT06u4uFhPu0pEREREz4sGT7JR69at8dZbb2ldZ25u/lQ7RLrh4uKCixcvwtbWtr53hYiIiOixPVGR2qZNG0RFRel4V0iXTE1N4eHhUd+7QURERPRE9HJO6tatWyGTybB161YcOHAAvXr1grW1Ndzc3MSYiooKxMbGonv37rC0tIS1tTVeeukl7N+/X2ufv/32G0JDQ2FnZwcrKyv4+/vj2LFjiIqKgkwmQ1pamtb8/5SWlgaZTKa1yL527RreeecduLq6QqFQwMnJCWPGjMH169c1YmUyGfr06YOCggKEhYXB3t4eFhYW6Nmzp9q+PKqsrAwLFy5Ely5d0LBhQ9ja2qJbt26YN28eKisrUVJSAktLS7zwwgtat1epVHBzc0Pjxo3x119/aY2pUt05qX369IFMJkNlZSWioqLg5uYGhUKBdu3aYc2aNTX2SURERGQoTzSTWle7d+/GV199hVdffRWTJ09GaWkpAECpVGLgwIFIS0uDp6cnxo0bh8rKShw6dAhDhw7FqlWrEBERIfZz8+ZN+Pn54caNGwgKCkL37t1x8eJF9O/fH3379tXJvmZlZSEoKAjl5eV49dVX0bZtW+Tk5GDHjh348ssvkZmZiVatWqltU1xcjN69e8PW1hZvv/02CgsLkZSUhKCgIGRnZ6NTp05ibGFhIfz9/XHp0iV4enpi0qRJUKlUuHTpEpYsWYJ///vfaNSoEUaOHInNmzcjIyMDL774olq+lJQUXL9+HVOmTIGFhcVTjTc0NBQnT57EoEGDYGJigl27dmHKlCkwNTXF+PHjn6pvIiIioqf1REXqlStXtM5EDhw4ED179hSXk5OTceTIEQQGBqrFffTRR0hLS8O8efOwcOFCyGQyAA9nGvv164d///vfeOONN+Ds7AwAmD17Nm7cuIHFixfjww8/FPtZv349Jk6c+CRDUFNZWYmRI0dCpVLh5MmT6Natm7ju+PHj6NOnD6ZNm4YDBw6obff9999j8uTJWLVqFeTyh5PS/fr1wzvvvIPVq1dj3bp1YuzkyZNx6dIlzJkzBx9//LFaPwUFBbCysgIATJw4EZs3b8aGDRs0itSNGzcCgE6KyN9//x3nz5+HjY0NAGDatGno1KkTVqxYwSKViIiI6t0THe6/evUqFi5cqPE6ceKEWtzQoUM1ClSVSoW1a9eidevWagUqAFhbW2P+/PmoqKjA3r17ATw8LSApKQkODg7497//rdbXO++8g7Zt2z7JENQcPHgQOTk5mDlzplqBCgC9e/fG0KFDcfjwYXEmuIqlpSWWLFkiFqgAEBYWhgYNGuDUqVNiW35+Pvbu3YvWrVtrLe6bNWuGBg0e/r7g4+ODbt26Yffu3Wr5bt26hf3796NHjx7o2rXrU485OjpaLFABoH379ujVqxcuX76MsrKyp+6fiIiI6Gk80UxqUFAQkpOTa43z8fHRaLt8+TJu374NZ2dnLFy4UGP9rVu3AACXLl0S4+/du4d+/fpp3DlALpejV69e+OWXX55kGKKq4vry5ctai8j8/HyoVCr8/PPP8Pb2FtvbtWsnzoBWadCgAZo1a6Z2K67Tp09DEAT07dsXpqamte7PxIkT8e677yIhIQHvvvsuAODzzz9HRUWFzmY5vby8NNqaN28O4OFpDNbW1jrJQ0RERPQk9HpOarNmzTTaioqKAAAXLlzAhQsXqt22vLwcAFBSUgIAcHBwqHOOx1W1Tzt27Kgxrmqfqjw6E/moBg0a4MGDB+Jy1RhcXFzqtD9vvvkm3nvvPWzcuFEsUjdt2gQrKyuEhobWqY/aaNv3qtncR/ediIiIqD7o9YlTjx7Kr1JVHAUHB0MQhGpfW7ZsAQDxPp+FhYVacxQUFGi0VR1+v3//vsa6qoJR2z4dOHCgxn3y9/evy7A1NGrUCABw48aNOsVbW1tj1KhRyM7Oxrlz5/Ddd9/h4sWLGDlypMbMLREREZExMvhjUTt06AAbGxucPn0alZWVtca3a9cO5ubmOH36NO7du6e2TqVSISMjQ2Obxo0bA9BeFJ49e1ajzdfXFwCQmZlZpzE8Lm9vb8jlcnzzzTd1GjMA8YKwDRs26PSCKSIiIqJngcGL1AYNGmDSpEm4fv063nvvPa1F2/nz58WZU4VCgREjRqCwsBArVqxQi9u4cSN+/vlnje29vLwgk8mQmJioVtj+8ssvWLlypUb80KFD4erqitjYWBw7dkxjfWVlJY4fP/7YY63SrFkzBAcHixec/VNhYaHGrG+3bt3Qo0cP7NixA7t370aXLl20nuNLREREZIz0ek5qdRYuXIgzZ87gs88+w6FDh/Dyyy/DwcEBN27cwI8//ojvv/8emZmZ4nmoMTExSE1Nxdy5c3H8+HF069YNFy9exOHDhzFgwAB89dVXav07OzsjNDQUCQkJ8PLywsCBA1FYWIgvvvgCAwcOxH/+8x+1eIVCgT179mDQoEHw9/dHv3790LlzZ8hkMly/fh3ffvstmjRpIl7M9STWrFmD8+fP4+OPP8bhw4fRr18/CIKAn3/+GV999RUKCgrE0wKqvPvuuxg3bhwAzqISERHR86VeilSFQoEvv/wSmzZtwueff47//Oc/UCqVaNasGTp27Ih3330XnTt3FuOdnJyQkZGBWbNm4ciRIzh27Bi8vLyQkpKCr7/+WqNIBR7Ostrb2yMpKQnx8fFo37491q9fD2dnZ40iFQB69OiB77//HsuWLcPhw4fx3XffQaFQwMXFBcOGDXvqC5bs7e1x4sQJLF++HLt378bq1athbm4Od3d3fPDBB7C0tNTYZuTIkZg8eTLkcjneeuutp8pPRERE9Cx5rCLVzc0NgiDUGjdmzBiNx3H+k4mJCSZMmIAJEybUKberqysSExM12r/++mut8RYWFli5cqXWw/vVjcHFxQVxcXGIi4urdX9qeh9ycnK0ttvY2OCjjz7CRx99VGv/APDTTz9BqVTi7bff1phlrU11n1V1j2wFHj5OVtujZA0tPj4ey5YtQ35+Prp27YpVq1ZVe6rDhQsXMH/+fGRnZ+P69ev49NNPMX36dLWY6Oho7N27F5cuXYKFhQVefPFFLFmyBO3btxdj+vTpg/T0dLXtJk6cqPZABiIiIjIcg5+TSnW3bNkyAMCkSZPqeU8MJykpCZGRkViwYAHOnDmDrl27IigoqNq7O9y9exetWrVCTEwMHB0dtcakp6djypQpOHHiBFJSUlBZWYkBAwZo3FJs/PjxuHnzpvhaunSpzsdHREREdVMvh/uperm5uUhISMCFCxewa9cuBAUFwc/Pr753y2BiY2Mxfvx4hIeHAwDWrVuHQ4cOYfPmzfjggw804nv06IEePXoAgNb1ADQePLF161Y4ODggOzsbL7/8stjesGHDagtdIiIiMiwWqRLz66+/Yvbs2bCyssKQIUOwfv36+t4lg6moqEB2djZmz54ttsnlcgQGBur09mBV98q1s7NTa9+xYwe2b98OR0dHDBkyBPPmzUPDhg1r7KuoqEjtDhUKhQIKhUJn+1qdqpx1vaVZfedRmNR+mpBCLqj9WZun2SdDvX/GmssYx2SsuYxxTMaayxjHVEWpVEKpVIrLdX38ukyoy0mmRAaQl5cHFxcXZGRkqM0ez5o1C+np6cjKyqpxezc3N0yfPl3jnNRHqVQqvPbaayguLla7rdj69evRsmVLODs744cffsD7778PHx8f7N27V2s/paWl4oMmHhUSEqKzp4IREREZg507dyIpKUmjvaSkpNqndwKcSaXnzJQpU3D+/HmN+94+egFf586d4eTkhICAAFy9ehWtW7eutr9r167B2tpaXDbkTGpKSgr69+8PU1NTyefpFHWk1hiFXMAibxXmnZZDqdJ8Wt0/nY8KeuL9MdT7Z6y5jHFMxprLGMdkrLmMcUxVAgICEB8fLy6XlZXB3d291u1YpJJk2Nvbw8TERONRtwUFBTo5VzQiIgIHDx7EsWPH0Lx58xpjq55CduXKlRqLVDs7uxp/C9Q3U1NTg3zBPG0e5YPai04xViWrU7wuxm2o989YcxnjmIw1lzGOyVhzGeuYHn2se11z8ur+f4iKioJMJqvxVk3GmFsKzMzM4OXlhdTUVLFNpVIhNTX1qS4eEwQBERER+OKLL/D111/X6be3c+fOAXh4j14iIiIyPMkXqWlpaZDJZIiKiqrvXXkmbN26FTKZTBL3O30SkZGR2LBhA7Zt24aLFy9i0qRJKC8vF6/2Hz16tNqFVRUVFTh37hzOnTuHiooK3LhxA+fOncOVK1fEmClTpmD79u1ISEiAtbU18vPzkZ+fj7/++gsAcPXqVSxatAjZ2dnIycnB/v37MXr0aLz88svo0qWLYd8AIiIiAsDD/RoiIiIwcuRIuLq61veuPJdCQkJw69YtzJ8/H/n5+fD09ERycjKaNWsG4OEtuuTyv3+3ysvLQ7du3cTl5cuXY/ny5fD39xdnpNeuXQvg4Q37H7VlyxaMGTMGZmZmOHr0KOLi4lBeXo4WLVogODgYc+fO1e9giYiIqFosUv/B3t4e9vb29b0bz7WIiAhERERoXffPUyHq8hS02ta3aNFC42lTREREVL8kfbg/KioKffv2BQAsXLgQMplMfFU9enTMmDGQyWT49ddfsWLFCnTs2BEKhUJ8LGteXh4WLFiAnj17wsHBAQqFAm5ubpg8ebLWpxhpOy80JycHMpkMY8aMwZUrV/D666+jcePGsLS0RGBgIL7//vvHGtdvv/2G0NBQ2NnZwcrKCv7+/jh27JjW2IqKCqxatQpBQUFo0aIFFAoFHBwc8MYbb+Ds2bNqsWPGjBEPi4eHh6u9X1Wys7MRERGBTp06wdbWFhYWFujcuTNiYmIMdr80IiIiotpIeia1T58+yMnJwbZt2+Dv7692uPafz7KfOnUqTpw4gcGDB2PIkCFwcHAAABw7dgwrVqxAQEAAfH19YWpqirNnz2Lt2rU4cuQIzpw5o/V+l9rk5OSgZ8+eeOGFFzB27FhcvXoV//3vf9G3b19cvHhRPCRdk5s3b8LPzw83btxAUFAQunfvjosXL6J///5iQf6ooqIiTJ8+HS+99BJeeeUVNG7cGL/++iv279+PL7/8EseOHROfuDRs2DAUFxfjv//9L4YOHQpPT0+N/jZs2IADBw7g5ZdfxiuvvIK7d+8iLS0Ns2fPxqlTp/Cf//ynTu8FERERkT5JvkgFgG3btqFPnz41Xjz1ww8/4OzZsxrnkvbr1w/5+flqtz4AgM8//xxhYWFYvXo1PvzwwzrtT3p6OmJiYvD++++LbfPmzcPixYuxZcuWah/L+ajZs2fjxo0bWLx4sVre9evXY+LEiRrxjRs3Rm5uLlxcXNTaL1y4gJ49e2LOnDlISUkBoF6kDhs2TJxNftScOXMQHx8PExMTsU0QBLzzzjvYvHkzvvvuO/Tq1avWcRARERHpk6QP9z+OmTNnar3YycHBQaNABYC3334bNjY2OHr0aJ1zuLu7Y+bMmWpt48aNAwCcOnWq1u0rKiqQlJQEBwcH/Pvf/1Zb984776Bt27Ya2ygUCo0CFQBeeOEF9O3bF8eOHXusw/Surq5qBSoAyGQyTJkyBQAe6/0gIiIi0hejKVJ9fHyqXbd3714EBQWhadOmaNCgAWQyGeRyOUpLS5GXl1fnHJ6enmpXlgMQbwpfXFxc6/aXL1/GvXv34O3tDXNzc7V1crm82hnMc+fO4c0334SrqyvMzMzE80wPHDiAiooK/PHHH3UeQ0VFBWJjY+Hj4wMbGxvI5XLIZDJ4eXkBwGO9H0RERET6IunD/Y+juvNBV6xYgffeew9NmzbFgAED0Lx5c1hYWAAA4uLioFQq65xD25OFGjR4+BY+ePCg1u1LSkoAQDxf9p+0jSEjIwP9+vUDAAwYMABt27aFlZUVZDIZ9u3bh++///6xxvCvf/0LBw4cQLt27RASEgIHBweYmpqiuLgYK1eufKy+iIiIiPTFaIrUR69gr3L//n0sWrQITk5OOHfunFpxKAgCli5dashdFC/Q0nZXAQAajwMFgI8//hhKpRLffvstevfurbbuxIkTj3VngVOnTuHAgQMICgrCoUOH1A77nzhxAitXrqxzX0RERET6JPnD/VWFVF1mKv/pjz/+QElJCfz8/DRmL0+fPi0+cchQ2rVrB3Nzc5w+fRr37t1TW6dSqZCRkaGxzdWrV2FnZ6dRoN69exdnzpzRiK/p/bp69SoAYPDgwRrnpX777bePNxgiIiIiPZJ8kWpnZwfg4b1FH5eDgwMsLCxw5swZ3L17V2y/ffs2pk6dqrN9rCuFQoERI0agsLAQK1asUFu3ceNG/PzzzxrbtGzZErdv38aFCxfEtgcPHuC9997DrVu3NOJrer9atmwJADh+/Lha+4ULFxAdHf34AyIiIiLSE8kf7vfw8ICzszMSExOhUCjQvHlzyGQyTJ06tdb7m8rlckyePBkrVqxA165dMWTIEJSWluLLL79Ey5Yt4ezsbKBR/C0mJgapqamYO3cujh8/jm7duuHixYs4fPgwBgwYgK+++kotfurUqfjqq6/Qu3dvjBgxAubm5khLS8ONGzfQp08fjScw+fn5wcLCAnFxcbh9+zaaNm0KAJg7dy58fHzg4+ODXbt24ebNm+jZsydyc3Oxf/9+DB48GHv27DHU20BERERUI8nPpJqYmGDv3r3o2bMndu7cifnz52PevHm4fft2nbaPjo7Gxx9/DJlMhjVr1iAlJQWhoaH46quvYGpqque91+Tk5ISMjAyEhISI54H++eefSElJgZ+fn0b8q6++ij179qBVq1bYvn07EhIS4OHhgZMnT4ozo4+ys7PDnj170K5dO2zYsAHz5s3DvHnzADx8Lw8ePCg+iGDVqlX46aefsHz5coOfn0tERERUE8nPpAKAr6+vxoxhla1bt2Lr1q3Vbmtqaoo5c+Zgzpw5GuuqHq36qKioKI2HBtT2fPjang3/T66urkhMTNRof/nll7U+sCA4OBjBwcEa7dWN/ZVXXsErr7yiNXfTpk2xadMmresedxxERERE+iL5mVQiIiIiev6wSCUiIiIiyWGRSkRERESSwyKViIiIiCSHRSoRERERSQ6LVCIiIiKSHBapRERERCQ5LFKJiIiISHJYpBIRERGR5DwTT5wiItKV8vJyWFlZAQBu376NRo0a1e8OERGRVixSichouH1wqNYYVcU98eceHx9FpYlFrdvkxAx+qv0iIqLHx8P9RERERCQ5LFJJcuLj4+Hm5gZzc3P4+vri5MmT1cZeuHABwcHBcHNzg0wmQ1xc3BP1ee/ePUyZMgVNmjSBlZUVgoODUVBQoMthkUTIzczRbs4B7Nu3D3Iz8/reHSIiqgaLVJKUpKQkREZGYsGCBThz5gy6du2KoKAgFBYWao2/e/cuWrVqhZiYGDg6Oj5xnzNmzMCBAwewe/dupKenIy8vD2+88YZexkhERES1Y5FKkhIbG4vx48cjPDwcHTt2xLp169CwYUNs3rxZa3yPHj2wbNkyjBw5EgqF4on6LCkpwaZNmxAbG4t+/frBy8sLW7ZsQUZGBk6cOKG3sRIREVH1eOEUSUZFRQWys7Mxe/ZssU0ulyMwMBCZmZl66zM7OxuVlZUIDAwUYzw8PODq6orMzEz07Nmz2v6LiopQWVkpLisUimqLZV2qyvlobinnUZgItcfIBbU/a6Ntn+qSR1e56spQn5UhcxnjmIw1lzGOyVhzGeOYqiiVSiiVSnG5rKysTtvJBEGo27c0kZ7l5eXBxcUFGRkZ8PPzE9tnzZqF9PR0ZGVl1bi9m5sbpk+fjunTpz9WnwkJCQgPD1f7BwQAPj4+6Nu3L5YsWaKRq7S0FLa2thrtISEhCA0NreuQiYiIjN7OnTuRlJSk0V5SUgIbG5tqt+NMKtFTuHbtGqytrcVlQ86kpqSkoH///jA1NZV8nk5RR2qNUcgFLPJWYd5pOZQqWa3x56OCniiPrnLVlaE+K0PmMsYxGWsuYxyTseYyxjFVCQgIQHx8vLhcVlYGd3f3WrdjkUqSYW9vDxMTE42r6gsKCqq9KEoXfTo6OqKiogLFxcVqN3avS147O7safwvUN1NTU4N8wTxtHuWD2gtBMVYlq1O8tv15nDxPm+txGeqzMmQuYxyTseYyxjEZay5jHVPVQ1SqluuCF06RZJiZmcHLywupqalim0qlQmpqqtqhel336eXlBVNTU7WYy5cvIzc394nzEhER0dPhTCpJSmRkJMLCwuDt7Q0fHx/ExcWhvLwc4eHhAIDRo0fDxcUF0dHRAB5eGPXTTz+JP9+4cQPnzp2DlZUV2rRpU6c+bW1tMW7cOERGRoozo1OnToWfn1+NF00RERGR/rBIJUkJCQnBrVu3MH/+fOTn58PT0xPJyclo1qwZACA3Nxdy+d8HAPLy8tCtWzdxefny5Vi+fDn8/f2RlpZWpz4B4NNPP4VcLkdwcDCUSiWCgoKwZs0awwyaiIiINLBIJcmJiIhARESE1nVVhWcVNzc31OUGFTX1CQDm5uaIj49XO7GbiIiI6g/PSSUiIiIiyWGRSkRERESSwyKViIiIiCSHRSoRERERSQ4vnCIiMgLl5eXizbJv376t9mAKIqJnEWdSiYiIiEhyOJNKRCRxbh8cqjVGVXFP/LnHx0dRaWJRY3xOzOCn3i8iIn3iTCoRkRGQm5mj3ZwD2LdvH+Rm5vW9O0RET41FKhERERFJDotUIiIiIpIcFqlEREREJDksUomIiIhIclikEhEREZHksEglIiIiIslhkUpEREREksMilYiIiIgkh0UqEREREUkOi1QiIiIikhwWqUREREQkOSxSiYiIiEhyWKQSERERkeSwSCUiIiIiyWGRSkRERESSwyKViIiIiCSHRSpJUnx8PNzc3GBubg5fX1+cPHmyxvjdu3fDw8MD5ubm6Ny5Mw4fPqy2XiaTaX0tW7ZMjHFzc9NYHxMTo5fxERERUc1YpJLkJCUlITIyEgsWLMCZM2fQtWtXBAUFobCwUGt8RkYGQkNDMW7cOJw9exbDhg3DsGHDcP78eTHm5s2baq/NmzdDJpMhODhYra+PPvpILW7q1Kl6HSsRERFpxyKVJCc2Nhbjx49HeHg4OnbsiHXr1qFhw4bYvHmz1viVK1di4MCBmDlzJjp06IBFixahe/fuWL16tRjj6Oio9vrvf/+Lvn37olWrVmp9WVtbq8VZWlrqdaxERESkXYP63gGiR1VUVCA7OxuzZ88W2+RyOQIDA5GZmal1m8zMTERGRqq1BQUFYd++fVrjCwoKcOjQIWzbtk1jXUxMDBYtWgRXV1e8+eabmDFjBho0qP6fSVFRESorK8VlhUIBhUJR0xB1oirno7mlnEdhItQeIxfU/qyNtn2qSx5d5aorXbyH+hhXfY+JuZ6tf8PMxc/qaSiVSiiVSnG5rKysTtvJBEGo27cfkQHk5eXBxcUFGRkZ8PPzE9tnzZqF9PR0ZGVlaWxjZmaGbdu2ITQ0VGxbs2YNFi5ciIKCAo34pUuXIiYmBnl5eTA3NxfbY2Nj0b17d9jZ2SEjIwOzZ89GeHg4YmNjNfooLS2Fra2tRntISIjafhARET3vdu7ciaSkJI32kpIS2NjYVLsdZ1LpubN582aMGjVKrUAFoDYb26VLF5iZmWHixImIjo6udnb02rVrsLa2FpcNOZOakpKC/v37w9TUVPJ5OkUdqTVGIRewyFuFeaflUKpktcafjwp6ojy6ylVXungP9TGu+h4Tcz1b/4aZi5/V0wgICEB8fLy4XFZWBnd391q3Y5FKkmJvbw8TExONGdCCggI4Ojpq3cbR0bHO8d9++y0uX76s9Te6f/L19cX9+/eRk5OD9u3ba42xs7Or8bdAfTM1NTXIF8zT5lE+qL0QFGNVsjrFa9ufx8nztLke19O8h/oYV32PibkMm8sYx2SsuYx1TFZWVmrLdcELp0hSzMzM4OXlhdTUVLFNpVIhNTVV7fD/o/z8/NTiASAlJUVr/KZNm+Dl5YWuXbvWui/nzp2DXC6Hg4PDY46CiIiInhZnUklyIiMjERYWBm9vb/j4+CAuLg7l5eUIDw8HAIwePRouLi6Ijo4GAEybNg3+/v5YsWIFBg8ejMTERJw+fRrr169X67e0tBS7d+/GihUrNHJmZmYiKysLffv2hbW1NTIzMzFjxgy89dZbaNy4sf4HTfSMKC8vF2dEbt++jUaNGtXvDhGR0WKRSpITEhKCW7duYf78+cjPz4enpyeSk5PRrFkzAEBubi7k8r8PArz44otISEjA3LlzMWfOHLRt2xb79u1Dp06d1PpNTEyEIAhaL2xSKBRITExEVFQUlEol3N3dMWPGDI27BhAZO7cPDtW4XlVxT/y5x8dHUWliUWufOTGDn3q/iOj5wyKVJCkiIgIRERFa16WlpWm0DR8+HMOHD6+xzwkTJmDChAla13Xv3h0nTpx47P0ket7IzczRbs4BLPV5gFknTYAH+svFWVui5xuLVCIiMrjaZmwBztoSPe9YpBIRkSRx1pbo+cYilYiIjJo+Zm2fZsaWBTFR3bBIJSKi556uZm2lVBAbshhm4U36wCKViIjIgAxVEOvqnF6pnT/Mgvj5wSKViIjICBnynF5jnImm+scnThEREdEzo6og3rdvH+Rm5vW9O6RHLFKJiIiISHJ4uJ+IiIhIC57/Wr9YpBIREdFzh+e/Sh8P9xMRERFpwfNf6xeLVCIiIiKSHBapRERERCQ5LFKJiIiISHJYpBIRERGR5LBIJSIiIiLJYZFKRERERJLDIpWIiIiIJIdFKhERERFJDotUIiIiIpIcFqlEREREJDksUomIiIhIclikEhEREZHksEglIiIiIslhkUqSFB8fDzc3N5ibm8PX1xcnT56sMX737t3w8PCAubk5OnfujMOHD6utHzNmDGQymdpr4MCBajFFRUUYNWoUbGxs0KhRI4wbNw537tzR+diIiIiodg3qeweI/ikpKQmRkZFYt24dfH19ERcXh6CgIFy+fBkODg4a8RkZGQgNDUV0dDReffVVJCQkYNiwYThz5gw6deokxg0cOBBbtmwRlxUKhVo/o0aNws2bN5GSkoLKykqEh4djwoQJSEhI0N9g6Znl9sGhWmNUFffw26f/AgC0eW83Kk0saozPiRmsk30jIjIGnEklyYmNjcX48eMRHh6Ojh07Yt26dWjYsCE2b96sNX7lypUYOHAgZs6ciQ4dOmDRokXo3r07Vq9erRanUCjg6Ogovho3biyuu3jxIpKTk7Fx40b4+vqid+/eWLVqFRITE5GXl6fX8ZLxkpuZo92cA9i3bx/kZub1vTtERM8UzqSSpFRUVCA7OxuzZ88W2+RyOQIDA5GZmal1m8zMTERGRqq1BQUFYd++fWptaWlpcHBwQOPGjdGvXz8sXrwYTZo0Efto1KgRvL29xfjAwEDI5XJkZWXh9ddf15q7qKgIlZWV4rJCodCYodWHqpyP5pZyHoWJUHuMXFD7szba9qkueaScq7r3WWq5pPr+GTIXP6tnJ5cUPqu6MNT3uqFzAYBSqYRSqRSXy8rK6rSdTBCEun1KRAaQl5cHFxcXZGRkwM/PT2yfNWsW0tPTkZWVpbGNmZkZtm3bhtDQULFtzZo1WLhwIQoKCgAAiYmJaNiwIdzd3XH16lXMmTMHVlZWyMzMhImJCT755BNs27YNly9fVuvbwcEBCxcuxKRJk9TaS0tLYWtrq7EvISEhavtBRET0vNu5cyeSkpI02ktKSmBjY1PtdpxJpefCyJEjxZ87d+6MLl26oHXr1khLS0NAQMAT93vt2jVYW1uLy4acSU1JSUH//v1hamoq+Tydoo7UGqOQC1jkrcK803IoVbJa489HBT1RHinn0pZHirmk+v4ZMhc/q2cnlxQ+q7ow1Pe6oXMBQEBAAOLj48XlsrIyuLu717odi1SSFHt7e5iYmIgzoFUKCgrg6OiodRtHR8fHigeAVq1awd7eHleuXEFAQAAcHR1RWFioFnP//n0UFRXV2I+dnV2NvwXqm6mpqUG+YJ42j/JB7f9hibEqWZ3ite3P4+SRYq7q3mOp5pLa+2fIXPysnp1cUvisHoehvtcNmcvU1BRWVlZqy3XBC6dIUszMzODl5YXU1FSxTaVSITU1Ve3w/6P8/PzU4gEgJSWl2ngA+P333/Hnn3/CyclJ7KO4uBjZ2dlizNdffw2VSgVfX9+nGRIRERE9ARapJDmRkZHYsGEDtm3bhosXL2LSpEkoLy9HeHg4AGD06NFqF1ZNmzYNycnJWLFiBS5duoSoqCicPn0aERERAIA7d+5g5syZOHHiBHJycpCamoqhQ4eiTZs2CAp6eGimQ4cOGDhwIMaPH4+TJ0/iu+++Q0REBEaOHAlnZ2fDvwlERETPOR7uJ8kJCQnBrVu3MH/+fOTn58PT0xPJyclo1qwZACA3Nxdy+d+/X7344otISEjA3LlzMWfOHLRt2xb79u0T75FqYmKCH374Adu2bUNxcTGcnZ0xYMAALFq0SO380R07diAiIgIBAQGQy+UIDg7GZ599ZtjBExEREQAWqSRRERER4kzoP6WlpWm0DR8+HMOHD9cab2FhgSNHaj9B3s7OjjfuJyIikgge7iciIiIiyWGRSkRERESSwyKViIiIiCSHRSoRERERSQ6LVCIiIiKSHBapRERERCQ5LFKJiIiISHJYpBIRERGR5LBIJSIiIiLJYZFKRERERJLDIpWIiIiIJIdFKhERERFJDotUIiIiIpIcFqlEREREJDksUomIiIhIclikEhEREZHksEglIiIiIslhkUpEREREksMilYiIiIgkh0UqEREREUkOi1QiIiIikhwWqUREREQkOSxSiYiIiEhyWKQSERERkeSwSCVJio+Ph5ubG8zNzeHr64uTJ0/WGL979254eHjA3NwcnTt3xuHDh8V1lZWVeP/999G5c2dYWlrC2dkZo0ePRl5enlofbm5ukMlkaq+YmBi9jI+IiIhqxiKVJCcpKQmRkZFYsGABzpw5g65duyIoKAiFhYVa4zMyMhAaGopx48bh7NmzGDZsGIYNG4bz588DAO7evYszZ85g3rx5OHPmDPbu3YvLly/jtdde0+jro48+ws2bN8XX1KlT9TpWIiIi0o5FKklObGwsxo8fj/DwcHTs2BHr1q1Dw4YNsXnzZq3xK1euxMCBAzFz5kx06NABixYtQvfu3bF69WoAgK2tLVJSUjBixAi0b98ePXv2xOrVq5GdnY3c3Fy1vqytreHo6Ci+LC0t9T5eIiIi0tSgvneA6FEVFRXIzs7G7NmzxTa5XI7AwEBkZmZq3SYzMxORkZFqbUFBQdi3b1+1eUpKSiCTydCoUSO19piYGCxatAiurq548803MWPGDDRoUP0/k6KiIlRWVorLCoUCCoWihhHqRlXOR3NLOY/CRKg9Ri6o/VkbbftUlzxSzlXd+yy1XFJ9/wyZi5/Vs5NLCp9VXRjqe93QuQBAqVRCqVSKy2VlZXXaTiYIQt0+JSIDyMvLg4uLCzIyMuDn5ye2z5o1C+np6cjKytLYxszMDNu2bUNoaKjYtmbNGixcuBAFBQUa8ffu3UOvXr3g4eGBHTt2iO2xsbHo3r077OzskJGRgdmzZyM8PByxsbEafZSWlsLW1lajPSQkRG0/iIiInnc7d+5EUlKSRntJSQlsbGyq3Y4zqfRcqaysxIgRIyAIAtauXau27tHZ2C5dusDMzAwTJ05EdHR0tbOj165dg7W1tbhsyJnUlJQU9O/fH6amppLP0ynqSK0xCrmARd4qzDsth1IlqzX+fFTQE+WRci5teaSYS6rvnyFz8bN6dnJJ4bOqC0N9rxs6FwAEBAQgPj5eXC4rK4O7u3ut27FIJUmxt7eHiYmJxgxoQUEBHB0dtW7j6OhYp/iqAvX69ev4+uuva/ztDQB8fX1x//595OTkoH379lpj7Ozsau1Hn0xNTQ3yBfO0eZQPav8PS4xVyeoUr21/HiePFHNV9x5LNZfU3j9D5uJn9ezkksJn9TgM9b1uyFympqawsrJSW64LXjhFkmJmZgYvLy+kpqaKbSqVCqmpqWqH/x/l5+enFg8AKSkpavFVBeovv/yCo0ePokmTJrXuy7lz5yCXy+Hg4PCEoyEiIqInxZlUkpzIyEiEhYXB29sbPj4+iIuLQ3l5OcLDwwEAo0ePhouLC6KjowEA06ZNg7+/P1asWIHBgwcjMTERp0+fxvr16wE8LFD/9a9/4cyZMzh48CAePHiA/Px8AA9nQs3MzJCZmYmsrCz07dsX1tbWyMzMxIwZM/DWW2+hcePG9fNGEBERPcdYpJLkhISE4NatW5g/fz7y8/Ph6emJ5ORkNGvWDACQm5sLufzvgwAvvvgiEhISMHfuXMyZMwdt27bFvn370KlTJwDAjRs3sH//fgCAp6enWq5vvvkGffr0gUKhQGJiIqKioqBUKuHu7o4ZM2Zo3DWAiIiIDINFKklSREQEIiIitK5LS0vTaBs+fDiGDx+uNd7NzQ213cSie/fuOHHixGPvJxEREekHz0klIiIiIslhkUpEREREksMilYiIiIgkh0UqEREREUkOi1QiIiIikhwWqUREREQkOSxSiYiIiEhyWKQSERERkeSwSCUiIiIiyWGRSkRERESSwyKViIiIiCSHRSoRERERSQ6LVCIiIiKSHBapRERERCQ5LFKJiIiISHJYpBIRERGR5LBIJSIiIiLJYZFKRERERJLDIpWIiIiIJIdFKhERERFJDotUIiIiIpIcFqlEREREJDksUomIiIhIclikEj2DlEoldu7cCaVSaRR5AEB1vxI7d+6E6n4lc0k8lzGOyVhzGeOYjDWXIb9vDZnrabBIJXoGKZVKJCUlGaRINUQeABAeVCIpKQnCA/3/p8Ncz0Ye5np28jDX0zPk960hcz0NFqkkSfHx8XBzc4O5uTl8fX1x8uTJGuN3794NDw8PmJubo3Pnzjh8+LDaekEQMH/+fDg5OcHCwgKBgYH45Zdf1GKKioowatQo2NjYoFGjRhg3bhzu3Lmj87ERERFR7VikkuQkJSUhMjISCxYswJkzZ9C1a1cEBQWhsLBQa3xGRgZCQ0Mxbtw4nD17FsOGDcOwYcNw/vx5MWbp0qX47LPPsG7dOmRlZcHS0hJBQUG4d++eGDNq1ChcuHABKSkpOHjwII4dO4YJEybofbxERESkqUF97wDRP8XGxmL8+PEIDw8HAKxbtw6HDh3C5s2b8cEHH2jEr1y5EgMHDsTMmTMBAIsWLUJKSgpWr16NdevWQRAExMXFYe7cuRg6dCgA4PPPP0ezZs2wb98+jBw5EhcvXkRycjJOnToFb29vAMCqVavwyiuvYPny5XB2dlbLKQgCAOD69euwtrYW283MzKBQKHT/pvzD7du3YW5ujtu3bz8TeRrcL69DzF2Ym5ujwf27derzzz//fKI8Us6lLY8Uc0n1/TNkLn5Wz04uKXxWdWGo73VD5wIenl5QUVEhLpeVlQH4+//SaglEEqJUKgUTExPhiy++UGsfPXq08Nprr2ndpkWLFsKnn36q1jZ//nyhS5cugiAIwtWrVwUAwtmzZ9ViXn75ZeF//ud/BEEQhE2bNgmNGjVSW19ZWSmYmJgIe/fu1cj522+/CQD44osvvvjii68nfP3222811gScSSVJ+eOPP/DgwQM0a9ZMrb1Zs2a4dOmS1m3y8/O1xufn54vrq9pqinFwcFBb36BBA9jZ2Ykxj3J2dsbVq1dhamoKmUwmtisUCoPMpBIRET0rlEql2kVagiCgsrJS4yjlP7FIJXoCcrkcrVq1qu/dICIiMlq8cIokxd7eHiYmJigoKFBrLygogKOjo9ZtHB0da4yv+rO2mH9emHX//n0UFRVVm5eIiIj0h0UqSYqZmRm8vLyQmpoqtqlUKqSmpsLPz0/rNn5+fmrxAJCSkiLGu7u7w9HRUS2mtLQUWVlZYoyfnx+Ki4uRnZ0txnz99ddQqVTw9fXV2fiIiIiobni4nyQnMjISYWFh8Pb2ho+PD+Li4lBeXi5e7T969Gi4uLggOjoaADBt2jT4+/tjxYoVGDx4MBITE3H69GmsX78eACCTyTB9+nQsXrwYbdu2hbu7O+bNmwdnZ2cMGzYMANChQwcMHDgQ48ePx7p161BZWYmIiAiMHDmy1nNmiIiISPdYpJLkhISE4NatW5g/fz7y8/Ph6emJ5ORk8cKn3NxcyOV/HwR48cUXkZCQgLlz52LOnDlo27Yt9u3bh06dOokxs2bNQnl5OSZMmIDi4mL07t0bycnJMDc3F2N27NiBiIgIBAQEQC6XIzg4GJ999pnhBk5ERER/q/HafyKShLCwMAGAMHHiRI11kydPFgAIYWFhOs9X9bKzsxOCgoKE77//Xmc5qstV9QoKCtJLnujoaLX2L774QtDXV+Hq1auFli1bCgqFQvDx8RGysrL0kic9PV149dVXBScnJwGAxi3cdOWTTz4RvL29BSsrK6Fp06bC0KFDhUuXLukl15o1a4TOnTsL1tbWgrW1tdCzZ0/h8OHDesn1qOjoaAGAMG3aNJ33vWDBAo2/5+3bt9d5niq///67MGrUKMHOzk4wNzcXOnXqJJw6dUrneVq2bKn13/DkyZN1muf+/fvC3LlzBTc3N8Hc3Fxo1aqV8NFHHwkqlUqneaqUlpYK06ZNE1xdXQVzc3PBz89POHnypF5ykXY8J5XoGdGiRQskJibir7/+Etvu3buHhIQEuLq66jzfwIEDcfPmTdy8eROpqalo0KABXn31VZ3n+WeuqtfOnTt1nsfc3BxLliwxyA2sH/fJaU+jvLwcXbt2RXx8vM77flR6ejqmTJmCEydOICUlBZWVlRgwYADKy+t2U/TH0bx5c8TExCA7OxunT59Gv379MHToUFy4cEHnuaqcOnUK//u//4suXbroLccLL7yg9vf8+PHjeslz+/Zt9OrVC6ampvjyyy/x008/YcWKFWjcuLHOc506dUptTCkpKQCA4cOH6zTPkiVLsHbtWqxevRoXL17EkiVLsHTpUqxatUqneaq88847SElJwf/93//hxx9/xIABAxAYGIgbN27oJR8A9OnTB1u3btVb/8+c+q6Siah2YWFhwtChQ4VOnToJ27dvF9t37NghdOnSRRg6dKjOZ1KHDh2q1vbtt98KAITCwkKd5akulz6EhYUJr776quDh4SHMnDlTbNfXTKqPj48wZcoUcfnBgweCs7OzxkyurkGPM6n/VFhYKAAQ0tPTDZKvcePGwsaNG/XSd1lZmdC2bVshJSVF8Pf319tMateuXXXerzbvv/++0Lt3b4Pk+qdp06YJrVu31vkM5+DBg4WxY8eqtb3xxhvCqFGjdJpHEATh7t27gomJiXDw4EG19u7duwsffvihzvNV8ff3F7Zs2aK3/p81nEkleoaMHTsWW7ZsEZc3b94sXlCmT3fu3MH27dvRpk0bNGnSRO/59MXExASffPIJVq1ahd9//11veSoqKpCdnY3AwECxTS6XIzAwEJmZmXrLa2glJSUAADs7O73mefDgARITE1FeXl7tXT6e1pQpUzB48GC1z0wffvnlFzg7O6NVq1YYNWoUcnNz9ZJn//798Pb2xvDhw+Hg4IBu3bphw4YNesn1qIqKCmzfvh1jx45Ve9CJLrz44otITU3Fzz//DAD4/vvvcfz4cQwaNEineYCHtyB88OCB2nULAGBhYaG32W/SxCKV6Bny1ltv4fjx47h+/TquX7+O7777Dm+99ZZech08eBBWVlawsrKCtbU19u/fj6SkJLWL1vSRq+r1ySef6DwPALz++uvw9PTEggUL9NI/UPOT07Q9wexZpFKpMH36dPTq1UvtIkVd+vHHH2FlZQWFQoF3330XX3zxBTp27KjzPImJiThz5ox4xxB98fX1xdatW5GcnIy1a9fi2rVreOmll8TnmOvSr7/+irVr16Jt27Y4cuQIJk2ahP/5n//Btm3bdJ7rUfv27UNxcTHGjBmj874/+OADjBw5Eh4eHjA1NUW3bt0wffp0jBo1Sue5rK2t4efnh0WLFiEvLw8PHjzA9u3bkZmZiZs3b+o8nyHt2LFD7bv222+/re9dqhav7id6hjRt2hSDBw/G1q1bIQgCBg8eDHt7e73k6tu3L9auXQvg4flta9aswaBBg3Dy5Em0bNlSb7mq6HN2bsmSJejXrx/ee+89veUwdlOmTMH58+f1OqvUvn17nDt3DiUlJdizZw/CwsKQnp6u00L1t99+w7Rp05CSkqIxa6Zrj874denSBb6+vmjZsiV27dqFcePG6TSXSqWCt7e3+Mtet27dcP78eaxbtw5hYWE6zfWoTZs2YdCgQXq5dd+uXbuwY8cOJCQk4IUXXsC5c+cwffp0ODs762VM//d//4exY8fCxcUFJiYm6N69O0JDQ9Xup/20PvnkE7VfyP/66y+cOHECERERYttPP/2k0+sOXnvtNbX7f7u4uOisb11jkUr0jBk7dqz4BabPC2UsLS3Rpk0bcXnjxo2wtbXFhg0bsHjxYr3m0reXX34ZQUFBmD17tl5mfJ7kyWnPkoiICBw8eBDHjh1D8+bN9ZbHzMxM/Hvh5eWFU6dOYeXKlfjf//1fneXIzs5GYWEhunfvLrY9ePAAx44dw+rVq6FUKmFiYqKzfI9q1KgR2rVrhytXrui8bycnJ41ivkOHDvjPf/6j81xVrl+/jqNHj2Lv3r166X/mzJnibCoAdO7cGdevX0d0dLReitTWrVsjPT0d5eXlKC0thZOTE0JCQnT6SOx3330XI0aMEJdHjRqF4OBgvPHGG2Kbrgt+a2trWFtb67RPfWGRSvSMGThwICoqKiCTyRAUFGSwvDKZDHK5XO3uAs+ymJgYeHp6on379jrv+9Enp1U9MKLqyWmPzpA8awRBwNSpU/HFF18gLS0N7u7uBs2vUqmgVCp12mdAQAB+/PFHtbbw8HB4eHjg/fff11uBCjw81/vq1at4++23dd53r169cPnyZbW2n3/+WedHQR61ZcsWODg4YPDgwXrp/+7duxqnG5mYmEClUuklXxVLS0tYWlri9u3bOHLkCJYuXaqzvu3s7NSOGllYWMDBwcGgv7RLGYtUomeMiYkJLl68KP6sL0qlUjx/8vbt21i9ejXu3LmDIUOG6DVXlQYNGujtVAbg4SzMqFGj9PbAhtqenKZLd+7cUZuNu3btGs6dOwc7OzudHiacMmUKEhIS8N///hfW1tbiZ2ZrawsLCwud5QGA2bNnY9CgQXB1dUVZWRkSEhKQlpaGI0eO6DSPtbW1xjm1lpaWaNKkic7PtX3vvfcwZMgQtGzZEnl5eViwYAFMTEwQGhqq0zwAMGPGDLz44ov45JNPMGLECJw8eRLr168Xn8SnayqVClu2bEFYWBgaNNBPaTFkyBB8/PHHcHV1xQsvvICzZ88iNjYWY8eO1Uu+I0eOQBAEtG/fHleuXMHMmTPh4eFhkItV6f+r57sLEFEd1HabJn3cggqP3JTb2tpa6NGjh7Bnzx6d5aguF/R0k3Nt7+G1a9cEMzMzvd3Mf9WqVYKrq6tgZmYm+Pj4CCdOnNBLnm+++Ubre6jLvxOCIGjNAUAvt8wZO3as0LJlS8HMzExo2rSpEBAQIHz11Vc6z6ONvm5BFRISIjg5OQlmZmaCi4uLEBISIly5ckXneaocOHBA6NSpk6BQKAQPDw9h/fr1est15MgRAYBw+fJlveX45831W7VqJXz44YeCUqnUS76kpCShVatWgpmZmeDo6ChMmTJFKC4u1kuuKrwFlTqZIAiCQatiIiIiIqJa8BZURERERCQ5LFKJiIiISHJYpBIRERGR5LBIJSIiIiLJYZFKRERERJLDIpWIiIiIJIdFKhERERFJDotUIiIiIpIcFqlEREREJDksUomIiIhIclikEhEREZHksEglIiIiIslhkUpEREREksMilYiIiIgkh0UqEREREUkOi1QiIiIikhwWqUREREQkOSxSiYiIiEhyWKQSERERkeSwSCUiIiIiyWGRSkRERESSwyKViIiIiCSHRSoRERERSQ6LVCIi0pkxY8ZAJpMhJyenvneFiJ5xLFKJiKhW2dnZGDduHNq2bQtLS0tYWFigdevWePvtt5GSklLfu2cQffr0gUwmq+/dIHpusEglIqJqqVQqREZGwtvbG59//jlatWqFd999F9OmTYOXlxcOHTqEAQMGYNGiRfW9q0RkZBrU9w4QEZF0zZ07F59++ik8PT2xZ88etG7dWm39X3/9hdWrV+PPP/+spz0kImPFmVQiItLqypUrWLp0KZo0aYLk5GSNAhUALCwsMHPmTCxcuFCtXRAEfPbZZ/Dw8IBCoUDLli2xcOFCqFQqtbiSkhIsWbIE/v7+cHZ2hpmZGZydnTF69GhcvXpVI19UVBRkMhnS0tKwdetWdO/eHQ0bNkSfPn2eqL+qfd2yZQteeuklNGrUCA0bNkTbtm0xceJE5ObmAgBkMhnS09PFn6teY8aMUevrhx9+wMiRI+Hk5AQzMzO0bNkSU6dO1Sjic3JyxO0vXryI119/HU2aNOH5vESP4EwqERFptXXrVjx48AATJ05Es2bNaoxVKBRqyzNnzkR6ejpeffVVBAUFYd++fYiKikJFRQU+/vhjMe7ixYuYP38++vbti9dffx2Wlpa4dOkSEhIScOjQIZw5cwYtW7bUyLds2TJ88803GDp0KAYMGAATE5Mn6k+lUiEkJAR79uyBi4sLQkNDYWNjg5ycHOzatQuDBg2Cq6srFixYgK1bt+L69etYsGCBuL2np6f48/79+zFixAjI5XIMHToULVq0wE8//YTVq1fjyJEjyMrKQuPGjdXGceXKFfTs2ROdO3fGmDFj8Oeff8LMzKz2D4foeSAQERFp0adPHwGAcPTo0TpvExYWJgAQ3N3dhby8PLH91q1bQqNGjQRra2tBqVSK7cXFxcKff/6p0c/XX38tyOVy4Z133lFrX7BggQBAsLS0FH744QeN7R63v1WrVgkAhICAAOHu3btq6+7evavWl7+/v1Ddf5t//PGHYGNjI7i4uAg5OTlq63bu3CkAECIiIsS2a9euCQAEAML8+fO19kn0vOPhfiIi0io/Px8A0Lx588fedt68eXBychKX7e3tMXToUJSVleHy5ctiu62tLezs7DS279u3L1544QUcPXpUa/8TJkxA586dNdoft781a9bAxMQEa9euhYWFhdo6CwsLrX1p8/nnn6O0tBTR0dEaM78jR45E9+7dkZiYqLGdo6MjPvzwwzrlIHre8HA/ERHpnJeXl0ZbVbFbXFys1p6Wloa4uDhkZWXhjz/+wP3798V11R369vHxqTZ3Xfu7c+cOLl68iDZt2qBt27Z1Gld1Tpw4AQDIysrSeu7rvXv38Mcff+CPP/6Avb292N61a1ce3ieqBotUIiLSytHREZcuXcKNGzfQvn37x9rWxsZGo61Bg4f/5Tx48EBs2717N0JCQmBlZYWgoCC4ubmhYcOGkMlk4jmg2lR3juzj9FdSUgIAcHFxeayxaVNUVAQAiI+PrzGuvLxcrUit7VxfoucZi1QiItKqV69eSEtLQ2pqKvr166eXHFFRUTA3N0d2drbGbKa2w+NVqrup/uP0Z2trCwC4cePGk+y6mqqi/Mcff0SnTp3qvB0fDkBUPZ6TSkREWo0ZMwYmJiZYv349bt26VWOsUql8ohxXr15Fhw4dNArKmzdv4tdff9Vrf1ZWVujYsSOuXbuGX375pda+q+4g8OhMcBVfX18AQGZm5mPvMxFpxyKViIi0atOmDWbNmoU//vgDgwYNwrVr1zRi7t27h9jYWERFRT1RjpYtW+LKlSsoKChQ63PSpEmorKzUe39TpkzBgwcPMHnyZPz1119q6+7duycexgcgXkT122+/afQTHh4Oa2trfPjhh7hw4YLG+rt374rnrRJR3fBwPxERVWvx4sW4d+8ePv30U7Rv3x79+vVDp06dYGpqimvXruHo0aP4888/sXjx4ifqf+rUqZg6dSq6deuGf/3rX7h//z5SUlIgCAK6du2K77//Xq/9TZo0Cenp6di1axfatm2L1157DTY2NsjNzcWRI0ewadMmDBs2DADQr18/7NmzB8HBwRg0aBDMzc3RtWtXDBkyBE2bNsXOnTsxfPhwdO3aFQMHDoSHhweUSiVycnKQnp6OF198EcnJyU/0PhE9j1ikEhFRteRyOWJjY/Hmm29i7dq1OHbsGI4dOwaVSgUnJycEBQUhPDwcgYGBT9T/lClTYGpqilWrVmHDhg1o1KgRBg8ejOjoaAwfPlzv/clkMiQmJmLAgAHYuHEjPv/8cwiCABcXF4wYMULtLgXjx49HTk4OEhMTsWTJEty/fx9hYWEYMmQIAGDw4ME4e/Ysli1bhqNHjyIlJQWWlpZo3rw5wsPD8dZbbz3Re0T0vJIJgiDU904QERERET2K56QSERERkeSwSCUiIiIiyWGRSkRERESSwyKViIiIiCSHRSoRERERSQ6LVCIiIiKSHBapRERERCQ5LFKJiIiISHJYpBIRERGR5LBIJSIiIiLJYZFKRERERJLDIpWIiIiIJOf/AbGDIqtB5ENMAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##=========================================================##\n",
    "##   Quickly visualise distribution of token frequencies   ##\n",
    "##=========================================================##\n",
    "\n",
    "##  Imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "##  Get sample of train data labels\n",
    "train_data_sample = np.concatenate([train_gen[i][1].numpy().flatten() for i in range(1000)])\n",
    "\n",
    "##  Ignore masked tokens\n",
    "train_data_sample = train_data_sample[train_data_sample != 0]\n",
    "\n",
    "##  Count number for each token\n",
    "chars, freqs = [], []\n",
    "for token, char in train_gen.token_transform.detokeniser_dict.items() :\n",
    "    chars.append(char)\n",
    "    freqs.append(len(train_data_sample[train_data_sample==token]))\n",
    "    \n",
    "##  Normalise counts to frequency\n",
    "freqs     = np.array(freqs).astype(np.float32)\n",
    "freqs_err = np.sqrt(freqs)\n",
    "freqs_tot = np.sum(freqs)\n",
    "freqs     /= freqs_tot\n",
    "freqs_err /= freqs_tot\n",
    "\n",
    "##  Log token frequencies\n",
    "for char, freq, freq_err in zip(chars, freqs, freqs_err) :\n",
    "    logger.debug(f\"Token '{char}' in training data with frequency {100.*freq:.1f} +- {100.*freq_err:.1f} % (masked)\")\n",
    "\n",
    "##  Plot quick bar chart of frequencies\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax  = fig.add_subplot(1, 1, 1)\n",
    "ax.tick_params(which=\"both\", axis=\"both\", right=True, top=True, labelsize=10, direction=\"in\")\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"Character\", fontsize=14, va=\"top\"  , labelpad=15)\n",
    "ax.set_ylabel(\"Frequency in\\ntrain data\", fontsize=14, ha=\"right\", rotation=0, labelpad=20)\n",
    "\n",
    "ax.bar(chars, freqs, yerr=freqs_err)\n",
    "\n",
    "fig_fname = f\"{working_dir}/token_distribution.pdf\"\n",
    "logger.info(f\"Saving distribution of token frequencies to file {fig_fname}\")\n",
    "\n",
    "plt.savefig(fig_fname, bbox_inches=\"tight\")\n",
    "plt.show(fig)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39db1bb",
   "metadata": {},
   "source": [
    "##  4.  Create model\n",
    "\n",
    "Create the keras model object that handles sequence-sequence transformations from alread-tokenised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae1868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers     import Add, Average, Concatenate, Embedding, Input, LayerNormalization\n",
    "from tensorflow.keras.models     import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from mathsformer.tf_objects import (DecoderBlock, EncoderBlock, Enumerate, FeedForwardBlock, LearnableMixture, MaskedCategoricalAccuracy,\n",
    "                                    MaskedSparseCategoricalCrossentropy, PositionalEncoding)\n",
    "from mathsformer.tf_objects import scalar_masked_sparse_categorical_crossentropy, scalar_masked_categorical_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98368f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_text_to_text_model(vocab_length:int, \n",
    "                              name:str, \n",
    "                              do_compile:bool       = True,\n",
    "                              use_old_loss:bool     = False,\n",
    "                              dtype_in              = tf.int32, \n",
    "                              dtype                 = tf.float32, \n",
    "                              dropout:float         = 0.1, \n",
    "                              jit_compile:bool      = None,\n",
    "                              optimizer             = Adam,\n",
    "                              optimizer_args:dict   = None,\n",
    "                              idempotent_size:int   = -1,\n",
    "                              pos_enc_num_freqs:int = 32, pos_enc_min_period:float = 4, pos_enc_max_period:float = 500 , pos_enc_learnable:bool = False,\n",
    "                              ndim_embedding:int          = 64, comb_type:str                  = \"average\",\n",
    "                              num_preencoder_blocks:int   = 5 , ndim_preencoder:int            = 64 , skip_connect_preencoder:bool  = True, mixture_skip_connect_preencoder:bool = False,\n",
    "                              num_encoder_blocks:int      = 5 , ndim_encoder:int               = 64 , skip_connect_encoder:bool     = True, mixture_skip_connect_encoder:bool    = False,\n",
    "                              num_decoder_blocks:int      = 5 , ndim_decoder:int               = 64 , skip_connect_decoder:bool     = True, mixture_skip_connect_decoder:bool    = False,\n",
    "                              num_heads_preencoder:int    = 8 , ndim_att_hidden_preencoder:int = 128, ndim_ff_hidden_preencoder:int = 128, \n",
    "                              num_heads_encoder:int       = 8 , ndim_att_hidden_encoder:int    = 128, ndim_ff_hidden_encoder:int    = 128, \n",
    "                              num_heads_decoder:int       = 8 , ndim_att_hidden_decoder:int    = 128, ndim_ff_hidden_decoder:int    = 128, \n",
    "                              num_preencoder_loops:int    = 1 , num_encoder_loops:int          = 1  , num_decoder_loops:int         = 1  ,\n",
    "                              num_post_layers_decoder:int = 3 , ndim_post_layers_decoder:int   = 512, \n",
    "                             ) :\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ##  Resolve mutable default args\n",
    "    if optimizer_args is None :\n",
    "        optimizer_args = {'learning_rate': 1e-3}\n",
    "    \n",
    "    ##=============================================##\n",
    "    ##===   Input layer - Output shape [B, S]   ===##\n",
    "    ##=============================================##\n",
    "    x_in_enc = Input((None,), dtype=dtype_in, name=f\"{name}_encoder_input_layer\")\n",
    "    x_in_dec = Input((None,), dtype=dtype_in, name=f\"{name}_decoder_input_layer\")\n",
    "            \n",
    "    ##===========================================================================##\n",
    "    ##===  Token embedding, masking 0s - Output shape [B, S, ndim_embedding]  ===##\n",
    "    ##===========================================================================##\n",
    "    x_embed_enc = Embedding(vocab_length, \n",
    "                            ndim_embedding, \n",
    "                            mask_zero=True, \n",
    "                            dtype=dtype, \n",
    "                            name=f\"{name}_encoder_embedding\")(x_in_enc)\n",
    "    x_embed_dec = Embedding(vocab_length, \n",
    "                            ndim_embedding, \n",
    "                            mask_zero=True, \n",
    "                            dtype=dtype, \n",
    "                            name=f\"{name}_decoder_embedding\")(x_in_dec)\n",
    "    \n",
    "    ##=========================================================================##\n",
    "    ##===  Enumerate indices for positional encoding - Output shape [B, S]  ===##\n",
    "    ##=========================================================================##\n",
    "    x_pos_enc = Enumerate(name=f\"{name}_encoder_enumerate\", dtype=dtype)(x_in_enc, minimal_dims=False)\n",
    "    x_pos_dec = Enumerate(name=f\"{name}_decoder_enumerate\", dtype=dtype)(x_in_dec, minimal_dims=False)\n",
    "    \n",
    "    ##========================================================================##\n",
    "    ##===  Positional encoding - Output shape [B, S, 2*pos_enc_num_freqs]  ===##\n",
    "    ##========================================================================##\n",
    "    x_pos_enc = PositionalEncoding(num_freqs  = pos_enc_num_freqs, \n",
    "                                   min_period = pos_enc_min_period, \n",
    "                                   max_period = pos_enc_max_period, \n",
    "                                   learnable  = pos_enc_learnable,\n",
    "                                   dtype      = dtype, \n",
    "                                   name       = f\"{name}_encoder_position_encoding\")(x_pos_enc)\n",
    "    x_pos_dec = PositionalEncoding(num_freqs  = pos_enc_num_freqs, \n",
    "                                   min_period = pos_enc_min_period, \n",
    "                                   max_period = pos_enc_max_period, \n",
    "                                   learnable  = pos_enc_learnable,\n",
    "                                   dtype      = dtype, \n",
    "                                   name       = f\"{name}_decoder_position_encoding\")(x_pos_dec)\n",
    "\n",
    "    ##==============================================================================================##\n",
    "    ##===  Combine embeddings end pos enc - Output shape [B, S, N] where N depends on comb_type  ===##\n",
    "    ##==============================================================================================##\n",
    "    allowed_comb_types = [\"add\", \"sum\", \"average\", \"mean\", \"concat\", \"concatenate\", \"mixture\"]\n",
    "    match comb_type.lower() :\n",
    "        case \"add\" | \"sum\" :\n",
    "            x_enc = Add(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = Add(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case \"average\" | \"mean\" :\n",
    "            x_enc = Average(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = Average(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case \"concat\" | \"concatenate\" :\n",
    "            x_enc = Concatenate(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = Concatenate(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case \"mixture\" :\n",
    "            x_enc = LearnableMixture(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = LearnableMixture(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case _ :\n",
    "            raise RuntimeError(f\"comb_type '{comb_type}' not recognised, recognised keywords are {allowed_comb_types}\")\n",
    "    \n",
    "    ##===================================================================##\n",
    "    ##===  Pre-encoder blocks - Output shape [B, S, ndim_preencoder]  ===##\n",
    "    ##===================================================================##\n",
    "    preencoder_blocks = []\n",
    "    for layer_idx in range(num_preencoder_blocks) :\n",
    "        preencoder_blocks.append(EncoderBlock(\n",
    "                                 ndim_preencoder, \n",
    "                                 num_heads_preencoder, \n",
    "                                 ndim_att_hidden_preencoder, \n",
    "                                 ndim_ff_hidden_preencoder, \n",
    "                                 dropout_mha          = dropout, \n",
    "                                 dtype                = dtype, \n",
    "                                 pre_layer_norm       = True, \n",
    "                                 post_layer_norm      = False, \n",
    "                                 skip_connect         = skip_connect_preencoder, \n",
    "                                 mixture_skip_connect = mixture_skip_connect_preencoder, \n",
    "                                 name                 = f\"{name}_preencoder_block_{layer_idx+1}\"))\n",
    "    \n",
    "    ##============================================================##\n",
    "    ##===  Encoder blocks - Output shape [B, S, ndim_encoder]  ===##\n",
    "    ##============================================================##\n",
    "    encoder_blocks = []\n",
    "    for layer_idx in range(num_encoder_blocks) :\n",
    "        encoder_blocks.append(EncoderBlock(\n",
    "                                 ndim_encoder, \n",
    "                                 num_heads_encoder, \n",
    "                                 ndim_att_hidden_encoder, \n",
    "                                 ndim_ff_hidden_encoder, \n",
    "                                 dropout_mha          = dropout, \n",
    "                                 dtype                = dtype, \n",
    "                                 pre_layer_norm       = True, \n",
    "                                 post_layer_norm      = False, \n",
    "                                 skip_connect         = skip_connect_encoder, \n",
    "                                 mixture_skip_connect = mixture_skip_connect_encoder, \n",
    "                                 name                 = f\"{name}_encoder_block_{layer_idx+1}\"))\n",
    "        \n",
    "    for loop_idx in range(num_encoder_loops) :\n",
    "        for encoder_block in encoder_blocks :\n",
    "            x_enc = encoder_block(x_enc)\n",
    "    x_enc_list = [x_enc] \n",
    "    ## Previously [LayerNormalization(name=f\"{name}_encoder_output_norm\")(x_enc)] but post-LN now irrelevant\n",
    "           \n",
    "    for loop_idx in range(idempotent_size) :\n",
    "        for encoder_block in encoder_blocks :\n",
    "            x_enc = encoder_block(x_enc)\n",
    "        x_enc_list.append(x_enc)\n",
    "    \n",
    "    ##============================================================##\n",
    "    ##===  Decoder blocks - Output shape [B, S, ndim_decoder]  ===##\n",
    "    ##============================================================##\n",
    "    decoder_blocks = []\n",
    "    for layer_idx in range(num_decoder_blocks) :\n",
    "        decoder_blocks.append(DecoderBlock(\n",
    "                                 ndim_decoder, \n",
    "                                 num_heads_decoder, \n",
    "                                 ndim_att_hidden_decoder, \n",
    "                                 ndim_ff_hidden_decoder, \n",
    "                                 dropout_mha          = dropout, \n",
    "                                 dtype                = dtype, \n",
    "                                 pre_layer_norm       = True, \n",
    "                                 post_layer_norm      = False, \n",
    "                                 skip_connect         = skip_connect_decoder, \n",
    "                                 mixture_skip_connect = mixture_skip_connect_decoder, \n",
    "                                 name                 = f\"{name}_decoder_block_{layer_idx+1}\"))\n",
    "        \n",
    "    x_dec_list = []\n",
    "    for x_enc_this in x_enc_list :\n",
    "        x_dec_this = x_dec\n",
    "        for loop_idx in range(num_decoder_loops) :\n",
    "            for decoder_block in decoder_blocks :\n",
    "                x_dec_this = decoder_block([x_dec_this, x_enc_this])\n",
    "        x_dec_list.append(x_dec_this)\n",
    "        \n",
    "    ##==================================================================================================##\n",
    "    ##===  Predict logit probabilities using feed-forward block - Output shape [B, S, vocab_length]  ===##\n",
    "    ##==================================================================================================##\n",
    "    ##  - use layer_norm instead of batch_norm because elements in sequence are not independent\n",
    "    ff_block = FeedForwardBlock(vocab_length, \n",
    "                         ndim_hidden       = ndim_post_layers_decoder, \n",
    "                         num_hidden_layers = num_post_layers_decoder, \n",
    "                         skip_connect      = False, \n",
    "                         pre_layer_norm    = True, \n",
    "                         post_layer_norm   = False, \n",
    "                         batch_norm        = False, \n",
    "                         dtype             = dtype, \n",
    "                         name              = f\"{name}_output\")\n",
    "    x_out = [ff_block(x) for x in x_dec_list]\n",
    "    \n",
    "    ##  Create model\n",
    "    model = Model([x_in_enc, x_in_dec], x_out if len(x_out)>1 else x_out[0], name=name)\n",
    "    \n",
    "    ##  Compile model with sparse categorical crossentropy loss and accuracy metric\n",
    "    if do_compile :\n",
    "        acc  = MaskedCategoricalAccuracy(scalar_output=True, equal_token_weight=True, use_keras_mask=False, mask_value=0)\n",
    "        loss = MaskedSparseCategoricalCrossentropy(scalar_output=True, equal_token_weight=True, use_keras_mask=False, mask_value=0, from_logits=True)\n",
    "        model.compile(loss        = loss, \n",
    "                      optimizer   = optimizer(**optimizer_args), \n",
    "                      metrics     = [acc],\n",
    "                      jit_compile = jit_compile)\n",
    "    \n",
    "    ##  Return model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "942355eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_to_text_model_from_config(cfg_model, token_transform) :\n",
    "    \"\"\"\n",
    "    Create a text-to-text transformer model\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "        >  cfg_model, Config\n",
    "           Model configuration\n",
    "           \n",
    "        >  token_transform, TokenTransform\n",
    "           Tokeniser\n",
    "    \"\"\"\n",
    "    return create_text_to_text_model(\n",
    "                          vocab_length                    = token_transform.vocab_length, \n",
    "                          name                            = cfg_model[\"name\"],\n",
    "                          do_compile                      = True,\n",
    "                          use_old_loss                    = cfg_model[\"use_old_loss\"],\n",
    "                          dtype_in                        = token_transform.dtype,\n",
    "                          dtype                           = cfg_model[\"dtype\"],\n",
    "                          dropout                         = cfg_model[\"dropout\"],\n",
    "                          jit_compile                     = cfg_model[\"jit_compile\"],\n",
    "                          optimizer                       = cfg_model.get(\"optimizer\", Adam),\n",
    "                          optimizer_args                  = cfg_model.get(\"optimizer_args\", {}),\n",
    "                          idempotent_size                 = cfg_model[\"idempotent_size\"],\n",
    "                          pos_enc_num_freqs               = cfg_model[\"positional_encoding\"][\"num_freqs\"],\n",
    "                          pos_enc_min_period              = cfg_model[\"positional_encoding\"][\"min_period\"],\n",
    "                          pos_enc_max_period              = cfg_model[\"positional_encoding\"][\"max_period\"],\n",
    "                          pos_enc_learnable               = cfg_model[\"positional_encoding\"][\"learnable\"],\n",
    "                          ndim_embedding                  = cfg_model[\"ndim_embedding\"],\n",
    "                          num_preencoder_blocks           = cfg_model[\"pre_encoder\"][\"num_blocks\"],\n",
    "                          num_preencoder_loops            = cfg_model[\"pre_encoder\"][\"num_loops\"],\n",
    "                          ndim_preencoder                 = cfg_model[\"pre_encoder\"][\"ndim\"],\n",
    "                          num_heads_preencoder            = cfg_model[\"pre_encoder\"][\"num_heads\"],\n",
    "                          ndim_att_hidden_preencoder      = cfg_model[\"pre_encoder\"][\"ndim_att_hidden\"],\n",
    "                          ndim_ff_hidden_preencoder       = cfg_model[\"pre_encoder\"][\"ndim_ff_hidden\"],\n",
    "                          skip_connect_preencoder         = cfg_model[\"pre_encoder\"][\"skip_connect\"],\n",
    "                          mixture_skip_connect_preencoder = cfg_model[\"pre_encoder\"][\"mixture_skip_connect\"],\n",
    "                          num_encoder_blocks              = cfg_model[\"encoder\"][\"num_blocks\"],\n",
    "                          num_encoder_loops               = cfg_model[\"encoder\"][\"num_loops\"],\n",
    "                          ndim_encoder                    = cfg_model[\"encoder\"][\"ndim\"],\n",
    "                          num_heads_encoder               = cfg_model[\"encoder\"][\"num_heads\"],\n",
    "                          ndim_att_hidden_encoder         = cfg_model[\"encoder\"][\"ndim_att_hidden\"],\n",
    "                          ndim_ff_hidden_encoder          = cfg_model[\"encoder\"][\"ndim_ff_hidden\"],\n",
    "                          skip_connect_encoder            = cfg_model[\"encoder\"][\"skip_connect\"],\n",
    "                          mixture_skip_connect_encoder    = cfg_model[\"encoder\"][\"mixture_skip_connect\"],\n",
    "                          num_decoder_blocks              = cfg_model[\"decoder\"][\"num_blocks\"],\n",
    "                          num_decoder_loops               = cfg_model[\"decoder\"][\"num_loops\"],\n",
    "                          ndim_decoder                    = cfg_model[\"decoder\"][\"ndim\"],\n",
    "                          num_heads_decoder               = cfg_model[\"decoder\"][\"num_heads\"],\n",
    "                          ndim_att_hidden_decoder         = cfg_model[\"decoder\"][\"ndim_att_hidden\"],\n",
    "                          ndim_ff_hidden_decoder          = cfg_model[\"decoder\"][\"ndim_ff_hidden\"],\n",
    "                          skip_connect_decoder            = cfg_model[\"decoder\"][\"skip_connect\"],\n",
    "                          mixture_skip_connect_decoder    = cfg_model[\"decoder\"][\"mixture_skip_connect\"],\n",
    "                          num_post_layers_decoder         = cfg_model[\"post_decoder\"][\"num_layers\"],\n",
    "                          ndim_post_layers_decoder        = cfg_model[\"post_decoder\"][\"ndim\"],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bb6a53e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Creating new text-to-text model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Model created with summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:Model created with summary:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Model: \"mathsformer_LLM\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:Model: \"mathsformer_LLM\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: __________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  Layer (type)                   Output Shape         Param #     Connected to                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: Layer (type)                   Output Shape         Param #     Connected to                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: ==================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_encoder_input_  [(None, None)]      0           []                               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_encoder_input_  [(None, None)]      0           []                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  layer (InputLayer)                                                                               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: layer (InputLayer)                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_encoder_enumer  (None, None)        0           ['mathsformer_LLM_encoder_input_l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_encoder_enumer  (None, None)        0           ['mathsformer_LLM_encoder_input_l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  ate (Enumerate)                                                 ayer[0][0]']                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: ate (Enumerate)                                                 ayer[0][0]']                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_encoder_embedd  (None, None, 160)   2560        ['mathsformer_LLM_encoder_input_l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_encoder_embedd  (None, None, 160)   2560        ['mathsformer_LLM_encoder_input_l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  ing (Embedding)                                                 ayer[0][0]']                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: ing (Embedding)                                                 ayer[0][0]']                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_encoder_positi  (None, None, 160)   80          ['mathsformer_LLM_encoder_enumera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_encoder_positi  (None, None, 160)   80          ['mathsformer_LLM_encoder_enumera\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  on_encoding (PositionalEncodin                                  te[0][0]']                       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: on_encoding (PositionalEncodin                                  te[0][0]']                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  g)                                                                                               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: g)                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_encoder_emb_an  (None, None, 160)   0           ['mathsformer_LLM_encoder_embeddi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_encoder_emb_an  (None, None, 160)   0           ['mathsformer_LLM_encoder_embeddi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  d_pos (Average)                                                 ng[0][0]',                       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: d_pos (Average)                                                 ng[0][0]',                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_positio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_positio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  n_encoding[0][0]']               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 n_encoding[0][0]']               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_encoder_block_  (None, None, 160)   1080804     ['mathsformer_LLM_encoder_emb_and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_encoder_block_  (None, None, 160)   1080804     ['mathsformer_LLM_encoder_emb_and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  1 (EncoderBlock)                                                _pos[0][0]',                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: 1 (EncoderBlock)                                                _pos[0][0]',                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [0][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [0][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [1][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [1][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [2][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [2][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [3][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [3][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [4][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [4][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [5][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [5][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [6][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [6][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [7][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [7][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [8][0]']                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [8][0]']                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_encoder_block_  (None, None, 160)   1080804     ['mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_encoder_block_  (None, None, 160)   1080804     ['mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  2 (EncoderBlock)                                                [0][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: 2 (EncoderBlock)                                                [0][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [1][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [1][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [2][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [2][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [3][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [3][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [4][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [4][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [5][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [5][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [6][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [6][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [7][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [7][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [8][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [8][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [9][0]']                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [9][0]']                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_decoder_input_  [(None, None)]      0           []                               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_decoder_input_  [(None, None)]      0           []                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  layer (InputLayer)                                                                               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: layer (InputLayer)                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_decoder_enumer  (None, None)        0           ['mathsformer_LLM_decoder_input_l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_decoder_enumer  (None, None)        0           ['mathsformer_LLM_decoder_input_l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  ate (Enumerate)                                                 ayer[0][0]']                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: ate (Enumerate)                                                 ayer[0][0]']                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_decoder_embedd  (None, None, 160)   2560        ['mathsformer_LLM_decoder_input_l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_decoder_embedd  (None, None, 160)   2560        ['mathsformer_LLM_decoder_input_l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  ing (Embedding)                                                 ayer[0][0]']                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: ing (Embedding)                                                 ayer[0][0]']                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_decoder_positi  (None, None, 160)   80          ['mathsformer_LLM_decoder_enumera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_decoder_positi  (None, None, 160)   80          ['mathsformer_LLM_decoder_enumera\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  on_encoding (PositionalEncodin                                  te[0][0]']                       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: on_encoding (PositionalEncodin                                  te[0][0]']                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  g)                                                                                               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: g)                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_decoder_emb_an  (None, None, 160)   0           ['mathsformer_LLM_decoder_embeddi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_decoder_emb_an  (None, None, 160)   0           ['mathsformer_LLM_decoder_embeddi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  d_pos (Average)                                                 ng[0][0]',                       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: d_pos (Average)                                                 ng[0][0]',                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_positio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_decoder_positio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  n_encoding[0][0]']               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 n_encoding[0][0]']               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_decoder_block_  (None, None, 160)   1904326     ['mathsformer_LLM_decoder_emb_and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_decoder_block_  (None, None, 160)   1904326     ['mathsformer_LLM_decoder_emb_and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  1 (DecoderBlock)                                                _pos[0][0]',                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: 1 (DecoderBlock)                                                _pos[0][0]',                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [7][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [7][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_emb_and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_decoder_emb_and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  _pos[0][0]',                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 _pos[0][0]',                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [8][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [8][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_emb_and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_decoder_emb_and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  _pos[0][0]',                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 _pos[0][0]',                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [9][0]']                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [9][0]']                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_decoder_block_  (None, None, 160)   1904326     ['mathsformer_LLM_decoder_block_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_decoder_block_  (None, None, 160)   1904326     ['mathsformer_LLM_decoder_block_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  2 (DecoderBlock)                                                [0][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: 2 (DecoderBlock)                                                [0][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [7][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [7][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_block_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_decoder_block_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [1][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [1][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [8][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [8][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_block_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_decoder_block_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [2][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [2][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_encoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [9][0]']                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [9][0]']                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_output (FeedFo  (None, None, 16)    1423536     ['mathsformer_LLM_decoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: mathsformer_LLM_output (FeedFo  (None, None, 16)    1423536     ['mathsformer_LLM_decoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  rwardBlock)                                                     [0][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer: rwardBlock)                                                     [0][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_decoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [1][0]',                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [1][0]',                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_block_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                  'mathsformer_LLM_decoder_block_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [2][0]']                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                 [2][0]']                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: ==================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Total params: 7,399,076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:Total params: 7,399,076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Trainable params: 7,399,076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:Trainable params: 7,399,076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Non-trainable params: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:Non-trainable params: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: __________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Optimizer is <keras.optimizers.adamw.AdamW object at 0x2888d10d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:Optimizer is <keras.optimizers.adamw.AdamW object at 0x2888d10d0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Learning rate is <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:Learning rate is <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Weight decay is 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:Weight decay is 0.02\n"
     ]
    }
   ],
   "source": [
    "##===================================================##\n",
    "##   Load or create self-supervised learning model   ##\n",
    "##===================================================##\n",
    "\n",
    "##  Get filename for load model\n",
    "fname = cfg_model.get(\"load_pretrained_model\", None)\n",
    "\n",
    "##  Load model if fname is not None, otherwise create from scratch\n",
    "if fname is not None :\n",
    "    logger.info   (f\"Loading model from: {fname}\")\n",
    "    logger.warning(\"Loading a pretrained model will disregard model config!\")\n",
    "    model = backend.load_text_to_text_model(fname)\n",
    "    model.optimizer.learning_rate.assign(cfg_model[\"optimizer_args\"][\"learning_rate\"])  ## Reset LR to config value\n",
    "else :\n",
    "    logger.info(f\"Creating new text-to-text model\")\n",
    "    model = create_text_to_text_model_from_config(cfg_model, token_transform)\n",
    "\n",
    "##  Create hack to catch model summary\n",
    "model_summary = []\n",
    "model.summary(print_fn = lambda s : model_summary.append(s))\n",
    "\n",
    "##  Print model summary\n",
    "logger.info(\"Model created with summary:\")\n",
    "for s in model_summary : logger.info(s)\n",
    "    \n",
    "##  Print optimizer summary\n",
    "logger.info(f\"Optimizer is {model.optimizer}\")\n",
    "if hasattr(model.optimizer, \"learning_rate\") : logger.info(f\"Learning rate is {model.optimizer.learning_rate}\")\n",
    "if hasattr(model.optimizer, \"weight_decay\" ) : logger.info(f\"Weight decay is {model.optimizer.weight_decay}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "793493a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##==============================================================##\n",
    "##   Create transformer wrapper for model and token_transform   ##\n",
    "##==============================================================##\n",
    "\n",
    "transformer = transformers.Transformer_Text_to_Text(model, token_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "956e30a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO test_transformer: Running text --> text mathsformer inference on some training data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:Running text --> text mathsformer inference on some training data:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table: --------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:--------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:                 INPUT         TRUE   PRED(MASK)    PRED(GEN)      CORRECT     RESIDUAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:                INPUT         TRUE   PRED(MASK)    PRED(GEN)      CORRECT     RESIDUAL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table: --------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:--------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:  N7724-8+N615-687-678        N9712      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend: N7724-8+N615-687-678        N9712      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:            N557+N3170        N3727      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:           N557+N3170        N3727      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:                     7            7      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:                    7            7      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:      N3+6+9469+N9+475         9938      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:     N3+6+9469+N9+475         9938      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:                 N7403        N7403      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:                N7403        N7403      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:   N2336-N15-700+N6219        N9240      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:  N2336-N15-700+N6219        N9240      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:   629+N815+308+N2-763         N643      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:  629+N815+308+N2-763         N643      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:         9+34-N65+N223         N115      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:        9+34-N65+N223         N115      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:   N3517-6312+N4-N2561        N7272      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:  N3517-6312+N4-N2561        N7272      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:           4-N2+6413+7         6426      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:          4-N2+6413+7         6426      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO test_transformer: Running text --> text mathsformer inference on some validation data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:Running text --> text mathsformer inference on some validation data:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table: --------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:--------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:                       INPUT         TRUE   PRED(MASK)    PRED(GEN)      CORRECT     RESIDUAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:                      INPUT         TRUE   PRED(MASK)    PRED(GEN)      CORRECT     RESIDUAL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table: --------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:--------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:                  5-N276-639         N358      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:                 5-N276-639         N358      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:    789+N24-N281+3095-N4+726         4871      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:   789+N24-N281+3095-N4+726         4871      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:               298-8445+N663        N8810      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:              298-8445+N663        N8810      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:  9+4-N8055-N302+N4928-N8672        12114      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend: 9+4-N8055-N302+N4928-N8672        12114      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:               N948-5139+N10        N6097      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:              N948-5139+N10        N6097      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:              N47+N935-N9554         8572      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:             N47+N935-N9554         8572      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:                     89+4-55           38      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:                    89+4-55           38      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:                 N93-649+396         N346      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:                N93-649+396         N346      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:                N62+N291+259          N94      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:               N62+N291+259          N94      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:                 9405-3+N447         8955      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:                9405-3+N447         8955      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO test_transformer: Running text --> text mathsformer inference on some test data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:Running text --> text mathsformer inference on some test data:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table: ------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:                           INPUT         TRUE   PRED(MASK)    PRED(GEN)      CORRECT     RESIDUAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:                          INPUT         TRUE   PRED(MASK)    PRED(GEN)      CORRECT     RESIDUAL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table: ------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:   N36+3544+9096+1-N3995-216+N40        16344      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:  N36+3544+9096+1-N3995-216+N40        16344      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:      37+N6502+N99-N5+N7-5228+N8       N11802      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:     37+N6502+N99-N5+N7-5228+N8       N11802      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:  N30-788-N965+N35-N255-9962-...        N3719      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend: N30-788-N965+N35-N255-9962-...        N3719      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:  N5-N5847+N64-N850+N87-348+N...         5157      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend: N5-N5847+N64-N850+N87-348+N...         5157      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:  3763-N40+N600-65+7099+55-N2...        10995      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend: 3763-N40+N600-65+7099+55-N2...        10995      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:   N9-2463+1333+4949+599+N5+N806         3598      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:  N9-2463+1333+4949+599+N5+N806         3598      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:         928+9-779+832+N6+7963-7         8940      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:        928+9-779+832+N6+7963-7         8940      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:            481-22+N95-8-7+N7+19          361      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:           481-22+N95-8-7+N7+19          361      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:  N690-N5068+N29-N5703-N95-N7...        10905      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend: N690-N5068+N29-N5703-N95-N7...        10905      --EEE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO print_predictions_table:  27+3-N584-N57+272-N21-N1771...         4359      --5EE55          --5                      ?   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend: 27+3-N584-N57+272-N21-N1771...         4359      --5EE55          --5                      ?   \n"
     ]
    }
   ],
   "source": [
    "##=========================================##\n",
    "##   Test transformer on data generators   ##\n",
    "##=========================================##\n",
    "\n",
    "backend.test_transformer(transformer, train_gen, val_gen, test_gen, negative_char=negative_char)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f7a52",
   "metadata": {},
   "source": [
    "##  5.  Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aea411fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO get_callbacks: Registered training callback: LoggerCallback with loglvl=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:Registered training callback: LoggerCallback with loglvl=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO get_callbacks: Registered training callback: AdaptiveLearningRate with decay_factor=0.2, patience=2, monitor=loss, mode=min, log_lvl=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:Registered training callback: AdaptiveLearningRate with decay_factor=0.2, patience=2, monitor=loss, mode=min, log_lvl=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO get_callbacks: Registered training callback: ModelCheckpoint with filepath=SSL_loopy_enc_dec_notebook_int1234_num1245_embed160_enc_2blocks_8loops_width800_dec_2blocks_1loops_width800_post3_width800_idem2_2023_06_28/model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:Registered training callback: ModelCheckpoint with filepath=SSL_loopy_enc_dec_notebook_int1234_num1245_embed160_enc_2blocks_8loops_width800_dec_2blocks_1loops_width800_post3_width800_idem2_2023_06_28/model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO get_callbacks: Registered training callback: LayerWeightsRecord with batch_frequency=2000, recursive=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:Registered training callback: LayerWeightsRecord with batch_frequency=2000, recursive=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO get_callbacks: Registered training callback: LambdaCallback for test_transformer with num_print=10, negative_char='N'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer.selfsupervised_learning_addition_model_backend:Registered training callback: LambdaCallback for test_transformer with num_print=10, negative_char='N'\n"
     ]
    }
   ],
   "source": [
    "##===================================##\n",
    "##   Create callbacks for training   ##\n",
    "##===================================##\n",
    "\n",
    "callbacks = backend.get_callbacks(cfg_training, working_dir, transformer=transformer, train_gen=train_gen_reproducible, \n",
    "                                  val_gen=val_gen, negative_char=negative_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21d1736d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Begin model training with max_epochs=100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mathsformer:Begin model training with max_epochs=100000\n",
      "DEBUG:mathsformer.selfsupervised_learning_addition_model_backend:Setting variable to learning_rate:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 18:51:59.645467: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 156/2000 [=>............................] - ETA: 28:04 - loss: 6.1129 - mathsformer_LLM_output_loss: 2.0383 - mathsformer_LLM_output_1_loss: 2.0365 - mathsformer_LLM_output_2_loss: 2.0382 - mathsformer_LLM_output_masked_categorical_accuracy: 0.3422 - mathsformer_LLM_output_1_masked_categorical_accuracy: 0.3424 - mathsformer_LLM_output_2_masked_categorical_accuracy: 0.3426"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     max_epochs \u001b[38;5;241m=\u001b[39m cfg_training[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBegin model training with max_epochs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m             \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m     16\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping model training following global config instructions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_macos2p12_modified_230626/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_macos2p12_modified_230626/lib/python3.11/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_macos2p12_modified_230626/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_macos2p12_modified_230626/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_macos2p12_modified_230626/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_macos2p12_modified_230626/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_macos2p12_modified_230626/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_macos2p12_modified_230626/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_macos2p12_modified_230626/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##=================##\n",
    "##   Train model   ##\n",
    "##=================##\n",
    "\n",
    "do_train = cfg_training.get(\"train\", True)\n",
    "\n",
    "if do_train :\n",
    "    max_epochs = cfg_training[\"max_epochs\"]\n",
    "    logger.info(f\"Begin model training with max_epochs={max_epochs}\")\n",
    "    model.fit(train_gen, \n",
    "              epochs          = max_epochs,\n",
    "              validation_data = val_gen,\n",
    "              callbacks       = callbacks\n",
    "             )\n",
    "else :\n",
    "    logger.warning(\"Skipping model training following global config instructions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb38943",
   "metadata": {},
   "outputs": [],
   "source": [
    "##================##\n",
    "##   Save model   ##\n",
    "##================##\n",
    "\n",
    "do_save = cfg_evaluate.get(\"save_model\", True)\n",
    "\n",
    "if do_save :\n",
    "    save_fname = f\"{working_dir}/final_model.keras\"\n",
    "    model.save(save_fname)\n",
    "    logger.info(f\"Model saved to file {save_fname}\")\n",
    "else :\n",
    "    logger.warning(\"Not saving model because no training was done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc69448",
   "metadata": {},
   "source": [
    "## 6.  Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c425ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "  \n",
    "##  Find out how many datapoints to print predictions for \n",
    "num_print = cfg_evaluate.get(\"num_print\", 20)\n",
    "\n",
    "##  Print tables\n",
    "backend.test_transformer(transformer, train_gen, val_gen, test_gen, num_print=num_print, \n",
    "                         negative_char=negative_char)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfb55b",
   "metadata": {},
   "source": [
    "##  7. Additional visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e385e68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##=============================================##\n",
    "##   Visualise layer weights during training   ##\n",
    "##=============================================##\n",
    "\n",
    "if cfg_evaluate[\"plot_weights\"] :\n",
    "    \n",
    "    logger.info(\"Plotting weights\")\n",
    "    backend.plot_weights(callbacks, show=True, close=True, savefig=f\"{working_dir}/layer_weights.pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "##===============================##\n",
    "##   Visualise training curves   ##\n",
    "##===============================##\n",
    "\n",
    "if cfg_evaluate[\"plot_training_curves\"] :\n",
    "    \n",
    "    if not hasattr(model, \"history\") :\n",
    "        logger.error(\"Cannot print training curves because no model history exists - perhaps you skipped training?\")\n",
    "    else :\n",
    "        logger.info(\"Plotting training curves\")\n",
    "        backend.plot_training_curves(model.history.history, show=True, close=True, savefig=f\"{working_dir}/training_curves.pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f188a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
