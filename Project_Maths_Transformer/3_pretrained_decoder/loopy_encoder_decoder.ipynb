{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884dc59d",
   "metadata": {},
   "source": [
    "#  Unsupervised learning addition model with generator  -  using loopy encoder and decoder method\n",
    "\n",
    "Author: S. Menary [sbmenary@gmail.com]\n",
    "\n",
    "Date: 15/6/2023  (last update: 15/6/2023)\n",
    "\n",
    "Overview: Train a `sequence -> sequence` model where the input sequence is a text representation of a simple sum $\\sum_{i=1}^N A_i$ for a configurable number $N$ of integers $A_i\\in\\mathbb{Z}$, and the output is a set of logits representing the probability of each token in the output sequence. Integers may have a configurable number of digits. At inference time, chains of text are generated auto-regressively until the terminate-sequence token is reached. The loss function is a sparse categorical entropy.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Set up program\n",
    "\n",
    "###  Import\n",
    "\n",
    "All imports go here at the top of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48f1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "##=========================##\n",
    "##   All imports go here   ##\n",
    "##=========================##\n",
    "\n",
    "##  Import entire python stdlib packages\n",
    "import logging, os, sys\n",
    "\n",
    "##  Import entire pypi packages\n",
    "import tensorflow as tf\n",
    "\n",
    "##  Remove tensorflow INFO messages\n",
    "tf.get_logger().setLevel('WARNING')\n",
    "\n",
    "##  Add directory above this to system path to expose mathsformer package location\n",
    "sys.path.append(\"/\".join(os.getcwd().split(\"/\")[:-1]))\n",
    "\n",
    "##  Import individual modules/objects from local packages\n",
    "from tensorflow.keras.optimizers.legacy import Adam, SGD\n",
    "from mathsformer import config, data, transformers, utils\n",
    "from mathsformer import selfsupervised_learning_addition_model_backend as backend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320886f9",
   "metadata": {},
   "source": [
    "## 1. Configure run\n",
    "\n",
    "Set configuration variables for entire program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701cef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##==============================##\n",
    "##   Set custom config values   ##\n",
    "##==============================##\n",
    "\n",
    "custom_config = {\n",
    "    \"global\" : {\n",
    "        \"base_seed\"        : -1,\n",
    "        \"working_dir\"      : \"SSL_loopy_enc_dec_notebook_[global>problem_tag]_embed[model>ndim_embedding]_enc_[model>encoder>num_blocks]blocks_[model>encoder>num_loops]loops_width[model>encoder>ndim_ff_hidden]_dec_[model>decoder>num_blocks]blocks_[model>decoder>num_loops]loops_width[model>decoder>ndim_ff_hidden]_post[model>post_decoder>num_layers]_width[model>post_decoder>ndim]_idem[model>idempotent_size]_[date]\",\n",
    "        \"problem_tag\"      : \"int1234_num1245\",\n",
    "        \"log_lvl_iostream\" : logging.INFO,\n",
    "        \"log_lvl_fstream\"  : logging.DEBUG,\n",
    "    },\n",
    "    \"data\" : {\n",
    "        \"train_data\" : {\n",
    "            \"int_lengths\"      : [1, 2, 3, 4],\n",
    "            \"num_ints\"         : [1, 2, 4, 5],\n",
    "            \"batch_size\"       : 32,\n",
    "            \"num_batches\"      : 1000,\n",
    "            \"gen_base_seed\"    : 101,\n",
    "            \"gen_reproducible\" : False, \n",
    "        },\n",
    "        \"val_data\" : {\n",
    "            \"int_lengths\"      : [1, 2, 3, 4],\n",
    "            \"num_ints\"         : [3],\n",
    "            \"batch_size\"       : 32,\n",
    "            \"num_batches\"      : 50,\n",
    "            \"gen_base_seed\"    : 102,\n",
    "            \"gen_reproducible\" : True,\n",
    "        },\n",
    "        \"test_data\" : {\n",
    "            \"int_lengths\"      : [1, 2, 3, 4],\n",
    "            \"num_ints\"         : [6],\n",
    "            \"batch_size\"       : 32,\n",
    "            \"num_batches\"      : 100,\n",
    "            \"gen_base_seed\"    : 103,\n",
    "            \"gen_reproducible\" : True,\n",
    "        },\n",
    "        \"characters\"              : ['M', 'B', 'E', 'N', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-'],\n",
    "        \"mask_char\"               : 'M',\n",
    "        \"seq_start_char\"          : 'B',\n",
    "        \"seq_end_char\"            : 'E',\n",
    "        \"negative_char\"           : 'N',\n",
    "        \"dtype\"                   : \"int32\",\n",
    "    },\n",
    "    \"model\" : {\n",
    "        \"load_pretrained_model\" : None,\n",
    "        \"name\"                  : \"mathsformer_LLM\",\n",
    "        \"dtype\"                 : \"float32\",\n",
    "        \"dropout\"               : 0.1,\n",
    "        \"jit_compile\"           : False,\n",
    "        \"use_old_loss\"          : True,\n",
    "        \"optimizer\"             : Adam,\n",
    "        \"optimizer_args\"        : {\"learning_rate\":1e-5},\n",
    "        \"idempotent_size\"       : -1,\n",
    "        \"positional_encoding\" : {\n",
    "            \"num_freqs\"         : 128,\n",
    "            \"min_period\"        : 4,\n",
    "            \"max_period\"        : 1000,\n",
    "            \"learnable\"         : True,\n",
    "        },\n",
    "        \"ndim_embedding\"        : 256,\n",
    "        \"comb_type\"             : 'average',\n",
    "        \"pre_encoder\"           : {\n",
    "            \"num_layers\"        : -1,\n",
    "            \"ndim\"              : 256,\n",
    "            \"skip_connect\"      : True,\n",
    "        },\n",
    "        \"pre_decoder\" : {\n",
    "            \"num_layers\"        : -1,\n",
    "            \"ndim\"              : 256,\n",
    "            \"skip_connect\"      : True,\n",
    "        },\n",
    "        \"encoder\" : {\n",
    "            \"num_blocks\"        : 2,\n",
    "            \"num_loops\"         : 3,\n",
    "            \"num_heads\"         : 8,\n",
    "            \"ndim\"              : 256,\n",
    "            \"ndim_att_hidden\"   : 256,\n",
    "            \"ndim_ff_hidden\"    : 1024,\n",
    "            \"skip_connect\"      : True,\n",
    "        },\n",
    "        \"decoder\" : {\n",
    "            \"num_blocks\"        : 2,\n",
    "            \"num_loops\"         : 3,\n",
    "            \"num_heads\"         : 8,\n",
    "            \"ndim\"              : 256,\n",
    "            \"ndim_att_hidden\"   : 256,\n",
    "            \"ndim_ff_hidden\"    : 256,\n",
    "            \"skip_connect\"      : True,\n",
    "        },\n",
    "        \"post_decoder\" : {\n",
    "            \"num_layers\"        : 3,\n",
    "            \"ndim\"              : 512,\n",
    "        },\n",
    "    },\n",
    "    \"training\" : {\n",
    "        \"train\"          : True,\n",
    "        \"max_epochs\"     : 100000,\n",
    "        \"log_after_epoch\" : {\n",
    "            \"do\"          : True,\n",
    "            \"log_lvl\"     : logging.DEBUG,\n",
    "        },\n",
    "        \"early_stopping\" : {\n",
    "            \"do\"                   : False,\n",
    "            \"patience\"             : 4,\n",
    "            \"monitor\"              : \"loss\",\n",
    "            \"mode\"                 : \"min\",\n",
    "            \"restore_best_weights\" : True,\n",
    "        },\n",
    "        \"model_checkpoint\" : {\n",
    "            \"do\"       : True,\n",
    "            \"filename\" : \"model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.h5\",\n",
    "        },\n",
    "        \"layer_weights_record\" : {\n",
    "            \"do\"               : True,\n",
    "            \"batch_frequency\"  : 2000,\n",
    "            \"recursive\"        : True,\n",
    "        },\n",
    "        \"adaptive_learning_rate\" : {\n",
    "            \"do\"                 : True,\n",
    "            \"decay_factor\"       : 0.2,\n",
    "            \"monitor\"            : \"loss\",\n",
    "            \"mode\"               : \"min\",\n",
    "            \"patience\"           : 2,\n",
    "            \"log_lvl\"            : logging.DEBUG,\n",
    "        },\n",
    "        \"print_tables_during_training\" : {\n",
    "            \"do\"        : True,\n",
    "            \"num_print\" : 10,\n",
    "        },\n",
    "    },\n",
    "    \"evaluate\" : {\n",
    "        \"num_print\"            : 50,\n",
    "        \"save_model\"           : True,\n",
    "        \"plot_weights\"         : False,\n",
    "        \"plot_training_curves\" : True,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e15977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "===   Config created   ===\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "##===================================##\n",
    "##   Load and validate full config   ##\n",
    "##===================================##\n",
    "\n",
    "##  Create config object containing default values\n",
    "cfg = config.Config(backend.DEFAULT_CONFIG)\n",
    "\n",
    "##  Override with custom values\n",
    "cfg.load_dict(custom_config)\n",
    "\n",
    "##  Validate config\n",
    "backend.validate_config(cfg)\n",
    "\n",
    "##  Print success\n",
    "print(utils.fancy_message(f\"Config created\"))\n",
    "\n",
    "##  For convenience, split configs for different sections\n",
    "cfg_global   = cfg[\"global\"  ]\n",
    "cfg_data     = cfg[\"data\"    ]\n",
    "cfg_model    = cfg[\"model\"   ]\n",
    "cfg_training = cfg[\"training\"]\n",
    "cfg_evaluate = cfg[\"evaluate\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af05439",
   "metadata": {},
   "source": [
    "##  2. Set up environment\n",
    "\n",
    "- Create working directory\n",
    "- Create logger\n",
    "- Log package versions for reproducibility\n",
    "- Log config values for reproducibility\n",
    "- Set random seeds for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f7cc532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================================================================================================\n",
      "===   Working directory created at SSL_loopy_enc_dec_notebook_int1234_num1245_embed256_enc_2blocks_3loops_width1024_dec_2blocks_3loops_width256_post3_width512_idemm1_2023_06_22_v2   ===\n",
      "=========================================================================================================================================================================================\n",
      "   INFO initialise_logging: Begin logging on 2023-06-22 at 19:41:43\n",
      "   INFO initialise_program: Program description: unsupervised_learning_addition_model_generator (notebook)\n",
      "   INFO initialise_program: Working directory: SSL_loopy_enc_dec_notebook_int1234_num1245_embed256_enc_2blocks_3loops_width1024_dec_2blocks_3loops_width256_post3_width512_idemm1_2023_06_22_v2\n",
      "   INFO log_versions: ------------------------------------------------------+-----------------------------------------------------------------------------------\n",
      "   INFO log_versions:                                              PACKAGE  |  VERSION\n",
      "   INFO log_versions: ------------------------------------------------------+-----------------------------------------------------------------------------------\n",
      "   INFO log_versions:                                               Python  |  3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:01:19) [Clang 14.0.6 ]\n",
      "   INFO log_versions:                                              IPython  |  8.13.2\n",
      "   INFO log_versions:                                 IPython.core.release  |  8.13.2\n",
      "   INFO log_versions:                                                  PIL  |  9.5.0\n",
      "   INFO log_versions:                                            PIL.Image  |  9.5.0\n",
      "   INFO log_versions:                                       PIL._deprecate  |  9.5.0\n",
      "   INFO log_versions:                                         PIL._version  |  9.5.0\n",
      "   INFO log_versions:                                                 _csv  |  1.0\n",
      "   INFO log_versions:                                              _ctypes  |  1.1.0\n",
      "   INFO log_versions:                                              _curses  |  b'2.2'\n",
      "   INFO log_versions:                                              decimal  |  1.70\n",
      "   INFO log_versions:                               _pydev_bundle.fsnotify  |  0.1.5\n",
      "   INFO log_versions:                 _pydevd_frame_eval.vendored.bytecode  |  0.13.0.dev\n",
      "   INFO log_versions:                                              appnope  |  0.1.3\n",
      "   INFO log_versions:                                             argparse  |  1.1\n",
      "   INFO log_versions:                                           astunparse  |  1.6.3\n",
      "   INFO log_versions:                                             backcall  |  0.2.0\n",
      "   INFO log_versions:                                              certifi  |  2023.05.07\n",
      "   INFO log_versions:                                                 cffi  |  1.15.1\n",
      "   INFO log_versions:                                   charset_normalizer  |  3.1.0\n",
      "   INFO log_versions:                           charset_normalizer.version  |  3.1.0\n",
      "   INFO log_versions:                                             colorama  |  0.4.6\n",
      "   INFO log_versions:                                                 comm  |  0.1.3\n",
      "   INFO log_versions:                                                  csv  |  1.0\n",
      "   INFO log_versions:                                               ctypes  |  1.1.0\n",
      "   INFO log_versions:                                      ctypes.macholib  |  1.0\n",
      "   INFO log_versions:                                               cycler  |  0.10.0\n",
      "   INFO log_versions:                                             dateutil  |  2.8.2\n",
      "   INFO log_versions:                                              debugpy  |  1.6.7\n",
      "   INFO log_versions:                                   debugpy.public_api  |  1.6.7\n",
      "   INFO log_versions:                                              decimal  |  1.70\n",
      "   INFO log_versions:                                            decorator  |  5.1.1\n",
      "   INFO log_versions:                                           defusedxml  |  0.7.1\n",
      "   INFO log_versions:                                            distutils  |  3.10.11\n",
      "   INFO log_versions:                                            executing  |  1.2.0\n",
      "   INFO log_versions:                                    executing.version  |  1.2.0\n",
      "   INFO log_versions:                                          flatbuffers  |  23.5.8\n",
      "   INFO log_versions:                                 flatbuffers._version  |  23.5.8\n",
      "   INFO log_versions:                                      google.protobuf  |  4.23.0\n",
      "   INFO log_versions:                                                 h5py  |  3.6.0\n",
      "   INFO log_versions:                                          http.server  |  0.6\n",
      "   INFO log_versions:                                                 idna  |  3.4\n",
      "   INFO log_versions:                                        idna.idnadata  |  15.0.0\n",
      "   INFO log_versions:                                    idna.package_data  |  3.4\n",
      "   INFO log_versions:                                            ipaddress  |  1.0\n",
      "   INFO log_versions:                                            ipykernel  |  6.23.0\n",
      "   INFO log_versions:                                   ipykernel._version  |  6.23.0\n",
      "   INFO log_versions:                                                 jedi  |  0.18.2\n",
      "   INFO log_versions:                                                 json  |  2.0.9\n",
      "   INFO log_versions:                                       jupyter_client  |  8.2.0\n",
      "   INFO log_versions:                              jupyter_client._version  |  8.2.0\n",
      "   INFO log_versions:                                         jupyter_core  |  5.3.0\n",
      "   INFO log_versions:                                 jupyter_core.version  |  5.3.0\n",
      "   INFO log_versions:                                                keras  |  2.12.0\n",
      "   INFO log_versions:                                  keras.api._v2.keras  |  2.12.0\n",
      "   INFO log_versions:                                      keras.api.keras  |  2.12.0\n",
      "   INFO log_versions:                                           kiwisolver  |  1.4.4\n",
      "   INFO log_versions:                                     kiwisolver._cext  |  1.4.4\n",
      "   INFO log_versions:                                              logging  |  0.5.1.2\n",
      "   INFO log_versions:                                           matplotlib  |  3.7.1\n",
      "   INFO log_versions:                                  matplotlib._version  |  3.7.1\n",
      "   INFO log_versions:                                                numpy  |  1.23.2\n",
      "   INFO log_versions:                                           numpy.core  |  1.23.2\n",
      "   INFO log_versions:                         numpy.core._multiarray_umath  |  3.1\n",
      "   INFO log_versions:                                            numpy.lib  |  1.23.2\n",
      "   INFO log_versions:                           numpy.linalg._umath_linalg  |  0.1.5\n",
      "   INFO log_versions:                                        numpy.version  |  1.23.2\n",
      "   INFO log_versions:                                           opt_einsum  |  v3.3.0\n",
      "   INFO log_versions:                                            packaging  |  23.1\n",
      "   INFO log_versions:                                                parso  |  0.8.3\n",
      "   INFO log_versions:                                              pexpect  |  4.8.0\n",
      "   INFO log_versions:                                          pickleshare  |  0.7.5\n",
      "   INFO log_versions:                 pkg_resources._vendor.more_itertools  |  9.0.0\n",
      "   INFO log_versions:                      pkg_resources._vendor.packaging  |  23.0\n",
      "   INFO log_versions:                   pkg_resources._vendor.platformdirs  |  2.6.2\n",
      "   INFO log_versions:           pkg_resources._vendor.platformdirs.version  |  2.6.2\n",
      "   INFO log_versions:                 pkg_resources._vendor.more_itertools  |  9.0.0\n",
      "   INFO log_versions:                      pkg_resources._vendor.packaging  |  23.0\n",
      "   INFO log_versions:                   pkg_resources._vendor.platformdirs  |  2.6.2\n",
      "   INFO log_versions:                                             platform  |  1.0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO log_versions:                                         platformdirs  |  3.5.0\n",
      "   INFO log_versions:                                 platformdirs.version  |  3.5.0\n",
      "   INFO log_versions:                                       prompt_toolkit  |  3.0.38\n",
      "   INFO log_versions:                                               psutil  |  5.9.5\n",
      "   INFO log_versions:                                           ptyprocess  |  0.7.0\n",
      "   INFO log_versions:                                            pure_eval  |  0.2.2\n",
      "   INFO log_versions:                                    pure_eval.version  |  0.2.2\n",
      "   INFO log_versions:                                               pydevd  |  2.9.5\n",
      "   INFO log_versions:                                             pygments  |  2.15.1\n",
      "   INFO log_versions:                                            pyparsing  |  3.0.9\n",
      "   INFO log_versions:                                                   re  |  2.2.1\n",
      "   INFO log_versions:                                             requests  |  2.30.0\n",
      "   INFO log_versions:                                 requests.__version__  |  2.30.0\n",
      "   INFO log_versions:                                                 idna  |  3.4\n",
      "   INFO log_versions:                                        idna.idnadata  |  15.0.0\n",
      "   INFO log_versions:                                    idna.package_data  |  3.4\n",
      "   INFO log_versions:                                              urllib3  |  1.26.15\n",
      "   INFO log_versions:                                     urllib3._version  |  1.26.15\n",
      "   INFO log_versions:                                   urllib3.connection  |  1.26.15\n",
      "   INFO log_versions:                                 urllib3.packages.six  |  1.16.0\n",
      "   INFO log_versions:                      urllib3.util.ssl_match_hostname  |  3.5.0.1\n",
      "   INFO log_versions:                                       requests.utils  |  2.30.0\n",
      "   INFO log_versions:                                                scipy  |  1.10.1\n",
      "   INFO log_versions:                                 scipy._lib.decorator  |  4.0.5\n",
      "   INFO log_versions:                                  scipy.linalg._fblas  |  1.21.6\n",
      "   INFO log_versions:                                scipy.linalg._flapack  |  1.21.6\n",
      "   INFO log_versions:                                scipy.linalg._flinalg  |  1.21.6\n",
      "   INFO log_versions:            scipy.sparse.linalg._eigen.arpack._arpack  |  1.21.6\n",
      "   INFO log_versions:               scipy.sparse.linalg._isolve._iterative  |  1.21.6\n",
      "   INFO log_versions:                               scipy.special._specfun  |  1.21.6\n",
      "   INFO log_versions:                                           setuptools  |  67.7.2\n",
      "   INFO log_versions:                                            distutils  |  3.10.11\n",
      "   INFO log_versions:                    setuptools._vendor.more_itertools  |  8.8.0\n",
      "   INFO log_versions:                       setuptools._vendor.ordered_set  |  3.1\n",
      "   INFO log_versions:                         setuptools._vendor.packaging  |  23.0\n",
      "   INFO log_versions:                    setuptools._vendor.more_itertools  |  8.8.0\n",
      "   INFO log_versions:                       setuptools._vendor.ordered_set  |  3.1\n",
      "   INFO log_versions:                         setuptools._vendor.packaging  |  23.0\n",
      "   INFO log_versions:                                   setuptools.version  |  67.7.2\n",
      "   INFO log_versions:                                                  six  |  1.16.0\n",
      "   INFO log_versions:                                         socketserver  |  0.4\n",
      "   INFO log_versions:                                           stack_data  |  0.6.2\n",
      "   INFO log_versions:                                   stack_data.version  |  0.6.2\n",
      "   INFO log_versions:                                          tensorboard  |  2.12.3\n",
      "   INFO log_versions:                   tensorboard.compat.tensorflow_stub  |  stub\n",
      "   INFO log_versions: tensorboard.compat.tensorflow_stub.pywrap_tensorflow  |  0\n",
      "   INFO log_versions:                                           tensorflow  |  2.12.0\n",
      "   INFO log_versions:                         tensorflow._api.v2.compat.v1  |  2.12.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v1.compat.v1  |  2.12.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v1.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                         tensorflow._api.v2.compat.v2  |  2.12.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v2.compat.v1  |  2.12.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v2.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                                 tensorflow.compat.v1  |  2.12.0\n",
      "   INFO log_versions:                       tensorflow.compat.v1.compat.v1  |  2.12.0\n",
      "   INFO log_versions:                       tensorflow.compat.v1.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                                 tensorflow.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                       tensorflow.compat.v2.compat.v1  |  2.12.0\n",
      "   INFO log_versions:                       tensorflow.compat.v2.compat.v2  |  2.12.0\n",
      "   INFO log_versions:                                     tensorflow.keras  |  2.12.0\n",
      "   INFO log_versions:           tensorflow.python.client.pywrap_tf_session  |  2.12.0\n",
      "   INFO log_versions:                 tensorflow.python.framework.versions  |  2.12.0\n",
      "   INFO log_versions:                              tensorflow.python.keras  |  2.6.0\n",
      "   INFO log_versions:                                            traitlets  |  5.9.0\n",
      "   INFO log_versions:                                   traitlets._version  |  5.9.0\n",
      "   INFO log_versions:                                       urllib.request  |  3.10\n",
      "   INFO log_versions:                                              urllib3  |  1.26.15\n",
      "   INFO log_versions:                                     urllib3._version  |  1.26.15\n",
      "   INFO log_versions:                                   urllib3.connection  |  1.26.15\n",
      "   INFO log_versions:                                 urllib3.packages.six  |  1.16.0\n",
      "   INFO log_versions:                      urllib3.util.ssl_match_hostname  |  3.5.0.1\n",
      "   INFO log_versions:                                              wcwidth  |  0.2.6\n",
      "   INFO log_versions:                                                wrapt  |  1.14.1\n",
      "   INFO log_versions:                                        xmlrpc.client  |  3.10\n",
      "   INFO log_versions:                                                 zlib  |  1.0\n",
      "   INFO log_versions:                                                  zmq  |  25.0.2\n",
      "   INFO log_versions:                                            zmq.sugar  |  25.0.2\n",
      "   INFO log_versions:                                    zmq.sugar.version  |  25.0.2\n",
      "   INFO log_versions: ------------------------------------------------------+-----------------------------------------------------------------------------------\n",
      "   INFO initialise_program: Registered config value global > base_seed: -1\n",
      "   INFO initialise_program: Registered config value global > working_dir: SSL_loopy_enc_dec_notebook_[global>problem_tag]_embed[model>ndim_embedding]_enc_[model>encoder>num_blocks]blocks_[model>encoder>num_loops]loops_width[model>encoder>ndim_ff_hidden]_dec_[model>decoder>num_blocks]blocks_[model>decoder>num_loops]loops_width[model>decoder>ndim_ff_hidden]_post[model>post_decoder>num_layers]_width[model>post_decoder>ndim]_idem[model>idempotent_size]_[date]\n",
      "   INFO initialise_program: Registered config value global > problem_tag: int1234_num1245\n",
      "   INFO initialise_program: Registered config value global > model_tag: baseline\n",
      "   INFO initialise_program: Registered config value global > log_lvl_iostream: 20\n",
      "   INFO initialise_program: Registered config value global > log_lvl_fstream: 10\n",
      "   INFO initialise_program: Registered config value data > train_data > int_lengths: [1, 2, 3, 4]\n",
      "   INFO initialise_program: Registered config value data > train_data > num_ints: [1, 2, 4, 5]\n",
      "   INFO initialise_program: Registered config value data > train_data > batch_size: 32\n",
      "   INFO initialise_program: Registered config value data > train_data > num_batches: 1000\n",
      "   INFO initialise_program: Registered config value data > train_data > gen_base_seed: 101\n",
      "   INFO initialise_program: Registered config value data > train_data > gen_reproducible: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO initialise_program: Registered config value data > val_data > int_lengths: [1, 2, 3, 4]\n",
      "   INFO initialise_program: Registered config value data > val_data > num_ints: [3]\n",
      "   INFO initialise_program: Registered config value data > val_data > batch_size: 32\n",
      "   INFO initialise_program: Registered config value data > val_data > num_batches: 50\n",
      "   INFO initialise_program: Registered config value data > val_data > gen_base_seed: 102\n",
      "   INFO initialise_program: Registered config value data > val_data > gen_reproducible: True\n",
      "   INFO initialise_program: Registered config value data > test_data > int_lengths: [1, 2, 3, 4]\n",
      "   INFO initialise_program: Registered config value data > test_data > num_ints: [6]\n",
      "   INFO initialise_program: Registered config value data > test_data > batch_size: 32\n",
      "   INFO initialise_program: Registered config value data > test_data > num_batches: 100\n",
      "   INFO initialise_program: Registered config value data > test_data > gen_base_seed: 103\n",
      "   INFO initialise_program: Registered config value data > test_data > gen_reproducible: True\n",
      "   INFO initialise_program: Registered config value data > characters: ['M', 'B', 'E', 'N', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-']\n",
      "   INFO initialise_program: Registered config value data > mask_char: M\n",
      "   INFO initialise_program: Registered config value data > seq_start_char: B\n",
      "   INFO initialise_program: Registered config value data > seq_end_char: E\n",
      "   INFO initialise_program: Registered config value data > negative_char: N\n",
      "   INFO initialise_program: Registered config value data > dtype: int32\n",
      "   INFO initialise_program: Registered config value model > load_pretrained_model: None\n",
      "   INFO initialise_program: Registered config value model > name: mathsformer_LLM\n",
      "   INFO initialise_program: Registered config value model > dtype: float32\n",
      "   INFO initialise_program: Registered config value model > dropout: 0.1\n",
      "   INFO initialise_program: Registered config value model > learning_rate: 0.001\n",
      "   INFO initialise_program: Registered config value model > jit_compile: False\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > num_freqs: 128\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > min_period: 4\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > max_period: 1000\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > learnable: True\n",
      "   INFO initialise_program: Registered config value model > ndim_embedding: 256\n",
      "   INFO initialise_program: Registered config value model > comb_type: average\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > num_layers: -1\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > ndim: 256\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > pre_decoder > num_layers: -1\n",
      "   INFO initialise_program: Registered config value model > pre_decoder > ndim: 256\n",
      "   INFO initialise_program: Registered config value model > pre_decoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > encoder > num_blocks: 2\n",
      "   INFO initialise_program: Registered config value model > encoder > num_heads: 8\n",
      "   INFO initialise_program: Registered config value model > encoder > ndim: 256\n",
      "   INFO initialise_program: Registered config value model > encoder > ndim_att_hidden: 256\n",
      "   INFO initialise_program: Registered config value model > encoder > ndim_ff_hidden: 1024\n",
      "   INFO initialise_program: Registered config value model > encoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > encoder > num_loops: 3\n",
      "   INFO initialise_program: Registered config value model > decoder > num_blocks: 2\n",
      "   INFO initialise_program: Registered config value model > decoder > num_heads: 8\n",
      "   INFO initialise_program: Registered config value model > decoder > ndim: 256\n",
      "   INFO initialise_program: Registered config value model > decoder > ndim_att_hidden: 256\n",
      "   INFO initialise_program: Registered config value model > decoder > ndim_ff_hidden: 256\n",
      "   INFO initialise_program: Registered config value model > decoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > decoder > num_loops: 3\n",
      "   INFO initialise_program: Registered config value model > post_decoder > num_layers: 3\n",
      "   INFO initialise_program: Registered config value model > post_decoder > ndim: 512\n",
      "   INFO initialise_program: Registered config value model > use_old_loss: True\n",
      "   INFO initialise_program: Registered config value model > optimizer: <class 'keras.optimizers.legacy.adam.Adam'>\n",
      "   INFO initialise_program: Registered config value model > optimizer_args > learning_rate: 1e-05\n",
      "   INFO initialise_program: Registered config value model > idempotent_size: -1\n",
      "   INFO initialise_program: Registered config value training > train: True\n",
      "   INFO initialise_program: Registered config value training > max_epochs: 100000\n",
      "   INFO initialise_program: Registered config value training > log_after_epoch > do: True\n",
      "   INFO initialise_program: Registered config value training > log_after_epoch > log_lvl: 10\n",
      "   INFO initialise_program: Registered config value training > early_stopping > do: False\n",
      "   INFO initialise_program: Registered config value training > early_stopping > patience: 4\n",
      "   INFO initialise_program: Registered config value training > early_stopping > monitor: loss\n",
      "   INFO initialise_program: Registered config value training > early_stopping > mode: min\n",
      "   INFO initialise_program: Registered config value training > early_stopping > restore_best_weights: True\n",
      "   INFO initialise_program: Registered config value training > model_checkpoint > do: True\n",
      "   INFO initialise_program: Registered config value training > model_checkpoint > filename: model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.h5\n",
      "   INFO initialise_program: Registered config value training > layer_weights_record > do: True\n",
      "   INFO initialise_program: Registered config value training > layer_weights_record > batch_frequency: 2000\n",
      "   INFO initialise_program: Registered config value training > layer_weights_record > recursive: True\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > do: True\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > decay_factor: 0.2\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > monitor: loss\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > mode: min\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > patience: 2\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > log_lvl: 10\n",
      "   INFO initialise_program: Registered config value training > print_tables_during_training > do: True\n",
      "   INFO initialise_program: Registered config value training > print_tables_during_training > num_print: 10\n",
      "   INFO initialise_program: Registered config value evaluate > num_print: 50\n",
      "   INFO initialise_program: Registered config value evaluate > save_model: True\n",
      "   INFO initialise_program: Registered config value evaluate > plot_weights: False\n",
      "   INFO initialise_program: Registered config value evaluate > plot_training_curves: True\n",
      "   INFO initialise_program: Python random seed set: 1687459304\n",
      "   INFO initialise_program: Numpy random seed set: 1687459305\n",
      "   INFO initialise_program: TensorFlow random seed set: 1687459306\n"
     ]
    }
   ],
   "source": [
    "##==============================##\n",
    "##   Create working directory   ##\n",
    "##==============================##\n",
    "\n",
    "##  Report success\n",
    "working_dir, logger, base_seed, np_seed, tf_seed = utils.initialise_program(\n",
    "    \"unsupervised_learning_addition_model_generator (notebook)\", \n",
    "    working_dir       = cfg_global[\"working_dir\"], \n",
    "    cfg               = cfg,\n",
    "    base_seed         = cfg_global[\"base_seed\"],\n",
    "    log_lvl_iostream  = cfg_global[\"log_lvl_iostream\"],\n",
    "    log_lvl_fstream   = cfg_global[\"log_lvl_fstream\" ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960860d",
   "metadata": {},
   "source": [
    "##  3. Create training data\n",
    "\n",
    "###  Create tokeniser\n",
    "\n",
    "Tokeniser object handles the transformation from strings to tensors and back again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db11d6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO summary: TokenTransform of dtype int32 with 16 characters: ['M', 'B', 'E', 'N', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-']\n",
      "   INFO summary: Special characters are seq_start_char (B), seq_end_char (E), mask_char (M)\n",
      "   INFO summary: Tokeniser dictionary is {'M': 0, 'B': 1, 'E': 2, 'N': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, '+': 14, '-': 15}\n",
      "   INFO summary: Detokeniser dictionary is {0: 'M', 1: 'B', 2: 'E', 3: 'N', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: '+', 15: '-'}\n"
     ]
    }
   ],
   "source": [
    "##======================##\n",
    "##   Create tokeniser   ##\n",
    "##======================##\n",
    "\n",
    "token_transform = data.TokenTransform.from_dictionary(cfg_data)\n",
    "token_transform.summary(print_fn=logger.info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5367bdd7",
   "metadata": {},
   "source": [
    "###  Create data generators for train/val/test sets\n",
    "\n",
    "Data generators create tensor inputs/outputs for the model on-the-fly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d87b308d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO get_data_generators: Training data generator created with the following config: Generator of [1, 2, 4, 5] integers of length [1, 2, 3, 4] in 1000 batches of size 32 (base_seed=101, reproducible=False)\n",
      "   INFO get_data_generators: Output shapes for a test batch are ((32, 27), (32, 6)), (32, 6)\n",
      "   INFO get_data_generators: Validation data generator created with the following config: Generator of [3] integers of length [1, 2, 3, 4] in 50 batches of size 32 (base_seed=102, reproducible=True)\n",
      "   INFO get_data_generators: Output shapes for a test batch are ((32, 18), (32, 6)), (32, 6)\n",
      "   INFO get_data_generators: Test data generator created with the following config: Generator of [6] integers of length [1, 2, 3, 4] in 100 batches of size 32 (base_seed=103, reproducible=True)\n",
      "   INFO get_data_generators: Output shapes for a test batch are ((32, 29), (32, 7)), (32, 7)\n"
     ]
    }
   ],
   "source": [
    "##============================##\n",
    "##   Create data generators   ##\n",
    "##============================##\n",
    "\n",
    "negative_char = cfg_data.get(\"negative_char\")\n",
    "train_gen, train_gen_reproducible, val_gen, test_gen = backend.get_data_generators(cfg_data, token_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa78cf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Saving distribution of token frequencies to file SSL_loopy_enc_dec_notebook_int1234_num1245_embed256_enc_2blocks_3loops_width1024_dec_2blocks_3loops_width256_post3_width512_idemm1_2023_06_22_v2/token_distribution.pdf\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##=========================================================##\n",
    "##   Quickly visualise distribution of token frequencies   ##\n",
    "##=========================================================##\n",
    "\n",
    "##  Imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "##  Get sample of train data labels\n",
    "train_data_sample = np.concatenate([train_gen[i][1].numpy().flatten() for i in range(1000)])\n",
    "\n",
    "##  Ignore masked tokens\n",
    "train_data_sample = train_data_sample[train_data_sample != 0]\n",
    "\n",
    "##  Count number for each token\n",
    "chars, freqs = [], []\n",
    "for token, char in train_gen.token_transform.detokeniser_dict.items() :\n",
    "    chars.append(char)\n",
    "    freqs.append(len(train_data_sample[train_data_sample==token]))\n",
    "    \n",
    "##  Normalise counts to frequency\n",
    "freqs     = np.array(freqs).astype(np.float32)\n",
    "freqs_err = np.sqrt(freqs)\n",
    "freqs_tot = np.sum(freqs)\n",
    "freqs     /= freqs_tot\n",
    "freqs_err /= freqs_tot\n",
    "\n",
    "##  Log token frequencies\n",
    "for char, freq, freq_err in zip(chars, freqs, freqs_err) :\n",
    "    logger.debug(f\"Token '{char}' in training data with frequency {100.*freq:.1f} +- {100.*freq_err:.1f} % (masked)\")\n",
    "\n",
    "##  Plot quick bar chart of frequencies\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax  = fig.add_subplot(1, 1, 1)\n",
    "ax.tick_params(which=\"both\", axis=\"both\", right=True, top=True, labelsize=10, direction=\"in\")\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"Character\", fontsize=14, va=\"top\"  , labelpad=15)\n",
    "ax.set_ylabel(\"Frequency in\\ntrain data\", fontsize=14, ha=\"right\", rotation=0, labelpad=20)\n",
    "\n",
    "ax.bar(chars, freqs, yerr=freqs_err)\n",
    "\n",
    "fig_fname = f\"{working_dir}/token_distribution.pdf\"\n",
    "logger.info(f\"Saving distribution of token frequencies to file {fig_fname}\")\n",
    "\n",
    "plt.savefig(fig_fname, bbox_inches=\"tight\")\n",
    "plt.show(fig)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39db1bb",
   "metadata": {},
   "source": [
    "##  4.  Create model\n",
    "\n",
    "Create the keras model object that handles sequence-sequence transformations from alread-tokenised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae1868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers     import Add, Average, Concatenate, Embedding, Input, LayerNormalization\n",
    "from tensorflow.keras.models     import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from mathsformer.tf_objects import (DecoderBlock, EncoderBlock, Enumerate, FeedForwardBlock, LearnableMixture, MaskedCategoricalAccuracy,\n",
    "                                    MaskedSparseCategoricalCrossentropy, PositionalEncoding)\n",
    "from mathsformer.tf_objects import scalar_masked_sparse_categorical_crossentropy, scalar_masked_categorical_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98368f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_text_to_text_model(vocab_length:int, \n",
    "                              name:str, \n",
    "                              do_compile:bool       = True,\n",
    "                              use_old_loss:bool     = False,\n",
    "                              dtype_in              = tf.int32, \n",
    "                              dtype                 = tf.float32, \n",
    "                              dropout:float         = 0.1, \n",
    "                              jit_compile:bool      = None,\n",
    "                              optimizer             = Adam,\n",
    "                              optimizer_args:dict   = None,\n",
    "                              idempotent_size:int   = 1,\n",
    "                              pos_enc_num_freqs:int = 32, pos_enc_min_period:float = 4, pos_enc_max_period:float = 500 , pos_enc_learnable:bool = False,\n",
    "                              ndim_embedding:int          = 64, comb_type:str                = \"average\",\n",
    "                              num_encoder_blocks:int      = 5 , ndim_encoder:int             = 64 , skip_connect_encoder:bool  = True,\n",
    "                              num_decoder_blocks:int      = 5 , ndim_decoder:int             = 64 , skip_connect_decoder:bool  = True,\n",
    "                              num_heads_encoder:int       = 8 , ndim_att_hidden_encoder:int  = 128, ndim_ff_hidden_encoder:int = 128, \n",
    "                              num_heads_decoder:int       = 8 , ndim_att_hidden_decoder:int  = 128, ndim_ff_hidden_decoder:int = 128, \n",
    "                              num_encoder_loops:int       = 1 , num_decoder_loops:int        = 1  ,\n",
    "                              num_post_layers_decoder:int = 3 , ndim_post_layers_decoder:int = 512, \n",
    "                             ) :\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ##  Resolve mutable default args\n",
    "    if optimizer_args is None :\n",
    "        optimizer_args = {'learning_rate': 1e-3}\n",
    "    \n",
    "    ##=============================================##\n",
    "    ##===   Input layer - Output shape [B, S]   ===##\n",
    "    ##=============================================##\n",
    "    x_in_enc = Input((None,), dtype=dtype_in, name=f\"{name}_encoder_input_layer\")\n",
    "    x_in_dec = Input((None,), dtype=dtype_in, name=f\"{name}_decoder_input_layer\")\n",
    "            \n",
    "    ##===========================================================================##\n",
    "    ##===  Token embedding, masking 0s - Output shape [B, S, ndim_embedding]  ===##\n",
    "    ##===========================================================================##\n",
    "    x_embed_enc = Embedding(vocab_length, \n",
    "                            ndim_embedding, \n",
    "                            mask_zero=True, \n",
    "                            dtype=dtype, \n",
    "                            name=f\"{name}_encoder_embedding\")(x_in_enc)\n",
    "    x_embed_dec = Embedding(vocab_length, \n",
    "                            ndim_embedding, \n",
    "                            mask_zero=True, \n",
    "                            dtype=dtype, \n",
    "                            name=f\"{name}_decoder_embedding\")(x_in_dec)\n",
    "    \n",
    "    ##=========================================================================##\n",
    "    ##===  Enumerate indices for positional encoding - Output shape [B, S]  ===##\n",
    "    ##=========================================================================##\n",
    "    x_pos_enc = Enumerate(name=f\"{name}_encoder_enumerate\", dtype=dtype)(x_in_enc, minimal_dims=False)\n",
    "    x_pos_dec = Enumerate(name=f\"{name}_decoder_enumerate\", dtype=dtype)(x_in_dec, minimal_dims=False)\n",
    "    \n",
    "    ##========================================================================##\n",
    "    ##===  Positional encoding - Output shape [B, S, 2*pos_enc_num_freqs]  ===##\n",
    "    ##========================================================================##\n",
    "    x_pos_enc = PositionalEncoding(num_freqs  = pos_enc_num_freqs, \n",
    "                                   min_period = pos_enc_min_period, \n",
    "                                   max_period = pos_enc_max_period, \n",
    "                                   learnable  = pos_enc_learnable,\n",
    "                                   dtype      = dtype, \n",
    "                                   name       = f\"{name}_encoder_position_encoding\")(x_pos_enc)\n",
    "    x_pos_dec = PositionalEncoding(num_freqs  = pos_enc_num_freqs, \n",
    "                                   min_period = pos_enc_min_period, \n",
    "                                   max_period = pos_enc_max_period, \n",
    "                                   learnable  = pos_enc_learnable,\n",
    "                                   dtype      = dtype, \n",
    "                                   name       = f\"{name}_decoder_position_encoding\")(x_pos_dec)\n",
    "\n",
    "    ##==============================================================================================##\n",
    "    ##===  Combine embeddings end pos enc - Output shape [B, S, N] where N depends on comb_type  ===##\n",
    "    ##==============================================================================================##\n",
    "    allowed_comb_types = [\"add\", \"sum\", \"average\", \"mean\", \"concat\", \"concatenate\", \"mixture\"]\n",
    "    match comb_type.lower() :\n",
    "        case \"add\" | \"sum\" :\n",
    "            x_enc = Add(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = Add(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case \"average\" | \"mean\" :\n",
    "            x_enc = Average(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = Average(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case \"concat\" | \"concatenate\" :\n",
    "            x_enc = Concatenate(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = Concatenate(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case \"mixture\" :\n",
    "            x_enc = LearnableMixture(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = LearnableMixture(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case _ :\n",
    "            raise RuntimeError(f\"comb_type '{comb_type}' not recognised, recognised keywords are {allowed_comb_types}\")\n",
    "    \n",
    "    ##============================================================##\n",
    "    ##===  Encoder blocks - Output shape [B, S, ndim_encoder]  ===##\n",
    "    ##============================================================##\n",
    "    encoder_blocks = []\n",
    "    for layer_idx in range(num_encoder_blocks) :\n",
    "        encoder_blocks.append(EncoderBlock(\n",
    "                                 ndim_encoder, \n",
    "                                 num_heads_encoder, \n",
    "                                 ndim_att_hidden_encoder, \n",
    "                                 ndim_ff_hidden_encoder, \n",
    "                                 dropout_mha     = dropout, \n",
    "                                 dtype           = dtype, \n",
    "                                 pre_layer_norm  = True, \n",
    "                                 post_layer_norm = False, \n",
    "                                 skip_connect    = skip_connect_encoder, \n",
    "                                 name            = f\"{name}_encoder_block_{layer_idx+1}\"))\n",
    "        \n",
    "    for loop_idx in range(num_encoder_loops) :\n",
    "        for encoder_block in encoder_blocks :\n",
    "            x_enc = encoder_block(x_enc)\n",
    "    x_enc = LayerNormalization(name=f\"{name}_encoder_output_norm\")(x_enc)\n",
    "           \n",
    "    x_post_enc = x_enc\n",
    "    for loop_idx in range(idempotent_size) :\n",
    "        for encoder_block in encoder_blocks :\n",
    "            x_post_enc = encoder_block(x_post_enc)\n",
    "    x_post_enc = LayerNormalization(name=f\"{name}_encoder_idem_output_norm\")(x_post_enc)\n",
    "    \n",
    "    ##============================================================##\n",
    "    ##===  Decoder blocks - Output shape [B, S, ndim_decoder]  ===##\n",
    "    ##============================================================##\n",
    "    decoder_blocks = []\n",
    "    for layer_idx in range(num_decoder_blocks) :\n",
    "        decoder_blocks.append(DecoderBlock(\n",
    "                                 ndim_decoder, \n",
    "                                 num_heads_decoder, \n",
    "                                 ndim_att_hidden_decoder, \n",
    "                                 ndim_ff_hidden_decoder, \n",
    "                                 dropout_mha     = dropout, \n",
    "                                 dtype           = dtype, \n",
    "                                 pre_layer_norm  = True, \n",
    "                                 post_layer_norm = False, \n",
    "                                 skip_connect    = skip_connect_decoder, \n",
    "                                 name            = f\"{name}_decoder_block_{layer_idx+1}\"))\n",
    "        \n",
    "    x_post_dec = x_dec\n",
    "    for loop_idx in range(num_decoder_loops) :\n",
    "        for decoder_block in decoder_blocks :\n",
    "            x_dec      = decoder_block([x_dec, x_enc])\n",
    "            x_post_dec = decoder_block([x_post_dec, x_post_enc])\n",
    "        \n",
    "    ##==================================================================================================##\n",
    "    ##===  Predict logit probabilities using feed-forward block - Output shape [B, S, vocab_length]  ===##\n",
    "    ##==================================================================================================##\n",
    "    ##  - use layer_norm instead of batch_norm because elements in sequence are not independent\n",
    "    ff_block = FeedForwardBlock(vocab_length, \n",
    "                         ndim_hidden       = ndim_post_layers_decoder, \n",
    "                         num_hidden_layers = num_post_layers_decoder, \n",
    "                         skip_connect      = False, \n",
    "                         pre_layer_norm    = True, \n",
    "                         post_layer_norm   = False, \n",
    "                         batch_norm        = False, \n",
    "                         dtype             = dtype, \n",
    "                         name              = f\"{name}_output\")\n",
    "    x, x2 = ff_block(x_dec), ff_block(x_post_dec)\n",
    "    \n",
    "    ##  Create model\n",
    "    if idempotent_size > 0 :\n",
    "        model = Model([x_in_enc, x_in_dec], [x, x2], name=name)\n",
    "    else :\n",
    "        model = Model([x_in_enc, x_in_dec], x, name=name)\n",
    "    \n",
    "    ##  Compile model with sparse categorical crossentropy loss and accuracy metric\n",
    "    if do_compile :\n",
    "        acc  = MaskedCategoricalAccuracy(scalar_output=True, equal_token_weight=True, use_keras_mask=False, mask_value=0)\n",
    "        loss = MaskedSparseCategoricalCrossentropy(scalar_output=True, equal_token_weight=True, use_keras_mask=False, mask_value=0, from_logits=True)\n",
    "        model.compile(loss        = loss, \n",
    "                      optimizer   = optimizer(**optimizer_args), \n",
    "                      metrics     = [acc],\n",
    "                      jit_compile = jit_compile)\n",
    "    \n",
    "    ##  Return model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "942355eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_to_text_model_from_config(cfg_model, token_transform) :\n",
    "    \"\"\"\n",
    "    Create a text-to-text transformer model\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "        >  cfg_model, Config\n",
    "           Model configuration\n",
    "           \n",
    "        >  token_transform, TokenTransform\n",
    "           Tokeniser\n",
    "    \"\"\"\n",
    "    return create_text_to_text_model(\n",
    "                          vocab_length                = token_transform.vocab_length, \n",
    "                          name                        = cfg_model[\"name\"],\n",
    "                          do_compile                  = True,\n",
    "                          use_old_loss                = cfg_model[\"use_old_loss\"],\n",
    "                          dtype_in                    = token_transform.dtype,\n",
    "                          dtype                       = cfg_model[\"dtype\"],\n",
    "                          dropout                     = cfg_model[\"dropout\"],\n",
    "                          jit_compile                 = cfg_model[\"jit_compile\"],\n",
    "                          optimizer                   = cfg_model.get(\"optimizer\", Adam),\n",
    "                          optimizer_args              = cfg_model.get(\"optimizer_args\", {}),\n",
    "                          idempotent_size             = cfg_model[\"idempotent_size\"],\n",
    "                          pos_enc_num_freqs           = cfg_model[\"positional_encoding\"][\"num_freqs\"],\n",
    "                          pos_enc_min_period          = cfg_model[\"positional_encoding\"][\"min_period\"],\n",
    "                          pos_enc_max_period          = cfg_model[\"positional_encoding\"][\"max_period\"],\n",
    "                          pos_enc_learnable           = cfg_model[\"positional_encoding\"][\"learnable\"],\n",
    "                          ndim_embedding              = cfg_model[\"ndim_embedding\"],\n",
    "                          num_encoder_blocks          = cfg_model[\"encoder\"][\"num_blocks\"],\n",
    "                          num_encoder_loops           = cfg_model[\"encoder\"][\"num_loops\"],\n",
    "                          ndim_encoder                = cfg_model[\"encoder\"][\"ndim\"],\n",
    "                          num_heads_encoder           = cfg_model[\"encoder\"][\"num_heads\"],\n",
    "                          ndim_att_hidden_encoder     = cfg_model[\"encoder\"][\"ndim_att_hidden\"],\n",
    "                          ndim_ff_hidden_encoder      = cfg_model[\"encoder\"][\"ndim_ff_hidden\"],\n",
    "                          skip_connect_encoder        = cfg_model[\"encoder\"][\"skip_connect\"],\n",
    "                          num_decoder_blocks          = cfg_model[\"decoder\"][\"num_blocks\"],\n",
    "                          num_decoder_loops           = cfg_model[\"decoder\"][\"num_loops\"],\n",
    "                          ndim_decoder                = cfg_model[\"decoder\"][\"ndim\"],\n",
    "                          num_heads_decoder           = cfg_model[\"decoder\"][\"num_heads\"],\n",
    "                          ndim_att_hidden_decoder     = cfg_model[\"decoder\"][\"ndim_att_hidden\"],\n",
    "                          ndim_ff_hidden_decoder      = cfg_model[\"decoder\"][\"ndim_ff_hidden\"],\n",
    "                          skip_connect_decoder        = cfg_model[\"decoder\"][\"skip_connect\"],\n",
    "                          num_post_layers_decoder     = cfg_model[\"post_decoder\"][\"num_layers\"],\n",
    "                          ndim_post_layers_decoder    = cfg_model[\"post_decoder\"][\"ndim\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bb6a53e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Creating new text-to-text model\n",
      "   INFO <module>: Model created with summary:\n",
      "   INFO <module>: Model: \"mathsformer_LLM\"\n",
      "   INFO <module>: __________________________________________________________________________________________________\n",
      "   INFO <module>:  Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "   INFO <module>: ==================================================================================================\n",
      "   INFO <module>:  mathsformer_LLM_encoder_input_  [(None, None)]      0           []                               \n",
      "   INFO <module>:  layer (InputLayer)                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_enumer  (None, None)        0           ['mathsformer_LLM_encoder_input_l\n",
      "   INFO <module>:  ate (Enumerate)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_embedd  (None, None, 256)   4096        ['mathsformer_LLM_encoder_input_l\n",
      "   INFO <module>:  ing (Embedding)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_positi  (None, None, 256)   128         ['mathsformer_LLM_encoder_enumera\n",
      "   INFO <module>:  on_encoding (PositionalEncodin                                  te[0][0]']                       \n",
      "   INFO <module>:  g)                                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_emb_an  (None, None, 256)   0           ['mathsformer_LLM_encoder_embeddi\n",
      "   INFO <module>:  d_pos (Average)                                                 ng[0][0]',                       \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_positio\n",
      "   INFO <module>:                                                                  n_encoding[0][0]']               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_block_  (None, None, 256)   2630144     ['mathsformer_LLM_encoder_emb_and\n",
      "   INFO <module>:  1 (EncoderBlock)                                                _pos[0][0]',                     \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n",
      "   INFO <module>:                                                                  [0][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_2\n",
      "   INFO <module>:                                                                  [1][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_block_  (None, None, 256)   2630144     ['mathsformer_LLM_encoder_block_1\n",
      "   INFO <module>:  2 (EncoderBlock)                                                [0][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n",
      "   INFO <module>:                                                                  [1][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_1\n",
      "   INFO <module>:                                                                  [2][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_input_  [(None, None)]      0           []                               \n",
      "   INFO <module>:  layer (InputLayer)                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_enumer  (None, None)        0           ['mathsformer_LLM_decoder_input_l\n",
      "   INFO <module>:  ate (Enumerate)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_embedd  (None, None, 256)   4096        ['mathsformer_LLM_decoder_input_l\n",
      "   INFO <module>:  ing (Embedding)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_positi  (None, None, 256)   128         ['mathsformer_LLM_decoder_enumera\n",
      "   INFO <module>:  on_encoding (PositionalEncodin                                  te[0][0]']                       \n",
      "   INFO <module>:  g)                                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_emb_an  (None, None, 256)   0           ['mathsformer_LLM_decoder_embeddi\n",
      "   INFO <module>:  d_pos (Average)                                                 ng[0][0]',                       \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_positio\n",
      "   INFO <module>:                                                                  n_encoding[0][0]']               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_output  (None, None, 256)   512         ['mathsformer_LLM_encoder_block_2\n",
      "   INFO <module>:  _norm (LayerNormalization)                                      [2][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_block_  (None, None, 256)   4340224     ['mathsformer_LLM_decoder_emb_and\n",
      "   INFO <module>:  1 (DecoderBlock)                                                _pos[0][0]',                     \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_output_\n",
      "   INFO <module>:                                                                  norm[0][0]',                     \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_block_2\n",
      "   INFO <module>:                                                                  [0][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_output_\n",
      "   INFO <module>:                                                                  norm[0][0]',                     \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_block_2\n",
      "   INFO <module>:                                                                  [2][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_output_\n",
      "   INFO <module>:                                                                  norm[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:  mathsformer_LLM_decoder_block_  (None, None, 256)   4340224     ['mathsformer_LLM_decoder_block_1\n",
      "   INFO <module>:  2 (DecoderBlock)                                                [0][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_output_\n",
      "   INFO <module>:                                                                  norm[0][0]',                     \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_block_1\n",
      "   INFO <module>:                                                                  [2][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_output_\n",
      "   INFO <module>:                                                                  norm[0][0]',                     \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_block_1\n",
      "   INFO <module>:                                                                  [4][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_output_\n",
      "   INFO <module>:                                                                  norm[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_output (FeedFo  (None, None, 16)    665616      ['mathsformer_LLM_decoder_block_2\n",
      "   INFO <module>:  rwardBlock)                                                     [4][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>: ==================================================================================================\n",
      "   INFO <module>: Total params: 14,615,312\n",
      "   INFO <module>: Trainable params: 14,615,312\n",
      "   INFO <module>: Non-trainable params: 0\n",
      "   INFO <module>: __________________________________________________________________________________________________\n",
      "   INFO <module>: Learning rate is 9.999999747378752e-06\n"
     ]
    }
   ],
   "source": [
    "##===================================================##\n",
    "##   Load or create self-supervised learning model   ##\n",
    "##===================================================##\n",
    "\n",
    "##  Get filename for load model\n",
    "fname = cfg_model.get(\"load_pretrained_model\", None)\n",
    "\n",
    "##  Load model if fname is not None, otherwise create from scratch\n",
    "if fname is not None :\n",
    "    logger.info   (f\"Loading model from: {fname}\")\n",
    "    logger.warning(\"Loading a pretrained model will disregard model config!\")\n",
    "    model = backend.load_text_to_text_model(fname)\n",
    "    model.optimizer.learning_rate.assign(cfg_model[\"optimizer_args\"][\"learning_rate\"])  ## Reset LR to config value\n",
    "else :\n",
    "    logger.info(f\"Creating new text-to-text model\")\n",
    "    model = create_text_to_text_model_from_config(cfg_model, token_transform)\n",
    "\n",
    "##  Create hack to catch model summary\n",
    "model_summary = []\n",
    "model.summary(print_fn = lambda s : model_summary.append(s))\n",
    "\n",
    "##  Print model summary\n",
    "logger.info(\"Model created with summary:\")\n",
    "for s in model_summary : logger.info(s)\n",
    "logger.info(f\"Learning rate is {model.optimizer.learning_rate.value()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "793493a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##==============================================================##\n",
    "##   Create transformer wrapper for model and token_transform   ##\n",
    "##==============================================================##\n",
    "\n",
    "transformer = transformers.Transformer_Text_to_Text(model, token_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "956e30a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO test_transformer: Running text --> text mathsformer inference on some training data:\n",
      "   INFO print_predictions_table: ------------------------------------------------------------------------------------------\n",
      "   INFO print_predictions_table:                 INPUT         TRUE   PRED(MASK)      PRED(GEN)      CORRECT       RESIDUAL\n",
      "   INFO print_predictions_table: ------------------------------------------------------------------------------------------\n",
      "   INFO print_predictions_table:               N901+87         N814      N111111 N1111111111113              -1111111110299\n",
      "   INFO print_predictions_table:                  N490         N490      1111111   111111111111                111111111601\n",
      "   INFO print_predictions_table:                N169-9         N178      N111111 N1111111111113              -1111111110935\n",
      "   INFO print_predictions_table:                  N875         N875      1111111   111111111111                111111111986\n",
      "   INFO print_predictions_table:        N6-283-555+N45         N889      N111111 N1111111111113              -1111111110224\n",
      "   INFO print_predictions_table:                N63-N7          N56      N111111 N1111111111113              -1111111111057\n",
      "   INFO print_predictions_table:              N469-N83         N386      N111111 N1111111111113              -1111111110727\n",
      "   INFO print_predictions_table:  9510-N36+1500+6537-3        17580      N111111 N1111111111113              -1111111128693\n",
      "   INFO print_predictions_table:               63+2517         2580      N111111 N1111111111113              -1111111113693\n",
      "   INFO print_predictions_table:            N374-N9949         9575      N111111 N1111111111113              -1111111120688\n",
      "   INFO test_transformer: Running text --> text mathsformer inference on some validation data:\n",
      "   INFO print_predictions_table: -----------------------------------------------------------------------------------\n",
      "   INFO print_predictions_table:          INPUT         TRUE   PRED(MASK)      PRED(GEN)      CORRECT       RESIDUAL\n",
      "   INFO print_predictions_table: -----------------------------------------------------------------------------------\n",
      "   INFO print_predictions_table:   3-N3988+N847         3144       N11111 N1111111111113              -1111111114257\n",
      "   INFO print_predictions_table:      7797+5-N4         7806       N11111 N1111111111113              -1111111118919\n",
      "   INFO print_predictions_table:   N8357-N11+N7        N8353       N11111 N1111111111113              -1111111102760\n",
      "   INFO print_predictions_table:  6686-N437-236         6887       N11111 N1111111111113              -1111111118000\n",
      "   INFO print_predictions_table:      N5+4442+8         4445       N11111 N1111111111113              -1111111115558\n",
      "   INFO print_predictions_table:    2123-N1+N68         2056       N11111 N1111111111113              -1111111113169\n",
      "   INFO print_predictions_table:    95+4563+879         5537       N11111 N1111111111113              -1111111116650\n",
      "   INFO print_predictions_table:   1639+N2868+5        N1224       N11111 N1111111111113              -1111111109889\n",
      "   INFO print_predictions_table:       8+N725-3         N720       N11111 N1111111111113              -1111111110393\n",
      "   INFO print_predictions_table:  N283+N962-N40        N1205       N11111 N1111111111113              -1111111109908\n",
      "   INFO test_transformer: Running text --> text mathsformer inference on some test data:\n",
      "   INFO print_predictions_table: -------------------------------------------------------------------------------------------------\n",
      "   INFO print_predictions_table:                        INPUT         TRUE   PRED(MASK)      PRED(GEN)      CORRECT       RESIDUAL\n",
      "   INFO print_predictions_table: -------------------------------------------------------------------------------------------------\n",
      "   INFO print_predictions_table:  N6774-N71+5814-6016+45+N976        N7836      1111111 11111111111113              11111111118949\n",
      "   INFO print_predictions_table:        N5489-65-65-N1+7-N734        N4877      N111111 N1111111111113              -1111111106236\n",
      "   INFO print_predictions_table:        N3-79+43-890+N3666-N6        N4589      N111111 N1111111111113              -1111111106524\n",
      "   INFO print_predictions_table:     N950+189+2766-N594+474-1         3072      1111111 11111111111113              11111111108041\n",
      "   INFO print_predictions_table:     N3994+N9+5718-N4-6+N9512        N7799      1111111 11111111111113              11111111118912\n",
      "   INFO print_predictions_table:   N742+8580+45+N52-N1561-N84         9476      1111111 11111111111113              11111111101637\n",
      "   INFO print_predictions_table:    3524-2067-3915+N252+N1-82        N2793      1111111 11111111111113              11111111113906\n",
      "   INFO print_predictions_table:   220-N665-74-N42-N415+N9861        N8593      1111111 11111111111113              11111111119706\n",
      "   INFO print_predictions_table:     N8355-N5-N97+317-N755+85        N7096      1111111 11111111111113              11111111118209\n",
      "   INFO print_predictions_table:    5769+6-9703-N6918-738+N48         2204      1111111 11111111111113              11111111108909\n"
     ]
    }
   ],
   "source": [
    "##=========================================##\n",
    "##   Test transformer on data generators   ##\n",
    "##=========================================##\n",
    "\n",
    "backend.test_transformer(transformer, train_gen, val_gen, test_gen, negative_char=negative_char)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f7a52",
   "metadata": {},
   "source": [
    "##  5.  Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aea411fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO get_callbacks: Registered training callback: LoggerCallback with loglvl=10\n",
      "   INFO get_callbacks: Registered training callback: AdaptiveLearningRate with decay_factor=0.2, patience=2, monitor=loss, mode=min, log_lvl=10\n",
      "   INFO get_callbacks: Registered training callback: ModelCheckpoint with filepath=SSL_loopy_enc_dec_notebook_int1234_num1245_embed256_enc_2blocks_3loops_width1024_dec_2blocks_3loops_width256_post3_width512_idemm1_2023_06_22_v2/model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.h5\n",
      "   INFO get_callbacks: Registered training callback: LayerWeightsRecord with batch_frequency=2000, recursive=True\n",
      "   INFO get_callbacks: Registered training callback: LambdaCallback for test_transformer with num_print=10, negative_char='N'\n"
     ]
    }
   ],
   "source": [
    "##===================================##\n",
    "##   Create callbacks for training   ##\n",
    "##===================================##\n",
    "\n",
    "callbacks = backend.get_callbacks(cfg_training, working_dir, transformer=transformer, train_gen=train_gen_reproducible, \n",
    "                                  val_gen=val_gen, negative_char=negative_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21d1736d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Begin model training with max_epochs=100000\n",
      "Epoch 1/100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 19:42:30.686173: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 550s 546ms/step - loss: 1.9630 - masked_categorical_accuracy: 0.3501 - val_loss: 2.0026 - val_masked_categorical_accuracy: 0.3318\n",
      "Epoch 2/100000\n",
      "1000/1000 [==============================] - 542s 542ms/step - loss: 1.8448 - masked_categorical_accuracy: 0.3618 - val_loss: 2.0640 - val_masked_categorical_accuracy: 0.3355\n",
      "Epoch 3/100000\n",
      "1000/1000 [==============================] - 2898s 3s/step - loss: 1.6464 - masked_categorical_accuracy: 0.4435 - val_loss: 1.9422 - val_masked_categorical_accuracy: 0.3459\n",
      "Epoch 4/100000\n",
      "1000/1000 [==============================] - 542s 542ms/step - loss: 1.4468 - masked_categorical_accuracy: 0.5004 - val_loss: 1.9248 - val_masked_categorical_accuracy: 0.3381\n",
      "Epoch 5/100000\n",
      "1000/1000 [==============================] - 541s 540ms/step - loss: 1.4167 - masked_categorical_accuracy: 0.5068 - val_loss: 1.9404 - val_masked_categorical_accuracy: 0.3411\n",
      "Epoch 6/100000\n",
      "1000/1000 [==============================] - 544s 544ms/step - loss: 1.4010 - masked_categorical_accuracy: 0.5092 - val_loss: 1.9299 - val_masked_categorical_accuracy: 0.3421\n",
      "Epoch 7/100000\n",
      "1000/1000 [==============================] - 547s 547ms/step - loss: 1.3895 - masked_categorical_accuracy: 0.5127 - val_loss: 1.9610 - val_masked_categorical_accuracy: 0.3434\n",
      "Epoch 8/100000\n",
      "1000/1000 [==============================] - 546s 546ms/step - loss: 1.3793 - masked_categorical_accuracy: 0.5151 - val_loss: 1.9482 - val_masked_categorical_accuracy: 0.3455\n",
      "Epoch 9/100000\n",
      "1000/1000 [==============================] - 551s 551ms/step - loss: 1.3608 - masked_categorical_accuracy: 0.5193 - val_loss: 1.9449 - val_masked_categorical_accuracy: 0.3523\n",
      "Epoch 10/100000\n",
      "1000/1000 [==============================] - 546s 546ms/step - loss: 1.3505 - masked_categorical_accuracy: 0.5205 - val_loss: 1.8864 - val_masked_categorical_accuracy: 0.3547\n",
      "Epoch 11/100000\n",
      "1000/1000 [==============================] - 546s 545ms/step - loss: 1.3269 - masked_categorical_accuracy: 0.5284 - val_loss: 1.8309 - val_masked_categorical_accuracy: 0.3647\n",
      "Epoch 12/100000\n",
      "1000/1000 [==============================] - 547s 547ms/step - loss: 1.3239 - masked_categorical_accuracy: 0.5288 - val_loss: 1.8378 - val_masked_categorical_accuracy: 0.3821\n",
      "Epoch 13/100000\n",
      "1000/1000 [==============================] - 546s 546ms/step - loss: 1.3090 - masked_categorical_accuracy: 0.5327 - val_loss: 1.7965 - val_masked_categorical_accuracy: 0.3872\n",
      "Epoch 14/100000\n",
      "1000/1000 [==============================] - 548s 548ms/step - loss: 1.3048 - masked_categorical_accuracy: 0.5344 - val_loss: 1.8078 - val_masked_categorical_accuracy: 0.4004\n",
      "Epoch 15/100000\n",
      "  51/1000 [>.............................] - ETA: 8:41 - loss: 1.2939 - masked_categorical_accuracy: 0.5375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##=================##\n",
    "##   Train model   ##\n",
    "##=================##\n",
    "\n",
    "do_train = cfg_training.get(\"train\", True)\n",
    "\n",
    "if do_train :\n",
    "    max_epochs = cfg_training[\"max_epochs\"]\n",
    "    logger.info(f\"Begin model training with max_epochs={max_epochs}\")\n",
    "    model.fit(train_gen, \n",
    "              epochs          = max_epochs,\n",
    "              validation_data = val_gen,\n",
    "              callbacks       = callbacks\n",
    "             )\n",
    "else :\n",
    "    logger.warning(\"Skipping model training following global config instructions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb38943",
   "metadata": {},
   "outputs": [],
   "source": [
    "##================##\n",
    "##   Save model   ##\n",
    "##================##\n",
    "\n",
    "do_save = cfg_evaluate.get(\"save_model\", True)\n",
    "\n",
    "if do_save :\n",
    "    save_fname = f\"{working_dir}/final_model.keras\"\n",
    "    model.save(save_fname)\n",
    "    logger.info(f\"Model saved to file {save_fname}\")\n",
    "else :\n",
    "    logger.warning(\"Not saving model because no training was done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc69448",
   "metadata": {},
   "source": [
    "## 6.  Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c425ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "  \n",
    "##  Find out how many datapoints to print predictions for \n",
    "num_print = cfg_evaluate.get(\"num_print\", 20)\n",
    "\n",
    "##  Print tables\n",
    "backend.test_transformer(transformer, train_gen, val_gen, test_gen, num_print=num_print, \n",
    "                         negative_char=negative_char)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfb55b",
   "metadata": {},
   "source": [
    "##  7. Additional visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e385e68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##=============================================##\n",
    "##   Visualise layer weights during training   ##\n",
    "##=============================================##\n",
    "\n",
    "if cfg_evaluate[\"plot_weights\"] :\n",
    "    \n",
    "    logger.info(\"Plotting weights\")\n",
    "    backend.plot_weights(callbacks, show=True, close=True, savefig=f\"{working_dir}/layer_weights.pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "##===============================##\n",
    "##   Visualise training curves   ##\n",
    "##===============================##\n",
    "\n",
    "if cfg_evaluate[\"plot_training_curves\"] :\n",
    "    \n",
    "    if not hasattr(model, \"history\") :\n",
    "        logger.error(\"Cannot print training curves because no model history exists - perhaps you skipped training?\")\n",
    "    else :\n",
    "        logger.info(\"Plotting training curves\")\n",
    "        backend.plot_training_curves(model.history.history, show=True, close=True, savefig=f\"{working_dir}/training_curves.pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd92c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d083b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
