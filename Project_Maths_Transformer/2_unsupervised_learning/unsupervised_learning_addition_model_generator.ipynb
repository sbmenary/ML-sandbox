{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884dc59d",
   "metadata": {},
   "source": [
    "#  Unsupervised learning addition model with generator\n",
    "\n",
    "Author: S. Menary [sbmenary@gmail.com]\n",
    "\n",
    "Date: 5/4/2023  (last update: 9/4/2023)\n",
    "\n",
    "Overview: Train a `sequence -> sequence` model where the input sequence is a text representation of a simple sum $\\sum_{i=1}^N A_i$ for a configurable number $N$ of integers $A_i\\in\\mathbb{Z}$, and the output is a set of logits representing the probability of each token in the output sequence. Integers may have a configurable number of digits. At inference time, chains of text are generated auto-regressively until the terminate-sequence token is reached. The loss function is a sparse categorical entropy.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Set up program\n",
    "\n",
    "###  Import\n",
    "\n",
    "All imports go here at the top of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48f1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "##=========================##\n",
    "##   All imports go here   ##\n",
    "##=========================##\n",
    "\n",
    "##  Import entire python stdlib packages\n",
    "import logging, math, os, pickle, random, sys, time\n",
    "\n",
    "##  Import entire pypi packages\n",
    "import numpy      as np\n",
    "import tensorflow as tf\n",
    "\n",
    "##  Import individual modules/objects from python stdlib packages\n",
    "from pathlib import Path\n",
    "\n",
    "##  Import individual modules/objects from pypi packages\n",
    "from tensorflow.keras.callbacks  import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "##  Add directory above this to system path to expose mathsformer package location\n",
    "sys.path.append(\"/\".join(os.getcwd().split(\"/\")[:-1]))\n",
    "\n",
    "##  Import individual modules/objects from local packages\n",
    "from mathsformer.data        import TokenTransform\n",
    "from mathsformer.tf_objects  import (create_custom_objects_dict, masked_accuracy, masked_sparse_categorical_crossentropy, \n",
    "                                     MetricRecord, LayerWeightsRecord, LoggerCallback)\n",
    "from mathsformer.transformer import create_text_to_text_model, Transformer_Text_to_Text\n",
    "from mathsformer.utils       import CustomLogLevel, create_working_directory, fancy_message, initialise_program\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320886f9",
   "metadata": {},
   "source": [
    "### Configuation\n",
    "\n",
    "Set global configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d874461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class AdaptiveLearningRate(Callback) :\n",
    "    \n",
    "    def __init__(self, decay_factor:float, patience:int=1, monitor:str=None, mode:str='min', \n",
    "                 variable=None, logger=None, log_lvl:int=logging.DEBUG) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        ##  Check that a valid mode was provided\n",
    "        mode = mode.lower()\n",
    "        if mode not in [\"min\", \"max\"] :\n",
    "            raise ValueError(f\"mode must be 'min' or 'max', but '{mode}' provided\")\n",
    "            \n",
    "        ##  Initialise constant variables\n",
    "        self.decay_factor = decay_factor\n",
    "        self.patience     = patience\n",
    "        self.monitor      = monitor\n",
    "        self.mode         = mode\n",
    "        self.variable     = variable\n",
    "        self.logger       = logger\n",
    "        self.log_lvl      = log_lvl\n",
    "        \n",
    "        \n",
    "    def on_epoch_end(self, epoch_idx:int, logs:dict) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        ##  Get latest value\n",
    "        monitor_val = logs[self.monitor]\n",
    "        \n",
    "        ##  Update run variables\n",
    "        if np.isnan(self.best_val) or (self.mode == 'min' and  monitor_val < self.best_val) or (self.mode == 'max' and  monitor_val > self.best_val) :\n",
    "            self.best_val = monitor_val\n",
    "            self.num_itr  = 0\n",
    "        else :\n",
    "            self.num_itr += 1\n",
    "            \n",
    "        ##  Update learning rate\n",
    "        if self.num_itr == self.patience :\n",
    "            self.update()\n",
    "            self.reset_run_variables()\n",
    "        \n",
    "        \n",
    "    def on_train_begin(self, logs:dict) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        ##  If no variable provided then fall back to model.optimizer.learning_rate\n",
    "        if not self.variable :\n",
    "            self.variable = self.model.optimizer.learning_rate\n",
    "            if self.logger :\n",
    "                self.logger.log(self.log_lvl, f\"Setting variable to {self.variable.name}\")\n",
    "            \n",
    "        ##  If no metric provided then fall back to self.model.metric_names[0]\n",
    "        if not self.monitor :\n",
    "            self.monitor = self.model.metric_names[0]\n",
    "            if self.logger :\n",
    "                self.logger.log(self.log_lvl, f\"Setting monitor to {self.monitor}\")\n",
    "                \n",
    "        ##  Initialise run variables\n",
    "        self.reset_run_variables()\n",
    "        \n",
    "    \n",
    "    def reset_run_variables(self) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.best_val = np.nan\n",
    "        self.num_itr  = 0\n",
    "                \n",
    "        \n",
    "    def update(self) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        current_value = self.variable.value()\n",
    "        new_value     = self.decay_factor * current_value\n",
    "        if logger :\n",
    "            logger.log(self.log_lvl, f\"Updating variable {self.variable.name} from {current_value.numpy()} to {new_value.numpy()}\")\n",
    "        self.variable.assign(new_value)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "042ea7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "===   Created global_config   ===\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "##===================##\n",
    "##   Global config   ##\n",
    "##===================##\n",
    "\n",
    "##  Create dictionary of config values\n",
    "##  -  config values to be set here and never changed!\n",
    "##  -  use nested dictionary as a proxy for namespacing\n",
    "global_config = {\n",
    "    \"global\" : {\n",
    "        \"base_seed\"         : -1,\n",
    "        \"working_directory\" : \"unsupervised_learning_addition_model_generator_[tag]_[date]\",\n",
    "        \"tag\"               : \"baseline\",\n",
    "        \"log_lvl_iostream\"  : logging.INFO,\n",
    "        \"log_lvl_fstream\"   : logging.DEBUG,\n",
    "    },\n",
    "    \"data\" : {\n",
    "        \"train_data\" : {\n",
    "            \"int_lengths\"      : [1, 2, 3],\n",
    "            \"num_ints\"         : [1, 2, 4],\n",
    "            \"batch_size\"       : 32,\n",
    "            \"num_batchs\"       : 4000,\n",
    "            \"gen_base_seed\"    : 100,\n",
    "            \"gen_reproducible\" : False, \n",
    "        },\n",
    "        \"val_data\" : {\n",
    "            \"int_lengths\"      : [1, 2, 3],\n",
    "            \"num_ints\"         : [3],\n",
    "            \"batch_size\"       : 32,\n",
    "            \"num_batchs\"       : 500,\n",
    "            \"gen_base_seed\"    : 101,\n",
    "            \"gen_reproducible\" : True,\n",
    "        },\n",
    "        \"test_data\" : {\n",
    "            \"int_lengths\"      : [1, 2, 3],\n",
    "            \"num_ints\"         : [3],\n",
    "            \"batch_size\"       : 32,\n",
    "            \"num_batchs\"       : 1000,\n",
    "            \"gen_base_seed\"    : 102,\n",
    "            \"gen_reproducible\" : True,\n",
    "        },\n",
    "        \"characters\"              : ['M', 'B', 'E', 'N', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-'],\n",
    "        \"mask_char\"               : 'M',\n",
    "        \"seq_start_char\"          : 'B',\n",
    "        \"seq_end_char\"            : 'E',\n",
    "        \"negative_char\"           : 'N',\n",
    "        \"dtype\"                   : \"int32\",\n",
    "    },\n",
    "    \"model\" : {\n",
    "        \"load_pretrained_model\" : \"\",\n",
    "        \"name\"                  : \"mathsformer_LLM\",\n",
    "        \"dtype\"                 : \"float32\",\n",
    "        \"dropout\"               : 0.1,\n",
    "        \"learning_rate\"         : 1e-2,\n",
    "        \"positional_encoding\" : {\n",
    "            \"num_freqs\"         : 16,\n",
    "            \"min_period\"        : 4,\n",
    "            \"max_period\"        : 400,\n",
    "        },\n",
    "        \"ndim_embedding\"        : 32,\n",
    "        \"comb_type\"             : 'average',\n",
    "        \"pre_encoder\"           : {\n",
    "            \"num_layers\"        : -1,\n",
    "            \"ndim\"              : 128,\n",
    "            \"skip_connect\"      : True,\n",
    "        },\n",
    "        \"pre_decoder\" : {\n",
    "            \"num_layers\"        : -1,\n",
    "            \"ndim\"              : 128,\n",
    "            \"skip_connect\"      : True,\n",
    "        },\n",
    "        \"encoder\" : {\n",
    "            \"num_blocks\"        : 4,\n",
    "            \"num_heads\"         : 8,\n",
    "            \"ndim\"              : 32,\n",
    "            \"ndim_att_hidden\"   : 32,\n",
    "            \"ndim_ff_hidden\"    : 128,\n",
    "        },\n",
    "        \"decoder\" : {\n",
    "            \"num_blocks\"        : 4,\n",
    "            \"num_heads\"         : 8,\n",
    "            \"ndim\"              : 32,\n",
    "            \"ndim_att_hidden\"   : 32,\n",
    "            \"ndim_ff_hidden\"    : 128,\n",
    "        },\n",
    "        \"post_decoder\" : {\n",
    "            \"num_layers\"        : 3,\n",
    "            \"ndim\"              : 256,\n",
    "        },\n",
    "    },\n",
    "    \"training\" : {\n",
    "        \"train\"          : True,\n",
    "        \"max_epochs\"     : 100000,\n",
    "        \"log_after_epoch\" : {\n",
    "            \"do\"          : True,\n",
    "            \"log_lvl\"     : CustomLogLevel.DEBUG_LOW,\n",
    "        },\n",
    "        \"early_stopping\" : {\n",
    "            \"do\"                   : True,\n",
    "            \"patience\"             : 7,\n",
    "            \"monitor\"              : \"val_masked_accuracy\",\n",
    "            \"mode\"                 : \"max\",\n",
    "            \"restore_best_weights\" : True,\n",
    "        },\n",
    "        \"model_checkpoint\" : {\n",
    "            \"do\"       : True,\n",
    "            \"filename\" : \"model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.h5\",\n",
    "        },\n",
    "        \"layer_weights_record\" : {\n",
    "            \"do\"               : True,\n",
    "            \"batch_frequency\"  : 250,\n",
    "            \"recursive\"        : True,\n",
    "        },\n",
    "        \"adaptive_learning_rate\" : {\n",
    "            \"do\"                 : True,\n",
    "            \"decay_factor\"       : 0.3,\n",
    "            \"monitor\"            : \"val_masked_accuracy\",\n",
    "            \"mode\"               : \"max\",\n",
    "            \"patience\"           : 1,\n",
    "            \"log_lvl\"            : CustomLogLevel.DEBUG_LOW,\n",
    "        },\n",
    "    },\n",
    "    \"evaluate\" : {\n",
    "        \"num_print\" : 20,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "##  Report success\n",
    "print(fancy_message(f\"Created global_config\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f0be50",
   "metadata": {},
   "source": [
    "###  Validate config\n",
    "\n",
    "Look for some obvious confguration errors. WARNING: This is not an exhaustive search and can't be replied upon to catch all misconfigurations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a0dad43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "===   Config successfully validated   ===\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "##===============================##\n",
    "##   Global config - continued   ##\n",
    "##===============================##\n",
    "\n",
    "def validate_config(config) :\n",
    "    \"\"\"Raise exceptions in the case of program misconfigurations\"\"\"\n",
    "    mask_char      = global_config[\"data\"][\"mask_char\"]\n",
    "    seq_start_char = global_config[\"data\"][\"seq_start_char\"]\n",
    "    seq_end_char   = global_config[\"data\"][\"seq_end_char\"]\n",
    "    negative_char  = global_config[\"data\"][\"negative_char\"]\n",
    "    char_tokens    = global_config[\"data\"][\"characters\"]\n",
    "    \n",
    "    ##  Check that only single character tokens are provided\n",
    "    for char_token in char_tokens :\n",
    "        if len(char_token) == 1 : continue\n",
    "        raise ValueError(f\"All character tokens must be single characters but '{char_tokens}' found\")\n",
    "        \n",
    "    ##  Check mask character is provided\n",
    "    if len(mask_char) != 1 :\n",
    "        raise ValueError(f\"Mask character must be a single character but '{mask_char}' provided\")\n",
    "        \n",
    "    ##  Check mask character in character list\n",
    "    if mask_char not in char_tokens :\n",
    "        raise ValueError(f\"Mask character '{mask_char}' not found in character list: {char_tokens}\")\n",
    "    \n",
    "    ##  Check that mask character is first in char_tokens list (ensures it's assigned a token of 0)\n",
    "    if char_tokens[0] != mask_char :\n",
    "        raise ValueError(f\"Mask character '{mask_char}' must be the first in the char_tokens list provided, \"\n",
    "                        +f\"instead found list: {char_tokens}\")\n",
    "        \n",
    "    ##  Check seq_start_char character is provided\n",
    "    if len(seq_start_char) != 1 :\n",
    "        raise ValueError(f\"Sequence start character must be a single character but '{seq_start_char}' provided\")\n",
    "        \n",
    "    ##  Check seq_start_char character in character list\n",
    "    if seq_start_char not in char_tokens :\n",
    "        raise ValueError(f\"Sequence start character '{seq_start_char}' not found in character list: {char_tokens}\")\n",
    "        \n",
    "    ##  Check seq_end_char character is provided\n",
    "    if len(seq_end_char) != 1 :\n",
    "        raise ValueError(f\"Sequence end character must be a single character but '{seq_end_char}' provided\")\n",
    "        \n",
    "    ##  Check seq_start_char character in character list\n",
    "    if seq_end_char not in char_tokens :\n",
    "        raise ValueError(f\"Sequence end character '{seq_end_char}' not found in character list: {char_tokens}\")\n",
    "        \n",
    "    ##  Check negative_char character is provided\n",
    "    if len(negative_char) != 1 :\n",
    "        raise ValueError(f\"Negative symbol character must be a single character but '{negative_char}' provided\")\n",
    "        \n",
    "    ##  Check negative_char character in character list\n",
    "    if negative_char not in char_tokens :\n",
    "        raise ValueError(f\"Negative symbol character '{negative_char}' not found in character list: {char_tokens}\")\n",
    "        \n",
    "    ##  If here then config validated correctly\n",
    "    print(fancy_message(\"Config successfully validated\"))\n",
    "    \n",
    "validate_config(global_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af05439",
   "metadata": {},
   "source": [
    "##  2. Set up environment\n",
    "\n",
    "- Create working directory\n",
    "- Create logger\n",
    "- Log package versions for reproducibility\n",
    "- Log config values for reproducibility\n",
    "- Set random seeds for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f7cc532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================================================\n",
      "===   Working directory created at unsupervised_learning_addition_model_generator_baseline_2023_04_14_v5   ===\n",
      "==============================================================================================================\n",
      "   INFO initialise_logging: Begin logging on 2023-04-14 at 16:38:54\n",
      "   INFO initialise_program: Program description: unsupervised_learning_model notebook\n",
      "   INFO initialise_program: Working directory: unsupervised_learning_addition_model_generator_baseline_2023_04_14_v5\n",
      "   INFO log_versions: ------------------------------------------------------+----------------------------------------------------------------------------------\n",
      "   INFO log_versions:                                              PACKAGE  |  VERSION\n",
      "   INFO log_versions: ------------------------------------------------------+----------------------------------------------------------------------------------\n",
      "   INFO log_versions:                                               Python  |  3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]\n",
      "   INFO log_versions:                                              IPython  |  8.7.0\n",
      "   INFO log_versions:                                 IPython.core.release  |  8.7.0\n",
      "   INFO log_versions:                                                  PIL  |  9.3.0\n",
      "   INFO log_versions:                                            PIL.Image  |  9.3.0\n",
      "   INFO log_versions:                                       PIL._deprecate  |  9.3.0\n",
      "   INFO log_versions:                                         PIL._version  |  9.3.0\n",
      "   INFO log_versions:                                                 _csv  |  1.0\n",
      "   INFO log_versions:                                              _ctypes  |  1.1.0\n",
      "   INFO log_versions:                                              _curses  |  b'2.2'\n",
      "   INFO log_versions:                                              decimal  |  1.70\n",
      "   INFO log_versions:                               _pydev_bundle.fsnotify  |  0.1.5\n",
      "   INFO log_versions:                 _pydevd_frame_eval.vendored.bytecode  |  0.13.0.dev\n",
      "   INFO log_versions:                                              appnope  |  0.1.3\n",
      "   INFO log_versions:                                             argparse  |  1.1\n",
      "   INFO log_versions:                                           astunparse  |  1.6.3\n",
      "   INFO log_versions:                                             backcall  |  0.2.0\n",
      "   INFO log_versions:                                              certifi  |  2022.12.07\n",
      "   INFO log_versions:                                                 cffi  |  1.15.1\n",
      "   INFO log_versions:                                   charset_normalizer  |  2.1.1\n",
      "   INFO log_versions:                           charset_normalizer.version  |  2.1.1\n",
      "   INFO log_versions:                                                 comm  |  0.1.2\n",
      "   INFO log_versions:                                                  csv  |  1.0\n",
      "   INFO log_versions:                                               ctypes  |  1.1.0\n",
      "   INFO log_versions:                                      ctypes.macholib  |  1.0\n",
      "   INFO log_versions:                                               cycler  |  0.10.0\n",
      "   INFO log_versions:                                             dateutil  |  2.8.2\n",
      "   INFO log_versions:                                              debugpy  |  1.6.4\n",
      "   INFO log_versions:                                   debugpy.public_api  |  1.6.4\n",
      "   INFO log_versions:                                              decimal  |  1.70\n",
      "   INFO log_versions:                                            decorator  |  5.1.1\n",
      "   INFO log_versions:                                           defusedxml  |  0.7.1\n",
      "   INFO log_versions:                                            distutils  |  3.10.8\n",
      "   INFO log_versions:                                          entrypoints  |  0.4\n",
      "   INFO log_versions:                                            executing  |  1.2.0\n",
      "   INFO log_versions:                                    executing.version  |  1.2.0\n",
      "   INFO log_versions:                                          flatbuffers  |  22.12.06\n",
      "   INFO log_versions:                                 flatbuffers._version  |  22.12.06\n",
      "   INFO log_versions:                                      google.protobuf  |  3.19.4\n",
      "   INFO log_versions:                                                 h5py  |  3.6.0\n",
      "   INFO log_versions:                                          http.server  |  0.6\n",
      "   INFO log_versions:                                                 idna  |  3.4\n",
      "   INFO log_versions:                                        idna.idnadata  |  15.0.0\n",
      "   INFO log_versions:                                    idna.package_data  |  3.4\n",
      "   INFO log_versions:                                            ipaddress  |  1.0\n",
      "   INFO log_versions:                                            ipykernel  |  6.19.4\n",
      "   INFO log_versions:                                   ipykernel._version  |  6.19.4\n",
      "   INFO log_versions:                                                 jedi  |  0.18.2\n",
      "   INFO log_versions:                                                 json  |  2.0.9\n",
      "   INFO log_versions:                                       jupyter_client  |  7.4.8\n",
      "   INFO log_versions:                              jupyter_client._version  |  7.4.8\n",
      "   INFO log_versions:                                         jupyter_core  |  5.1.0\n",
      "   INFO log_versions:                                 jupyter_core.version  |  5.1.0\n",
      "   INFO log_versions:                                                keras  |  2.11.0\n",
      "   INFO log_versions:                                  keras.api._v2.keras  |  2.11.0\n",
      "   INFO log_versions:                                      keras.api.keras  |  2.11.0\n",
      "   INFO log_versions:                                           kiwisolver  |  1.4.4\n",
      "   INFO log_versions:                                     kiwisolver._cext  |  1.4.4\n",
      "   INFO log_versions:                                              logging  |  0.5.1.2\n",
      "   INFO log_versions:                                           matplotlib  |  3.6.2\n",
      "   INFO log_versions:                                  matplotlib._version  |  3.6.2\n",
      "   INFO log_versions:                                                numpy  |  1.23.2\n",
      "   INFO log_versions:                                           numpy.core  |  1.23.2\n",
      "   INFO log_versions:                         numpy.core._multiarray_umath  |  3.1\n",
      "   INFO log_versions:                                            numpy.lib  |  1.23.2\n",
      "   INFO log_versions:                           numpy.linalg._umath_linalg  |  0.1.5\n",
      "   INFO log_versions:                                        numpy.version  |  1.23.2\n",
      "   INFO log_versions:                                           opt_einsum  |  v3.3.0\n",
      "   INFO log_versions:                                            packaging  |  22.0\n",
      "   INFO log_versions:                                  packaging.__about__  |  22.0\n",
      "   INFO log_versions:                                                parso  |  0.8.3\n",
      "   INFO log_versions:                                              pexpect  |  4.8.0\n",
      "   INFO log_versions:                                          pickleshare  |  0.7.5\n",
      "   INFO log_versions:                        pkg_resources._vendor.appdirs  |  1.4.3\n",
      "   INFO log_versions:                 pkg_resources._vendor.more_itertools  |  8.12.0\n",
      "   INFO log_versions:                      pkg_resources._vendor.packaging  |  21.3\n",
      "   INFO log_versions:            pkg_resources._vendor.packaging.__about__  |  21.3\n",
      "   INFO log_versions:                      pkg_resources._vendor.pyparsing  |  3.0.9\n",
      "   INFO log_versions:                        pkg_resources._vendor.appdirs  |  1.4.3\n",
      "   INFO log_versions:                 pkg_resources._vendor.more_itertools  |  8.12.0\n",
      "   INFO log_versions:                      pkg_resources._vendor.packaging  |  21.3\n",
      "   INFO log_versions:                      pkg_resources._vendor.pyparsing  |  3.0.9\n",
      "   INFO log_versions:                                             platform  |  1.0.8\n",
      "   INFO log_versions:                                         platformdirs  |  2.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO log_versions:                                 platformdirs.version  |  2.6.0\n",
      "   INFO log_versions:                                       prompt_toolkit  |  3.0.36\n",
      "   INFO log_versions:                                               psutil  |  5.9.4\n",
      "   INFO log_versions:                                           ptyprocess  |  0.7.0\n",
      "   INFO log_versions:                                            pure_eval  |  0.2.2\n",
      "   INFO log_versions:                                    pure_eval.version  |  0.2.2\n",
      "   INFO log_versions:                                               pydevd  |  2.9.1\n",
      "   INFO log_versions:                                             pygments  |  2.13.0\n",
      "   INFO log_versions:                                            pyparsing  |  3.0.9\n",
      "   INFO log_versions:                                                   re  |  2.2.1\n",
      "   INFO log_versions:                                             requests  |  2.28.1\n",
      "   INFO log_versions:                                 requests.__version__  |  2.28.1\n",
      "   INFO log_versions:                                                 idna  |  3.4\n",
      "   INFO log_versions:                                        idna.idnadata  |  15.0.0\n",
      "   INFO log_versions:                                    idna.package_data  |  3.4\n",
      "   INFO log_versions:                                              urllib3  |  1.26.13\n",
      "   INFO log_versions:                                     urllib3._version  |  1.26.13\n",
      "   INFO log_versions:                                   urllib3.connection  |  1.26.13\n",
      "   INFO log_versions:                                 urllib3.packages.six  |  1.16.0\n",
      "   INFO log_versions:                      urllib3.util.ssl_match_hostname  |  3.5.0.1\n",
      "   INFO log_versions:                                       requests.utils  |  2.28.1\n",
      "   INFO log_versions:                                           setuptools  |  65.6.3\n",
      "   INFO log_versions:                                            distutils  |  3.10.8\n",
      "   INFO log_versions:                    setuptools._vendor.more_itertools  |  8.8.0\n",
      "   INFO log_versions:                       setuptools._vendor.ordered_set  |  3.1\n",
      "   INFO log_versions:                         setuptools._vendor.packaging  |  21.3\n",
      "   INFO log_versions:               setuptools._vendor.packaging.__about__  |  21.3\n",
      "   INFO log_versions:                         setuptools._vendor.pyparsing  |  3.0.9\n",
      "   INFO log_versions:                    setuptools._vendor.more_itertools  |  8.8.0\n",
      "   INFO log_versions:                       setuptools._vendor.ordered_set  |  3.1\n",
      "   INFO log_versions:                         setuptools._vendor.packaging  |  21.3\n",
      "   INFO log_versions:                         setuptools._vendor.pyparsing  |  3.0.9\n",
      "   INFO log_versions:                                   setuptools.version  |  65.6.3\n",
      "   INFO log_versions:                                                  six  |  1.16.0\n",
      "   INFO log_versions:                                         socketserver  |  0.4\n",
      "   INFO log_versions:                                           stack_data  |  0.6.2\n",
      "   INFO log_versions:                                   stack_data.version  |  0.6.2\n",
      "   INFO log_versions:                                          tensorboard  |  2.11.0\n",
      "   INFO log_versions:                   tensorboard.compat.tensorflow_stub  |  stub\n",
      "   INFO log_versions: tensorboard.compat.tensorflow_stub.pywrap_tensorflow  |  0\n",
      "   INFO log_versions:                                           tensorflow  |  2.11.0\n",
      "   INFO log_versions:                         tensorflow._api.v2.compat.v1  |  2.11.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v1.compat.v1  |  2.11.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v1.compat.v2  |  2.11.0\n",
      "   INFO log_versions:                         tensorflow._api.v2.compat.v2  |  2.11.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v2.compat.v1  |  2.11.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v2.compat.v2  |  2.11.0\n",
      "   INFO log_versions:                                 tensorflow.compat.v1  |  2.11.0\n",
      "   INFO log_versions:                       tensorflow.compat.v1.compat.v1  |  2.11.0\n",
      "   INFO log_versions:                       tensorflow.compat.v1.compat.v2  |  2.11.0\n",
      "   INFO log_versions:                                 tensorflow.compat.v2  |  2.11.0\n",
      "   INFO log_versions:                       tensorflow.compat.v2.compat.v1  |  2.11.0\n",
      "   INFO log_versions:                       tensorflow.compat.v2.compat.v2  |  2.11.0\n",
      "   INFO log_versions:                                     tensorflow.keras  |  2.11.0\n",
      "   INFO log_versions:           tensorflow.python.client.pywrap_tf_session  |  2.11.0\n",
      "   INFO log_versions:                 tensorflow.python.framework.versions  |  2.11.0\n",
      "   INFO log_versions:                              tensorflow.python.keras  |  2.6.0\n",
      "   INFO log_versions:                                            traitlets  |  5.8.0\n",
      "   INFO log_versions:                                   traitlets._version  |  5.8.0\n",
      "   INFO log_versions:                                       urllib.request  |  3.10\n",
      "   INFO log_versions:                                              urllib3  |  1.26.13\n",
      "   INFO log_versions:                                     urllib3._version  |  1.26.13\n",
      "   INFO log_versions:                                   urllib3.connection  |  1.26.13\n",
      "   INFO log_versions:                                 urllib3.packages.six  |  1.16.0\n",
      "   INFO log_versions:                      urllib3.util.ssl_match_hostname  |  3.5.0.1\n",
      "   INFO log_versions:                                              wcwidth  |  0.2.5\n",
      "   INFO log_versions:                                                wrapt  |  1.14.1\n",
      "   INFO log_versions:                                        xmlrpc.client  |  3.10\n",
      "   INFO log_versions:                                                 zlib  |  1.0\n",
      "   INFO log_versions:                                                  zmq  |  24.0.1\n",
      "   INFO log_versions:                                            zmq.sugar  |  24.0.1\n",
      "   INFO log_versions:                                    zmq.sugar.version  |  24.0.1\n",
      "   INFO log_versions: ------------------------------------------------------+----------------------------------------------------------------------------------\n",
      "   INFO initialise_program: Registered global config value base_seed: -1\n",
      "   INFO initialise_program: Registered global config value working_directory: unsupervised_learning_addition_model_generator_[tag]_[date]\n",
      "   INFO initialise_program: Registered global config value tag: baseline\n",
      "   INFO initialise_program: Registered global config value log_lvl_iostream: 20\n",
      "   INFO initialise_program: Registered global config value log_lvl_fstream: 10\n",
      "   INFO initialise_program: Python random seed set: 1681486734\n",
      "   INFO initialise_program: Numpy random seed set: 1681486735\n",
      "   INFO initialise_program: TensorFlow random seed set: 1681486736\n"
     ]
    }
   ],
   "source": [
    "##==============================##\n",
    "##   Create working directory   ##\n",
    "##==============================##\n",
    "\n",
    "##  Report success\n",
    "working_dir, logger, base_seed, np_seed, tf_seed = initialise_program(\n",
    "    \"unsupervised_learning_model notebook\", \n",
    "    working_dir       = global_config[\"global\"][\"working_directory\"], \n",
    "    global_config     = global_config[\"global\"],\n",
    "    base_seed         = global_config[\"global\"][\"base_seed\"],\n",
    "    log_lvl_iostream  = global_config[\"global\"][\"log_lvl_iostream\"],\n",
    "    log_lvl_fstream   = global_config[\"global\"][\"log_lvl_fstream\" ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960860d",
   "metadata": {},
   "source": [
    "##  3. Create training data\n",
    "\n",
    "###  Generate string-string pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca186fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO summary: TokenTransform of dtype int32 with 16 characters: ['M', 'B', 'E', 'N', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-']\n",
      "   INFO summary: Special characters are seq_start_char (B), seq_end_char (E), mask_char (M)\n",
      "   INFO summary: Tokeniser dictionary is {'M': 0, 'B': 1, 'E': 2, 'N': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, '+': 14, '-': 15}\n",
      "   INFO summary: Detokeniser dictionary is {0: 'M', 1: 'B', 2: 'E', 3: 'N', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: '+', 15: '-'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "token_transform = TokenTransform.from_dictionary(global_config[\"data\"])\n",
    "token_transform.summary(print_fn=logger.info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa347b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataGenerator(tf.keras.utils.Sequence) :\n",
    "    \n",
    "    def __init__(self, token_transform:TokenTransform, int_lengths:list, num_ints:list, batch_size:int, num_batches:int, \n",
    "                 base_seed:int=-1, reproducible:bool=False) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if base_seed < 0 :\n",
    "            base_seed = int(time.time())\n",
    "        \n",
    "        self.token_transform = token_transform\n",
    "        self.int_lengths     = int_lengths\n",
    "        self.num_ints        = num_ints\n",
    "        self.batch_size      = batch_size\n",
    "        self.num_batches     = num_batches\n",
    "        self.base_seed       = base_seed\n",
    "        self.reproducible    = reproducible\n",
    "        self.reset_rng()\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index:int) :\n",
    "        \"\"\"\n",
    "        Returns ([X, Y_in], Y_out)\n",
    "        \"\"\"\n",
    "        if self.reproducible :\n",
    "            self.reset_rng(self.base_seed + index)\n",
    "        x = self.rng.choice(self.num_ints, size=(self.batch_size,))\n",
    "        y = [self._generate_string(xp, self.int_lengths) for xp in x]\n",
    "        X, Y = [yp[0] for yp in y], [yp[1] for yp in y]\n",
    "        X = self.token_transform.strings_to_tensor(X)\n",
    "        Y = self.token_transform.strings_to_tensor(Y)\n",
    "        return [X, Y[:,:-1]], Y[:,1:]\n",
    "    \n",
    "    \n",
    "    def __len__(self) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self.num_batches\n",
    "    \n",
    "    \n",
    "    def __str__(self) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return f\"Generator of {self.num_ints} integers of length {self.int_lengths} in {self.num_batches} batches of size {self.batch_size} (base_seed={self.base_seed}, reproducible={self.reproducible})\"\n",
    "    \n",
    "    \n",
    "    def _generate_int_string(self, length) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        sign        = self.rng.choice([\"\", \"N\"])\n",
    "        lead_char   = str(self.rng.randint(1, 10))\n",
    "        other_chars = \"\".join([str(self.rng.randint(0, 10)) for i in range(length-1)])\n",
    "        return sign + lead_char + other_chars\n",
    "    \n",
    "    \n",
    "    def _generate_int_strings(self, lengths) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return np.array([self._generate_int_string(l) for l in lengths])\n",
    "    \n",
    "    \n",
    "    def _generate_string(self, num, lengths) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        lengths = self.rng.choice(lengths, size=(num,))\n",
    "        ints    = self._generate_int_strings(lengths)\n",
    "        out_s, out_i = ints[0], int(ints[0].replace(\"N\",\"-\"))\n",
    "        for si in ints[1:] :\n",
    "            f = self.rng.uniform(0, 1)\n",
    "            i = int(si.replace(\"N\",\"-\"))\n",
    "            if f < 0.5 :\n",
    "                out_s += \"+\" + si\n",
    "                out_i += i\n",
    "            else :\n",
    "                out_s += \"-\" + si\n",
    "                out_i -= i\n",
    "        return out_s, str(out_i).replace(\"-\",\"N\")\n",
    "    \n",
    "    \n",
    "    def get_as_tensors(self, num_batches:int=-1) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        ##  If num batches not set then return all of them\n",
    "        if num_batches < 1 :\n",
    "            num_batches = len(self)\n",
    "        \n",
    "        ##  Containers to stores batches\n",
    "        X, Y_in, Y_out = [], [] ,[]\n",
    "\n",
    "        ##  Fill containers with batch results\n",
    "        for i in range(num_batches) :\n",
    "            [x, yi], yo = self[i]\n",
    "            X, Y_in, Y_out = X + [x], Y_in + [yi], Y_out + [yo]\n",
    "\n",
    "        ##  Find max widths of tensors, which currently have ragged shapes\n",
    "        len_x, len_yi, len_yo = max([xp.shape[1] for xp in X]), max([xp.shape[1] for xp in Y_in]), max([xp.shape[1] for xp in Y_out])\n",
    "\n",
    "        ##  Pad all tensors to the same width\n",
    "        for i in range(len(X)) :\n",
    "            X    [i] = tf.pad(X    [i], [[0, 0], (0, len_x -X    [i].shape[1])])\n",
    "            Y_in [i] = tf.pad(Y_in [i], [[0, 0], (0, len_yi-Y_in [i].shape[1])])\n",
    "            Y_out[i] = tf.pad(Y_out[i], [[0, 0], (0, len_yo-Y_out[i].shape[1])])\n",
    "\n",
    "        ##  Concatenate batch results into single tensor\n",
    "        X, Y_in, Y_out = tf.concat(X, axis=0), tf.concat(Y_in, axis=0), tf.concat(Y_out, axis=0)\n",
    "        \n",
    "        ##  Return\n",
    "        return X, Y_in, Y_out\n",
    "    \n",
    "    \n",
    "    def print_predictions_table(self, transformer, num_print:int, max_tokens:int=-1) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        X, Y_in, Y_out = self.get_as_tensors(num_batches=math.ceil(num_print/self.batch_size))\n",
    "\n",
    "        ##  Log table header\n",
    "        logger.info(\"-\"*80)\n",
    "        logger.info(\"INPUT\".rjust(32) + \"TRUE\".rjust(12) + \"PRED\".rjust(max([max_tokens,12])) + \"CORRECT\".rjust(12) + \"RESIDUAL\".rjust(12))\n",
    "        logger.info(\"-\"*80)\n",
    "\n",
    "        ##  Get model predictions and log alongside true labels \n",
    "        for x, x_str, true_y_str in zip(X[:num_print], \n",
    "                                        transformer.token_transform.detokenise_strings(X    [:num_print,:].numpy()),\n",
    "                                        transformer.token_transform.detokenise_strings(Y_out[:num_print  ].numpy())) :\n",
    "            pred_y_str = transformer.transform_from_data_tensor(x, max_tokens=max_tokens)\n",
    "            result     = \"  X  \" if pred_y_str == true_y_str else \"\"\n",
    "            try    : residual = str(int(pred_y_str.replace(\"N\",\"-\")) - int(true_y_str.replace(\"N\",\"-\")))\n",
    "            except : residual = \"N/A\"\n",
    "            logger.info(x_str.rjust(32) + true_y_str.rjust(12) + pred_y_str.rjust(max([max_tokens,12])) + result.rjust(12) + residual.rjust(10))\n",
    "            \n",
    "            \n",
    "    def reset_rng(self, seed:int=-1) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if seed < 0 :\n",
    "            seed = self.base_seed\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "        \n",
    "        \n",
    "    def summary(self, print_fn=print) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        print_fn(str(self))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d4d3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Training data generator created with the following config: Generator of [1, 2, 4] integers of length [1, 2, 3] in 4000 batches of size 32 (base_seed=100, reproducible=False)\n",
      "   INFO <module>: Output shapes for a test batch are ((32, 19), (32, 6)), (32, 6)\n",
      "   INFO <module>: Validation data generator created with the following config: Generator of [3] integers of length [1, 2, 3] in 500 batches of size 32 (base_seed=101, reproducible=True)\n",
      "   INFO <module>: Output shapes for a test batch are ((32, 15), (32, 6)), (32, 6)\n",
      "   INFO <module>: Test data generator created with the following config: Generator of [3] integers of length [1, 2, 3] in 1000 batches of size 32 (base_seed=102, reproducible=True)\n",
      "   INFO <module>: Output shapes for a test batch are ((32, 15), (32, 6)), (32, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_gen = RandomDataGenerator(token_transform, \n",
    "                                global_config[\"data\"][\"train_data\"][\"int_lengths\"],\n",
    "                                global_config[\"data\"][\"train_data\"][\"num_ints\"],\n",
    "                                global_config[\"data\"][\"train_data\"][\"batch_size\"],\n",
    "                                global_config[\"data\"][\"train_data\"][\"num_batchs\"],\n",
    "                                global_config[\"data\"][\"train_data\"][\"gen_base_seed\"],\n",
    "                                global_config[\"data\"][\"train_data\"][\"gen_reproducible\"],)\n",
    "\n",
    "logger.info(f\"Training data generator created with the following config: {train_gen}\")\n",
    "(X, Y_in), Y_out = train_gen[0]\n",
    "logger.info(f\"Output shapes for a test batch are ({X.shape}, {Y_in.shape}), {Y_out.shape}\")\n",
    "\n",
    "val_gen   = RandomDataGenerator(token_transform, \n",
    "                                global_config[\"data\"][\"val_data\"][\"int_lengths\"],\n",
    "                                global_config[\"data\"][\"val_data\"][\"num_ints\"],\n",
    "                                global_config[\"data\"][\"val_data\"][\"batch_size\"],\n",
    "                                global_config[\"data\"][\"val_data\"][\"num_batchs\"],\n",
    "                                global_config[\"data\"][\"val_data\"][\"gen_base_seed\"],\n",
    "                                global_config[\"data\"][\"val_data\"][\"gen_reproducible\"],)\n",
    "\n",
    "logger.info(f\"Validation data generator created with the following config: {val_gen}\")\n",
    "(X, Y_in), Y_out = val_gen[0]\n",
    "logger.info(f\"Output shapes for a test batch are ({X.shape}, {Y_in.shape}), {Y_out.shape}\")\n",
    "\n",
    "test_gen  = RandomDataGenerator(token_transform, \n",
    "                                global_config[\"data\"][\"test_data\"][\"int_lengths\"],\n",
    "                                global_config[\"data\"][\"test_data\"][\"num_ints\"],\n",
    "                                global_config[\"data\"][\"test_data\"][\"batch_size\"],\n",
    "                                global_config[\"data\"][\"test_data\"][\"num_batchs\"],\n",
    "                                global_config[\"data\"][\"test_data\"][\"gen_base_seed\"],\n",
    "                                global_config[\"data\"][\"test_data\"][\"gen_reproducible\"],)\n",
    "\n",
    "logger.info(f\"Test data generator created with the following config: {test_gen}\")\n",
    "(X, Y_in), Y_out = test_gen[0]\n",
    "logger.info(f\"Output shapes for a test batch are ({X.shape}, {Y_in.shape}), {Y_out.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39db1bb",
   "metadata": {},
   "source": [
    "##  4.  Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb6a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Model created with summary:\n",
      "   INFO <module>: Model: \"mathsformer_LLM\"\n",
      "   INFO <module>: __________________________________________________________________________________________________\n",
      "   INFO <module>:  Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "   INFO <module>: ==================================================================================================\n",
      "   INFO <module>:  mathsformer_LLM_encoder_input_  [(None, None)]      0           []                               \n",
      "   INFO <module>:  layer (InputLayer)                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_enumer  (1, None)           0           ['mathsformer_LLM_encoder_input_l\n",
      "   INFO <module>:  ate (Enumerate)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_embedd  (None, None, 32)    512         ['mathsformer_LLM_encoder_input_l\n",
      "   INFO <module>:  ing (Embedding)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_positi  (1, None, 32)       0           ['mathsformer_LLM_encoder_enumera\n",
      "   INFO <module>:  on_encoding (PositionalEncodin                                  te[0][0]']                       \n",
      "   INFO <module>:  g)                                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_emb_an  (None, None, 32)    2           ['mathsformer_LLM_encoder_embeddi\n",
      "   INFO <module>:  d_pos (LearnableMixture)                                        ng[0][0]',                       \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_positio\n",
      "   INFO <module>:                                                                  n_encoding[0][0]']               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_input_  [(None, None)]      0           []                               \n",
      "   INFO <module>:  layer (InputLayer)                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_block_  (None, None, 32)    42240       ['mathsformer_LLM_encoder_emb_and\n",
      "   INFO <module>:  1 (EncoderBlock)                                                _pos[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_enumer  (1, None)           0           ['mathsformer_LLM_decoder_input_l\n",
      "   INFO <module>:  ate (Enumerate)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_block_  (None, None, 32)    42240       ['mathsformer_LLM_encoder_block_1\n",
      "   INFO <module>:  2 (EncoderBlock)                                                [0][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_embedd  (None, None, 32)    512         ['mathsformer_LLM_decoder_input_l\n",
      "   INFO <module>:  ing (Embedding)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_positi  (1, None, 32)       0           ['mathsformer_LLM_decoder_enumera\n",
      "   INFO <module>:  on_encoding (PositionalEncodin                                  te[0][0]']                       \n",
      "   INFO <module>:  g)                                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_block_  (None, None, 32)    42240       ['mathsformer_LLM_encoder_block_2\n",
      "   INFO <module>:  3 (EncoderBlock)                                                [0][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_emb_an  (None, None, 32)    2           ['mathsformer_LLM_decoder_embeddi\n",
      "   INFO <module>:  d_pos (LearnableMixture)                                        ng[0][0]',                       \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_positio\n",
      "   INFO <module>:                                                                  n_encoding[0][0]']               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_block_  (None, None, 32)    42240       ['mathsformer_LLM_encoder_block_3\n",
      "   INFO <module>:  4 (EncoderBlock)                                                [0][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_block_  (None, None, 32)    75872       ['mathsformer_LLM_decoder_emb_and\n",
      "   INFO <module>:  1 (DecoderBlock)                                                _pos[0][0]',                     \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_4\n",
      "   INFO <module>:                                                                  [0][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_block_  (None, None, 32)    75872       ['mathsformer_LLM_decoder_block_1\n",
      "   INFO <module>:  2 (DecoderBlock)                                                [0][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_4\n",
      "   INFO <module>:                                                                  [0][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_block_  (None, None, 32)    75872       ['mathsformer_LLM_decoder_block_2\n",
      "   INFO <module>:  3 (DecoderBlock)                                                [0][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_4\n",
      "   INFO <module>:                                                                  [0][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_block_  (None, None, 32)    75872       ['mathsformer_LLM_decoder_block_3\n",
      "   INFO <module>:  4 (DecoderBlock)                                                [0][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_4\n",
      "   INFO <module>:                                                                  [0][0]']                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_feedfwd_block_  (None, None, 16)    145680      ['mathsformer_LLM_decoder_block_4\n",
      "   INFO <module>:  post_attention (FeedForwardBlo                                  [0][0]']                         \n",
      "   INFO <module>:  ck)                                                                                              \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>: ==================================================================================================\n",
      "   INFO <module>: Total params: 619,156\n",
      "   INFO <module>: Trainable params: 619,156\n",
      "   INFO <module>: Non-trainable params: 0\n",
      "   INFO <module>: __________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##==================================================##\n",
    "##   Create supervised learning model - continued   ##\n",
    "##==================================================##\n",
    "\n",
    "model = create_text_to_text_model(\n",
    "                     vocab_length             = token_transform.vocab_length, \n",
    "                     name                     = global_config[\"model\"][\"name\"],\n",
    "                     do_compile               = True,\n",
    "                     dtype_in                 = token_transform.dtype,\n",
    "                     dtype                    = global_config[\"model\"][\"dtype\"],\n",
    "                     dropout                  = global_config[\"model\"][\"dropout\"],\n",
    "                     optimizer_args           = {\"learning_rate\": global_config[\"model\"][\"learning_rate\"]},\n",
    "                     pos_enc_num_freqs        = global_config[\"model\"][\"positional_encoding\"][\"num_freqs\"],\n",
    "                     pos_enc_min_period       = global_config[\"model\"][\"positional_encoding\"][\"min_period\"],\n",
    "                     pos_enc_max_period       = global_config[\"model\"][\"positional_encoding\"][\"max_period\"],\n",
    "                     ndim_embedding           = global_config[\"model\"][\"ndim_embedding\"],\n",
    "                     comb_type                = global_config[\"model\"][\"comb_type\"],\n",
    "                     num_pre_layers_encoder   = global_config[\"model\"][\"pre_encoder\"][\"num_layers\"],\n",
    "                     ndim_pre_layers_encoder  = global_config[\"model\"][\"pre_encoder\"][\"ndim\"],\n",
    "                     skip_connect_pre_encoder = global_config[\"model\"][\"pre_encoder\"][\"skip_connect\"],\n",
    "                     num_pre_layers_decoder   = global_config[\"model\"][\"pre_decoder\"][\"num_layers\"],\n",
    "                     ndim_pre_layers_decoder  = global_config[\"model\"][\"pre_decoder\"][\"ndim\"],\n",
    "                     skip_connect_pre_decoder = global_config[\"model\"][\"pre_decoder\"][\"skip_connect\"],\n",
    "                     num_encoder_blocks       = global_config[\"model\"][\"encoder\"][\"num_blocks\"],\n",
    "                     ndim_encoder             = global_config[\"model\"][\"encoder\"][\"ndim\"],\n",
    "                     skip_connect_encoder     = True,\n",
    "                     num_heads_encoder        = global_config[\"model\"][\"encoder\"][\"num_heads\"],\n",
    "                     ndim_att_hidden_encoder  = global_config[\"model\"][\"encoder\"][\"ndim_att_hidden\"],\n",
    "                     ndim_ff_hidden_encoder   = global_config[\"model\"][\"encoder\"][\"ndim_ff_hidden\"],\n",
    "                     num_decoder_blocks       = global_config[\"model\"][\"decoder\"][\"num_blocks\"],\n",
    "                     ndim_decoder             = global_config[\"model\"][\"decoder\"][\"ndim\"],\n",
    "                     skip_connect_decoder     = True,\n",
    "                     num_heads_decoder        = global_config[\"model\"][\"decoder\"][\"num_heads\"],\n",
    "                     ndim_att_hidden_decoder  = global_config[\"model\"][\"decoder\"][\"ndim_att_hidden\"],\n",
    "                     ndim_ff_hidden_decoder   = global_config[\"model\"][\"decoder\"][\"ndim_ff_hidden\"],\n",
    "                     num_post_layers_decoder  = global_config[\"model\"][\"post_decoder\"][\"num_layers\"],\n",
    "                     ndim_post_layers_decoder = global_config[\"model\"][\"post_decoder\"][\"ndim\"])\n",
    "\n",
    "\n",
    "##  Load model if requested\n",
    "load_model_fname = global_config.get(\"model\", {}).get(\"load_pretrained_model\", {})\n",
    "if load_model_fname :\n",
    "    logger.info(f\"Loading model from file: {load_model_fname}\")\n",
    "    custom_objects = create_custom_objects_dict(model=model)\n",
    "    custom_objects[\"masked_sparse_categorical_crossentropy\"] = masked_sparse_categorical_crossentropy\n",
    "    custom_objects[\"masked_accuracy\"] = masked_accuracy\n",
    "    tf.keras.models.load_model(load_model_fname, custom_objects=custom_objects)\n",
    "\n",
    "##  Create hack to catch model summary\n",
    "model_summary = []\n",
    "model.summary(print_fn = lambda s : model_summary.append(s))\n",
    "\n",
    "logger.info(\"Model created with summary:\")\n",
    "for s in model_summary : logger.info(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81d4b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##  Create transformer wrapper for model and token_transform\n",
    "transformer = Transformer_Text_to_Text(model, token_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f7a52",
   "metadata": {},
   "source": [
    "##  5.  Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aea411fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Registered training callback: LoggerCallback with loglvl=14\n",
      "   INFO <module>: Registered training callback: EarlyStopping with monitor=val_masked_accuracy, mode=max, patience=1, restore_best_weights=True\n",
      "   INFO <module>: Registeried training callback: AdaptiveLearningRate with decay_factor=0.3, patience=1, monitor=val_masked_accuracy, mode=max, log_lvl=14\n",
      "   INFO <module>: Registeried training callback: ModelCheckpoint with filepath=unsupervised_learning_addition_model_generator_baseline_2023_04_14_v5/model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.h5\n",
      "   INFO <module>: Registered training callback: LayerWeightsRecord with batch_frequency=250, recursive=True\n"
     ]
    }
   ],
   "source": [
    "##===================================##\n",
    "##   Create callbacks for training   ##\n",
    "##===================================##\n",
    "\n",
    "\n",
    "##  Create list of training callbacks\n",
    "callbacks = []\n",
    "\n",
    "\n",
    "##  Add logger callback\n",
    "logger_callback_config = global_config[\"training\"].get(\"log_after_epoch\", {})\n",
    "if logger_callback_config.get(\"do\", True) :\n",
    "    log_lvl = logger_callback_config.get(\"log_lvl\", logging.DEBUG)\n",
    "    callbacks.append(LoggerCallback(logger, loglvl=log_lvl))\n",
    "    logger.info(f\"Registered training callback: LoggerCallback with loglvl={log_lvl}\")\n",
    "\n",
    "\n",
    "##  Add callback for early stopping\n",
    "early_stopping_config = global_config[\"training\"].get(\"early_stopping\", {})\n",
    "if early_stopping_config.get(\"do\", False) :\n",
    "    monitor              = early_stopping_config.get(\"monitor\"                , \"val_loss\")\n",
    "    mode                 = early_stopping_config.get(\"mode\"                   , 'min')\n",
    "    restore_best_weights = early_stopping_config.get(\"restore_best_weights\"   , True      )\n",
    "    patience             = early_stopping_config.get(\"early_stopping_patience\", 1         )\n",
    "    callbacks.append(EarlyStopping(monitor              = monitor, \n",
    "                                   mode                 = mode,\n",
    "                                   patience             = patience, \n",
    "                                   restore_best_weights = restore_best_weights))\n",
    "    logger.info(f\"Registered training callback: EarlyStopping with monitor={monitor}, mode={mode}, patience={patience}, restore_best_weights={restore_best_weights}\")\n",
    "    \n",
    "    \n",
    "## Adaptive learning rate\n",
    "adaptive_learning_rate_config = global_config[\"training\"].get(\"adaptive_learning_rate\", {})\n",
    "if adaptive_learning_rate_config.get(\"do\", False) :\n",
    "    decay_factor = adaptive_learning_rate_config.get(\"decay_factor\", 0.5)\n",
    "    patience     = adaptive_learning_rate_config.get(\"patience\"    , 1)\n",
    "    monitor      = adaptive_learning_rate_config.get(\"monitor\"     , None)\n",
    "    mode         = adaptive_learning_rate_config.get(\"mode\"        , 'min')\n",
    "    log_lvl      = adaptive_learning_rate_config.get(\"log_lvl\"     , logging.DEBUG)\n",
    "    callbacks.append(AdaptiveLearningRate(decay_factor = decay_factor,\n",
    "                                          patience     = patience,\n",
    "                                          monitor      = monitor,\n",
    "                                          mode         = mode,\n",
    "                                          logger       = logger,\n",
    "                                          log_lvl      = log_lvl,))\n",
    "    logger.info(f\"Registeried training callback: AdaptiveLearningRate with decay_factor={decay_factor}, patience={patience}, monitor={monitor}, mode={mode}, log_lvl={log_lvl}\")\n",
    "            \n",
    "    \n",
    "## Add callback for model checkpointing\n",
    "model_checkpoint_config = global_config[\"training\"].get(\"model_checkpoint\", {})\n",
    "if model_checkpoint_config.get(\"do\", False) :\n",
    "    filename = model_checkpoint_config.get(\"filename\", \"model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.h5\")\n",
    "    filepath = f\"{working_dir}/{filename}\"\n",
    "    callbacks.append(ModelCheckpoint(filepath=filepath))\n",
    "    logger.info(f\"Registeried training callback: ModelCheckpoint with filepath={filepath}\")\n",
    "\n",
    "\n",
    "##  Add callback to record layer weights - use recursive=True to monitor all sublayers\n",
    "layer_weights_record_config = global_config[\"training\"].get(\"layer_weights_record\", {})\n",
    "if layer_weights_record_config.get(\"do\", False) :\n",
    "    batch_frequency = layer_weights_record_config.get(\"batch_frequency\", 1000)\n",
    "    recursive       = layer_weights_record_config.get(\"recursive\"      , True)\n",
    "    layer_weights_record = LayerWeightsRecord(batch_frequency = batch_frequency, \n",
    "                                              recursive       = recursive      )\n",
    "    callbacks.append(layer_weights_record)\n",
    "    logger.info(f\"Registered training callback: LayerWeightsRecord with batch_frequency={batch_frequency}, recursive={recursive}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "249a69c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Running text --> text mathsformer inference on some training data:\n",
      "   INFO print_predictions_table: --------------------------------------------------------------------------------\n",
      "   INFO print_predictions_table:                            INPUT        TRUE           PRED     CORRECT    RESIDUAL\n",
      "   INFO print_predictions_table: --------------------------------------------------------------------------------\n",
      "   INFO print_predictions_table:                         212+N362        N150 +0+993299199++                   N/A\n",
      "   INFO print_predictions_table:                      25+N11-5+N3           6 +0+993299199++                   N/A\n",
      "   INFO print_predictions_table:                          N951+N7        N958 +0+993299199++                   N/A\n",
      "   INFO print_predictions_table:                    81+27-N918+30        1056 B0+993299199++                   N/A\n",
      "   INFO print_predictions_table:                              234         234 +0+99339919999                   N/A\n",
      "   INFO print_predictions_table:                  159+N63+N108+98          86 15+993299199++                   N/A\n",
      "   INFO print_predictions_table:                    N18+N2-6+N812        N838 B0+993299199++                   N/A\n",
      "   INFO print_predictions_table:                             N722        N722 +0+99336919999                   N/A\n",
      "   INFO print_predictions_table:                     N6+N4-83+N60        N153 B0+993299199++                   N/A\n",
      "   INFO print_predictions_table:                              N66         N66 +0+99339919999                   N/A\n"
     ]
    }
   ],
   "source": [
    "##==================================##\n",
    "##   Test training data generator   ##\n",
    "##==================================##\n",
    "\n",
    "logger.info(\"Running text --> text mathsformer inference on some training data:\")\n",
    "train_gen.print_predictions_table(transformer, 10, max_tokens=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8a02d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Running text --> text mathsformer inference on some validation data:\n",
      "   INFO print_predictions_table: --------------------------------------------------------------------------------\n",
      "   INFO print_predictions_table:                            INPUT        TRUE           PRED     CORRECT    RESIDUAL\n",
      "   INFO print_predictions_table: --------------------------------------------------------------------------------\n",
      "   INFO print_predictions_table:                               N6          N6 -0+99329919999                   N/A\n",
      "   INFO print_predictions_table:                  64+N579+24+N124        N615 15+993299199++                   N/A\n",
      "   INFO print_predictions_table:                    N21-N482-3-N1         459 B0+993299199++                   N/A\n",
      "   INFO print_predictions_table:                                2           2 -0+99369919999                   N/A\n",
      "   INFO print_predictions_table:                                9           9 -0+99329919999                   N/A\n",
      "   INFO print_predictions_table:                             6-40         N34 +0+99336919999                   N/A\n",
      "   INFO print_predictions_table:                             6+N9          N3 +0+99339919999                   N/A\n",
      "   INFO print_predictions_table:                          N771-N2        N769 +0+993299199++                   N/A\n",
      "   INFO print_predictions_table:                  N748-62+N1-N608        N203 15+993299199++                   N/A\n",
      "   INFO print_predictions_table:                     N6-236+N14+2        N254 B0+993299199++                   N/A\n"
     ]
    }
   ],
   "source": [
    "##====================================##\n",
    "##   Test validation data generator   ##\n",
    "##====================================##\n",
    "\n",
    "logger.info(\"Running text --> text mathsformer inference on some validation data:\")\n",
    "val_gen.print_predictions_table(transformer, 10, max_tokens=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Begin model training with max_epochs=100000\n",
      "Epoch 1/100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 16:39:06.591838: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 395s 97ms/step - loss: 2.3406 - masked_accuracy: 0.2507 - val_loss: 2.3582 - val_masked_accuracy: 0.2347\n",
      "Epoch 2/100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ste/miniforge3/envs/py3p10_221222_tf_macos_only/lib/python3.10/site-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 725/4000 [====>.........................] - ETA: 5:36 - loss: 2.3297 - masked_accuracy: 0.2514"
     ]
    }
   ],
   "source": [
    "##=================##\n",
    "##   Train model   ##\n",
    "##=================##\n",
    "\n",
    "##  Fit the model if configured\n",
    "if global_config.get(\"training\",{}).get(\"train\",True) :\n",
    "    max_epochs = global_config[\"training\"][\"max_epochs\"]\n",
    "    logger.info(f\"Begin model training with max_epochs={max_epochs}\")\n",
    "    model.fit(train_gen, \n",
    "              epochs          = max_epochs,\n",
    "              validation_data = val_gen,\n",
    "              callbacks       = callbacks\n",
    "             )\n",
    "else :\n",
    "    logger.warning(\"Skipping model training following global config instructions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb38943",
   "metadata": {},
   "outputs": [],
   "source": [
    "##================##\n",
    "##   Save model   ##\n",
    "##================##\n",
    "\n",
    "if global_config.get(\"training\",{}).get(\"train\",True) :\n",
    "    save_fname = f\"{working_dir}/final_model.h5\"\n",
    "    model.save(save_fname)\n",
    "    logger.info(f\"Model save to file {save_fname}\")\n",
    "else :\n",
    "    logger.warning(\"Not saving model because no training was done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc69448",
   "metadata": {},
   "source": [
    "## 6.  Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "##  Find out how many datapoints to print predictions for \n",
    "num_print = int(global_config.get(\"evaluate\",{}).get(\"num_print\", 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bf1bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##  Print vs val data\n",
    "logger.info(\"Running text --> text mathsformer inference on the train set:\")\n",
    "train_gen.print_predictions_table(transformer, num_print)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bc596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##  Print vs val data\n",
    "logger.info(\"Running text --> text mathsformer inference on the validation set:\")\n",
    "val_gen.print_predictions_table(transformer, num_print)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b22cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##  Print vs val data\n",
    "logger.info(\"Running text --> text mathsformer inference on the test set:\")\n",
    "test_gen.print_predictions_table(transformer, num_print)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfb55b",
   "metadata": {},
   "source": [
    "##  7. Additional visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e385e68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##=============================================##\n",
    "##   Visualise layer weights during training   ##\n",
    "##=============================================##\n",
    "\n",
    "if len(layer_weights_record.batch_indices) == 0 :\n",
    "    logger.warning(\"Not plotting layer weights because no data found\")\n",
    "else :\n",
    "    logger.info(\"Plotting layer weights\")\n",
    "    layer_weights_record.plot(num_col=7)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1702c4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
