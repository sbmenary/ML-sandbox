{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884dc59d",
   "metadata": {},
   "source": [
    "#  Unsupervised learning addition model with generator\n",
    "\n",
    "Author: S. Menary [sbmenary@gmail.com]\n",
    "\n",
    "Date: 11/4/2023  (last update: 15/4/2023)\n",
    "\n",
    "Overview: Train a `sequence -> sequence` model where the input sequence is a text representation of a simple sum $\\sum_{i=1}^N A_i$ for a configurable number $N$ of integers $A_i\\in\\mathbb{Z}$, and the output is a set of logits representing the probability of each token in the output sequence. Integers may have a configurable number of digits. At inference time, chains of text are generated auto-regressively until the terminate-sequence token is reached. The loss function is a sparse categorical entropy.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Set up program\n",
    "\n",
    "###  Import\n",
    "\n",
    "All imports go here at the top of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48f1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "##=========================##\n",
    "##   All imports go here   ##\n",
    "##=========================##\n",
    "\n",
    "##  Import entire python stdlib packages\n",
    "import logging, os, sys\n",
    "\n",
    "##  Import entire pypi packages\n",
    "import tensorflow as tf\n",
    "\n",
    "##  Add directory above this to system path to expose mathsformer package location\n",
    "sys.path.append(\"/\".join(os.getcwd().split(\"/\")[:-1]))\n",
    "\n",
    "##  Import individual modules/objects from local packages\n",
    "from mathsformer import config, data, transformers, utils\n",
    "from mathsformer import selfsupervised_learning_addition_model_backend as backend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320886f9",
   "metadata": {},
   "source": [
    "## 1. Configure run\n",
    "\n",
    "Set configuration variables for entire program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701cef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##==============================##\n",
    "##   Set custom config values   ##\n",
    "##==============================##\n",
    "\n",
    "custom_config = {\n",
    "    \"global\" : {\n",
    "        \"base_seed\"        : -1,\n",
    "        \"working_dir\"      : \"SSL_addition_generator_notebook_[problem_tag]_[model_tag]_[date]\",\n",
    "        \"problem_tag\"      : \"baseline\",\n",
    "        \"model_tag\"        : \"3layers_64width_1preblock\",\n",
    "        \"log_lvl_iostream\" : logging.INFO,\n",
    "        \"log_lvl_fstream\"  : logging.DEBUG,\n",
    "    },\n",
    "    \"data\" : {\n",
    "        \"train_data\" : {\n",
    "            \"int_lengths\"      : [1, 2, 3],\n",
    "            \"num_ints\"         : [1, 2, 4],\n",
    "            \"batch_size\"       : 32,\n",
    "            \"num_batches\"      : 4000,\n",
    "            \"gen_base_seed\"    : 100,\n",
    "            \"gen_reproducible\" : False, \n",
    "        },\n",
    "        \"val_data\" : {\n",
    "            \"int_lengths\"      : [1, 2, 3],\n",
    "            \"num_ints\"         : [3],\n",
    "            \"batch_size\"       : 32,\n",
    "            \"num_batches\"      : 500,\n",
    "            \"gen_base_seed\"    : 101,\n",
    "            \"gen_reproducible\" : True,\n",
    "        },\n",
    "        \"test_data\" : {\n",
    "            \"int_lengths\"      : [4],\n",
    "            \"num_ints\"         : [3],\n",
    "            \"batch_size\"       : 32,\n",
    "            \"num_batches\"      : 1000,\n",
    "            \"gen_base_seed\"    : 102,\n",
    "            \"gen_reproducible\" : True,\n",
    "        },\n",
    "        \"characters\"              : ['M', 'B', 'E', 'N', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-'],\n",
    "        \"mask_char\"               : 'M',\n",
    "        \"seq_start_char\"          : 'B',\n",
    "        \"seq_end_char\"            : 'E',\n",
    "        \"negative_char\"           : 'N',\n",
    "        \"dtype\"                   : \"int32\",\n",
    "    },\n",
    "    \"model\" : {\n",
    "        \"load_pretrained_model\" : None,\n",
    "        \"name\"                  : \"mathsformer_LLM\",\n",
    "        \"dtype\"                 : \"float32\",\n",
    "        \"dropout\"               : 0.1,\n",
    "        \"learning_rate\"         : 1e-3,\n",
    "        \"jit_compile\"           : False,\n",
    "        \"positional_encoding\" : {\n",
    "            \"num_freqs\"         : 32,\n",
    "            \"min_period\"        : 4,\n",
    "            \"max_period\"        : 400,\n",
    "        },\n",
    "        \"ndim_embedding\"        : 64,\n",
    "        \"comb_type\"             : 'average',\n",
    "        \"pre_encoder\"           : {\n",
    "            \"num_layers\"        : 1,\n",
    "            \"ndim\"              : 128,\n",
    "            \"skip_connect\"      : True,\n",
    "        },\n",
    "        \"pre_decoder\" : {\n",
    "            \"num_layers\"        : 1,\n",
    "            \"ndim\"              : 128,\n",
    "            \"skip_connect\"      : True,\n",
    "        },\n",
    "        \"encoder\" : {\n",
    "            \"num_blocks\"        : 3,\n",
    "            \"num_heads\"         : 8,\n",
    "            \"ndim\"              : 64,\n",
    "            \"ndim_att_hidden\"   : 64,\n",
    "            \"ndim_ff_hidden\"    : 128,\n",
    "            \"skip_connect\"      : True,\n",
    "        },\n",
    "        \"decoder\" : {\n",
    "            \"num_blocks\"        : 3,\n",
    "            \"num_heads\"         : 8,\n",
    "            \"ndim\"              : 64,\n",
    "            \"ndim_att_hidden\"   : 64,\n",
    "            \"ndim_ff_hidden\"    : 128,\n",
    "            \"skip_connect\"      : True,\n",
    "        },\n",
    "        \"post_decoder\" : {\n",
    "            \"num_layers\"        : 3,\n",
    "            \"ndim\"              : 256,\n",
    "        },\n",
    "    },\n",
    "    \"training\" : {\n",
    "        \"train\"          : True,\n",
    "        \"max_epochs\"     : 100000,\n",
    "        \"log_after_epoch\" : {\n",
    "            \"do\"          : True,\n",
    "            \"log_lvl\"     : logging.DEBUG,\n",
    "        },\n",
    "        \"early_stopping\" : {\n",
    "            \"do\"                   : True,\n",
    "            \"patience\"             : 6,\n",
    "            \"monitor\"              : \"val_masked_accuracy\",\n",
    "            \"mode\"                 : \"max\",\n",
    "            \"restore_best_weights\" : True,\n",
    "        },\n",
    "        \"model_checkpoint\" : {\n",
    "            \"do\"       : True,\n",
    "            \"filename\" : \"model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.h5\",\n",
    "        },\n",
    "        \"layer_weights_record\" : {\n",
    "            \"do\"               : True,\n",
    "            \"batch_frequency\"  : 4000,\n",
    "            \"recursive\"        : True,\n",
    "        },\n",
    "        \"adaptive_learning_rate\" : {\n",
    "            \"do\"                 : True,\n",
    "            \"decay_factor\"       : 0.3,\n",
    "            \"monitor\"            : \"loss\",\n",
    "            \"mode\"               : \"min\",\n",
    "            \"patience\"           : 2,\n",
    "            \"log_lvl\"            : logging.DEBUG,\n",
    "        },\n",
    "    },\n",
    "    \"evaluate\" : {\n",
    "        \"num_print\"            : 20,\n",
    "        \"save_model\"           : True,\n",
    "        \"plot_weights\"         : False,\n",
    "        \"plot_training_curves\" : True,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e15977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "===   Config created   ===\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "##===================================##\n",
    "##   Load and validate full config   ##\n",
    "##===================================##\n",
    "\n",
    "##  Create config object containing default values\n",
    "cfg = config.Config(backend.DEFAULT_CONFIG)\n",
    "\n",
    "##  Override with custom values\n",
    "cfg.load_dict(custom_config)\n",
    "\n",
    "##  Validate config\n",
    "backend.validate_config(cfg)\n",
    "\n",
    "##  Print success\n",
    "print(utils.fancy_message(f\"Config created\"))\n",
    "\n",
    "##  For convenience, split configs for different sections\n",
    "cfg_global   = cfg[\"global\"  ]\n",
    "cfg_data     = cfg[\"data\"    ]\n",
    "cfg_model    = cfg[\"model\"   ]\n",
    "cfg_training = cfg[\"training\"]\n",
    "cfg_evaluate = cfg[\"evaluate\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af05439",
   "metadata": {},
   "source": [
    "##  2. Set up environment\n",
    "\n",
    "- Create working directory\n",
    "- Create logger\n",
    "- Log package versions for reproducibility\n",
    "- Log config values for reproducibility\n",
    "- Set random seeds for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f7cc532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================================\n",
      "===   Working directory created at SSL_addition_generator_notebook_baseline_3layers_64width_1preblock_2023_04_18   ===\n",
      "======================================================================================================================\n",
      "   INFO initialise_logging: Begin logging on 2023-04-18 at 15:31:30\n",
      "   INFO initialise_program: Program description: unsupervised_learning_addition_model_generator (notebook)\n",
      "   INFO initialise_program: Working directory: SSL_addition_generator_notebook_baseline_3layers_64width_1preblock_2023_04_18\n",
      "   INFO log_versions: ------------------------------------------------------+----------------------------------------------------------------------------------\n",
      "   INFO log_versions:                                              PACKAGE  |  VERSION\n",
      "   INFO log_versions: ------------------------------------------------------+----------------------------------------------------------------------------------\n",
      "   INFO log_versions:                                               Python  |  3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]\n",
      "   INFO log_versions:                                              IPython  |  8.7.0\n",
      "   INFO log_versions:                                 IPython.core.release  |  8.7.0\n",
      "   INFO log_versions:                                                  PIL  |  9.3.0\n",
      "   INFO log_versions:                                            PIL.Image  |  9.3.0\n",
      "   INFO log_versions:                                       PIL._deprecate  |  9.3.0\n",
      "   INFO log_versions:                                         PIL._version  |  9.3.0\n",
      "   INFO log_versions:                                                 _csv  |  1.0\n",
      "   INFO log_versions:                                              _ctypes  |  1.1.0\n",
      "   INFO log_versions:                                              _curses  |  b'2.2'\n",
      "   INFO log_versions:                                              decimal  |  1.70\n",
      "   INFO log_versions:                               _pydev_bundle.fsnotify  |  0.1.5\n",
      "   INFO log_versions:                 _pydevd_frame_eval.vendored.bytecode  |  0.13.0.dev\n",
      "   INFO log_versions:                                              appnope  |  0.1.3\n",
      "   INFO log_versions:                                             argparse  |  1.1\n",
      "   INFO log_versions:                                           astunparse  |  1.6.3\n",
      "   INFO log_versions:                                             backcall  |  0.2.0\n",
      "   INFO log_versions:                                              certifi  |  2022.12.07\n",
      "   INFO log_versions:                                                 cffi  |  1.15.1\n",
      "   INFO log_versions:                                   charset_normalizer  |  2.1.1\n",
      "   INFO log_versions:                           charset_normalizer.version  |  2.1.1\n",
      "   INFO log_versions:                                                 comm  |  0.1.2\n",
      "   INFO log_versions:                                                  csv  |  1.0\n",
      "   INFO log_versions:                                               ctypes  |  1.1.0\n",
      "   INFO log_versions:                                      ctypes.macholib  |  1.0\n",
      "   INFO log_versions:                                               cycler  |  0.10.0\n",
      "   INFO log_versions:                                             dateutil  |  2.8.2\n",
      "   INFO log_versions:                                              debugpy  |  1.6.4\n",
      "   INFO log_versions:                                   debugpy.public_api  |  1.6.4\n",
      "   INFO log_versions:                                              decimal  |  1.70\n",
      "   INFO log_versions:                                            decorator  |  5.1.1\n",
      "   INFO log_versions:                                           defusedxml  |  0.7.1\n",
      "   INFO log_versions:                                            distutils  |  3.10.8\n",
      "   INFO log_versions:                                          entrypoints  |  0.4\n",
      "   INFO log_versions:                                            executing  |  1.2.0\n",
      "   INFO log_versions:                                    executing.version  |  1.2.0\n",
      "   INFO log_versions:                                          flatbuffers  |  22.12.06\n",
      "   INFO log_versions:                                 flatbuffers._version  |  22.12.06\n",
      "   INFO log_versions:                                      google.protobuf  |  3.19.4\n",
      "   INFO log_versions:                                                 h5py  |  3.6.0\n",
      "   INFO log_versions:                                          http.server  |  0.6\n",
      "   INFO log_versions:                                                 idna  |  3.4\n",
      "   INFO log_versions:                                        idna.idnadata  |  15.0.0\n",
      "   INFO log_versions:                                    idna.package_data  |  3.4\n",
      "   INFO log_versions:                                            ipaddress  |  1.0\n",
      "   INFO log_versions:                                            ipykernel  |  6.19.4\n",
      "   INFO log_versions:                                   ipykernel._version  |  6.19.4\n",
      "   INFO log_versions:                                                 jedi  |  0.18.2\n",
      "   INFO log_versions:                                                 json  |  2.0.9\n",
      "   INFO log_versions:                                       jupyter_client  |  7.4.8\n",
      "   INFO log_versions:                              jupyter_client._version  |  7.4.8\n",
      "   INFO log_versions:                                         jupyter_core  |  5.1.0\n",
      "   INFO log_versions:                                 jupyter_core.version  |  5.1.0\n",
      "   INFO log_versions:                                                keras  |  2.11.0\n",
      "   INFO log_versions:                                  keras.api._v2.keras  |  2.11.0\n",
      "   INFO log_versions:                                      keras.api.keras  |  2.11.0\n",
      "   INFO log_versions:                                           kiwisolver  |  1.4.4\n",
      "   INFO log_versions:                                     kiwisolver._cext  |  1.4.4\n",
      "   INFO log_versions:                                              logging  |  0.5.1.2\n",
      "   INFO log_versions:                                           matplotlib  |  3.6.2\n",
      "   INFO log_versions:                                  matplotlib._version  |  3.6.2\n",
      "   INFO log_versions:                                                numpy  |  1.23.2\n",
      "   INFO log_versions:                                           numpy.core  |  1.23.2\n",
      "   INFO log_versions:                         numpy.core._multiarray_umath  |  3.1\n",
      "   INFO log_versions:                                            numpy.lib  |  1.23.2\n",
      "   INFO log_versions:                           numpy.linalg._umath_linalg  |  0.1.5\n",
      "   INFO log_versions:                                        numpy.version  |  1.23.2\n",
      "   INFO log_versions:                                           opt_einsum  |  v3.3.0\n",
      "   INFO log_versions:                                            packaging  |  22.0\n",
      "   INFO log_versions:                                  packaging.__about__  |  22.0\n",
      "   INFO log_versions:                                                parso  |  0.8.3\n",
      "   INFO log_versions:                                              pexpect  |  4.8.0\n",
      "   INFO log_versions:                                          pickleshare  |  0.7.5\n",
      "   INFO log_versions:                        pkg_resources._vendor.appdirs  |  1.4.3\n",
      "   INFO log_versions:                 pkg_resources._vendor.more_itertools  |  8.12.0\n",
      "   INFO log_versions:                      pkg_resources._vendor.packaging  |  21.3\n",
      "   INFO log_versions:            pkg_resources._vendor.packaging.__about__  |  21.3\n",
      "   INFO log_versions:                      pkg_resources._vendor.pyparsing  |  3.0.9\n",
      "   INFO log_versions:                        pkg_resources._vendor.appdirs  |  1.4.3\n",
      "   INFO log_versions:                 pkg_resources._vendor.more_itertools  |  8.12.0\n",
      "   INFO log_versions:                      pkg_resources._vendor.packaging  |  21.3\n",
      "   INFO log_versions:                      pkg_resources._vendor.pyparsing  |  3.0.9\n",
      "   INFO log_versions:                                             platform  |  1.0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO log_versions:                                         platformdirs  |  2.6.0\n",
      "   INFO log_versions:                                 platformdirs.version  |  2.6.0\n",
      "   INFO log_versions:                                       prompt_toolkit  |  3.0.36\n",
      "   INFO log_versions:                                               psutil  |  5.9.4\n",
      "   INFO log_versions:                                           ptyprocess  |  0.7.0\n",
      "   INFO log_versions:                                            pure_eval  |  0.2.2\n",
      "   INFO log_versions:                                    pure_eval.version  |  0.2.2\n",
      "   INFO log_versions:                                               pydevd  |  2.9.1\n",
      "   INFO log_versions:                                             pygments  |  2.13.0\n",
      "   INFO log_versions:                                            pyparsing  |  3.0.9\n",
      "   INFO log_versions:                                                   re  |  2.2.1\n",
      "   INFO log_versions:                                             requests  |  2.28.1\n",
      "   INFO log_versions:                                 requests.__version__  |  2.28.1\n",
      "   INFO log_versions:                                                 idna  |  3.4\n",
      "   INFO log_versions:                                        idna.idnadata  |  15.0.0\n",
      "   INFO log_versions:                                    idna.package_data  |  3.4\n",
      "   INFO log_versions:                                              urllib3  |  1.26.13\n",
      "   INFO log_versions:                                     urllib3._version  |  1.26.13\n",
      "   INFO log_versions:                                   urllib3.connection  |  1.26.13\n",
      "   INFO log_versions:                                 urllib3.packages.six  |  1.16.0\n",
      "   INFO log_versions:                      urllib3.util.ssl_match_hostname  |  3.5.0.1\n",
      "   INFO log_versions:                                       requests.utils  |  2.28.1\n",
      "   INFO log_versions:                                           setuptools  |  65.6.3\n",
      "   INFO log_versions:                                            distutils  |  3.10.8\n",
      "   INFO log_versions:                    setuptools._vendor.more_itertools  |  8.8.0\n",
      "   INFO log_versions:                       setuptools._vendor.ordered_set  |  3.1\n",
      "   INFO log_versions:                         setuptools._vendor.packaging  |  21.3\n",
      "   INFO log_versions:               setuptools._vendor.packaging.__about__  |  21.3\n",
      "   INFO log_versions:                         setuptools._vendor.pyparsing  |  3.0.9\n",
      "   INFO log_versions:                    setuptools._vendor.more_itertools  |  8.8.0\n",
      "   INFO log_versions:                       setuptools._vendor.ordered_set  |  3.1\n",
      "   INFO log_versions:                         setuptools._vendor.packaging  |  21.3\n",
      "   INFO log_versions:                         setuptools._vendor.pyparsing  |  3.0.9\n",
      "   INFO log_versions:                                   setuptools.version  |  65.6.3\n",
      "   INFO log_versions:                                                  six  |  1.16.0\n",
      "   INFO log_versions:                                         socketserver  |  0.4\n",
      "   INFO log_versions:                                           stack_data  |  0.6.2\n",
      "   INFO log_versions:                                   stack_data.version  |  0.6.2\n",
      "   INFO log_versions:                                          tensorboard  |  2.11.0\n",
      "   INFO log_versions:                   tensorboard.compat.tensorflow_stub  |  stub\n",
      "   INFO log_versions: tensorboard.compat.tensorflow_stub.pywrap_tensorflow  |  0\n",
      "   INFO log_versions:                                           tensorflow  |  2.11.0\n",
      "   INFO log_versions:                         tensorflow._api.v2.compat.v1  |  2.11.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v1.compat.v1  |  2.11.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v1.compat.v2  |  2.11.0\n",
      "   INFO log_versions:                         tensorflow._api.v2.compat.v2  |  2.11.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v2.compat.v1  |  2.11.0\n",
      "   INFO log_versions:               tensorflow._api.v2.compat.v2.compat.v2  |  2.11.0\n",
      "   INFO log_versions:                                 tensorflow.compat.v1  |  2.11.0\n",
      "   INFO log_versions:                       tensorflow.compat.v1.compat.v1  |  2.11.0\n",
      "   INFO log_versions:                       tensorflow.compat.v1.compat.v2  |  2.11.0\n",
      "   INFO log_versions:                                 tensorflow.compat.v2  |  2.11.0\n",
      "   INFO log_versions:                       tensorflow.compat.v2.compat.v1  |  2.11.0\n",
      "   INFO log_versions:                       tensorflow.compat.v2.compat.v2  |  2.11.0\n",
      "   INFO log_versions:                                     tensorflow.keras  |  2.11.0\n",
      "   INFO log_versions:           tensorflow.python.client.pywrap_tf_session  |  2.11.0\n",
      "   INFO log_versions:                 tensorflow.python.framework.versions  |  2.11.0\n",
      "   INFO log_versions:                              tensorflow.python.keras  |  2.6.0\n",
      "   INFO log_versions:                                            traitlets  |  5.8.0\n",
      "   INFO log_versions:                                   traitlets._version  |  5.8.0\n",
      "   INFO log_versions:                                       urllib.request  |  3.10\n",
      "   INFO log_versions:                                              urllib3  |  1.26.13\n",
      "   INFO log_versions:                                     urllib3._version  |  1.26.13\n",
      "   INFO log_versions:                                   urllib3.connection  |  1.26.13\n",
      "   INFO log_versions:                                 urllib3.packages.six  |  1.16.0\n",
      "   INFO log_versions:                      urllib3.util.ssl_match_hostname  |  3.5.0.1\n",
      "   INFO log_versions:                                              wcwidth  |  0.2.5\n",
      "   INFO log_versions:                                                wrapt  |  1.14.1\n",
      "   INFO log_versions:                                        xmlrpc.client  |  3.10\n",
      "   INFO log_versions:                                                 zlib  |  1.0\n",
      "   INFO log_versions:                                                  zmq  |  24.0.1\n",
      "   INFO log_versions:                                            zmq.sugar  |  24.0.1\n",
      "   INFO log_versions:                                    zmq.sugar.version  |  24.0.1\n",
      "   INFO log_versions: ------------------------------------------------------+----------------------------------------------------------------------------------\n",
      "   INFO initialise_program: Registered config value global > base_seed: -1\n",
      "   INFO initialise_program: Registered config value global > working_dir: SSL_addition_generator_notebook_[problem_tag]_[model_tag]_[date]\n",
      "   INFO initialise_program: Registered config value global > problem_tag: baseline\n",
      "   INFO initialise_program: Registered config value global > model_tag: 3layers_64width_1preblock\n",
      "   INFO initialise_program: Registered config value global > log_lvl_iostream: 20\n",
      "   INFO initialise_program: Registered config value global > log_lvl_fstream: 10\n",
      "   INFO initialise_program: Registered config value data > train_data > int_lengths: [1, 2, 3]\n",
      "   INFO initialise_program: Registered config value data > train_data > num_ints: [1, 2, 4]\n",
      "   INFO initialise_program: Registered config value data > train_data > batch_size: 32\n",
      "   INFO initialise_program: Registered config value data > train_data > num_batches: 4000\n",
      "   INFO initialise_program: Registered config value data > train_data > gen_base_seed: 100\n",
      "   INFO initialise_program: Registered config value data > train_data > gen_reproducible: False\n",
      "   INFO initialise_program: Registered config value data > val_data > int_lengths: [1, 2, 3]\n",
      "   INFO initialise_program: Registered config value data > val_data > num_ints: [3]\n",
      "   INFO initialise_program: Registered config value data > val_data > batch_size: 32\n",
      "   INFO initialise_program: Registered config value data > val_data > num_batches: 500\n",
      "   INFO initialise_program: Registered config value data > val_data > gen_base_seed: 101\n",
      "   INFO initialise_program: Registered config value data > val_data > gen_reproducible: True\n",
      "   INFO initialise_program: Registered config value data > test_data > int_lengths: [4]\n",
      "   INFO initialise_program: Registered config value data > test_data > num_ints: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO initialise_program: Registered config value data > test_data > batch_size: 32\n",
      "   INFO initialise_program: Registered config value data > test_data > num_batches: 1000\n",
      "   INFO initialise_program: Registered config value data > test_data > gen_base_seed: 102\n",
      "   INFO initialise_program: Registered config value data > test_data > gen_reproducible: True\n",
      "   INFO initialise_program: Registered config value data > characters: ['M', 'B', 'E', 'N', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-']\n",
      "   INFO initialise_program: Registered config value data > mask_char: M\n",
      "   INFO initialise_program: Registered config value data > seq_start_char: B\n",
      "   INFO initialise_program: Registered config value data > seq_end_char: E\n",
      "   INFO initialise_program: Registered config value data > negative_char: N\n",
      "   INFO initialise_program: Registered config value data > dtype: int32\n",
      "   INFO initialise_program: Registered config value model > load_pretrained_model: None\n",
      "   INFO initialise_program: Registered config value model > name: mathsformer_LLM\n",
      "   INFO initialise_program: Registered config value model > dtype: float32\n",
      "   INFO initialise_program: Registered config value model > dropout: 0.1\n",
      "   INFO initialise_program: Registered config value model > learning_rate: 0.001\n",
      "   INFO initialise_program: Registered config value model > jit_compile: False\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > num_freqs: 32\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > min_period: 4\n",
      "   INFO initialise_program: Registered config value model > positional_encoding > max_period: 400\n",
      "   INFO initialise_program: Registered config value model > ndim_embedding: 64\n",
      "   INFO initialise_program: Registered config value model > comb_type: average\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > num_layers: 1\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > ndim: 128\n",
      "   INFO initialise_program: Registered config value model > pre_encoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > pre_decoder > num_layers: 1\n",
      "   INFO initialise_program: Registered config value model > pre_decoder > ndim: 128\n",
      "   INFO initialise_program: Registered config value model > pre_decoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > encoder > num_blocks: 3\n",
      "   INFO initialise_program: Registered config value model > encoder > num_heads: 8\n",
      "   INFO initialise_program: Registered config value model > encoder > ndim: 64\n",
      "   INFO initialise_program: Registered config value model > encoder > ndim_att_hidden: 64\n",
      "   INFO initialise_program: Registered config value model > encoder > ndim_ff_hidden: 128\n",
      "   INFO initialise_program: Registered config value model > encoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > decoder > num_blocks: 3\n",
      "   INFO initialise_program: Registered config value model > decoder > num_heads: 8\n",
      "   INFO initialise_program: Registered config value model > decoder > ndim: 64\n",
      "   INFO initialise_program: Registered config value model > decoder > ndim_att_hidden: 64\n",
      "   INFO initialise_program: Registered config value model > decoder > ndim_ff_hidden: 128\n",
      "   INFO initialise_program: Registered config value model > decoder > skip_connect: True\n",
      "   INFO initialise_program: Registered config value model > post_decoder > num_layers: 3\n",
      "   INFO initialise_program: Registered config value model > post_decoder > ndim: 256\n",
      "   INFO initialise_program: Registered config value training > train: True\n",
      "   INFO initialise_program: Registered config value training > max_epochs: 100000\n",
      "   INFO initialise_program: Registered config value training > log_after_epoch > do: True\n",
      "   INFO initialise_program: Registered config value training > log_after_epoch > log_lvl: 10\n",
      "   INFO initialise_program: Registered config value training > early_stopping > do: True\n",
      "   INFO initialise_program: Registered config value training > early_stopping > patience: 6\n",
      "   INFO initialise_program: Registered config value training > early_stopping > monitor: val_masked_accuracy\n",
      "   INFO initialise_program: Registered config value training > early_stopping > mode: max\n",
      "   INFO initialise_program: Registered config value training > early_stopping > restore_best_weights: True\n",
      "   INFO initialise_program: Registered config value training > model_checkpoint > do: True\n",
      "   INFO initialise_program: Registered config value training > model_checkpoint > filename: model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.h5\n",
      "   INFO initialise_program: Registered config value training > layer_weights_record > do: True\n",
      "   INFO initialise_program: Registered config value training > layer_weights_record > batch_frequency: 4000\n",
      "   INFO initialise_program: Registered config value training > layer_weights_record > recursive: True\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > do: True\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > decay_factor: 0.3\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > monitor: loss\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > mode: min\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > patience: 2\n",
      "   INFO initialise_program: Registered config value training > adaptive_learning_rate > log_lvl: 10\n",
      "   INFO initialise_program: Registered config value evaluate > num_print: 20\n",
      "   INFO initialise_program: Registered config value evaluate > save_model: True\n",
      "   INFO initialise_program: Registered config value evaluate > plot_weights: False\n",
      "   INFO initialise_program: Registered config value evaluate > plot_training_curves: True\n",
      "   INFO initialise_program: Python random seed set: 1681828290\n",
      "   INFO initialise_program: Numpy random seed set: 1681828291\n",
      "   INFO initialise_program: TensorFlow random seed set: 1681828292\n"
     ]
    }
   ],
   "source": [
    "##==============================##\n",
    "##   Create working directory   ##\n",
    "##==============================##\n",
    "\n",
    "##  Report success\n",
    "working_dir, logger, base_seed, np_seed, tf_seed = utils.initialise_program(\n",
    "    \"unsupervised_learning_addition_model_generator (notebook)\", \n",
    "    working_dir       = cfg_global[\"working_dir\"], \n",
    "    cfg               = cfg,\n",
    "    base_seed         = cfg_global[\"base_seed\"],\n",
    "    log_lvl_iostream  = cfg_global[\"log_lvl_iostream\"],\n",
    "    log_lvl_fstream   = cfg_global[\"log_lvl_fstream\" ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960860d",
   "metadata": {},
   "source": [
    "##  3. Create training data\n",
    "\n",
    "###  Create tokeniser\n",
    "\n",
    "Tokeniser object handles the transformation from strings to tensors and back again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db11d6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO summary: TokenTransform of dtype int32 with 16 characters: ['M', 'B', 'E', 'N', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-']\n",
      "   INFO summary: Special characters are seq_start_char (B), seq_end_char (E), mask_char (M)\n",
      "   INFO summary: Tokeniser dictionary is {'M': 0, 'B': 1, 'E': 2, 'N': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, '+': 14, '-': 15}\n",
      "   INFO summary: Detokeniser dictionary is {0: 'M', 1: 'B', 2: 'E', 3: 'N', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: '+', 15: '-'}\n"
     ]
    }
   ],
   "source": [
    "##======================##\n",
    "##   Create tokeniser   ##\n",
    "##======================##\n",
    "\n",
    "token_transform = data.TokenTransform.from_dictionary(cfg_data)\n",
    "token_transform.summary(print_fn=logger.info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5367bdd7",
   "metadata": {},
   "source": [
    "###  Create data generators for train/val/test sets\n",
    "\n",
    "Data generators create tensor inputs/outputs for the model on-the-fly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d87b308d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO get_data_generators: Training data generator created with the following config: Generator of [1, 2, 4] integers of length [1, 2, 3] in 4000 batches of size 32 (base_seed=100, reproducible=False)\n",
      "   INFO get_data_generators: Output shapes for a test batch are ((32, 19), (32, 6)), (32, 6)\n",
      "   INFO get_data_generators: Validation data generator created with the following config: Generator of [3] integers of length [1, 2, 3] in 500 batches of size 32 (base_seed=101, reproducible=True)\n",
      "   INFO get_data_generators: Output shapes for a test batch are ((32, 15), (32, 6)), (32, 6)\n",
      "   INFO get_data_generators: Test data generator created with the following config: Generator of [3] integers of length [4] in 1000 batches of size 32 (base_seed=102, reproducible=True)\n",
      "   INFO get_data_generators: Output shapes for a test batch are ((32, 19), (32, 7)), (32, 7)\n"
     ]
    }
   ],
   "source": [
    "##============================##\n",
    "##   Create data generators   ##\n",
    "##============================##\n",
    "\n",
    "train_gen, val_gen, test_gen = backend.get_data_generators(cfg_data, token_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39db1bb",
   "metadata": {},
   "source": [
    "##  4.  Create model\n",
    "\n",
    "Create the keras model object that handles sequence-sequence transformations from alread-tokenised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb6a53e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Creating new text-to-text model\n",
      "   INFO <module>: Model created with summary:\n",
      "   INFO <module>: Model: \"mathsformer_LLM\"\n",
      "   INFO <module>: __________________________________________________________________________________________________\n",
      "   INFO <module>:  Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "   INFO <module>: ==================================================================================================\n",
      "   INFO <module>:  mathsformer_LLM_encoder_input_  [(None, None)]      0           []                               \n",
      "   INFO <module>:  layer (InputLayer)                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_enumer  (1, None)           0           ['mathsformer_LLM_encoder_input_l\n",
      "   INFO <module>:  ate (Enumerate)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_embedd  (None, None, 64)    1024        ['mathsformer_LLM_encoder_input_l\n",
      "   INFO <module>:  ing (Embedding)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_positi  (1, None, 64)       0           ['mathsformer_LLM_encoder_enumera\n",
      "   INFO <module>:  on_encoding (PositionalEncodin                                  te[0][0]']                       \n",
      "   INFO <module>:  g)                                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_input_  [(None, None)]      0           []                               \n",
      "   INFO <module>:  layer (InputLayer)                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_emb_an  (None, None, 64)    0           ['mathsformer_LLM_encoder_embeddi\n",
      "   INFO <module>:  d_pos (Average)                                                 ng[0][0]',                       \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_positio\n",
      "   INFO <module>:                                                                  n_encoding[0][0]']               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_enumer  (1, None)           0           ['mathsformer_LLM_decoder_input_l\n",
      "   INFO <module>:  ate (Enumerate)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_feedfw  (None, None, 64)    16832       ['mathsformer_LLM_encoder_emb_and\n",
      "   INFO <module>:  d_block_pre_attention (FeedFor                                  _pos[0][0]']                     \n",
      "   INFO <module>:  wardBlock)                                                                                       \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_embedd  (None, None, 64)    1024        ['mathsformer_LLM_decoder_input_l\n",
      "   INFO <module>:  ing (Embedding)                                                 ayer[0][0]']                     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_positi  (1, None, 64)       0           ['mathsformer_LLM_decoder_enumera\n",
      "   INFO <module>:  on_encoding (PositionalEncodin                                  te[0][0]']                       \n",
      "   INFO <module>:  g)                                                                                               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_block_  (None, None, 64)    149632      ['mathsformer_LLM_encoder_feedfwd\n",
      "   INFO <module>:  1 (EncoderBlock)                                                _block_pre_attention[0][0]']     \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_emb_an  (None, None, 64)    0           ['mathsformer_LLM_decoder_embeddi\n",
      "   INFO <module>:  d_pos (Average)                                                 ng[0][0]',                       \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_decoder_positio\n",
      "   INFO <module>:                                                                  n_encoding[0][0]']               \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_block_  (None, None, 64)    149632      ['mathsformer_LLM_encoder_block_1\n",
      "   INFO <module>:  2 (EncoderBlock)                                                [0][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_feedfw  (None, None, 64)    16832       ['mathsformer_LLM_decoder_emb_and\n",
      "   INFO <module>:  d_block_pre_attention (FeedFor                                  _pos[0][0]']                     \n",
      "   INFO <module>:  wardBlock)                                                                                       \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_encoder_block_  (None, None, 64)    149632      ['mathsformer_LLM_encoder_block_2\n",
      "   INFO <module>:  3 (EncoderBlock)                                                [0][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_block_  (None, None, 64)    282432      ['mathsformer_LLM_decoder_feedfwd\n",
      "   INFO <module>:  1 (DecoderBlock)                                                _block_pre_attention[0][0]',     \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_3\n",
      "   INFO <module>:                                                                  [0][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_block_  (None, None, 64)    282432      ['mathsformer_LLM_decoder_block_1\n",
      "   INFO <module>:  2 (DecoderBlock)                                                [0][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_3\n",
      "   INFO <module>:                                                                  [0][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_decoder_block_  (None, None, 64)    282432      ['mathsformer_LLM_decoder_block_2\n",
      "   INFO <module>:  3 (DecoderBlock)                                                [0][0]',                         \n",
      "   INFO <module>:                                                                   'mathsformer_LLM_encoder_block_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>:                                                                  [0][0]']                         \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>:  mathsformer_LLM_feedfwd_block_  (None, None, 16)    153872      ['mathsformer_LLM_decoder_block_3\n",
      "   INFO <module>:  post_attention (FeedForwardBlo                                  [0][0]']                         \n",
      "   INFO <module>:  ck)                                                                                              \n",
      "   INFO <module>:                                                                                                   \n",
      "   INFO <module>: ==================================================================================================\n",
      "   INFO <module>: Total params: 1,485,776\n",
      "   INFO <module>: Trainable params: 1,485,776\n",
      "   INFO <module>: Non-trainable params: 0\n",
      "   INFO <module>: __________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##===================================================##\n",
    "##   Load or create self-supervised learning model   ##\n",
    "##===================================================##\n",
    "\n",
    "##  Get filename for load model\n",
    "fname = cfg_model.get(\"load_pretrained_model\", None)\n",
    "\n",
    "##  Load model if fname is not None, otherwise create from scratch\n",
    "if fname is not None :\n",
    "    logger.info   (f\"Loading model from: {fname}\")\n",
    "    logger.warning(\"Loading a pretrained model will disregard model config!\")\n",
    "    model = backend.load_text_to_text_model(fname)\n",
    "else :\n",
    "    logger.info(f\"Creating new text-to-text model\")\n",
    "    model = backend.create_text_to_text_model_from_config(cfg_model, token_transform)\n",
    "\n",
    "##  Create hack to catch model summary\n",
    "model_summary = []\n",
    "model.summary(print_fn = lambda s : model_summary.append(s))\n",
    "\n",
    "##  Print model summary\n",
    "logger.info(\"Model created with summary:\")\n",
    "for s in model_summary : logger.info(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "793493a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##==============================================================##\n",
    "##   Create transformer wrapper for model and token_transform   ##\n",
    "##==============================================================##\n",
    "\n",
    "transformer = transformers.Transformer_Text_to_Text(model, token_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "956e30a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO test_transformer: Running text --> text mathsformer inference on some training data:\n",
      "-------------------------------------------------------------------------------\n",
      "           INPUT       TRUE                          PRED    CORRECT   RESIDUAL\n",
      "-------------------------------------------------------------------------------\n",
      "        212+N362       N150 B7888875M904404B0M00+00-88640                  ?   \n",
      "     25+N11-5+N3          6 B7888875M90440750M00+00-88600                  ?   \n",
      "         N951+N7       N958 B7888875M904404B0M00+00-88640                  ?   \n",
      "   81+27-N918+30       1056 B78+8875M94440750M00+00-88+00                  ?   \n",
      "             234        234 B7888075M94440550M00B+0-88640                  ?   \n",
      " 159+N63+N108+98         86 B78+8875M94440750M00+00-88+00                  ?   \n",
      "   N18+N2-6+N812       N838 B78+8875M94440750M00+00-88+00                  ?   \n",
      "            N722       N722 B7888075M94440550M00+00-88640                  ?   \n",
      "    N6+N4-83+N60       N153 B78+8875M94440750M00+00-88+00                  ?   \n",
      "             N66        N66 B7888075M94440550M00B+0-88640                  ?   \n",
      "   INFO test_transformer: Running text --> text mathsformer inference on some validation data:\n",
      "-----------------------------------------------------------------------------\n",
      "         INPUT       TRUE                          PRED    CORRECT   RESIDUAL\n",
      "-----------------------------------------------------------------------------\n",
      "   N94+N950-68      N1112 B7888875M90440750M00+00-88600                  ?   \n",
      "     9-N47-898       N842 B7888875M90440750M00+00-88640                  ?   \n",
      "      8-527-N8       N511 B7888875M904404B0M00+00-88640                  ?   \n",
      "      418-4+43        457 B7888875M904404B0M00+00-88640                  ?   \n",
      "   4+N756-N321       N431 B7888875M90440750M00+00-88600                  ?   \n",
      "   N6-468-N675        201 B7888875M90440750M00+00-88600                  ?   \n",
      " N456+N755+N84      N1295 B78+8875M94440750M00+00-88+00                  ?   \n",
      "  N36+N91-N518        391 B78+8875M94440750M00+00-88+00                  ?   \n",
      "    N918-79+N5      N1002 B7888875M90440750M00+00-88600                  ?   \n",
      "      N3+N2-N5          0 B7888875M904404B0M00+00-88640                  ?   \n",
      "   INFO test_transformer: Running text --> text mathsformer inference on some test data:\n",
      "---------------------------------------------------------------------------------\n",
      "             INPUT       TRUE                          PRED    CORRECT   RESIDUAL\n",
      "---------------------------------------------------------------------------------\n",
      "   4222+N9897-8062     N13737 B78+8875M94440750000+00-88+00                  ?   \n",
      "   7797-5932+N7587      N5722 B78+8875M94440750M00+00-88+00                  ?   \n",
      " N8590-N2960+N3568      N9198 B78+8875M944404B0000+00-88+00                  ?   \n",
      "   N8213-1443-5034     N14690 B78+8875M94440750M00+00-88+00                  ?   \n",
      "  N9305-2123+N1358     N12786 B78+8875M94440750000+00-88+00                  ?   \n",
      " N1853+N6632+N8968     N17453 B78+8875M944404B0000+00-88+00                  ?   \n",
      "   1639-N2868+5666      10173 B78+8875M94440750M00+00-88+00                  ?   \n",
      "   8362+N1230+2838       9970 B78+8875M94440750000+00-88+00                  ?   \n",
      "  N4003+8915-N2771       7683 B78+8875M94440750000+00-88+00                  ?   \n",
      " N5096-N5046-N8597       8547 B78+8875M944404B0000+00-88+00                  ?   \n"
     ]
    }
   ],
   "source": [
    "##=========================================##\n",
    "##   Test transformer on data generators   ##\n",
    "##=========================================##\n",
    "\n",
    "backend.test_transformer(transformer, train_gen, val_gen, test_gen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f7a52",
   "metadata": {},
   "source": [
    "##  5.  Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea411fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO get_callbacks: Registered training callback: LoggerCallback with loglvl=10\n",
      "   INFO get_callbacks: Registered training callback: EarlyStopping with monitor=val_masked_accuracy, mode=max, patience=6, restore_best_weights=True\n",
      "   INFO get_callbacks: Registeried training callback: AdaptiveLearningRate with decay_factor=0.3, patience=2, monitor=loss, mode=min, log_lvl=10\n",
      "   INFO get_callbacks: Registeried training callback: ModelCheckpoint with filepath=SSL_addition_generator_notebook_baseline_3layers_64width_1preblock_2023_04_18/model_checkpoint_epoch{epoch}_val_loss_{val_loss:.5}.h5\n",
      "   INFO get_callbacks: Registered training callback: LayerWeightsRecord with batch_frequency=4000, recursive=True\n"
     ]
    }
   ],
   "source": [
    "##===================================##\n",
    "##   Create callbacks for training   ##\n",
    "##===================================##\n",
    "\n",
    "callbacks = backend.get_callbacks(cfg_training, working_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INFO <module>: Begin model training with max_epochs=100000\n",
      "Epoch 1/100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 15:32:01.462935: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 292s 72ms/step - loss: 1.6316 - masked_accuracy: 0.4302 - val_loss: 1.7503 - val_masked_accuracy: 0.4045\n",
      "Epoch 2/100000\n",
      "4000/4000 [==============================] - 286s 71ms/step - loss: 1.3598 - masked_accuracy: 0.5198 - val_loss: 1.7133 - val_masked_accuracy: 0.4181\n",
      "Epoch 3/100000\n",
      "4000/4000 [==============================] - 291s 73ms/step - loss: 1.3286 - masked_accuracy: 0.5506 - val_loss: 1.9115 - val_masked_accuracy: 0.3854\n",
      "Epoch 4/100000\n",
      "4000/4000 [==============================] - ETA: 0s - loss: 1.5563 - masked_accuracy: 0.4870"
     ]
    }
   ],
   "source": [
    "##=================##\n",
    "##   Train model   ##\n",
    "##=================##\n",
    "\n",
    "do_train = cfg_training.get(\"train\", True)\n",
    "\n",
    "if do_train :\n",
    "    max_epochs = cfg_training[\"max_epochs\"]\n",
    "    logger.info(f\"Begin model training with max_epochs={max_epochs}\")\n",
    "    record = model.fit(train_gen, \n",
    "                       epochs          = max_epochs,\n",
    "                       validation_data = val_gen,\n",
    "                       callbacks       = callbacks\n",
    "                      )\n",
    "else :\n",
    "    record = {}\n",
    "    logger.warning(\"Skipping model training following global config instructions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb38943",
   "metadata": {},
   "outputs": [],
   "source": [
    "##================##\n",
    "##   Save model   ##\n",
    "##================##\n",
    "\n",
    "do_save = cfg_evaluate.get(\"save_model\", True)\n",
    "\n",
    "if do_save :\n",
    "    save_fname = f\"{working_dir}/final_model.h5\"\n",
    "    model.save(save_fname)\n",
    "    logger.info(f\"Model saved to file {save_fname}\")\n",
    "else :\n",
    "    logger.warning(\"Not saving model because no training was done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc69448",
   "metadata": {},
   "source": [
    "## 6.  Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c425ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "##  Find out how many datapoints to print predictions for \n",
    "num_print = cfg_evaluate.get(\"num_print\", 20)\n",
    "\n",
    "##  Print tables\n",
    "backend.test_transformer(transformer, train_gen, val_gen, test_gen, num_print=num_print)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfb55b",
   "metadata": {},
   "source": [
    "##  7. Additional visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e385e68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##=============================================##\n",
    "##   Visualise layer weights during training   ##\n",
    "##=============================================##\n",
    "\n",
    "if cfg_evaluate[\"plot_weights\"] :\n",
    "    \n",
    "    backend.plot_weights(callbacks, show=True, close=True, savefig=f\"{working_dir}/layer_weights.pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c358e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if cfg_evaluate[\"plot_training_curves\"] :\n",
    "    \n",
    "    backend.plot_training_curves(history.history, show=True, close=True, savefig=f\"{working_dir}/training_curves.pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca608a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
