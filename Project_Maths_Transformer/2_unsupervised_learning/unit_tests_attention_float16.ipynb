{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accaa3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"/\".join(os.getcwd().split(\"/\")[:-1]))\n",
    "\n",
    "import numpy      as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers     import Add, Average, Concatenate, Embedding, Input\n",
    "from tensorflow.keras.models     import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from mathsformer.tf_objects import (DecoderBlock, EncoderBlock, Enumerate, FeedForwardBlock, LearnableMixture, MaskedCategoricalAccuracy,\n",
    "                                    MaskedSparseCategoricalCrossentropy, PositionalEncoding)\n",
    "\n",
    "from mathsformer.data import RandomDataGenerator_Addition, TokenTransform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91e29504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_to_text_model(vocab_length:int, \n",
    "                              name:str, \n",
    "                              do_compile:bool     = True,\n",
    "                              dtype_in            = tf.int32, \n",
    "                              dtype               = tf.float32, \n",
    "                              dropout:float       = 0.1, \n",
    "                              jit_compile:bool    = None,\n",
    "                              optimizer           = Adam,\n",
    "                              optimizer_args:dict = None,\n",
    "                              pos_enc_num_freqs:int       = 16, pos_enc_min_period:float     = 5, pos_enc_max_period:float = 10000,\n",
    "                              pos_enc_learnable:bool      = False,\n",
    "                              ndim_embedding:int          = 32, comb_type:str                = \"average\",\n",
    "                              num_pre_layers_encoder:int  = 1 , ndim_pre_layers_encoder:int  = 128, skip_connect_pre_encoder:bool = True,\n",
    "                              num_pre_layers_decoder:int  = 1 , ndim_pre_layers_decoder:int  = 128, skip_connect_pre_decoder:bool = True,\n",
    "                              num_encoder_blocks:int      = 2 , ndim_encoder:int             = 32 , skip_connect_encoder:bool     = True,\n",
    "                              num_heads_encoder:int       = 8 , ndim_att_hidden_encoder:int  = 64 , ndim_ff_hidden_encoder:int    = 64  , \n",
    "                              num_decoder_blocks:int      = 2 , ndim_decoder:int             = 32 , skip_connect_decoder:bool     = True,\n",
    "                              num_heads_decoder:int       = 8 , ndim_att_hidden_decoder:int  = 64 , ndim_ff_hidden_decoder:int    = 64  , \n",
    "                              num_post_layers_decoder:int = 2 , ndim_post_layers_decoder:int = 128, \n",
    "                             ) :\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ##  Resolve mutable default args\n",
    "    if optimizer_args is None :\n",
    "        optimizer_args = {'learning_rate': 0.001}\n",
    "    \n",
    "    ##=============================================##\n",
    "    ##===   Input layer - Output shape [B, S]   ===##\n",
    "    ##=============================================##\n",
    "    x_in_enc = Input((None,), dtype=dtype_in, name=f\"{name}_encoder_input_layer\")\n",
    "    x_in_dec = Input((None,), dtype=dtype_in, name=f\"{name}_decoder_input_layer\")\n",
    "            \n",
    "    ##===========================================================================##\n",
    "    ##===  Token embedding, masking 0s - Output shape [B, S, ndim_embedding]  ===##\n",
    "    ##===========================================================================##\n",
    "    x_embed_enc = Embedding(vocab_length, \n",
    "                            ndim_embedding, \n",
    "                            mask_zero=True, \n",
    "                            dtype=dtype, \n",
    "                            name=f\"{name}_encoder_embedding\")(x_in_enc)\n",
    "    x_embed_dec = Embedding(vocab_length, \n",
    "                            ndim_embedding, \n",
    "                            mask_zero=True, \n",
    "                            dtype=dtype, \n",
    "                            name=f\"{name}_decoder_embedding\")(x_in_dec)\n",
    "    \n",
    "    model1 = Model(x_in_enc, x_embed_enc, name=\"model_encoder_embedding\")\n",
    "    model2 = Model(x_in_dec, x_embed_dec, name=\"model_decoder_embedding\")\n",
    "    \n",
    "    ##=========================================================================##\n",
    "    ##===  Enumerate indices for positional encoding - Output shape [B, S]  ===##\n",
    "    ##=========================================================================##\n",
    "    ##  -  if comb_type will lead to broadcasting with embeddings later on, then we don't need to repeat the enumerations\n",
    "    ##     along the batch axis and can use minimal_dims=True for an ouput of [1, S] instead. This saves us memory here\n",
    "    ##     and reduces the number of operations in the positional encoding step by a factor of B\n",
    "    minimal_dims = comb_type.lower() in [\"add\", \"sum\", \"average\", \"mean\", \"mixture\"]\n",
    "    x_pos_enc    = Enumerate(name=f\"{name}_encoder_enumerate\", dtype=dtype)(x_in_enc, minimal_dims=minimal_dims)\n",
    "    x_pos_dec    = Enumerate(name=f\"{name}_decoder_enumerate\", dtype=dtype)(x_in_dec, minimal_dims=minimal_dims)\n",
    "    \n",
    "    model3 = Model(x_in_enc, x_pos_enc, name=\"model_encoder_enum\")\n",
    "    model4 = Model(x_in_dec, x_pos_dec, name=\"model_decoder_enum\")\n",
    "    \n",
    "    ##========================================================================##\n",
    "    ##===  Positional encoding - Output shape [B, S, 2*pos_enc_num_freqs]  ===##\n",
    "    ##========================================================================##\n",
    "    x_pos_enc = PositionalEncoding(num_freqs  = pos_enc_num_freqs, \n",
    "                                   min_period = pos_enc_min_period, \n",
    "                                   max_period = pos_enc_max_period, \n",
    "                                   learnable  = pos_enc_learnable,\n",
    "                                   dtype      = dtype, \n",
    "                                   name       = f\"{name}_encoder_position_encoding\")(x_pos_enc)\n",
    "    x_pos_dec = PositionalEncoding(num_freqs  = pos_enc_num_freqs, \n",
    "                                   min_period = pos_enc_min_period, \n",
    "                                   max_period = pos_enc_max_period, \n",
    "                                   learnable  = pos_enc_learnable,\n",
    "                                   dtype      = dtype, \n",
    "                                   name       = f\"{name}_decoder_position_encoding\")(x_pos_dec)\n",
    "\n",
    "    model5 = Model(x_in_enc, x_pos_enc, name=\"model_encoder_pos_enc\")\n",
    "    model6 = Model(x_in_dec, x_pos_dec, name=\"model_decoder_pos_enc\")\n",
    "    \n",
    "    ##==============================================================================================##\n",
    "    ##===  Combine embeddings end pos enc - Output shape [B, S, N] where N depends on comb_type  ===##\n",
    "    ##==============================================================================================##\n",
    "    allowed_comb_types = [\"add\", \"sum\", \"average\", \"mean\", \"concat\", \"concatenate\", \"mixture\"]\n",
    "    match comb_type.lower() :\n",
    "        case \"add\" | \"sum\" :\n",
    "            x_enc = Add(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = Add(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case \"average\" | \"mean\" :\n",
    "            x_enc = Average(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = Average(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case \"concat\" | \"concatenate\" :\n",
    "            x_enc = Concatenate(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = Concatenate(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case \"mixture\" :\n",
    "            x_enc = LearnableMixture(name=f\"{name}_encoder_emb_and_pos\", dtype=dtype)([x_embed_enc, x_pos_enc])\n",
    "            x_dec = LearnableMixture(name=f\"{name}_decoder_emb_and_pos\", dtype=dtype)([x_embed_dec, x_pos_dec])\n",
    "        case _ :\n",
    "            raise RuntimeError(f\"comb_type '{comb_type}' not recognised, recognised keywords are {allowed_comb_types}\")\n",
    "\n",
    "    model7 = Model(x_in_enc, x_enc, name=\"model_encoder_comb\")\n",
    "    model8 = Model(x_in_dec, x_dec, name=\"model_decoder_comb\")\n",
    "    \n",
    "    ##=========================================================================##\n",
    "    ##===  Initial pre-processing - Output shape [B, S, ndim_(en/de)coder]  ===##\n",
    "    ##=========================================================================##\n",
    "    ##  - use layer_norm instead of batch_norm because elements in sequence are not independent\n",
    "    if num_pre_layers_encoder >= 0 :\n",
    "        x_enc = FeedForwardBlock(ndim_encoder, \n",
    "                                 ndim_hidden       = ndim_pre_layers_encoder, \n",
    "                                 num_hidden_layers = num_pre_layers_encoder, \n",
    "                                 dropout           = dropout, \n",
    "                                 layer_norm        = True, \n",
    "                                 batch_norm        = False,  \n",
    "                                 skip_connect      = skip_connect_pre_encoder, \n",
    "                                 dtype             = dtype, \n",
    "                                 name              = f\"{name}_encoder_feedfwd_block_pre_attention\")(x_enc)\n",
    "    if num_pre_layers_decoder >= 0 :\n",
    "        x_dec = FeedForwardBlock(ndim_decoder, \n",
    "                                 ndim_hidden       = ndim_pre_layers_decoder, \n",
    "                                 num_hidden_layers = num_pre_layers_decoder, \n",
    "                                 dropout           = dropout, \n",
    "                                 layer_norm        = True, \n",
    "                                 batch_norm        = False,  \n",
    "                                 skip_connect      = skip_connect_pre_decoder, \n",
    "                                 dtype             = dtype, \n",
    "                                 name              = f\"{name}_decoder_feedfwd_block_pre_attention\")(x_dec)\n",
    "    \n",
    "    model9  = Model(x_in_enc, x_enc, name=\"model_encoder_pre\")\n",
    "    model10 = Model(x_in_dec, x_dec, name=\"model_decoder_pre\")\n",
    "    \n",
    "    ##============================================================##\n",
    "    ##===  Encoder blocks - Output shape [B, S, ndim_encoder]  ===##\n",
    "    ##============================================================##\n",
    "    for layer_idx in range(num_encoder_blocks) :\n",
    "        x_enc = EncoderBlock(ndim_encoder, \n",
    "                             num_heads_encoder, \n",
    "                             ndim_att_hidden_encoder, \n",
    "                             ndim_ff_hidden_encoder, \n",
    "                             dropout_mha  = dropout, \n",
    "                             dtype        = dtype, \n",
    "                             layer_norm   = True, \n",
    "                             skip_connect = skip_connect_encoder, \n",
    "                             name         = f\"{name}_encoder_block_{layer_idx+1}\")(x_enc)\n",
    "    \n",
    "    model11 = Model(x_in_enc, x_enc, name=\"model_encoder\")\n",
    "    \n",
    "    ##============================================================##\n",
    "    ##===  Decoder blocks - Output shape [B, S, ndim_decoder]  ===##\n",
    "    ##============================================================##\n",
    "    for layer_idx in range(num_decoder_blocks) :\n",
    "        x_dec = DecoderBlock(ndim_decoder, \n",
    "                             num_heads_decoder, \n",
    "                             ndim_att_hidden_decoder, \n",
    "                             ndim_ff_hidden_decoder, \n",
    "                             dropout_mha  = dropout, \n",
    "                             dtype        = dtype, \n",
    "                             layer_norm   = True, \n",
    "                             skip_connect = skip_connect_decoder, \n",
    "                             name         = f\"{name}_decoder_block_{layer_idx+1}\")([x_dec, x_enc])\n",
    "        \n",
    "    model12 = Model([x_in_enc, x_in_dec], x_dec, name=\"model_decoder\")\n",
    "    \n",
    "    ##==================================================================================================##\n",
    "    ##===  Predict logit probabilities using feed-forward block - Output shape [B, S, vocab_length]  ===##\n",
    "    ##==================================================================================================##\n",
    "    ##  - use layer_norm instead of batch_norm because elements in sequence are not independent\n",
    "    x = FeedForwardBlock(vocab_length, \n",
    "                         ndim_hidden       = ndim_post_layers_decoder, \n",
    "                         num_hidden_layers = num_post_layers_decoder, \n",
    "                         skip_connect      = False, \n",
    "                         layer_norm        = True, \n",
    "                         batch_norm        = False, \n",
    "                         dtype             = dtype, \n",
    "                         name              = f\"{name}_feedfwd_block_post_attention\")(x_dec)\n",
    "        \n",
    "    model13 = Model([x_in_enc, x_in_dec], x, name=\"model_decoder_post\")\n",
    "    \n",
    "    ##  Create model\n",
    "    model = Model([x_in_enc, x_in_dec], x, name=name)\n",
    "    \n",
    "    ##  Compile model with sparse categorical crossentropy loss and accuracy metric\n",
    "    if do_compile :\n",
    "        acc  = MaskedCategoricalAccuracy(scalar_output=True, equal_token_weight=True, use_keras_mask=False, mask_value=0)\n",
    "        loss = MaskedSparseCategoricalCrossentropy(scalar_output=True, equal_token_weight=True, use_keras_mask=False, mask_value=0, from_logits=True)\n",
    "        model.compile(loss        = loss, \n",
    "                      optimizer   = optimizer(**optimizer_args), \n",
    "                      metrics     = [acc],\n",
    "                      jit_compile = jit_compile)\n",
    "    \n",
    "    ##  Return model\n",
    "    return [model1, model2, model3, model4, model5, model6, model7, model8, model9, model10, model11, model12, model13, model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45c0667e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Exception encountered when calling layer \"test_model_encoder_feedfwd_block_pre_attention\" (type FeedForwardBlock).\n\nin user code:\n\n    File \"/Users/Ste/PROJECTS/misc/ML-sandbox/ML-sandbox/Project_Maths_Transformer/mathsformer/tf_objects.py\", line 933, in call  *\n        if x_dims != y_dims : raise RuntimeError(f\"Cannot apply skip-connection combining tensors of different dimensions {x_dims} and {y_dims}\")\n\n    RuntimeError: Cannot apply skip-connection combining tensors of different dimensions 64 and 32\n\n\nCall arguments received by layer \"test_model_encoder_feedfwd_block_pre_attention\" (type FeedForwardBlock):\n  • x=tf.Tensor(shape=(None, None, 64), dtype=float16)\n  • training=None\n  • mask=tf.Tensor(shape=(None, None), dtype=bool)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_text_to_text_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomb_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconcat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 110\u001b[0m, in \u001b[0;36mcreate_text_to_text_model\u001b[0;34m(vocab_length, name, do_compile, dtype_in, dtype, dropout, jit_compile, optimizer, optimizer_args, pos_enc_num_freqs, pos_enc_min_period, pos_enc_max_period, pos_enc_learnable, ndim_embedding, comb_type, num_pre_layers_encoder, ndim_pre_layers_encoder, skip_connect_pre_encoder, num_pre_layers_decoder, ndim_pre_layers_decoder, skip_connect_pre_decoder, num_encoder_blocks, ndim_encoder, skip_connect_encoder, num_heads_encoder, ndim_att_hidden_encoder, ndim_ff_hidden_encoder, num_decoder_blocks, ndim_decoder, skip_connect_decoder, num_heads_decoder, ndim_att_hidden_decoder, ndim_ff_hidden_decoder, num_post_layers_decoder, ndim_post_layers_decoder)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m##=========================================================================##\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m##===  Initial pre-processing - Output shape [B, S, ndim_(en/de)coder]  ===##\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m##=========================================================================##\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m##  - use layer_norm instead of batch_norm because elements in sequence are not independent\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_pre_layers_encoder \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[0;32m--> 110\u001b[0m     x_enc \u001b[38;5;241m=\u001b[39m \u001b[43mFeedForwardBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mndim_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mndim_hidden\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mndim_pre_layers_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mnum_hidden_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_pre_layers_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mskip_connect\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_connect_pre_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_encoder_feedfwd_block_pre_attention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_enc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_pre_layers_decoder \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[1;32m    120\u001b[0m     x_dec \u001b[38;5;241m=\u001b[39m FeedForwardBlock(ndim_decoder, \n\u001b[1;32m    121\u001b[0m                              ndim_hidden       \u001b[38;5;241m=\u001b[39m ndim_pre_layers_decoder, \n\u001b[1;32m    122\u001b[0m                              num_hidden_layers \u001b[38;5;241m=\u001b[39m num_pre_layers_decoder, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m                              dtype             \u001b[38;5;241m=\u001b[39m dtype, \n\u001b[1;32m    128\u001b[0m                              name              \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_decoder_feedfwd_block_pre_attention\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x_dec)\n",
      "File \u001b[0;32m~/miniforge3/envs/py3p10_221222_tf_macos_only/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/__autograph_generated_filepymn422w.py:48\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, x, training, mask)\u001b[0m\n\u001b[1;32m     46\u001b[0m y_dims \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_dims\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     47\u001b[0m x_dims \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_dims\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskip_connect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/__autograph_generated_filepymn422w.py:40\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body\u001b[39m():\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dims\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_dims\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m y \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_average, ([ag__\u001b[38;5;241m.\u001b[39mld(x), ag__\u001b[38;5;241m.\u001b[39mld(y)],), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(training)), fscope)\n",
      "File \u001b[0;32m/var/folders/6_/gprzxt797d5098h8dtk22nch0000gn/T/__autograph_generated_filepymn422w.py:36\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_1.<locals>.if_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mif_body\u001b[39m():\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;167;01mRuntimeError\u001b[39;00m), (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot apply skip-connection combining tensors of different dimensions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(x_dims)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(y_dims)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception encountered when calling layer \"test_model_encoder_feedfwd_block_pre_attention\" (type FeedForwardBlock).\n\nin user code:\n\n    File \"/Users/Ste/PROJECTS/misc/ML-sandbox/ML-sandbox/Project_Maths_Transformer/mathsformer/tf_objects.py\", line 933, in call  *\n        if x_dims != y_dims : raise RuntimeError(f\"Cannot apply skip-connection combining tensors of different dimensions {x_dims} and {y_dims}\")\n\n    RuntimeError: Cannot apply skip-connection combining tensors of different dimensions 64 and 32\n\n\nCall arguments received by layer \"test_model_encoder_feedfwd_block_pre_attention\" (type FeedForwardBlock):\n  • x=tf.Tensor(shape=(None, None, 64), dtype=float16)\n  • training=None\n  • mask=tf.Tensor(shape=(None, None), dtype=bool)"
     ]
    }
   ],
   "source": [
    "models = create_text_to_text_model(32, name=\"test_model\", dtype=tf.float16, comb_type=\"concat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89794868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'test_model_encoder_position_encoding_frequencies:0' shape=(1, 16) dtype=float16, numpy=\n",
       " array([[6.285e-04, 1.043e-03, 1.731e-03, 2.872e-03, 4.768e-03, 7.919e-03,\n",
       "         1.314e-02, 2.180e-02, 3.619e-02, 6.009e-02, 9.973e-02, 1.655e-01,\n",
       "         2.749e-01, 4.561e-01, 7.568e-01, 1.257e+00]], dtype=float16)>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[4].layers[-1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0611061b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_encoder_embedding float16\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.002018\n",
      "0.002018\n",
      "model_decoder_embedding float16\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.001136\n",
      "0.001136\n",
      "model_encoder_enum float16\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1.5\n",
      "1.5\n",
      "model_decoder_enum float16\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1.5\n",
      "1.5\n",
      "model_encoder_pos_enc float16\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "0.5024\n",
      "0.5024\n",
      "model_decoder_pos_enc float16\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "0.5024\n",
      "0.5024\n",
      "model_encoder_comb float16\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "0.0\n",
      "0.2524\n",
      "model_decoder_comb float16\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "0.0\n",
      "0.252\n",
      "model_encoder_pre float16\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "nan\n",
      "0.3079\n",
      "model_decoder_pre float16\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "nan\n",
      "0.064\n",
      "model_encoder float16\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "nan\n",
      "0.0265\n",
      "model_decoder float16\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "nan\n",
      "0.1294\n",
      "model_decoder_post float16\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "nan\n",
      "-0.01807\n",
      "test_model float16\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "nan\n",
      "-0.01807\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(low=0, high=32, size=(2, 4))\n",
    "Y = np.random.randint(low=0, high=32, size=(2, 4))\n",
    "\n",
    "for model in models :\n",
    "    inp = [X, Y] if type(model.input) is list else X\n",
    "    print(model.name, model.layers[-1].dtype)\n",
    "    print(np.mean(model.predict(inp)))\n",
    "    print(np.mean(model(inp, training=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb64f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 822ms/step - loss: nan - masked_categorical_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "token_transform = TokenTransform(['M', 'B', 'E', 'N', '+', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], \n",
    "                                mask_char='M', seq_start_char='B', seq_end_char='E')\n",
    "\n",
    "gen = RandomDataGenerator_Addition(token_transform, int_lengths=[3], num_ints=[3], batch_size=32, num_batches=1, negative_char='N')\n",
    "\n",
    "models[-1].evaluate(gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dbbf6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 309ms/step\n"
     ]
    }
   ],
   "source": [
    "[X1, X2], Y_true = gen[0]\n",
    "\n",
    "Y_pred = models[-1].predict([X1, X2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e129594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f47fc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnum_test = 1\\nX = np.random.randint(2, size=(num_test, 4), dtype=np.int32)\\nX = tf.constant(X)\\nprint(X)\\n\\nfor dtype in [tf.float16, tf.float32] :\\n    for use_causal_mask in [True, False] :\\n        print(dtype, use_causal_mask)\\n        m = create_model(dtype=dtype, use_causal_mask=use_causal_mask)\\n        Y = m(X)\\n        print(Y)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "num_test = 1\n",
    "X = np.random.randint(2, size=(num_test, 4), dtype=np.int32)\n",
    "X = tf.constant(X)\n",
    "print(X)\n",
    "\n",
    "for dtype in [tf.float16, tf.float32] :\n",
    "    for use_causal_mask in [True, False] :\n",
    "        print(dtype, use_causal_mask)\n",
    "        m = create_model(dtype=dtype, use_causal_mask=use_causal_mask)\n",
    "        Y = m(X)\n",
    "        print(Y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "211ef5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nm = create_model(dtype=tf.float16, use_causal_mask=True)\\nl = m.layers[2]\\nprint(l.dtype)\\nfor d in l.get_weights() :\\n    print(d.dtype, d.shape)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "m = create_model(dtype=tf.float16, use_causal_mask=True)\n",
    "l = m.layers[2]\n",
    "print(l.dtype)\n",
    "for d in l.get_weights() :\n",
    "    print(d.dtype, d.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2de354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
