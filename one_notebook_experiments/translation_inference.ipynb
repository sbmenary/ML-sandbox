{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac539285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_text\n",
    "\n",
    "from tensorflow.keras.layers import Add, Concatenate, Dense, Dropout, Embedding, Input, Layer, LayerNormalization, Softmax\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff37013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================\n",
    "#===  Create keras layer for dot-product attention  ===\n",
    "#======================================================\n",
    "\n",
    "class LinearDotProductAttention(Layer) :\n",
    "    def __init__(self, dk, dv, same_transform_QK=False, same_transform_KV=False, use_causal_mask=False):\n",
    "        \"\"\"\n",
    "        Init docstring\n",
    "        \"\"\"\n",
    "        ##  Initialise base class\n",
    "        super().__init__()\n",
    "        \n",
    "        ##  Store dimension information\n",
    "        self.dk      = dk\n",
    "        self.dv      = dv\n",
    "        self.sqrt_dk = np.sqrt(dk)\n",
    "        self.use_causal_mask = use_causal_mask\n",
    "        \n",
    "        ##  Create Softmax layer, which can handle masking whereas tf.nn.softmax cannot\n",
    "        self.softmax = Softmax()\n",
    "        \n",
    "        ##  Create Dense transform of query feature vectors\n",
    "        self.query_transform = Dense(dk)\n",
    "        \n",
    "        ##  Create Dense transform of key feature vectors\n",
    "        if same_transform_QK : self.key_transform = self.query_transform\n",
    "        else                 : self.key_transform = Dense(dk)\n",
    "            \n",
    "        ##  Create Dense transform of value feature vectors\n",
    "        if same_transform_KV : \n",
    "            if dk != dk :\n",
    "                raise ValueError(f\"Can only use same transform for keys and values if dk (={dk}) \\\n",
    "                                   is equal to dv (={dv})\")\n",
    "            self.value_transform = self.key_transform\n",
    "        else : \n",
    "            self.value_transform = Dense(dv)\n",
    "                    \n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"\n",
    "        Call docstring\n",
    "        \"\"\"\n",
    "        ##  Resolve inputs\n",
    "        if len(inputs) != 2 : raise ValueError(f\"inputs of length {len(inputs)}, expected 2\")\n",
    "        query_features = inputs[0]  # shape [batch_size, query_sequence_length, query_feature_length]\n",
    "        ref_features   = inputs[1]  # shape [batch_size, ref_sequence_length  , ref_feature_length  ]\n",
    "                \n",
    "        ##  Calculate Q, K, V matrices\n",
    "        Q = self.query_transform(query_features, training=training)  # shape [batch_size, query_sequence_length, dk]\n",
    "        K = self.key_transform  (ref_features  , training=training)  # shape [batch_size, ref_sequence_length  , dk]\n",
    "        V = self.value_transform(ref_features  , training=training)  # shape [batch_size, ref_sequence_length  , dv]\n",
    "                \n",
    "        ##  Calculate transpose of K, without modifying the first axis which indexes batch samples\n",
    "        K_T = tf.transpose(K, perm=[0,2,1])  # shape [batch_size, dk, ref_sequence_length]\n",
    "                \n",
    "        ##  Calculate dot-product attention scores\n",
    "        x = tf.matmul(Q, K_T)             # shape [batch_size, query_sequence_length, ref_sequence_length]\n",
    "        x = x / self.sqrt_dk              # shape [batch_size, query_sequence_length, ref_sequence_length]\n",
    "        \n",
    "        ##  Create a causal mask on-the-fly if needed\n",
    "        mask = None\n",
    "        if self.use_causal_mask :\n",
    "            mask_shape = tf.shape(x)\n",
    "            mask = self._create_causal_mask(mask_shape)\n",
    "                \n",
    "        ##  Calculate attention weights\n",
    "        x = self.softmax(x, mask=mask, training=training)   # shape [batch_size, query_sequence_length, ref_sequence_length]\n",
    "                        \n",
    "        ##  Attend to reference sequence and return updated feature vector of length dv\n",
    "        x = tf.matmul(x, V)              # shape [batch_size, query_sequence_length, dv] \n",
    "                \n",
    "        return x\n",
    "    \n",
    "    def _create_causal_mask(self, mask_shape) :\n",
    "        \"\"\"\n",
    "        Method docstring\n",
    "        - using trick for creating causal mask from from keras base_dense_attention class method\n",
    "        - https://github.com/keras-team/keras/blob/e6784e4302c7b8cd116b74a784f4b78d60e83c26/keras/layers/attention/base_dense_attention.py\n",
    "        Mask is 1 for elements that we want to include, 0 for elements we want to exclude\n",
    "        Axis -1 is the \"reference sequence\" index\n",
    "        Axis -2 is the \"query sequence\" index\n",
    "        We want mask to be 1 only when Axis -1 <= Axis -2, the same as Axis -2 >= Axis -1\n",
    "        With indices [row, col], we have 1 when row >= col, giving a lower triangular matrix\n",
    "        \"\"\"\n",
    "        ones_like_x = tf.ones(shape=mask_shape, dtype=tf.int32)\n",
    "        query_index = tf.cumsum(ones_like_x, axis=-2)\n",
    "        ref_index   = tf.cumsum(ones_like_x, axis=-1)\n",
    "        return tf.greater_equal(query_index, ref_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "429d9e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================================\n",
    "#===  Create keras layer for multi-head attention  ===\n",
    "#=====================================================\n",
    "\n",
    "class MultiHeadAttention(Layer) :\n",
    "    \"\"\"\n",
    "    Class docstring\n",
    "    \"\"\"\n",
    "    def __init__(self, num_heads, d_out, dk_per_head, dv_per_head, use_causal_mask=True, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Init docstring\n",
    "        \"\"\"\n",
    "        ##  Initialise base class\n",
    "        super().__init__()\n",
    "        \n",
    "        ##  Store dimension information\n",
    "        self.num_heads       = num_heads\n",
    "        self.d_out           = d_out\n",
    "        self.dk_per_head     = dk_per_head   \n",
    "        self.dv_per_head     = dv_per_head\n",
    "        self.use_causal_mask = use_causal_mask\n",
    "        \n",
    "        ##  Create heads\n",
    "        self.heads = [LinearDotProductAttention(self.dk_per_head, self.dv_per_head, use_causal_mask=use_causal_mask) \n",
    "                      for hi in range(num_heads)]\n",
    "                    \n",
    "        ##  Create other keras layers\n",
    "        self.concat  = Concatenate()\n",
    "        self.linear  = Dense(d_out)\n",
    "        self.dropout = Dropout(dropout)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"\n",
    "        Call docstring\n",
    "        \"\"\"    \n",
    "        ##  Calculate attention heads\n",
    "        #        shape [batch_size, query_sequence_length, dv] for each list element\n",
    "        x = [head(inputs, training=training) for head in self.heads]\n",
    "        \n",
    "        ##  Concatenate heads and project onto single output\n",
    "        x = self.concat (x)\n",
    "        x = self.dropout(x, training=training)  \n",
    "        x = self.linear (x, training=training)     \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f71f2d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================\n",
    "#===  Create keras layer for encoder block  ===\n",
    "#==============================================\n",
    "\n",
    "class EncoderBlock(Layer) :\n",
    "    \"\"\"\n",
    "    Class docstring\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dk_per_head, dv_per_head, dff, dropout=0.1, name=\"\"):\n",
    "        \"\"\"\n",
    "        Init docstring\n",
    "        \"\"\"\n",
    "        ##  Initialise base class\n",
    "        super().__init__()\n",
    "        \n",
    "        ##  Store dimension information\n",
    "        self.d_model     = d_model\n",
    "        self.num_heads   = num_heads\n",
    "        self.dk_per_head = dk_per_head\n",
    "        self.dv_per_head = dv_per_head\n",
    "        self.dff         = dff\n",
    "        \n",
    "        ##  Create attention layer\n",
    "        self.mha = MultiHeadAttention(num_heads, d_model, dk_per_head, dv_per_head)\n",
    "                    \n",
    "        ##  Create other keras layers\n",
    "        self.add1    = Add()\n",
    "        self.norm1   = LayerNormalization()\n",
    "        self.add2    = Add()\n",
    "        self.norm2   = LayerNormalization()\n",
    "        self.dense1  = Dense(dff, activation=\"relu\")\n",
    "        self.dense2  = Dense(d_model)\n",
    "        self.dropout = Dropout(dropout)\n",
    "        \n",
    "    def call(self, query_features, training=False):\n",
    "        \"\"\"\n",
    "        Call docstring\n",
    "        \"\"\"\n",
    "        ##  Calculate multi-head attention\n",
    "        x_skip = query_features\n",
    "        x = self.mha([query_features, query_features], training=training)   # shape [batch_size, query_sequence_length, d_model] \n",
    "                \n",
    "        ##  Combine attention output with skip-connection\n",
    "        x = self.add1([x, x_skip], training=training)    # shape [batch_size, query_sequence_length, d_model] \n",
    "        x = self.norm1(x, training=training)             # shape [batch_size, query_sequence_length, d_model] \n",
    "        x_skip = x\n",
    "                \n",
    "        ##  Feed-forward processing of linearly-combined feature vectors from each head\n",
    "        x = self.dense1 (x, training=training)            # shape [batch_size, query_sequence_length, dff] \n",
    "        x = self.dense2 (x, training=training)            # shape [batch_size, query_sequence_length, d_model] \n",
    "        x = self.dropout(x, training=training)            # shape [batch_size, query_sequence_length, d_model] \n",
    "                \n",
    "        ##  Skip-connect and return\n",
    "        x = self.add2([x, x_skip], training=training)    # shape [batch_size, query_sequence_length, d_model] \n",
    "        x = self.norm2(x, training=training)             # shape [batch_size, query_sequence_length, d_model]     \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af25a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer) :\n",
    "    \n",
    "    def __init__(self, d_in, d_model) :\n",
    "        \"\"\"\n",
    "        Init docstring\n",
    "        \"\"\"\n",
    "        ##  Initialise base class\n",
    "        super().__init__()\n",
    "        \n",
    "        ##  Store dimension information\n",
    "        self.d_in      = d_in\n",
    "        self.d_model   = d_model\n",
    "        \n",
    "        ##  Store Tensor object with pre-computed positional encodings\n",
    "        self.encoded_positions = self.create_encoded_positions_tensor(d_in, d_model)\n",
    "\n",
    "    def call(self, x) :\n",
    "        \"\"\"\n",
    "        Call docstring\n",
    "        \"\"\"\n",
    "        ##  Return slice of stored encoded_positions Tensor with correct shape\n",
    "        length = tf.shape(x)[1]\n",
    "        return self.encoded_positions[tf.newaxis, :length, :]\n",
    "    \n",
    "    def create_encoded_positions_tensor(self, d_in, d_model) :\n",
    "        \"\"\"\n",
    "        Method docstring\n",
    "        \"\"\"\n",
    "        ##  Create numpy array with positions\n",
    "        positions = np.arange(d_in)   # shape (d_in)\n",
    "        \n",
    "        ##  Combine with indices to create 2D array of angles\n",
    "        half_indices = np.arange(d_model/2)   # shape (d_model/2)\n",
    "        angles = (10000**(-half_indices))     # shape (d_model/2)\n",
    "        angles = np.outer(positions, angles)  # shape (d_in, d_model/2)\n",
    "\n",
    "        ##  Interleave sing and cos of angles into single 2D array of positional encodings\n",
    "        pos_encoding = np.concatenate([np.sin(angles), np.cos(angles)], axis=-1)   # shape (d_in, d_model)\n",
    "\n",
    "        ##  Return Tensor of positional encodings\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b46a34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================\n",
    "#===  Create keras layer for encoder  ===\n",
    "#========================================\n",
    "\n",
    "class Encoder(Layer) :\n",
    "    \"\"\"\n",
    "    Class docstring\n",
    "    \"\"\"\n",
    "    def __init__(self, num_blocks, d_in, d_model, num_heads, dk_per_head, dv_per_head, dff):\n",
    "        \"\"\"\n",
    "        Init docstring\n",
    "        \"\"\"\n",
    "        ##  Initialise base class\n",
    "        super().__init__()\n",
    "        \n",
    "        ##  Store dimension information\n",
    "        self.num_blocks  = num_blocks\n",
    "        self.d_model     = d_model\n",
    "        self.num_heads   = num_heads\n",
    "        self.dk_per_head = dk_per_head\n",
    "        self.dv_per_head = dv_per_head\n",
    "        self.dff         = dff\n",
    "        self.emb_scalar  = tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "                    \n",
    "        ##  Create embedding layers\n",
    "        self.add               = Add()\n",
    "        self.token_embedding   = Embedding(d_in, d_model, mask_zero=True)\n",
    "        self.position_encoding = PositionalEncoding(d_in, d_model)\n",
    "        \n",
    "        ##  Create encoder block layers\n",
    "        self.encoder_blocks = [EncoderBlock(d_model, num_heads, dk_per_head, dv_per_head, dff) \n",
    "                               for ei in range(num_blocks)]\n",
    "        \n",
    "    def call(self, query_features, training=False):\n",
    "        \"\"\"\n",
    "        Call docstring\n",
    "        \"\"\"\n",
    "        ##  Calculate embeddings\n",
    "        token_embedding   = self.token_embedding(query_features, training=training) # shape [batch_size, query_sequence_length, d_model]\n",
    "        token_embedding  *= self.emb_scalar                                         # shape [batch_size, query_sequence_length, d_model]\n",
    "        position_encoding = self.position_encoding(query_features)                  # shape [batch_size, query_sequence_length, d_model]\n",
    "        x = self.add([token_embedding, position_encoding], training=training)       # shape [batch_size, query_sequence_length, d_model] \n",
    "                \n",
    "        ##  Pass through encoder blocks\n",
    "        for encoder_block in self.encoder_blocks :\n",
    "            x = encoder_block(x, training=training)\n",
    "            \n",
    "        ##  Return encoded sequence\n",
    "        return x\n",
    "    \n",
    "    '''def compute_mask(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Method docstring\n",
    "        \"\"\"\n",
    "        return self.token_embedding.compute_mask(*args, **kwargs)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa8af5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================\n",
    "#===  Create keras layer for encoder block  ===\n",
    "#==============================================\n",
    "\n",
    "class DecoderBlock(Layer) :\n",
    "    \"\"\"\n",
    "    Class docstring\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dk_per_head, dv_per_head, dff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Init docstring\n",
    "        \"\"\"\n",
    "        ##  Initialise base class\n",
    "        super().__init__()\n",
    "        \n",
    "        ##  Store dimension information\n",
    "        self.d_model     = d_model\n",
    "        self.num_heads   = num_heads\n",
    "        self.dk_per_head = dk_per_head\n",
    "        self.dv_per_head = dv_per_head\n",
    "        self.dff         = dff\n",
    "        \n",
    "        ##  Create attention layers\n",
    "        self.masked_attention = MultiHeadAttention(num_heads, d_model, dk_per_head, dv_per_head, use_causal_mask=True )\n",
    "        self.cross_attention  = MultiHeadAttention(num_heads, d_model, dk_per_head, dv_per_head, use_causal_mask=False)\n",
    "                    \n",
    "        ##  Create other keras layers\n",
    "        self.add1    = Add()\n",
    "        self.norm1   = LayerNormalization()\n",
    "        self.add2    = Add()\n",
    "        self.norm2   = LayerNormalization()\n",
    "        self.add3    = Add()\n",
    "        self.norm3   = LayerNormalization()\n",
    "        self.dense1  = Dense(dff, activation=\"relu\")\n",
    "        self.dense2  = Dense(d_model)\n",
    "        self.dropout = Dropout(dropout)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"\n",
    "        Call docstring\n",
    "        \"\"\"\n",
    "        ##  Resolve inputs\n",
    "        if len(inputs) != 2 : raise ValueError(f\"inputs of length {len(inputs)}, expected 2\")\n",
    "        decoder_input  = inputs[0]\n",
    "        encoder_output = inputs[1]\n",
    "        \n",
    "        ##  Calculate masked self-attention\n",
    "        x_skip = decoder_input\n",
    "        x = self.masked_attention([decoder_input, decoder_input], training=training)   # shape [batch_size, query_sequence_length, d_model] \n",
    "                \n",
    "        ##  Combine attention output with skip-connection\n",
    "        x = self.add1([x, x_skip], training=training)          # shape [batch_size, query_sequence_length, d_model] \n",
    "        x = self.norm1(x, training=training)                   # shape [batch_size, query_sequence_length, d_model] \n",
    "        x_skip = x\n",
    "        \n",
    "        ##  Calculate cross-attention\n",
    "        x = self.cross_attention([x, encoder_output], training=training)   # shape [batch_size, query_sequence_length, d_model] \n",
    "                \n",
    "        ##  Combine attention output with skip-connection\n",
    "        x = self.add2([x, x_skip], training=training)          # shape [batch_size, query_sequence_length, d_model] \n",
    "        x = self.norm2(x, training=training)                   # shape [batch_size, query_sequence_length, d_model] \n",
    "        x_skip = x\n",
    "        \n",
    "        ##  Feed-forward processing of linearly-combined feature vectors from each head\n",
    "        x = self.dense1 (x, training=training)            # shape [batch_size, query_sequence_length, dff] \n",
    "        x = self.dense2 (x, training=training)            # shape [batch_size, query_sequence_length, d_model] \n",
    "        x = self.dropout(x, training=training)            # shape [batch_size, query_sequence_length, d_model] \n",
    "                \n",
    "        ##  Skip-connect and return\n",
    "        x = self.add3([x, x_skip], training=training)          # shape [batch_size, query_sequence_length, d_model] \n",
    "        x = self.norm3(x, training=training)                   # shape [batch_size, query_sequence_length, d_model] \n",
    "                \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11af44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================\n",
    "#===  Create keras layer for decoder  ===\n",
    "#========================================\n",
    "\n",
    "class Decoder(Layer) :\n",
    "    \"\"\"\n",
    "    Class docstring\n",
    "    \"\"\"\n",
    "    def __init__(self, num_blocks, d_in, d_model, num_heads, dk_per_head, dv_per_head, dff, name=\"\"):\n",
    "        \"\"\"\n",
    "        Init docstring\n",
    "        \"\"\"\n",
    "        ##  Initialise base class\n",
    "        super().__init__()\n",
    "        \n",
    "        ##  Store dimension information\n",
    "        self.num_blocks  = num_blocks\n",
    "        self.d_in        = d_in\n",
    "        self.d_model     = d_model\n",
    "        self.num_heads   = num_heads\n",
    "        self.dk_per_head = dk_per_head\n",
    "        self.dv_per_head = dv_per_head\n",
    "        self.dff         = dff\n",
    "        self.emb_scalar  = tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "                    \n",
    "        ##  Create embedding layers\n",
    "        self.add               = Add()\n",
    "        self.token_embedding   = Embedding(d_in, d_model, mask_zero=True)\n",
    "        self.position_encoding = PositionalEncoding(d_in, d_model)\n",
    "        \n",
    "        ##  Create decoder block layers\n",
    "        self.decoder_blocks = [DecoderBlock(d_model, num_heads, dk_per_head, dv_per_head, dff) \n",
    "                               for ei in range(num_blocks)]\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"\n",
    "        Call docstring\n",
    "        \"\"\"\n",
    "        ##  Resolve inputs\n",
    "        if len(inputs) != 2 : raise ValueError(f\"inputs of length {len(inputs)}, expected 2\")\n",
    "        decoder_input  = inputs[0]\n",
    "        encoder_output = inputs[1]\n",
    "        \n",
    "        ##  Calculate embeddings\n",
    "        token_embedding   = self.token_embedding(decoder_input, training=training) # shape [batch_size, query_sequence_length, d_model]\n",
    "        token_embedding  *= self.emb_scalar                                        # shape [batch_size, query_sequence_length, d_model]\n",
    "        position_encoding = self.position_encoding(decoder_input)                  # shape [batch_size, query_sequence_length, d_model]\n",
    "        x = self.add([token_embedding, position_encoding], training=training)      # shape [batch_size, query_sequence_length, d_model] \n",
    "                \n",
    "        ##  Pass through decoder blocks\n",
    "        for decoder_block in self.decoder_blocks :\n",
    "            x = decoder_block([x, encoder_output], training=training)\n",
    "            \n",
    "        ##  Return token probabilities\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03e32be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================\n",
    "#===  Create keras layer for decoder  ===\n",
    "#========================================\n",
    "\n",
    "class Transformer(Layer) :\n",
    "    \"\"\"\n",
    "    Class docstring\n",
    "    \"\"\"\n",
    "    def __init__(self, num_blocks, d_in, d_out, d_model, num_heads, dk_per_head, dv_per_head, dff):\n",
    "        \"\"\"\n",
    "        Init docstring\n",
    "        \"\"\"\n",
    "        ##  Initialise base class\n",
    "        super().__init__()\n",
    "        \n",
    "        ##  Store dimension information\n",
    "        self.num_blocks  = num_blocks\n",
    "        self.d_in        = d_in\n",
    "        self.d_out       = d_out\n",
    "        self.d_model     = d_model\n",
    "        self.num_heads   = num_heads\n",
    "        self.dk_per_head = dk_per_head\n",
    "        self.dv_per_head = dv_per_head\n",
    "        self.dff         = dff\n",
    "        self.emb_scalar  = tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "                    \n",
    "        ##  Create encoder and decoder layers\n",
    "        self.encoder = Encoder(num_blocks, d_in , d_model, num_heads, dk_per_head, dv_per_head, dff)\n",
    "        self.decoder = Decoder(num_blocks, d_out, d_model, num_heads, dk_per_head, dv_per_head, dff)\n",
    "                \n",
    "        ##  Create layers to convert decoder output to token probabilities\n",
    "        self.linear  = Dense(d_out)\n",
    "        self.softmax = Softmax()\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"\n",
    "        Call docstring\n",
    "        \"\"\"\n",
    "        ##  Resolve inputs\n",
    "        if len(inputs) != 2 : raise ValueError(f\"inputs of length {len(inputs)}, expected 2\")\n",
    "        encoder_input = inputs[0]\n",
    "        decoder_input = inputs[1]\n",
    "        \n",
    "        ##  Calculate encoding\n",
    "        x = self.encoder(encoder_input, training=training)\n",
    "                \n",
    "        ##  Calculate decoding\n",
    "        x = self.decoder([decoder_input, x], training=training)\n",
    "                        \n",
    "        ##  Turn decoder outputs into token probabilities\n",
    "        x = self.linear (x, training=training)\n",
    "        x = self.softmax(x, training=training)\n",
    "            \n",
    "        ##  Return token probabilities\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d33875a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "#===  Create method for building simple model that performs the decoding  ===\n",
    "#============================================================================\n",
    "\n",
    "def build_transformer_model(num_blocks, d_in, d_out, d_model, num_heads, dk_per_head, dv_per_head, dff, name=None) :\n",
    "    \"\"\"\n",
    "    Method docstring\n",
    "    \"\"\" \n",
    "    ##  Create model inputs\n",
    "    original_message   = Input((None,))\n",
    "    translated_message = Input((None,))\n",
    "    \n",
    "    ##  Perform attention step\n",
    "    x = Transformer(num_blocks, d_in, d_out, d_model, num_heads, dk_per_head, dv_per_head, dff)([original_message, translated_message])\n",
    "    \n",
    "    ##  Create model\n",
    "    model = Model([original_message, translated_message], x, name=name)\n",
    "    \n",
    "    ##  Return\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e75fda06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer_1 (Transformer)    (None, None, 7010)   10184162    ['input_3[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,184,162\n",
      "Trainable params: 10,184,162\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#==============================================================\n",
    "#===  Build and print model to check for structural errors  ===\n",
    "#==============================================================\n",
    "\n",
    "d_in        = 7765    # portuguese vocab size\n",
    "d_out       = 7010    # english vocab size\n",
    "d_model     = 128\n",
    "num_blocks  = 4\n",
    "num_heads   = 8\n",
    "dk_per_head = d_model  # int(d_model / num_heads)\n",
    "dv_per_head = d_model  # int(d_model / num_heads)\n",
    "dff         = 512\n",
    "\n",
    "transformer = build_transformer_model(num_blocks, d_in, d_out, d_model, num_heads, dk_per_head, dv_per_head, \n",
    "                                      dff, name=\"transformer\")\n",
    "\n",
    "transformer.summary(expand_nested=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bc351ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 7010), dtype=float32, numpy=\n",
       "array([[[1.74837885e-04, 1.42590186e-04, 1.58885814e-04, ...,\n",
       "         9.54626012e-05, 1.51287401e-04, 1.15952156e-04],\n",
       "        [1.75502399e-04, 1.42746474e-04, 1.57207760e-04, ...,\n",
       "         9.56099975e-05, 1.51239874e-04, 1.16575655e-04]]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer([tf.cast([[2, 5, 912, 3]], dtype=tf.int32), tf.cast([[2, 84]], dtype=tf.int32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20dd468d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2ca5be350>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_weights_fname = 'saved_model/transformer_weights'\n",
    "\n",
    "transformer.load_weights(model_weights_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cfd1be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 7010), dtype=float32, numpy=\n",
       "array([[[1.74837885e-04, 1.42590186e-04, 1.58885814e-04, ...,\n",
       "         9.54626012e-05, 1.51287401e-04, 1.15952156e-04],\n",
       "        [1.75502399e-04, 1.42746474e-04, 1.57207760e-04, ...,\n",
       "         9.56099975e-05, 1.51239874e-04, 1.16575655e-04]]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer([tf.cast([[2, 5, 912, 3]], dtype=tf.int32), tf.cast([[2, 84]], dtype=tf.int32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee2d25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer_model_fname = 'ted_hrlr_translate_pt_en_converter'\n",
    "\n",
    "tokenizers = tf.saved_model.load(tokenizer_model_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f682cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def translate_sentence(sentence, transformer, tokenizers, max_tokens=100) :\n",
    "    with tf.device(\"CPU\") :\n",
    "        tokenised_sentence = tokenizers.pt.tokenize([sentence]).to_tensor()\n",
    "        print(tokenised_sentence)\n",
    "        \n",
    "        start_end   = tokenizers.en.tokenize([''])[0]\n",
    "        begin_token = start_end[0 ]\n",
    "        end_token   = start_end[-1]\n",
    "        \n",
    "        tokenised_translated_sentence = tf.cast([[begin_token]], dtype=tf.int64)\n",
    "                \n",
    "        best_token, num_tokens = begin_token, 1\n",
    "        while best_token != end_token and num_tokens < max_tokens :\n",
    "            #print(\"CALL\")\n",
    "            #print(tokenised_sentence)\n",
    "            #print(tokenised_translated_sentence)\n",
    "            token_probs = transformer([tokenised_sentence, tokenised_translated_sentence])\n",
    "            #print(token_probs[0,-1,:])\n",
    "            #print(token_probs[0,-1,5906:5911])\n",
    "            best_token  = tf.argmax(token_probs[0,-1,:], axis=-1)\n",
    "            tokenised_translated_sentence = tf.concat([tokenised_translated_sentence, \n",
    "                                                       tf.reshape(best_token, (1,1))],\n",
    "                                                      axis=-1)\n",
    "            num_tokens += 1\n",
    "            \n",
    "        translated_sentence = tokenizers.en.detokenize(tokenised_translated_sentence)[0]\n",
    "        return translated_sentence.numpy().decode('utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "475d2217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[   2 1616   14   97  483  105   14  138  693   93  266    3]], shape=(1, 12), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates primates'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_sentence('Olá, como você está, minha cabeça dói', transformer, tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6213b2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi , as you are , my head , i ' m voice .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenised_translated_sentence = tf.cast([[2, 2265,   13,  100,   79,   86,   13,   99,  589,   13,   45,\n",
    "           9,   49,  613,   15,    3]], dtype=tf.int64)\n",
    "translated_sentence = tokenizers.en.detokenize(tokenised_translated_sentence)[0]\n",
    "print(translated_sentence.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1561395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "    mask = label != 0\n",
    "    #loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "    loss = loss_object(label, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "    pred = tf.argmax(pred, axis=2)\n",
    "    label = tf.cast(label, pred.dtype)\n",
    "    match = label == pred\n",
    "\n",
    "    mask = label != 0\n",
    "\n",
    "    match = match & mask\n",
    "\n",
    "    match = tf.cast(match, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30092a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformer.compile(loss=masked_loss, optimizer=\"adam\", metrics=[masked_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1f51a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 45s 2s/step - loss: 7.5399 - masked_accuracy: 0.0440 - val_loss: 7.0122 - val_masked_accuracy: 0.0281\n"
     ]
    }
   ],
   "source": [
    "train_batches = tf.data.Dataset.load(\"tokenised_train_batches\")\n",
    "val_batches   = tf.data.Dataset.load(\"tokenised_val_batches\")\n",
    "\n",
    "with tf.device(\"CPU\") :\n",
    "    transformer.fit(\n",
    "        train_batches.take(10), \n",
    "        epochs=1, \n",
    "        validation_data=val_batches.take(10))\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9ba62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb28f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
